{"pages":[{"title":"","date":"2020-12-08T10:25:34.884Z","path":"boostnote.json","text":"{\"folders\":[],\"version\":\"1.0\"}"},{"title":"Tags","date":"2020-12-08T10:25:34.885Z","path":"tags/index.html","text":""},{"title":"About","date":"2018-04-04T11:30:14.000Z","path":"about/index.html","text":"HereI’m a software engineer who emphasizes on good design and code quality. Here is my development Wiki: www.jifu.io"},{"title":"Categories","date":"2020-12-08T10:25:34.885Z","path":"categories/index.html","text":""}],"posts":[{"title":"一个惊人快速的终端录像工具，也能录制 VSCode 和 Chrome 窗口","date":"2021-03-28T00:02:47.000Z","path":"posts/4263562837/","text":"【导语】：t-rec 是一款惊人的快速终端记录器，可以生成 gif 图像。 简介t-rec 是使用 Rust 实现的一款快速终端记录器，结果可生成动图或视频，有以下特点： 以每秒 4 帧的速度录制终端 生成高质量的小尺寸动画 gif 图像或 mp4 视频 内置空闲帧检测和优化 (用于超级流体演示) 应用 (可以禁用) 边框装饰效果，如投影 在 MacOS 和 Linux 上运行 使用本地高效的 api 在没有任何云服务的情况下运行，完全脱机 支持终端尺寸大于 80x24 字体和颜色均可正常显示 支持基于 curses 的程序 支持转义序列 没有记录和重放 - 只是一个简单的命令来管理 隐藏功能: 记录任意窗口 项目地址github 下载安装t-rec 仅支持在 MacOS 和 Linux 安装使用，方法如下： 在 MacOS 下安装使用 使用 homebrew 安装： brew install t-rec 使用 cargo 安装： #先安装依赖imagemagick brew install imagemagick cargo install -f t-rec 在 Linux 下安装使用 下载 deb 安装包安装： sudo apt-get install imagemagick wget https://github.com/sassman/t-rec-rs/releases/download/v0.5.0/t-rec_0.5.0_amd64.deb sudo dpkg -i t-rec_0.5.0_amd64.deb 使用 snap 安装： sudo snap install t-rec --classic /snap/bin/t-rec --version t-rec 0.4.3 从 AUR 下载 paru -S t-rec 使用 cargo 安装： # 先安装依赖imagemagick sudo apt-get install libx11-dev imagemagick cargo install -f t-rec ubuntu 20.10 GNOME 下使用效果： ubuntu 20.10 i3wm 下使用效果： linux mint 20 cinnamon 下使用效果： ArcoLinux 5.4 Xfwm4 下使用效果： 使用命令详解t-rec [FLAGS] [OPTIONS] [shell or program to launch] FLAGS: -h, --help 打印帮助信息 -l, --ls-win 显示窗口ID，设置环境变量'WINDOWID'去录制指定的窗口 -n, --natural 自然的打字体验并禁用空闲检测和采样优化 -q, --quiet 静音模式，不提示:“Press Ctrl+D to end recording” -V, --version 显示版本信息 -v, --verbose 详细信息 OPTIONS: -b, --bg &lt;bg> 背景颜色[默认: transparent]，[可选: white, black,transparent] -d, --decor &lt;decor> 装饰效果 [默认: shadow] [可选: shadow, none] -m, --video &lt;video> 对gif生成一个mp4视频[默认: mp4] [可选: mp4] ARGS: &lt;shell or program to launch> 启动指定的程序，例如 '/bin/sh' 录制指定的窗口 通过环境变量 TERM_PROGRAM 指定录制 Google Chrome 窗口 TERM_PROGRAM=\"google chrome\" t-rec Frame cache dir: \"/var/folders/m8/084p1v0x4770rpwpkrgl5b6h0000gn/T/trec-74728.rUxBx3ohGiQ2\" Recording window: \"Google Chrome 2\" Press Ctrl+D to end recording 通过环境变量 WINDOWID 指定录制 VSCode 窗口 t-rec --ls-win | grep -i code Code | 27600 # set the WINDOWID variable and run t-rec WINDOWID=27600 t-rec Frame cache dir: \"/var/folders/m8/084p1v0x4770rpwpkrgl5b6h0000gn/T/trec-77862.BMYiHNRWqv9Y\" Press Ctrl+D to end recording","tags":[{"name":"Chrome","slug":"Chrome","permalink":"http://www.jifu.io/tags/Chrome/"},{"name":"VSCode","slug":"VSCode","permalink":"http://www.jifu.io/tags/VSCode/"},{"name":"终端","slug":"终端","permalink":"http://www.jifu.io/tags/终端/"},{"name":"录像","slug":"录像","permalink":"http://www.jifu.io/tags/录像/"}],"categories":[{"name":"OPS","slug":"OPS","permalink":"http://www.jifu.io/categories/OPS/"},{"name":"MacOS","slug":"OPS/MacOS","permalink":"http://www.jifu.io/categories/OPS/MacOS/"}]},{"title":"我用 Python 的 Seaborn 库，绘制了 17 个超好看图表!","date":"2021-03-08T22:18:11.000Z","path":"posts/3634498847/","text":"Seaborn简介定义Seaborn是一个基于matplotlib且数据结构与pandas统一的统计图制作库。Seaborn框架旨在以数据可视化为中心来挖掘与理解数据。 优点 代码较少 图形美观 功能齐全 主流模块安装 pip命令安装`pip install matplotlib pip install seaborn` 从github安装`pip install git+https://github.com/mwaskom/seaborn.git` 流程导入绘图模块 `mport matplotlib.pyplot as plt import seaborn as sns` 提供显示条件`%matplotlib inline #在Jupyter中正常显示图形` 导入数据`#Seaborn内置数据集导入 dataset = sns.load_dataset('dataset') #外置数据集导入（以csv格式为例） dataset = pd.read_csv('dataset.csv')` 设置画布`#设置一块大小为(12,6)的画布 plt.figure(figsize=(12, 6))` 输出图形`#整体图形背景样式，共5种:\"white\", \"dark\", \"whitegrid\", \"darkgrid\", \"ticks\" sns.set_style('white') #以条形图为例输出图形 sns.barplot(x=x,y=y,data=dataset,...) ''' barplot()括号里的是需要设置的具体参数， 涉及到数据、颜色、坐标轴、以及具体图形的一些控制变量， 基本的一些参数包括'x'、'y'、'data'，分别表示x轴，y轴， 以及选择的数据集。 '''` 保存图形`#将画布保存为png、jpg、svg等格式图片 plt.savefig('jg.png')` 实战`#数据准备 df = pd.read_csv('./cook.csv') #读取数据集(「菜J学Python」公众号后台回复cook获取) df['难度'] = df['用料数'].apply(lambda x:'简单' if x&lt;5 else('一般' if x&lt;15 else '较难')) #增加难度字段 df = df[['菜谱','用料','用料数','难度','菜系','评分','用户']] #选择需要的列 df.sample(5) #查看数据集的随机5行数据` `#导入相关包 import numpy as np import pandas as pd import matplotlib.pyplot as plt import matplotlib as mpl import seaborn as sns %matplotlib inline plt.rcParams['font.sans-serif'] = ['SimHei'] # 设置加载的字体名 plt.rcParams['axes.unicode_minus'] = False # 解决保存图像是负号'-'显示为方块的问题 sns.set_style('white') #设置图形背景样式为white` 直方图`#语法 ''' seaborn.distplot(a, bins=None, hist=True, kde=True, rug=False, fit=None, hist_kws=None, kde_kws=None, rug_kws=None, fit_kws=None, color=None, vertical=False, norm_hist=False, axlabel=None, label=None, ax=None) ''' #distplot()输出直方图，默认拟合出密度曲线 plt.figure(figsize=(10, 6)) #设置画布大小 rate = df['评分'] sns.distplot(rate,color=\"salmon\",bins=20) #参数color样式为salmon，bins参数设定数据片段的数量` `#kde参数设为False,可去掉拟合的密度曲线 plt.figure(figsize=(10, 6)) sns.distplot(rate,kde=False,color=\"salmon\",bins=20)` `#设置rug参数，可添加观测数值的边际毛毯 fig,axes=plt.subplots(1,2,figsize=(10,6)) #为方便对比，创建一个1行2列的画布,figsize设置画布大小 sns.distplot(rate,color=\"salmon\",bins=10,ax=axes[0]) #axes[0]表示第一张图(左图) sns.distplot(rate,color=\"green\",bins=10,rug=True,ax=axes[1]) #axes[1]表示第一张图(右图)` `#多个参数可通过字典传递 fig,axes=plt.subplots(1,2,figsize=(10,6)) sns.distplot(rate,color=\"salmon\",bins=20,rug=True,ax=axes[0]) sns.distplot(rate,rug=True, hist_kws={'color':'g','label':'直方图'}, kde_kws={'color':'b','label':'密度曲线'}, bins=20, ax=axes[1])` 散点图常规散点图:scatterplot`#语法 ''' seaborn.scatterplot(x=None, y=None, hue=None, style=None, size=None, data=None, palette=None, hue_order=None, hue_norm=None, sizes=None, size_order=None, size_norm=None, markers=True, style_order=None, x_bins=None, y_bins=None, units=None, estimator=None, ci=95, n_boot=1000, alpha='auto', x_jitter=None, y_jitter=None, legend='brief', ax=None, **kwargs) ''' fig,axes=plt.subplots(1,2,figsize=(10,6)) #hue参数，对数据进行细分 sns.scatterplot(x=\"用料数\", y=\"评分\",hue=\"难度\",data=df,ax=axes[0]) #style参数通过不同的颜色和标记显示分组变量 sns.scatterplot(x=\"用料数\", y=\"评分\",hue=\"难度\",style='难度',data=df,ax=axes[1])` 分簇散点图:stripplot`#语法 ''' seaborn.stripplot(x=None, y=None, hue=None, data=None, order=None, hue_order=None, jitter=True, dodge=False, orient=None, color=None, palette=None, size=5, edgecolor='gray', linewidth=0, ax=None, **kwargs) ''' #设置jitter参数控制抖动的大小 plt.figure(figsize=(10, 6)) sns.stripplot(x=\"菜系\", y=\"评分\",hue=\"难度\",jitter=1,data=df)` 分类散点图:swarmplot`#绘制分类散点图(带分布属性) #语法 ''' seaborn.swarmplot(x=None, y=None, hue=None, data=None, order=None, hue_order=None, dodge=False, orient=None, color=None, palette=None, size=5, edgecolor='gray', linewidth=0, ax=None, **kwargs) ''' plt.figure(figsize=(10, 6)) sns.swarmplot(x=\"菜系\", y=\"评分\",hue=\"难度\",data=df)` 条形图常规条形图:barplot`#语法 ''' seaborn.barplot(x=None, y=None, hue=None, data=None, order=None, hue_order=None,ci=95, n_boot=1000, units=None, orient=None, color=None, palette=None, saturation=0.75, errcolor='.26', errwidth=None, capsize=None, ax=None, estimator=&lt;function mean>，**kwargs) ''' #barplot()默认展示的是某种变量分布的平均值（可通过修改estimator参数为max、min、median等） # from numpy import median fig,axes=plt.subplots(1,2,figsize=(10,6)) sns.barplot(x='菜系',y='评分',color=\"r\",data=df,ax=axes[0]) sns.barplot(x='菜系',y='评分',color=\"salmon\",data=df,estimator=min,ax=axes[1])` `fig,axes=plt.subplots(1,2,figsize=(10,6)) #设置hue参数，对x轴的数据进行细分 sns.barplot(x='菜系',y='评分',color=\"salmon\",hue='难度',data=df,ax=axes[0]) #调换x和y的顺序，可将纵向条形图转为水平条形图 sns.barplot(x='评分',y='菜系',color=\"salmon\",hue='难度',data=df,ax=axes[1])` 计数条形图:countplot` #语法 '''seaborn.countplot(x=None, y=None, hue=None, data=None, order=None,hue_order=None, orient=None, color=None, palette=None, saturation=0.75, dodge=True, ax=None, **kwargs)'''fig,axes=plt.subplots(1,2,figsize=(10,6)) #选定某个字段，countplot()会自动统计该字段下各类别的数目sns.countplot(x='菜系',color=\"salmon\",data=df,ax=axes[0]) #同样可以加入hue参数sns.countplot(x='菜系',color=\"salmon\",hue='难度',data=df,ax=axes[1]) ` 折线图`#语法 ''' seaborn.lineplot(x=None, y=None, hue=None, size=None, style=None, data=None, palette=None, hue_order=None, hue_norm=None, sizes=None, size_order=None, size_norm=None, dashes=True, markers=None, style_order=None, units=None, estimator='mean', ci=95, n_boot=1000, sort=True, err_style='band', err_kws=None, legend='brief', ax=None, **kwargs) ''' fig,axes=plt.subplots(1,2,figsize=(10,6)) #默认折线图有聚合 sns.lineplot(x=\"用料数\", y=\"评分\", hue=\"菜系\",data=df,ax=axes[0]) #estimator参数设置为None可取消聚合 sns.lineplot(x=\"用料数\", y=\"评分\", hue=\"菜系\",estimator=None,data=df,ax=axes[1])` 箱图箱线图:boxplot`#语法 ''' seaborn.boxplot(x=None, y=None, hue=None, data=None, order=None, hue_order=None, orient=None, color=None, palette=None, saturation=0.75, width=0.8, dodge=True, fliersize=5, linewidth=None, whis=1.5, notch=False, ax=None, **kwargs) ''' fig,axes=plt.subplots(1,2,figsize=(10,6)) sns.boxplot(x='菜系',y='评分',hue='难度',data=df,ax=axes[0]) #调节order和hue_order参数，可以控制x轴展示的顺序,linewidth调节线宽 sns.boxplot(x='菜系',y='评分',hue='难度',data=df,color=\"salmon\",linewidth=1, order=['清真菜','粤菜','东北菜','鲁菜','浙菜','湖北菜','川菜'], hue_order=['简单','一般','较难'],ax=axes[1])` 箱型图:boxenplot`#语法 ''' seaborn.boxenplot(x=None, y=None, hue=None, data=None, order=None, hue_order=None, orient=None, color=None, palette=None, saturation=0.75, width=0.8, dodge=True, k_depth='proportion', linewidth=None, scale='exponential', outlier_prop=None, ax=None, **kwargs) ''' fig,axes=plt.subplots(1,2,figsize=(10,6)) sns.boxenplot(x='菜系',y='评分',hue='难度',data=df,color=\"salmon\",ax=axes[0]) #palette参数可设置调色板 sns.boxenplot(x='菜系',y='评分',hue='难度',data=df, palette=\"Set2\",ax=axes[1])` 小提琴图`#语法 ''' seaborn.violinplot(x=None, y=None, hue=None, data=None, order=None, hue_order=None, bw='scott', cut=2, scale='area', scale_hue=True, gridsize=100, width=0.8, inner='box', split=False, dodge=True, orient=None, linewidth=None, color=None, palette=None, saturation=0.75, ax=None, **kwargs) ''' fig,axes=plt.subplots(1,2,figsize=(10,6)) sns.violinplot(x='菜系',y='评分',data=df, color=\"salmon\",linewidth=1,ax=axes[0]) #inner参数可在小提琴内部添加图形,palette设置颜色渐变 sns.violinplot(x='菜系',y='评分',data=df,palette=sns.color_palette('Greens'),inner='stick',ax=axes[1])` 回归图regplot`''' seaborn.regplot(x, y, data=None, x_estimator=None, x_bins=None, x_ci='ci', scatter=True, fit_reg=True, ci=95, n_boot=1000, units=None, order=1, logistic=False, lowess=False, robust=False, logx=False, x_partial=None, y_partial=None, truncate=False, dropna=True, x_jitter=None, y_jitter=None, label=None, color=None, marker='o', scatter_kws=None, line_kws=None, ax=None) ''' fig,axes=plt.subplots(1,2,figsize=(10,6)) #marker参数可设置数据点的形状 sns.regplot(x='用料数',y='评分',data=df,color='r',marker='+',ax=axes[0]) #ci参数设置为None可去除直线附近阴影(置信区间) sns.regplot(x='用料数',y='评分',data=df,ci=None,color='g',marker='*',ax=axes[1])` lmplot`#语法 ''' seaborn.lmplot(x, y, data, hue=None, col=None, row=None, palette=None, col_wrap=None, height=5, aspect=1, markers='o', sharex=True, sharey=True, hue_order=None, col_order=None, row_order=None, legend=True, legend_out=True, x_estimator=None, x_bins=None, x_ci='ci', scatter=True, fit_reg=True, ci=95, n_boot=1000, units=None, order=1, logistic=False, lowess=False, robust=False, logx=False, x_partial=None, y_partial=None, truncate=False, x_jitter=None, y_jitter=None, scatter_kws=None, line_kws=None, size=None) ''' #lmplot()可以设置hue,进行多个类别的显示,而regplot()是不支持的 sns.lmplot(x='用料数',y='评分',hue='难度',data=df, palette=sns.color_palette('Reds'),ci=None,markers=['*','o','+'])` 热力图`#语法 ''' seaborn.heatmap(data, vmin=None, vmax=None, cmap=None, center=None, robust=False, annot=None, fmt='.2g', annot_kws=None, linewidths=0, linecolor='white', cbar=True, cbar_kws=None, cbar_ax=None, square=False, xticklabels='auto', yticklabels='auto', mask=None, ax=None, **kwargs) ''' fig,axes=plt.subplots(1,2,figsize=(10,6)) h=pd.pivot_table(df,index=['菜系'],columns=['难度'],values=['评分'],aggfunc=np.mean) sns.heatmap(h,ax=axes[0]) #annot参数设置为True可显示数字,cmap参数可设置热力图调色板 cmap = sns.diverging_palette(200,20,sep=20,as_cmap=True) sns.heatmap(h,annot=True,cmap=cmap,ax=axes[1]) #保存图形 plt.savefig('jg.png')`","tags":[{"name":"Python","slug":"Python","permalink":"http://www.jifu.io/tags/Python/"},{"name":"Seaborn","slug":"Seaborn","permalink":"http://www.jifu.io/tags/Seaborn/"},{"name":"图表","slug":"图表","permalink":"http://www.jifu.io/tags/图表/"}],"categories":[{"name":"back-end","slug":"back-end","permalink":"http://www.jifu.io/categories/back-end/"},{"name":"Python","slug":"back-end/Python","permalink":"http://www.jifu.io/categories/back-end/Python/"},{"name":"Library","slug":"back-end/Python/Library","permalink":"http://www.jifu.io/categories/back-end/Python/Library/"}]},{"title":"工作两三年了，整不明白架构图都画啥？","date":"2021-03-03T08:09:53.000Z","path":"posts/2097636152/","text":"1. 前言很多程序员画架构图头疼，不知道画什么、怎么画！ 分享、评审、述职、答辩，只要你在程序员这个行业，就几乎离不开要画图。 一提到画图很多人就想站会起来喊，”内卷“、”内卷啦“、”PPT工程师“，但程序代码本身就是一种数学逻辑的具体实现，如果没有一些图表配合文字的阐述，讲真很难让所有人都能在共同的共识下进行交流。 这不像是文科，”八表流云澄夜色，九霄华月动春城“ 上来就能联想到它是在描述啥。但是偏理科代码逻辑或架构设计，只能把抽象的内容用图表的形式展现出来，让大家在同一的共识下共同协同工作。 而我们画的架构图、流程图、结构图、功能图、逻辑图等，都需要好看、好懂、好用、好搞，因为： 好看是为了提升沟通效率， 好懂是为了提升交流共识， 好用是为了提升交付质量， 好搞是为了提升实施速度。 这就像君子在追求漂亮姑娘一样，好看就想主动撩一下、有品行和共同的三观很快让你开口说我懂你、接下来就是交付质量和实施速度了，那也是水到渠成的事。 好，别激动，接下来我们就开始专心研究研究架构图，都有哪些，该怎么画，有什么手法。 2. 架构图有哪几种？仅说技术架构图的话，通常我们☞指的是选型各项技术组件来支撑整个服务建设的系统架构。但用于不同人群范围和不同场景下会有其他分类，如图 26-1 架构图分类 业务架构：需求初期业务的结果和过程描述一般比较模糊，可能来自于某个老板、运营或用户的反馈。客户说海尔洗衣机洗土豆会堵，海尔立马设计专门的土豆洗衣机 业务方向往往是定方向和结果的叫战略，主要包括业务规划、业务模块和流程以及问题域的列表等。 应用架构：服务复用、跨组协同，简单、灵活、整合是应用架构必须考虑的点，就像你要上线一个聊天功能，那么聊天内容的输入法、文字识别、舆情监控以及视频服务、支付服务等，它们都是在应用架构分层下沉淀到平台的产物，在供各个方使用。 产品架构：业务提需求，产品定方案，相对于业务的粗放流程，产品架构会更加细腻以及考虑各个模块的分层和边界。 数据架构：数据的获取、数据的存放和数据的使用是数据架构要解决的三个问题，数据库存放、大数据汇总、数据分析等。 技术架构：是离程序员最近的架构设计，它不仅是系统搭建的架构图设计，还包括了结构、功能、流程、逻辑等内容。它的具体描述就是整个系统如何落地的具体实现方案。 3. Zachman框架是什么？ Zachman框架，由约翰 扎科曼（John Zachman ）在1987年创立的全球第一个企业架构理论，其论文《信息系统架构框架》至今仍被业界认为是企业架构设计方面最权威的理论。 Zachman框架（Zachman framework）是一种逻辑结构，它可以对企业信息按照不同分类和不同角度进行表示。 Zachman框架，从横向六个角度看待企业，这个六个观点可以分为；什么内容、如何工作、什么地点、谁负责、为什么这么做（称为W5H）。 框架的列由一组工件组成，分为规划者、拥有者、设计者（架构师）、建造者、分包者、产品，或者有时表示为视点：范围上下文，业务概念，系统逻辑，技术，物理，组件组装和操作类。整体如图 26-2 TOGAF Zachman框架 表格横向六项 代表了用于描述信息系统的某一个方面，对于任何一个事物只要在这几个基本方面对其进行清洗的解释就足够可以描述清楚。 数据（What，即什么内容）：什么是业务数据，信息或对象？ 功能（How，即如何工作）：业务如何运作，即什么是业务流程？ 网络（Where，即何处）：企业运营、部署在哪里？ 人（Who，即何人负责）：什么人？什么是业务部门及其等级制度？ 时间（When，即什么时间）：业务计划和工作流程是什么？什么时候执行？ 原因（Why，即为什么做）：为什么选择的解决方案？这是怎么产生的？ 表格纵向六项 代表了在信息系统构造过程中所涉及到的人在描述信息系统时所采用的视角，包括： 范围/规划者（Planner）：此视图描述了业务目的和策略，充当其他视图将被派生和管理的上下文。 业务模型/拥有者（Owner）：这是对信息系统必须在其中运作的组织的描述。 系统模型/设计师（Designer）：该视图概述了系统如何满足组织的信息需求。 技术模型/建造者（Builder）：这是系统如何实施的表示，它使特定的解决方案和技术显而易见。 详细表述/分包者（Sub-Contractor）：这些表示说明了某些系统元素的特定于实现的细节：在生产开始之前需要进一步说明的部分。 功能系统/产品（Functioning Enterprise）：在1987年的论文（《A framework for information systems architecture》）中并没有这一行的内容，实际上此行的内容也并不在架构描述的范畴的之内，不过为了使得架构Zachman框架对于架构的表述更加完备，这一行最终还是被加了进去。 根据 TOGAF 的定义，企业是具有一系列共同目标组织的集合，而架构则是为了有效地实现这一系列目标。 在实现的过程中 定义了企业的结构和运作模式的概念蓝图（SearchCIO），以及构成企业的所有关键元素和其关系的综合描述（Zachman）。通过创建、沟通和优化用以描述企业未来状态和发展的关键原则和模型以将业务愿景和战略转化成有效的企业变更的过程（Gartner）。 可以这一部分内容会比较绕，但可以作为架构设计的知识扩展进行学习理解以及运用。 4. 陪你画个架构图简单来说，架构图就是为了达成交流共识的实现方案演示，并不一定非得拘泥于某种形式，只要你能画的清楚，讲的明白就最合适不过了。 4.1. 架构选型图 难度：⭐⭐⭐ 作用：通常在新项目开发初期，都要做一些技术选型工作。在负载、网关、架构、治理、框架、服务、数据以及环境和支撑服务上，要选择适合当前开发的技术。 4.2. 微服务架构 难度：⭐⭐⭐⭐ 作用：技术选型完毕后，接下来就是对于这些技术的运用。这个过程有点像搭积木一样，把每一个区域用适合此位置的积木填充进去。如果是团队初建或者是技术升级，那么这个过程还是比较复杂的，需要大量的验证。不过其实互联网的技术分层和使用已经相对稳定，搭建一个这样的微服务并不会耗费太长的时间。 4.3. 技术架构图 难度：⭐⭐⭐⭐ 作用：技术架构图主要是对于研发层面做技术实现指导的，它可以把系统分层和实现结构划分清楚。另外一般也会把案例工程的结构拿出来一起讲解，这样可以让团队伙伴快速的进入开发。 5. 总结 本章节向大家讲解了什么是架构图，架构图的分类和怎么画架构图，通过这样的内容可以让大家对架构图有一个全貌的认知。在以后自己画架构图了也可以非常明确的知道面对的什么用户群体，要画的内容是什么。 TOGAF有一套非常完善的企业架构理论，它描述了一种开发和管理企业体系结构生命周期的方法，并构成了TOGAF的核心。所涉及到的知识非常丰富，值得认真看一下。 好看，能把一件事做的好看非常重要，好看能让人提起兴趣、好看可以使沟通成本降低。也鼓励大家尽可能把经过自己手里的东西，做的好看一些。","tags":[{"name":"架构","slug":"架构","permalink":"http://www.jifu.io/tags/架构/"}],"categories":[{"name":"Soft engineering","slug":"Soft-engineering","permalink":"http://www.jifu.io/categories/Soft-engineering/"},{"name":"Architecture","slug":"Soft-engineering/Architecture","permalink":"http://www.jifu.io/categories/Soft-engineering/Architecture/"}]},{"title":"RabbitMQ 集群高可用原理及实战部署介绍","date":"2021-02-28T01:06:06.000Z","path":"posts/2846671594/","text":"前言 在项目中想要 RabbitMQ 变得更加健壮，就要使得其变成高可用，今天我们一起来聊聊关于 RabbitMQ 集群原理和部署流程 1. 介绍在前几篇文章中，我们详细的介绍了 RabbitMQ 的内部结构和使用，以及 SpringBoot 和 RabbitMQ 整合，都是基于单台 RabbitMQ 进行使用的。 我们知道在微服务流行的当下，一旦单台服务器挂了，基本上就无法提供高可用的服务了，因此为了保证服务高可用，在生产环境上我们通常的做法是搭建一个 RabbitMQ 集群，即使某台 RabbitMQ 故障了，其他正常的 RabbitMQ 服务器依然可以使用，应用程序的持续运行不会受到影响。 2. 集群架构原理在前几篇文章中，我们有介绍到 RabbitMQ 内部有各种基础构件，包括队列、交换器、绑定、虚拟主机等，他们组成了 AMQP 协议消息通信的基础，而这些构件以元数据的形式存在，它始终记录在 RabbitMQ 内部，它们分别是： 队列元数据：队列名称和它们的属性 交换器元数据：交换器名称、类型和属性 绑定元数据：一张简单的表格展示了如何将消息路由到队列 vhost 元数据：为 vhost 内的队列、交换器和绑定提供命名空间和安全属性 这些元数据，其实本质是一张查询表，里面包括了交换器名称和一个队列的绑定列表，当你将消息发布到交换器中，实际上是将你所在的信道将消息上的路由键与交换器的绑定列表进行匹配，然后将消息路由出去。 消息路由表 有了这个机制，那么在所有节点上传递交换器消息将简单很多，而 RabbitMQ 所做的事情就是把交换器元数据拷贝到所有节点上，因此每个节点上的每条信道都可以访问完整的交换器。 如果消息生产者所连接的是节点 2 或者节点 3，此时队列1的完整数据不在该两个节点上，那么在发送消息过程中这两个节点主要起了一个路由转发作用，根据这两个节点上的元数据转发至节点1上，最终发送的消息还是会存储至节点1的队列1上。 同样，如果消息消费者所连接的节点2或者节点3，那这两个节点也会作为路由节点起到转发作用，将会从节点1的队列1中拉取消息进行消费。 与常见的集群主从架构模式不同的地方在于：RabbitMQ 集群模式下，仅仅只是同步元数据，每个队列内容还是在自己的服务器节点上。 这么设计主要还是基于集群本身的性能和存储空间上来考虑： 存储空间：真正存放数据的地方是在队列里面，如果每个集群节点都拥有所有队列的完全数据拷贝，那么每个节点的存储空间会非常大，集群的消息积压能力会非常弱。例如你现在存储了 3G 队列内容，那么在另外一个只有 1G 存储空间的节点上，就会造成内存空间不足的情况，也就是无法通过集群节点的扩容提高消息积压能力。 性能：消息的发布者需要将消息复制到每一个集群节点，每一条消息都会触发磁盘活动，这会导致整个集群内性能负载急剧拉升。 既然每个队列内容还是在自己的服务器节点上，同样也会带来新的问题，那就是如果队列所在服务器挂了，那存在服务器上的队列数据是不是全部都丢失了？ 在单个节点上，RabbitMQ 存储数据有两种方案： 内存模式：这种模式会将数据存储在内存当中，如果服务器突然宕机重启之后，那么附加在该节点上的队列和其关联的绑定都会丢失，并且消费者可以重新连接集群并重新创建队列； 磁盘模式：这种模式会将数据存储磁盘当中，如果服务器突然宕机重启，数据会自动恢复，该队列又可以进行传输数据了，并且在恢复故障磁盘节点之前，不能在其它节点上让消费者重新连到集群并重新创建队列，如果消费者继续在其它节点上声明该队列，会得到一个 404 NOT_FOUND 错误，这样确保了当故障节点恢复后加入集群，该节点上的队列消息不会丢失，也避免了队列会在一个节点以上出现冗余的问题。 在集群中的每个节点，要么是内存节点，要么是磁盘节点，如果是内存节点，会将所有的元数据信息仅存储到内存中，而磁盘节点则不仅会将所有元数据存储到内存上， 还会将其持久化到磁盘。 在单节点 RabbitMQ 上，仅允许该节点是磁盘节点，这样确保了节点发生故障或重启节点之后，所有关于系统的配置与元数据信息都会从磁盘上恢复。 而在 RabbitMQ 集群上，至少有一个磁盘节点，也就是在集群环境中需要添加 2 台及以上的磁盘节点，这样其中一台发生故障了，集群仍然可以保持运行。其它节点均设置为内存节点，这样会让队列和交换器声明之类的操作会更加快速，元数据同步也会更加高效。 3. 集群部署为了和生产环境保持一致，我们选用CentOS7操作系统进行环境部署，分别创建 3 台虚拟机。 # 3台服务器的IP 197.168.24.206 197.168.24.233 197.168.24.234 放开防火墙限制，保证 3 台服务器网络都可以互通！ 3.1、重新设置主机名由于 RabbitMQ 集群连接是通过主机名来连接服务的，必须保证各个主机名之间可以 ping 通，重新设置 3 台服务器主机名，所以需要做以下操作： # 修改节点1的主机名 hostname node1 # 修改节点2的主机名 hostname node2 # 修改节点3的主机名 hostname node3 编辑/etc/hosts文件，添加到在三台机器的/etc/hosts中以下内容： sudo vim /etc/hosts 添加内容如下： 197.168.24.206 node1 197.168.24.233 node2 197.168.24.234 node3 3.2、rabbitMQ安装RabbitMQ 基于 erlang 进行通信，相比其它的软件，安装有些麻烦，不过本例采用rpm方式安装，任何新手都可以完成安装，过程如下！ 3.2.1、安装前命令准备输入如下命令，完成安装前的环境准备。 yum install lsof build-essential openssl openssl-devel unixODBC unixODBC-devel make gcc gcc-c++ kernel-devel m4 ncurses-devel tk tc xz wget vim 3.2.2、下载 RabbitMQ、erlang、socat 的安装包本次下载的是RabbitMQ-3.6.5版本，采用rpm一键安装，适合新手直接上手。 先创建一个rabbitmq目录，本例的目录路径为/usr/app/rabbitmq，然后在目录下执行如下命令，下载安装包！ 下载erlang wget www.rabbitmq.com/releases/erlang/erlang-18.3-1.el7.centos.x86_64.rpm 下载socat wget http://repo.iotti.biz/CentOS/7/x86_64/socat-1.7.3.2-5.el7.lux.x86_64.rpm 下载rabbitMQ wget www.rabbitmq.com/releases/rabbitmq-server/v3.6.5/rabbitmq-server-3.6.5-1.noarch.rpm 最终目录文件如下： 3.2.3、安装软件包下载完之后，按顺序依次安装软件包，这个很重要哦～ 安装erlang rpm -ivh erlang-18.3-1.el7.centos.x86_64.rpm 安装socat rpm -ivh socat-1.7.3.2-5.el7.lux.x86_64.rpm 安装rabbitmq rpm -ivh rabbitmq-server-3.6.5-1.noarch.rpm 安装完成之后，修改rabbitmq的配置，默认配置文件在/usr/lib/rabbitmq/lib/rabbitmq_server-3.6.5/ebin目录下。 vim /usr/lib/rabbitmq/lib/rabbitmq_server-3.6.5/ebin/rabbit.app 修改loopback_users节点的值！ 分别重新命令rabbit节点名称 vim /etc/rabbitmq/rabbitmq-env.conf 在文件里添加一行，如下配置！ NODENAME=rabbit@node1 其它两个节点命令也类似，然后，再保存！通过如下命令，启动服务即可！ # 启动服务 rabbitmq-server start &amp; # 停止服务 rabbitmqctl stop 通过如下命令，查询服务是否启动成功！ lsof -i:5672 如果出现5672已经被监听，说明已经启动成功！ 3.2.4、启动可视化的管控台输入如下命令，启动控制台！ rabbitmq-plugins enable rabbitmq_management 用浏览器打开http://ip:15672，这里的ip就是 CentOS 系统的 ip，结果如下： 账号、密码，默认为guest，如果出现无法访问，检测防火墙是否开启，如果开启将其关闭即可！ 登录之后的监控平台，界面如下： 3.3、复制 Erlang cookieRabbitMQ 集群环境下，元数据同步基于 cookie 共享方案实现。 在这里将 node1 的 cookie 文件复制到 node2，由于这个文件权限是 400 为方便传输，先修改权限，非必须操作，所以需要先修改 node1 中的该文件权限为 777 chmod 777 /var/lib/rabbitmq/.erlang.cookie 用 scp 拷贝到节点 2，节点 3 的操作也类似。 scp /var/lib/rabbitmq/.erlang.cookie node2:/var/lib/rabbitmq/ 最后，将权限改回来 chmod 400 /var/lib/rabbitmq/.erlang.cookie 3.4、组成集群在节点 2 执行如下命令： # 停止rabbitmq服务 rabbitmqctl stop_app # 清空节点状态 rabbitmqctl reset # node2和node1构成集群,node2必须能通过node1的主机名ping通 rabbitmqctl join_cluster rabbit@node1 # 开启rabbitmq服务 rabbitmqctl start_app 节点 3 的操作也类似！ 在任意一台机上面查看集群状态： rabbitmqctl cluster_status 第一行：表示当前节点信息 第二行：表示集群中的节点成员，disc 表示这些都是磁盘节点 第三行：表示正在运行的节点成员 登录可视化管控台，可以很清晰的看到，三个服务节点已经互相关联起来了！ 如果你想将某个节点移除集群，以移除节点3为例，可以按照如下方式进行操作！ # 首先停止要移除的节点服务 rabbitmqctl stop # 移除节点3 rabbitmqctl -n rabbit@node1 forget_cluster_node rabbit@node3 如果移除之后，无法启动 rabbitMQ，删除已有 mnesia 信息！ rm -rf /var/lib/rabbitmq/mnesia 然后再次重启服务即可！ 3.5、设置内存节点#加入时候设置节点为内存节点（默认加入的为磁盘节点） rabbitmqctl join_cluster rabbit@node1 --ram 其中--ram指的是作为内存节点，如果不加，那就默认为磁盘节点。 如果节点在集群中已经是磁盘节点了，通过以下命令可以将节点改成内存节点： # 停止rabbitmq服务 rabbitmqctl stop_app # 更改节点为内存节点 rabbitmqctl change_cluster_node_type ram # 开启rabbitmq服务 rabbitmqctl start_app 3.6、镜像队列上面我们提到，在默认情况下，队列只会保存在其中一个节点上，当节点发生故障时，尽管所有元数据信息都可以从磁盘节点上将元数据恢复到本节点上，但是内存节点的队列消息内容就不行了，这样就会导致消息的丢失。 RabbitMQ 很早就意识到这个问题，在 2.6 以后的版本中增加了队列冗余选项：镜像队列。 所谓镜像队列，其实就是主队列（master）依然是仅存在于一个节点上，通过关联的 rabbitMQ 服务器，从主队列同步消息到各个节点，也就是所谓的主从模式，将主队列的消息进行备份处理。 如果主队列没有发生故障，那么其工作流程跟普通队列一样，生产者和消费者不会感知其变化，当发布消息时，依然是路由到主队列中，而主队列通过类似广播的机制，将消息扩散同步至其余从队列中，这就有点像 fanout 交换器一样。而消费者依然是从主队列中读取消息。 一旦主队列发生故障，集群就会从最老的一个从队列选举为新的主队列，这也就实现了队列的高可用了，但我们切记不要滥用这个机制，在上面也说了，队列的冗余操作会导致不能通过扩展节点增加存储空间，而且会造成性能瓶颈。 命令格式如下： rabbitmqctl set_policy [-p Vhost] Name Pattern Definition [Priority] 参数介绍： -p Vhost: 可选参数，针对指定vhost下的queue进行设置 Name: policy的名称 Pattern: queue的匹配模式(正则表达式) Definition: 镜像定义，包括三个部分ha-mode, ha-params, ha-sync-mode ha-mode: 指明镜像队列的模式，有效值为 all/exactly/nodes all: 表示在集群中所有的节点上进行镜像 exactly: 表示在指定个数的节点上进行镜像，节点的个数由ha-params指定 nodes: 表示在指定的节点上进行镜像，节点名称通过ha-params指定 ha-params: ha-mode模式需要用到的参数 ha-sync-mode: 进行队列中消息的同步方式，有效值为automatic和manual priority: 可选参数，policy的优先级 举个例子，声明名为ha-all的策略，它与名称以ha开头的队列相匹配，并将镜像配置到集群中的所有节点： rabbitmqctl set_policy ha-all \"^\" '{\"ha-mode\":\"all\"}' 类似操作很多，具体使用可以参考官方 api。 4. 集群的负载均衡HAProxy 提供高可用性、负载均衡以及基于TCP和HTTP应用的代理，支持虚拟主机，它是免费、快速并且可靠的一种解决方案。根据官方数据，其最高极限支持10G的并发。HAProxy支持从4层至7层的网络交换，即覆盖所有的 TCP 协议。就是说，Haproxy 甚至还支持 Mysql 的均衡负载。为了实现 RabbitMQ 集群的软负载均衡，这里可以选择HAProxy。 4.1、HAProxy 安装HAProxy 的安装也很简单，单独部署在一台服务器上，通过如下命令即可安装完成！ yum install haproxy 编辑 HAProxy 配置文件： vim /etc/haproxy/haproxy.cfg 我们只需要在文件末尾加上如下配置即可！ #绑定配置 listen rabbitmq_cluster bind 0.0.0.0:5672 #配置TCP模式 mode tcp #加权轮询 balance roundrobin #RabbitMQ集群节点配置 server rmq_node1 197.168.24.206:5672 check inter 5000 rise 2 fall 3 weight 1 server rmq_node2 197.168.24.233:5672 check inter 5000 rise 2 fall 3 weight 1 server rmq_node3 197.168.24.234:5672 check inter 5000 rise 2 fall 3 weight 1 #haproxy监控页面地址 listen monitor bind 0.0.0.0:8100 mode http option httplog stats enable stats uri /stats stats refresh 5s 绑定配置参数说明： bind：这里定义了客户端连接连接 IP 地址和端口号，用于客户端连接 balance roundrobin：表示加权轮询负载均衡算法 RabbitMQ 集群节点配置说明： server rmq_node1：定义HAProxy内RabbitMQ服务的标识 197.168.24.206:5672：标识了后端RabbitMQ的服务地址 check inter 5000：表示每隔多少毫秒检查RabbitMQ服务是否可用，示例参数值为 5000 rise 2：表示 RabbitMQ 服务在发生故障之后，需要多少次健康检查才能被再次确认可用，示例参数值为 2 fall 2：表示需要经历多少次失败的健康检查之后，HAProxy 才会停止使用此RabbitMQ服务，示例参数值为 2 weight 1：表示权重比例，值越低，会优先进行数据分配，示例参数值为 1 启动 HAProxy： /usr/sbin/haproxy -f /etc/haproxy/haproxy.cfg 登录http://ip:8100/statsweb 管理界面，即可进行监控查看！ 5. Java 客户端使用如果是配置了 HAProxy 代理服务器，可以直接使用 HAProxy 代理服务器地址即可！ //ConnectionFactory创建MQ的物理连接 connectionFactory = new ConnectionFactory(); connectionFactory.setHost(\"197.168.24.207\"); //代理服务器地址 connectionFactory.setPort(5672); //代理服务器端口 connectionFactory.setUsername(\"admin\"); //guest只能在本机进行访问,通过代理服务器发送消息时需要重新建立用户 connectionFactory.setPassword(\"admin\"); //guest connectionFactory.setVirtualHost(\"/\"); //虚拟主机 如果没有代理服务器，使用Spring的CachingConnectionFactory类进行配置。 以SpringBoot项目为例，配置文件如下： spring.rabbitmq.addresses=197.168.24.206:5672,197.168.24.233:5672,197.168.24.234:5672 spring.rabbitmq.username=guest spring.rabbitmq.password=guest spring.rabbitmq.virtual-host=/ RabbitConfig配置类如下： @Configuration public class RabbitConfig { /** * 初始化连接工厂 * @param addresses * @param userName * @param password * @param vhost * @return */ @Bean ConnectionFactory connectionFactory(@Value(\"${spring.rabbitmq.addresses}\") String addresses, @Value(\"${spring.rabbitmq.username}\") String userName, @Value(\"${spring.rabbitmq.password}\") String password, @Value(\"${spring.rabbitmq.virtual-host}\") String vhost) { CachingConnectionFactory connectionFactory = new CachingConnectionFactory(); connectionFactory.setAddresses(addresses); connectionFactory.setUsername(userName); connectionFactory.setPassword(password); connectionFactory.setVirtualHost(vhost); return connectionFactory; } /** * 重新实例化 RabbitAdmin 操作类 * @param connectionFactory * @return */ @Bean public RabbitAdmin rabbitAdmin(ConnectionFactory connectionFactory){ return new RabbitAdmin(connectionFactory); } /** * 重新实例化 RabbitTemplate 操作类 * @param connectionFactory * @return */ @Bean public RabbitTemplate rabbitTemplate(ConnectionFactory connectionFactory){ RabbitTemplate rabbitTemplate=new RabbitTemplate(connectionFactory); //数据转换为json存入消息队列 rabbitTemplate.setMessageConverter(new Jackson2JsonMessageConverter()); return rabbitTemplate; } } 6. 总结本文主要详细介绍了 RabbitMQ 集群的工作原理和如何搭建一个具备负载均衡能力的 RabbitMQ 集群的方法。 限于笔者的才疏学浅，对本文内容可能还有理解不到位的地方，如有阐述不合理之处还望留言一起探讨。","tags":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://www.jifu.io/tags/RabbitMQ/"},{"name":"集群","slug":"集群","permalink":"http://www.jifu.io/tags/集群/"},{"name":"高可用性","slug":"高可用性","permalink":"http://www.jifu.io/tags/高可用性/"}],"categories":[{"name":"back-end","slug":"back-end","permalink":"http://www.jifu.io/categories/back-end/"},{"name":"Middle-ware","slug":"back-end/Middle-ware","permalink":"http://www.jifu.io/categories/back-end/Middle-ware/"},{"name":"RabbitMQ","slug":"back-end/Middle-ware/RabbitMQ","permalink":"http://www.jifu.io/categories/back-end/Middle-ware/RabbitMQ/"}]},{"title":"Swift：解包的正确姿势","date":"2021-02-26T03:32:25.000Z","path":"posts/3772598043/","text":"嗯，先来一段感慨对于Swift学习而言，可选类型Optional是永远绕不过的坎，特别是从OC刚刚转Swift的时候，可能就会被代码行间的?与!，有的时候甚至是??搞得稀里糊涂的。 这篇文章会给各位带来我对于可选类型的一些认识以及如何进行解包，其中会涉及到Swift中if let以及guard let的使用以及思考，还有涉及OC部分的nullable和nonnull两个关键字，以及一点点对两种语言的思考。 var num: Int? 它是什么类型?在进行解包前，我们先来理解一个概念，这样可能更有利于对于解包。 首先我们来看看这样一段代码: `var num: Int? num = 10 if num is Optional&lt;Int> { print(\"它是Optional类型\") }else { print(\"它是Int类型\") }` 请先暂时不要把这段代码复制到Xcode中，先自问自答，num是什么类型，是Int类型吗? 好了，你可以将这段代码复制到Xcode里去了，然后在Xcode中的if上一定会出现这样一段话： ` 'is' test is always true ` num不是Int类，它是Optional类型。 那么Optional类型是啥呢–可选类型，具体Optional是啥，Optional类型的本质实际上就是一个带有泛型参数的enum类型，各位去源码中仔细看看就能了解到，这个类型和Swift中的Result类有异曲同工之妙。 var num: Int?这是一个人Optional的声明，意思不是“我声明了一个Optional的Int值”，而是“我声明了一个Optional类型，它可能包含一个Int值，也可能什么都不包含”，也就是说实际上我们声明的是Optional类型，而不是声明了一个Int类型！ 至于像Int!或者Int?这种写法，只是一种Optional类型的糖语法写法。 以此类推String?是什么类型，泛型T?是什么类型，答案各位心中已经明了吧。 正是因为num是一个可选类型。所以它才能赋值为nil， var num: Int = nil。这样是不可能赋值成功的。因为Int类型中没有nil这个概念！ 这就是Swift与OC一个很大区别，在OC中我们的对象都可以赋值为nil，而在Swift中，能赋值为nil只有Optional类型！ 解包的基本思路，使用if let或者guard let，而非强制解包我们先来看一个简单的需求，虽然这个需求在实际开发中意义不太大： 我们需要从网络请求获取到的一个人的身高(cm为单位)以除以100倍，以获取m为单位的结果然后将其结果进行返回。 设计思路： 由于实际网络请求中，后台可能会返回我们的身高为空(即nil)，所以在转模型的时候我们不能定义Float类型，而是定义Float?便于接受数据。 如果身高为nil，那么nil除以100是没有意义的，在编译器中Float?除以100会直接报错，那么其返回值也应该为nil，所以函数的返回值也是Float?类型 那么函数应该设计成为这个样子是这样的: `func getHeight(_ height: Float?) -> Float?` 如果一般解包的话，我们的函数实现大概会写成这样: `func getHeight(_ height: Float?) -> Float? { if height != nil { return height! / 100 } return nil }` 使用!进行强制解包，然后进行运算。 我想说的是使用强制解包固然没有错，不过如果在实际开发中这个height参数可能还要其他用途，那么是不是每使用一次都要进行强制解包？ 强制解包是一种很危险的行为，一旦解包失败,就有崩溃的可能，也许你会说这不是有if判断,然而实际开发中，情况往往比想的复杂的多。所以安全的解包行为应该是通过if let 或者guard let来进行。 `func getHeight(_ height: Float?) -> Float? { if let unwrapedHeight = height { return unwrapedHeight / 100 } return nil }` 或者： `func getHeight(_ height: Float?) -> Float? { guard let unwrapedHeight = height else { return nil } return unwrapedHeight / 100 }` 那么if let和guard let 你更倾向使用哪个呢？ 在本例子中，其实感觉二者的差别不大，不过我个人更倾向于使用guard let。 原因如下： 在使用if let的时候其大括号类中的情况才是正常情况，而外部主体是非正常情况的返回的nil； 而在使用guard let的时候，guard let else中的大括号是异常情况，而外部主体返回的是正常情况。 对于一个以返回结果为目的的函数，函数主体展示正常返回值，而将异常抛出在判断中，这样不仅逻辑更清晰，而且更加易于代码阅读。 解包深入有这么一个需求，从本地路径获取一个json文件，最终将其转为字典，准备进行转模型操作。 在这个过程中我们大概有这么几个步骤： 1. 获取本地路径`func path(forResource name: String?, ofType ext: String?) -> String? ` 2. 将本地路径读取转为Data`init(contentsOf url: URL, options: Data.ReadingOptions = default) throws ` 3. JSON序列化`class func jsonObject(with data: Data, options opt: JSONSerialization.ReadingOptions = []) throws -> Any ` 4. 是否可以转为字典类型我们可以看到以上几个函数中，获取路径获取返回的路径结果是一个可选类型而转Data的方法是抛出异常，JSON序列化也是抛出异常，至于最后一步的类型转换是使用as？[Sting: Any]这样的操作 这个函数我是这来进行设计与步骤分解的函数的返回类型为可选类型，因为下面的4步中都有可能失败进而返回nil。 虽然有人会说第一步获取本地路径，一定是本地有的才会进行读取操作，但是作为一个严谨操作，凡事和字符串打交道的书写都是有隐患的，所以我这里还是用了guard let进行守护。 这个函数看起来很不简洁，每一个guard let 后面都跟着一个异常返回，甚至不如使用if let看着简洁 但是这么写的好处是：在调试过程中你可以明确的知道自己哪一步出错 `func getDictFromLocal() -> [String: Any]? { /// 1 获取路径 guard let path = Bundle.main.path(forResource: \"test\", ofType:\"json\") else { return nil } /// 2 获取json文件里面的内容 guard let jsonData = try? Data.init(contentsOf: URL.init(fileURLWithPath: path)) else { return nil } /// 3 解析json内容 guard let json = try? JSONSerialization.jsonObject(with: jsonData, options:[]) else { return nil } /// 4 将Any转为Dict guard let dict = json as? [String: Any] else { return nil } return dict }` 当然,如果你要追求简洁,这么写也未尝不可,一波流带走 `func getDictFromLocal() -> [String: Any]? { guard let path = Bundle.main.path(forResource: \"test\", ofType:\"json\"), let jsonData = try? Data.init(contentsOf: URL.init(fileURLWithPath: path)), let json = try? JSONSerialization.jsonObject(with: jsonData, options:[]), let dict = json as? [String: Any] else { return nil } return dict }` guard let与if let不仅可以判断一个值的解包,而且可以进行连续操作 像下面这种写法，更加追求的是结果，对于一般的调试与学习，多几个guard let进行拆分，未尝不是好事。 至于哪种用法更适合，因人而异。 可选链的解包至于可选链的解包是完全可以一步到位，假设我们有以下这个模型。 `class Person { var phone: Phone? } class Phone { var number: String? }` Person类中有一个手机对象属性，手机类中有个手机号属性，现在我们有位小明同学，我们想知道他的手机号。 小明他不一定有手机，可能有手机而手机并没有上手机号码。 `let xiaoming = Person() guard let number = xiaoming.phone?.number else { return } print(number)` 这里只是抛砖引玉，更长的可选链也可以一步到位，而不必一层层进行判断，因为可选链中一旦有某个链为nil，那么就会返回nil。 nullable和nonnull我们先来看这两个函数,PHImageManager在OC与Swift中通过PHAsset实例获取图片的例子 `[[PHImageManager defaultManager] requestImageForAsset:asset targetSize:size contentMode:PHImageContentModeDefault options:options resultHandler:^(UIImage * _Nullable result, NSDictionary * _Nullable info) { //、 非空才进行操作 注意_Nullable,Swift中即为nil,注意判断 if (result) { } }];` ` PHImageManager.default().requestImage(for: asset, targetSize: size, contentMode: .default, options: options, resultHandler: { (result: UIImage?, info: [AnyHashable : Any]?) in guard let image = result else { return } }) ` 在Swift中闭包返回的是两个可选类型，result: UIImage?与info: [AnyHashable : Any]? 而在OC中返回的类型是 UIImage _Nullable result, NSDictionary _Nullable info 注意观察OC中返回的类型UIImage * 后面使用了Nullable来修饰,至于Nullable这个单词是什么意思，我想稍微有点英文基础的应该一看就懂–”可以为空”，这不恰恰和Swift的可选类型呼应吗？_ 另外还有PHFetchResult遍历这个函数,我们再来看看在OC与Swift中的表达 `PHFetchResult *fetchResult; [fetchResult enumerateObjectsUsingBlock:^(id _Nonnull obj, NSUInteger idx, BOOL * _Nonnull stop) { }];` `let fetchResult: PHFetchResult fetchResult.enumerateObjects({ (obj, index, stop) in })` 看见OC中Block中的回调使用了Nonnull来修饰，即不可能为空，不可能为nil，一定有值，对于使用这样的字符修饰的对象，我们就不必为其做健壮性判断了。 这也就是nullable与nonnull两个关键字出现的原因吧–与Swift做桥接使用以及显式的提醒对象的状态 一点点Swift与OC的语言思考我之前写过一篇文章,是说有关于一个字符串拼接函数的 从Swift来反思OC的语法 OC函数是这样的： ` - (NSString *)stringByAppendingString:(NSString *)aString; ` Swift中函数是这样的： ` public mutating func append(_ other: String) ` 仅从API来看，OC的入参是很危险的,因为类型是NSString * 那么nil也可以传入其中，而传入nil的后果就是崩掉，我觉得对于这种传入参数为nil会崩掉的函数需要特别提醒一下，应该写成这样: ` - (NSString *)stringByAppendingString:(NSString * _Nonnull)aString; /// 或者下面这样 - (NSString *)stringByAppendingString:(nonnull NSString *)aString; ` 以便告诉程序员，入参不能为空，不能为空，不能为空，重要的事情说三遍！！！ 反观Swift就不会出现这种情况，other后面的类型为String，而不是String?，说明入参是一个非可选类型。 基于以上对于代码的严谨性，所以我才更喜欢使用Swift进行编程。 当然，Swift的严谨使得它失去部分的灵活性，OC在灵活性上比Swift卓越。","tags":[{"name":"Swift","slug":"Swift","permalink":"http://www.jifu.io/tags/Swift/"},{"name":"解包","slug":"解包","permalink":"http://www.jifu.io/tags/解包/"}],"categories":[{"name":"iOS Development","slug":"iOS-Development","permalink":"http://www.jifu.io/categories/iOS-Development/"}]},{"title":"macOS 下 FFmpeg 视频转码入门及进阶使用心得","date":"2021-02-23T07:38:50.000Z","path":"posts/2652542772/","text":"简介如今较为常见的视频封装格式有 mp4 和 mkv 等， 内部的视频编码格式从前几年盛行的 H.264/x264 逐渐开始向新一代的 HEVC/x265（ High Efficiency Video Coding 高效视频编码）过渡，而常见的音频编码格式无非 AC3、DTS 或者 AAC 等。无论是借助带有 GUI 的编码软件，还是使用命令行，FFmpeg 是最为广泛使用的工具，理论上 FFmpeg 支持各个平台，包括 Windows、macOS、iOS 以及 Android 等，这里只介绍在 macOS 下的使用。通过简单的命令，你可以大致了解 FFmpeg 在视频转换上的强大之处，视频编码部分也集中在 x264、x265，以及如何压制 macOS High Sierra 和 iOS 11 可以正确识别并生成缩略图的 HEVC 10bit 视频。最后会用一个较为复杂的例子，应用 -filter_complex 进行视频帧率的插值运算、嵌入 pgs 图形字幕，以及最后输出 HEVC 编码进行说明。 FFmpeg安装如果有看过我以前文章的朋友，可能会注意到使用 Homebrew 编译 mpv 的一个重要依赖就是 FFmpeg。不过，如果将其用作视频转码，默认编译的 FFmpeg 会缺少一部分组件，因此这里可能需要重新安装 FFmpeg。以我个人编译版本为例，使用 –HEAD 来配合最新的 mpv，在 Terminal 中输入如下命令： brew install ffmpeg --HEAD --with-fdk-aac --with-sdl2 --with-freetype --with-libass --with-libbluray --with-libvorbis --with-libvpx --with-opus --with-webp --with-x265 等待安装结束即可。 基础篇压制 x264 编码视频文件ffmpeg -i input.mp4 -c:a libfdk_aac -c:v libx264 -crf 20 -preset slow output.mp4 使用 FFmpeg 编码的基本规则， -i 之后的文件为输入的视频文件，即 input.mp4 ，支持的格式众多，例如 mkv、flv、vob 等等，文件可以包含目录，使用 macOS 的文件拖拽功能很方便。output.mp4 即为输出文件，文件名可自定义，视频封装格式建议对应编码格式，不应将 mpeg-2 或者 vp8 编码的视频也封装为 mp4。-c:a 之后表示输出文件的音频编码器，一般 mp4 常用的音频编码为 AAC-LC，按照官方 Wiki 指南，建议使用编码器 libfdk_aac 而不是 aac，libfdk_aac 音质更好，这也是为什么在前文中编译 FFmpeg 增加 –with-fdk-aac 的原因。-c:v 之后代表输出文件的视频编码器，使用 libx264 即可压制 x264 编码的视频流。-crf 20 代表视频编码的码率系数，数字越大，压制的效果越差，建议选择范围在 16 - 28，压制高质量的视频建议取值 20 以下。-preset slow 代表一组控制压缩时间和文件大小的参数选择，一般常选 fast、medium 和 slow。 以上都是基于 one-pass 压制，如果需要严格控制码率则需要使用 two-pass，更详细的介绍，可以参考 Encode / H.264。 压制 HEVC 10bit 编码视频文件 其实 FFmpeg 很早就开始支持 HEVC (x265) 的视频转码，只是一直改动较大，而最近的版本也终于支持编码 macOS High Sierra 下 Quicktime 可以播放，并且在系统中能够正确预览并生成缩略图的视频文件。编码命令的改动很小，添加一个 format tag 参数即可，如下： ffmpeg -i input.mp4 \\ -c:v libx265 -preset medium -crf 18 -pix_fmt yuv420p10le \\ -c:a libfdk_aac -b:a 256k \\ -tag:v hvc1 \\ output_10bit.mp4 和压制 x264 视频非常类似，主要的不同点在于 -c:v 视频编码器需换为 libx265，并且压制 10bit 需要指定色彩空间，添加 -pix_fmt yuv420p10le。在音频编码参数中，如何增加的 -b:a，可以控制音频文件的码率，按需使用。最后，非常重要的一点，必须添加参数 tag:v hvc1，这样输出的 Video Stream 会被标记为 hvc1，可以被 macOS 以及 iOS 11 原生支持播放，否则默认会被标记为 hev1，不被原生支持，第三方播放器播放倒没什么问题。 进阶篇修改视频分辨率假如原视频的分辨率为 1920x1080，为了降低文件大小，最简单的办法是将其转压成一个分辨率较低的版本，例如 720p，即 1280x720，那么我们可以使用 scale 视频滤镜来缩放视频： ffmpeg -i input.mp4 -vf scale=-2:720 -c:v libx264 -crf 20 -preset slow -c:a copy output.mp4 -vf scale=-2:720 会自动计算对应的横向分辨率（需为 2 的倍数，因此为 -2 ），源文件音频编码保持不变，因此设为 copy 即可。特殊情况下，遇到源文件视频比例错误，除了修改分辨率数值，还需要设置 dar 参数，例如： ffmpeg -i input.avi -vf scale=722x406,setdar=16/9 -c:v libx264 -c:a libfdk_aac -preset slow -crf 20 output.mp4 另外，绝对不建议增大分辨率，因为毫无意义，受限于原视频的视频质量，增大分辨率除了体积增大，画质只会更差。 反交错（ Deinterlace ）偶尔我会遇到一些早期使用 VCD/DVD 时代编码的视频，其中一个重要的特点就是隔行扫描，而直接转码的结果就是视频中快速运动的物体都能看到非常明显的扫描线。解决办法同样需要应用 vf 视频滤镜中的 yadif 来进行反交错，如下： ffmpeg -i input.vob -vf yadif -c:v libx264 -preset slow -crf 20 -c:a libfdk_aac -b:a 256k output.mp4 如果压制出来的效果不佳（还是有扫描线），可以尝试将 vf 的部分改为 -vf yadif=1:-1:0,mcdeint=2:1:10。 旋转视频需要将原视频进行旋转，同样可以应用视频滤镜来达到目的，如下： ffmpeg -i input.mov -vf \"transpose=1\" -c:a copy output.mov 其中， 0 = 90 Counter Clockwise and Vertical Flip (default) 1 = 90 Clockwise 2 = 90 Counter Clockwise 3 = 90 Clockwise and Vertical Flip 如果想要 180 度翻转视频，则需要改为 -vf “transpose=2,transpose=2”。值得注意的是，旋转视频意味着对视频进行重编码，输出质量会稍微受到影响，可以添加 crf 参数控制视频输出质量，音频部分可以使用 copy。 一个复杂的“栗子”最后的这个例子，是我最近遇到的一个视频，简要的编码信息如下： Input #0, matroska,webm, from 'Input.mkv': Duration: 00:23:55.97, start: 0.000000, bitrate: 16372 kb/s Stream #0:0: Video: hevc (Main 10), yuv420p10le(tv, bt709), 1920x1080, SAR 1:1 DAR 16:9, 59.94 fps, 59.94 tbr, 1k tbn, 59.94 tbc (default) Stream #0:1(jpn): Audio: flac, 48000 Hz, stereo, s32 (24 bit) (default) Stream #0:2(jpn): Audio: flac, 48000 Hz, stereo, s32 (24 bit) Stream #0:3(chi): Subtitle: hdmv_pgs_subtitle (default) Stream #0:4(chi): Subtitle: hdmv_pgs_subtitle 可以看到，这是一个 HEVC 10bit 编码，分辨率 1080p，帧率 59.94 fps 的视频文件，带有两条 flac 编码的音轨，另有两条是 pgs 格式的图形字幕。我自己的 Macbook Pro 已经无法完全流畅地播放这个视频了，除了 HEVC 带来的巨大计算量，高帧率也是一个麻烦，可惜网上没有其它好的片源，因此，我只有自己尝试压缩。目标：维持分辨率但帧率减半，即降为 29. 97 fps，音轨只需要第一条，并且重编码为 AAC-LC，原片为日语，因此必须带有字幕，图形字幕直接嵌入视频，最后以 HEVC 10bit 重编码，少许降低码率。 改变帧率普遍会使用 -vf fps=fps=29.97 这类的参数，但自己尝试后发现一个问题，视频观看的感觉有跳跃性，不流畅，很像是丢帧的感觉。因为将帧率减半，意味着有一半的信息都丢弃了，而普通降低帧率的算法只有简单的插值运算甚至完全没有，造成了视频不连贯的效果。因此，改变帧率正确的做法是进行运动插值运算（ Motion Interpolation ），此法既可用在提高帧率上，也可以用于降低帧率，最终的结果都是提高视频播放的流畅度。这里会使用 -filter_complex 代替 vf，联合应用 minterpolate、overlay 以及 map 来解决帧率、嵌入视频，和保留一条音轨的问题。压制命令如下： ffmpeg -i input.mkv \\ -filter_complex \"[0:v]minterpolate='fps=29.97:mi_mode=mci:me_mode=bidir:mc_mode=aobmc:vsbmc=1'[bg],[bg][0:s:0]overlay[v]\" -map \"[v]\" -map 0:a:0 \\ -c:v libx265 -preset medium -crf 18 -pix_fmt yuv420p10le \\ -c:a libfdk_aac -b:a 256k \\ -tag:v hvc1 \\ output_10bit.mp4 这里看起来会很复杂，实际上 -filter_complex 的工作模式就像是 pipe，[0:v] 表示输入文件的视频流，对应 Stream #0:0。从 minterpolate 到 vsbmc=1 都是插补滤镜的设置参数，具体的作用可以查看官方文档。[bg]代表该滤镜输出后的视频流，并传递给下一个滤镜 overlay。[0:s:0]表示输入文件的第一个字幕通，对应 Stream #0:3，所以如果是 [0:s:1] 则对应 Stream #0:4。 overlay 就会将该图形字幕嵌入到视频中，然后输出为 [v]，进行 mapping。视频取处理后的 [v]，音频取原输入文件的第一个音频通道，[0:a:0] 即代表 Stream #0:1。最后和此前压制视频的参数就一模一样了，压制为 HEVC 10bit 编码的视频文件。 需要注意的是，运动插值运算非常耗时，CPU 占用确不高，应该是 minterpolate 滤镜只能调用单核的缘故。在我的电脑上， 此 23 分钟左右的视频压制一次耗时约 20 小时，请谨慎使用。 补充 - 用来自动切黑边的脚本有时候碰到比较懒的小组发的片源，连黑边都不切，这样外挂字幕就跑到黑边去了，我很不喜欢……. 保存代码为 crop-border.sh 并修改权限，用法：./crop-border.sh input.mp4 output.mp4 #!/bin/bash # autodetect crop size crop=`ffmpeg -i $1 -t 1 -vf cropdetect -f null - 2>&amp;1 | awk '/crop/ { print $NF }' | tail -1` echo \"detected crop fromat: $crop\" echo \"input: $1\" echo \"output: $2\" date ; read -t 5 -p \"Hit ENTER or wait five seconds\" ; date ffmpeg -i $1 -c:a copy -c:v libx265 -preset medium -crf 18 -pix_fmt yuv420p10le -tag:v hvc1 -vf $crop -y $2 压制的参数 -c:a 和 -c:v 部分还需调整","tags":[{"name":"MacOS","slug":"MacOS","permalink":"http://www.jifu.io/tags/MacOS/"},{"name":"FFmpeg","slug":"FFmpeg","permalink":"http://www.jifu.io/tags/FFmpeg/"},{"name":"视频转码","slug":"视频转码","permalink":"http://www.jifu.io/tags/视频转码/"},{"name":"H.265","slug":"H-265","permalink":"http://www.jifu.io/tags/H-265/"}],"categories":[{"name":"OPS","slug":"OPS","permalink":"http://www.jifu.io/categories/OPS/"},{"name":"MacOS","slug":"OPS/MacOS","permalink":"http://www.jifu.io/categories/OPS/MacOS/"}]},{"title":"为远程桌面启用Windows防火墙例外","date":"2021-02-23T07:26:36.000Z","path":"posts/3669230936/","text":"问题介绍装完系统后在“远程设置处”设置为允许连接到计算机，但是上面有一个警告“必须为远程桌面启用Windows防火墙例外”。 就是没有获得防火墙的允许权限。 于是打开防火墙：控制面板—–Windows 防火墙—–允许的程序： 发现防火墙允许的程序中确实没有“远程桌面”，而虽然用户已是管理员身份，但“更改设置”按钮不可用： 解决方法打开本地组策略编辑器开始—— &gt; 运行—– &gt; gpedit.msc 启用Windows防火墙允许入站远程桌面例外打开“本地组策略编辑器”，按如下设置：计算机配置—–&gt;管理模板—–&gt;网络—–&gt;网络连接—–&gt;Windows防火墙—–&gt;标准配置文件—–&gt;Windows防火墙允许入站远程桌面例外（默认为未配置），选择“已启用”，并在下面的IP地址框中输入*号（可根据需要添加相应的IP） 打开防火墙策略设置完后，发现Windows防火墙允许的程序中已有了“远程桌面”，当然原先的警告“必须为远程桌面启用Windows防火墙例外”也已消失 测试进行连接测试，连接界面可以出来，输入正确的用户名密码，连接时却出现“您的凭据不工作”的错误，还是无法连接 凭证不工作解决方法再次进入“本地组策略编辑器”，进行如下设置：计算机配置—–&gt;管理模板—–&gt;系统—–&gt;凭据分配—–&gt;允许分配保存的凭据用于仅NTLM服务器身份验证，选择已启用，显示—–&gt;输入：“TERMSRV/*”。（确保 TERMSRV 为大写） 重启电脑测试成功","tags":[{"name":"Windows","slug":"Windows","permalink":"http://www.jifu.io/tags/Windows/"},{"name":"防火墙","slug":"防火墙","permalink":"http://www.jifu.io/tags/防火墙/"},{"name":"远程桌面","slug":"远程桌面","permalink":"http://www.jifu.io/tags/远程桌面/"}],"categories":[{"name":"OPS","slug":"OPS","permalink":"http://www.jifu.io/categories/OPS/"},{"name":"Windows","slug":"OPS/Windows","permalink":"http://www.jifu.io/categories/OPS/Windows/"}]},{"title":"高性能 Nginx HTTPS 调优 - 如何为 HTTPS 提速 30%","date":"2021-02-23T07:11:15.000Z","path":"posts/1350143519/","text":"为什么要优化 Nginx HTTPS 延迟 Nginx 常作为最常见的服务器，常被用作负载均衡 (Load Balancer)、反向代理 (Reverse Proxy)，以及网关 (Gateway) 等等。一个配置得当的 Nginx 服务器单机应该可以期望承受住 50K 到 80K 左右每秒的请求，同时将 CPU 负载在可控范围内。 但在很多时候，负载并不是需要首要优化的重点。比如对于卡拉搜索来说，我们希望用户在每次击键的时候，可以体验即时搜索的感觉，也就是说，每个搜索请求必须在 100ms - 200ms 的时间内端对端地返回给用户，才能让用户搜索时没有“卡顿”和“加载”。因此，对于我们来说，优化请求延迟才是最重要的优化方向。 这篇文章中，我们先介绍 Nginx 中的 TLS 设置有哪些与请求延迟可能相关，如何调整才能最大化加速。然后我们用优化卡拉搜索 Nginx 服务器的实例来分享如何调整 Nginx TLS/SSL 设置，为首次搜索的用户提速 30% 左右。我们会详细讨论每一步我们做了一些什么优化，优化的动机和效果。希望可以对其它遇到类似问题的同学提供帮助。 照例，本文的 Nginx 设置文件放置于 github，欢迎直接使用: 高性能 Nginx HTTPS 调优(https://github.com/Kalasearch/high-performance-nginx-tls-tuning) TLS 握手和延迟 很多时候开发者会认为：如果不是绝对在意性能，那么了解底层和更细节的优化没有必要。这句话在很多时候是恰当的，因为很多时候复杂的底层逻辑必须包起来，才能让更高层的应用开发复杂度可控。比如说，如果你就只需要开发一个 APP 或者网站，可能并没有必要关注汇编细节，关注编译器如何优化你的代码——毕竟在苹果或者安卓上很多优化在底层就做好了。 那么，了解底层的 TLS 和应用层的 Nginx 延迟优化有什么关系呢？ 答案是多数情况下，优化网络延迟其实是在尝试减少用户和服务器之间的数据传输次数，也就是所谓的 roundtrip。由于物理限制，北京到云南的光速传播差不多就是要跑 20 来毫秒，如果你不小心让数据必须多次往返于北京和云南之间，那么必然延迟就上去了。 因此如果你需要优化请求延迟，那么了解一点底层网络的上下文则会大有裨益，很多时候甚至是你是否可以轻松理解一个优化的关键。本文中我们不深入讨论太多 TCP 或者 TLS 机制的细节，如果有兴趣的话请参考 High Performance Browser Networking 一书。 举个例子，下图中展示了如果你的服务启用了 HTTPS，在开始传输任何数据之前的数据传输情况。 可以看到，在你的用户拿到他需要的数据前，底层的数据包就已经在用户和你的服务器之间跑了 3 个来回。 假设每次来回需要 28 毫秒的话，用户已经等了 224 毫秒之后才开始接收数据。 同时这个 28 毫秒其实是非常乐观的假设，在国内电信、联通和移动以及各种复杂的网络状况下，用户与服务器之间的延迟更不可控。另一方面，通常一个网页需要数十个请求，这些请求不一定可以全部并行，因此几十乘以 224 毫秒，页面打开可能就是数秒之后了。 所以，原则上如果可能的话，我们需要尽量减少用户和服务器之间的往返程 (roundtrip)，在下文的设置中，对于每个设置我们会讨论为什么这个设置有可能帮助减少往返程。 Nginx 中的 TLS 设置 那么在 Nginx 设置中，怎样调整参数会减少延迟呢？ 开启 HTTP/2HTTP/2 标准是从 Google 的 SPDY 上进行的改进，比起 HTTP 1.1 提升了不少性能，尤其是需要并行多个请求的时候可以显著减少延迟。在现在的网络上，一个网页平均需要请求几十次，而在 HTTP 1.1 时代浏览器能做的就是多开几个连接（通常是 6 个）进行并行请求，而 HTTP 2 中可以在一个连接中进行并行请求。HTTP 2 原生支持多个并行请求，因此大大减少了顺序执行的请求的往返程，可以首要考虑开启。 如果你想自己看一下 HTTP 1.1 和 HTTP 2.0 的速度差异，可以试一下：https://www.httpvshttps.com/。我的网络测试下来 HTTP/2 比 HTTP 1.1 快了 66%。 在 Nginx 中开启 HTTP 2.0 非常简单，只需要增加一个 http2 标志即可 listen 443 ssl; # 改为 listen 443 ssl http2; 如果你担心你的用户用的是旧的客户端，比如 Python 的 requests，暂时还不支持 HTTP 2 的话，那么其实不用担心。如果用户的客户端不支持 HTTP 2，那么连接会自动降级为 HTTP 1.1，保持了后向兼容。因此，所有使用旧 Client 的用户，仍然不受影响，而新的客户端则可以享受 HTTP/2 的新特性。 如何确认你的网站或者 API 开启了 HTTP 2在 Chrome 中打开开发者工具，点开 Protocol 之后在所有的请求中都可以看到请求用的协议了。如果 protocol 这列的值是 h2 的话，那么用的就是 HTTP 2 了 当然另一个办法是直接用 curl 如果返回的 status 前有 HTTP/2 的话自然也就是 HTTP/2 开启了。 ➜ ~ curl --http2 -I https://kalasearch.cn HTTP/2 403 server: Tengine content-type: application/xml content-length: 264 date: Tue, 22 Dec 2020 18:38:46 GMT x-oss-request-id: 5FE23D363ADDB93430197043 x-oss-cdn-auth: success x-oss-server-time: 0 x-alicdn-da-ups-status: endOs,0,403 via: cache13.l2et2[148,0], cache10.l2ot7[291,0], cache4.us13[360,0] timing-allow-origin: * eagleid: 2ff6169816086623266688093e 调整 Cipher 优先级尽量挑选更新更快的 Cipher，有助于减少延迟: # 手动启用 cipher 列表 ssl_prefer_server_ciphers on; # prefer a list of ciphers to prevent old and slow ciphers ssl_ciphers 'EECDH+AESGCM:EDH+AESGCM:AES256+EECDH:AES256+EDH'; 启用 OCSP Stapling在国内这可能是对使用 Let’s Encrypt 证书的服务或网站影响最大的延迟优化了。如果不启用 OCSP Stapling 的话，在用户连接你的服务器的时候，有时候需要去验证证书。而因为一些不可知的原因（这个就不说穿了）Let’s Encrypt 的验证服务器并不是非常通畅，因此可以造成有时候数秒甚至十几秒延迟的问题，这个问题在 iOS 设备上特别严重 解决这个问题的方法有两个： 不使用 Let’s Encrypt，可以尝试替换为阿里云提供的免费 DV 证书 开启 OCSP Stapling 开启了 OCSP Stapling 的话，跑到证书验证这一步可以省略掉。省掉一个 roundtrip，特别是网络状况不可控的 roundtrip，可能可以将你的延迟大大减少。 在 Nginx 中启用 OCSP Stapling 也非常简单，只需要设置： ssl_stapling on; ssl_stapling_verify on; ssl_trusted_certificate /path/to/full_chain.pem; 如何检测 OCSP Stapling 是否已经开启？可以通过以下命令 openssl s_client -connect test.kalasearch.cn:443 -servername kalasearch.cn -status -tlsextdebug &lt; /dev/null 2>&amp;1 | grep -i \"OCSP response\" 来测试。如果结果为 OCSP response: OCSP Response Data: OCSP Response Status: successful (0x0) Response Type: Basic OCSP Response 则表明已经开启。参考 HTTPS 在 iPhone 上慢的问题 一文 调整 ssl_buffer_sizesslbuffersize 控制在发送数据时的 buffer 大小，默认设置是 16k。这个值越小，则延迟越小，而添加的报头之类会使 overhead 会变大，反之则延迟越大，overhead 越小。 因此如果你的服务是 REST API或者网站的话，将这个值调小可以减小延迟和 TTFB，但如果你的服务器是用来传输大文件的，那么可以维持 16k。关于这个值的讨论和更通用的 TLS Record Size 的讨论，可以参考：Best value for nginx’s sslbuffersize option 如果是网站或者 REST API，建议值为 4k，但是这个值的最佳取值显然会因为数据的不同而不一样，因此请尝试 2 - 16k 间不同的值。在 Nginx 中调整这个值也非常容易 ssl_buffer_size 4k; 启用 SSL Session 缓存启用 SSL Session 缓存可以大大减少 TLS 的反复验证，减少 TLS 握手的 roundtrip。虽然 session 缓存会占用一定内存，但是用 1M 的内存就可以缓存 4000 个连接，可以说是非常非常划算的。同时，对于绝大多数网站和服务，要达到 4000 个同时连接本身就需要非常非常大的用户基数，因此可以放心开启。 这里 ssl_session_cache 设置为使用 50M 内存，以及 4 小时的连接超时关闭时间 ssl_session_timeout # Enable SSL cache to speed up for return visitors ssl_session_cache shared:SSL:50m; # speed up first time. 1m ~= 4000 connections ssl_session_timeout 4h; 卡拉搜索如何减少 30% 的请求延迟 卡拉搜索是国内的 Algolia，致力于帮助开发者快速搭建即时搜索功能(instant search)，做国内最快最易用的搜索即服务。 开发者接入后，所有搜索请求通过卡拉 API 即可直接返回给终端用户。为了让用户有即时搜索的体验，我们需要在用户每次击键后极短的时间内（通常是 100ms 到 200ms）将结果返回给用户。因此每次搜索需要可以达到 50 毫秒以内的引擎处理时间和 200 毫秒以内的端对端时间。 我们用豆瓣电影的数据做了一个电影搜索的 Demo，如果感兴趣的话欢迎体验一下即时搜索，尝试一下搜索“无间道”或者“大话西游”体验一下速度和相关度：https://movies-demo.kalasearch.cn/ 对于每个请求只有 100 到 200 毫秒的延迟预算，我们必须把每一步的延迟都考虑在内。 简化一下，每个搜索请求需要经历的延迟有 总延迟 = 用户请求到达服务器(T1) + 反代处理(Nginx T2) + 数据中心延迟(T3) + 服务器处理 (卡拉引擎 T4) + 用户请求返回(T3+T1) 在上述延迟中，T1 只与用户与服务器的物理距离相关，而 T3 非常小（参考Jeff Dean Numbe)可以忽略不计。 所以我们能控制的大致只有 T2 和 T4，即 Nginx 服务器的处理时间和卡拉的引擎处理时间。 Nginx 在这里作为反向代理，处理一些安全、流量控制和 TLS 的逻辑，而卡拉的引擎则是一个在 Lucene 基础上的倒排引擎。 我们首先考虑的第一个可能性是：延迟是不是来自卡拉引擎呢？ 在下图展示的 Grafana 仪表盘中，我们看到除了几个时不时的慢查询，搜索的 95% 服务器处理延迟小于 20 毫秒。对比同样的数据集上 benchmark 的 Elastic Search 引擎的 P95 搜索延迟则在 200 毫秒左右，所以排除了引擎速度慢的可能。 而在阿里云监控中，我们设置了从全国各地向卡拉服务器发送搜索请求。我们终于发现 SSL 处理时间时常会超过 300 毫秒，也就是说在 T2 这一步，光处理 TLS 握手之类的事情，Nginx 已经用掉了我们所有的请求时间预算。 同时检查之后我们发现，在苹果设备上搜索速度格外慢，特别是第一次访问的设备。因此我们大致判断应该是因为我们使用的 Let’s Encrypt 证书的问题。 我们按照上文中的步骤对 Nginx 设置进行了调整，并将步骤总结出来写了这篇文章。在调整了 Nginx TLS 的设置后，SSL 时间从平均的 140ms 降低到了 110ms 左右（全国所有省份联通和移动测试点），同时苹果设备上首次访问慢的问题也消失了。 在调整过后，全国范围内测试的搜索延迟降低到了 150 毫秒左右。 总结 调整 Nginx 中的 TLS 设置对于使用 HTTPS 的服务和网站延迟有非常大的影响。 本文中总结了 Nginx 中与 TLS 相关的设置，详细讨论各个设置可能对延迟的影响，并给出了调整建议。之后我们会继续讨论 HTTP/2 对比 HTTP 1.x 有哪些具体改进，以及在 REST API 使用 HTTP/2 有哪些优缺点","tags":[{"name":"Nginx","slug":"Nginx","permalink":"http://www.jifu.io/tags/Nginx/"},{"name":"高性能","slug":"高性能","permalink":"http://www.jifu.io/tags/高性能/"},{"name":"调优","slug":"调优","permalink":"http://www.jifu.io/tags/调优/"},{"name":"提速","slug":"提速","permalink":"http://www.jifu.io/tags/提速/"}],"categories":[{"name":"back-end","slug":"back-end","permalink":"http://www.jifu.io/categories/back-end/"},{"name":"Middle-ware","slug":"back-end/Middle-ware","permalink":"http://www.jifu.io/categories/back-end/Middle-ware/"},{"name":"Nginx","slug":"back-end/Middle-ware/Nginx","permalink":"http://www.jifu.io/categories/back-end/Middle-ware/Nginx/"}]},{"title":"Swift 5.4 有什么新功能？","date":"2021-02-18T09:44:13.000Z","path":"posts/684390890/","text":"导言多个变量参数，改进隐式成员语法，结果构建器等。 Swift 5.4带来了一些巨大的编译改进，包括更好地完成带错误的表达式中的代码，以及增量编译的大提速。不过，它也增加了一些重要的新特性和改进，让我们在这里深入了解一下…… 小贴士： 如果你想自己尝试代码样本，也可以下载这个作为Xcode Playground。 改进了隐式成员语法SE-0287改进了Swift使用隐式成员表达式的能力，所以你可以制作它们的链子，而不是只支持一个单一的静态成员。 Swift一直以来都有能力使用隐式成员语法来处理简单的表达式，例如，如果你想在SwiftUI中给一些文本着色，你可以使用.red而不是Color.red。 `struct ContentView1: View { var body: some View { Text(\"You're not my supervisor!\") .foregroundColor(.red) } } ` 在Swift 5.4之前，这在更复杂的表达式中是行不通的。例如，如果你想让你的红色略微透明，你就需要这样写。 `struct ContentView2: View { var body: some View { Text(\"You're not my supervisor!\") .foregroundColor(Color.red.opacity(0.5)) } } ` 从Swift 5.4开始，编译器能够理解多个链式成员，这意味着可以推断出Color类型。 `struct ContentView3: View { var body: some View { Text(\"You're not my supervisor!\") .foregroundColor(.red.opacity(0.5)) } } ` 函数中的多变量参数SE-0284引入了让函数、下标和初始化器使用多个变量参数的能力，只要变量参数后面的所有参数都有标签。在Swift 5.4之前，这种情况下只能有一个变量参数。 所以，有了这个改进，我们可以写一个函数，接受一个变量参数，存储足球比赛中进球的次数，再加上第二个变量参数，打出进球球员的名字。 `func summarizeGoals(times: Int..., players: String...) { let joinedNames = ListFormatter.localizedString(byJoining: players) let joinedTimes = ListFormatter.localizedString(byJoining: times.map(String.init)) print(\"\\(times.count) goals where scored by \\(joinedNames) at the follow minutes: \\(joinedTimes)\") } ` 要调用该函数，提供两组值作为变量参数，确保第一个变量之后的所有参数都有标签。 `summarizeGoals(times: 18, 33, 55, 90, players: \"Dani\", \"Jamie\", \"Roy\") ` 结果生成器函数构建器在Swift 5.1中非正式地出现了，但在Swift 5.4之前，它们作为SE-0289正式通过了Swift进化提案过程，以便进行讨论和完善。作为这个过程的一部分，它们被重新命名为结果构建器以更好地反映它们的实际目的，甚至获得了一些新的功能。 首先是最重要的部分：结果构建器允许我们通过在我们选择的序列中一步步地创造一个新的价值。它们为SwiftUI的视图创建系统的很大一部分提供了动力，所以当我们拥有一个内部有各种视图的VStack时，Swift会默默地将它们归为一个内部的TupleView类型，这样它们就可以作为VStack的一个子代来存储–它将一个视图序列变成了一个视图。 结果构建器应该有自己的详细文章，但我至少想给你一些小的代码示例，这样你就可以看到它们的运作。 下面是一个返回单个字符串的函数。 `func makeSentence1() -> String { \"Why settle for a Duke when you can have a Prince?\" } print(makeSentence1()) ` 这很好用，但如果有几个字符串我们想连接在一起呢？就像SwiftUI一样，我们可能想把它们都单独提供，然后让Swift来解决。 `// This is invalid Swift, and will not compile. // func makeSentence2() -> String { // \"Why settle for a Duke\" // \"when you can have\" // \"a Prince?\" // } ` 就其本身而言，这段代码是行不通的，因为Swift不再理解我们的意思。然而，我们可以创建一个结果生成器，它可以理解如何使用我们想要的任何转换将几个字符串转换为一个字符串，就像这样。 `@resultBuilder struct SimpleStringBuilder { static func buildBlock(_ parts: String...) -> String { parts.joined(separator: \"\\n\") } } ` 尽管这只是少量的代码，但有很多需要解压。 @resultBuilder属性告诉SwiftUI以下类型应该被视为结果构建器。 以前这种行为是通过@_functionBuilder实现的，它有一个下划线来表明这不是为一般使用而设计的。 每个结果构建器都必须提供至少一个名为buildBlock()的静态方法，该方法应该接收某种数据并对其进行转换。 上面的例子是接收零个或多个字符串，将它们连接起来，然后以单个字符串的形式发送回来。 最终的结果是，我们的SimpleStringBuilder结构变成了一个结果构建器，这意味着我们可以在任何需要它的字符串连接能力的地方使用@SimpleStringBuilder。 没有什么可以阻止我们直接使用SimpleStringBuilder.buildBlock()，就像这样。 `let joined = SimpleStringBuilder.buildBlock( \"Why settle for a Duke\", \"when you can have\", \"a Prince?\" ) print(joined) ` 然而，由于我们在SimpleStringBuilder结构中使用了@resultBuilder注解，我们也可以将其应用到函数中，就像这样。 `@SimpleStringBuilder func makeSentence3() -> String { \"Why settle for a Duke\" \"when you can have\" \"a Prince?\" } print(makeSentence3()) ` 请注意，我们不再需要每个字符串末尾的逗号--@resultBuilder通过使用SimpleStringBuilder自动将makeSentence()中的每个语句转换为单个字符串。 在实践中，结果生成器能够做得更多，通过向你的生成器类型添加更多的方法来完成。例如，我们可以通过添加两个额外的方法来为我们的SimpleStringBuilder添加if/else支持，这两个方法描述了我们要如何转换数据。在我们的代码中，我们根本不想转换我们的字符串，所以我们可以直接把它们送回去。 `@resultBuilder struct ConditionalStringBuilder { static func buildBlock(_ parts: String...) -> String { parts.joined(separator: \"\\n\") } static func buildEither(first component: String) -> String { return component } static func buildEither(second component: String) -> String { return component } } ` 我知道，看起来我们几乎没有做任何工作，但现在我们的函数能够使用条件。 `@ConditionalStringBuilder func makeSentence4() -> String { \"Why settle for a Duke\" \"when you can have\" if Bool.random() { \"a Prince?\" } else { \"a King?\" } } print(makeSentence4()) ` 同样，我们也可以通过在构建器类型中添加 buildArray() 方法来添加对循环的支持。 `@resultBuilder struct ComplexStringBuilder { static func buildBlock(_ parts: String...) -> String { parts.joined(separator: \"\\n\") } static func buildEither(first component: String) -> String { return component } static func buildEither(second component: String) -> String { return component } static func buildArray(_ components: [String]) -> String { components.joined(separator: \"\\n\") } } ` 现在我们可以使用for循环。 `@ComplexStringBuilder func countDown() -> String { for i in (0...10).reversed() { \"\\(i)…\" } \"Lift off!\" } print(countDown()) ` 这感觉几乎就像魔法一样，因为结果构建器系统几乎为我们做了所有的工作，尽管我们的例子已经相当简单，但我希望你能感受到结果构建器给Swift带来的非凡力量。 值得补充的是，Swift 5.4扩展了结果构建器系统，支持属性被放置在存储的属性上，这将自动调整结构的隐式成员初始化器来应用结果构建器。 这对于使用结果构建器的自定义SwiftUI视图特别有帮助，比如这个视图。 `struct CustomVStack&lt;Content: View>: View { @ViewBuilder let content: Content var body: some View { VStack { // custom functionality here content } } } ` 如果你想看到更多高级的、实际操作的结果构建器的例子，你应该查看GitHub上的Awesome Function Builders仓库。 本地函数现在支持重载SR-10069要求能够在本地上下文中重载函数，这实际上意味着嵌套函数现在可以重载，这样Swift就可以根据使用的类型来选择运行哪个函数。 例如，如果我们想制作一些简单的 cookie，我们可能会写这样的代码。 `struct Butter { } struct Flour { } struct Sugar { } func makeCookies() { func add(item: Butter) { print(\"Adding butter…\") } func add(item: Flour) { print(\"Adding flour…\") } func add(item: Sugar) { print(\"Adding sugar…\") } add(item: Butter()) add(item: Flour()) add(item: Sugar()) } ` 在Swift 5.4之前，三个add()方法只有在没有嵌套在makeCookies()里面的情况下才能被重载，但从Swift 5.4开始，这种情况下也支持函数重载。 现在支持本地变量的属性包装器了 属性包装器最早是在Swift 5.1中引入的，作为一种以简单、可重用的方式为属性附加额外功能的方式，但在Swift 5.4中，它们的行为得到了扩展，支持在函数中作为局部变量使用。 例如，我们可以创建一个属性包装器，确保其值永远不会低于零。 `@propertyWrapper struct NonNegative&lt;T: Numeric &amp; Comparable> { var value: T var wrappedValue: T { get { value } set { if newValue &lt; 0 { value = 0 } else { value = newValue } } } init(wrappedValue: T) { if wrappedValue &lt; 0 { self.value = 0 } else { self.value = wrappedValue } } } ` 而从Swift 5.4开始，我们可以在一个常规函数里面使用这个属性包装器，而不仅仅是附加到一个属性上。例如，我们可以写一个游戏，在这个游戏中，我们的玩家可以获得或失去分数，但他们的分数绝对不能低于0。 `func playGame() { @NonNegative var score = 0 // player was correct score += 4 // player was correct again score += 8 // player got one wrong score -= 15 // player got another one wrong score -= 16 print(score) } ` 软件包现在可以声明可执行目标SE-0294 为使用 Swift 包管理器的应用程序增加了一个新的目标选项，允许我们明确声明一个可执行目标。 这对于想要使用 SE-0281（使用 @main 来标记你的程序的入口点）的人来说特别重要，因为它与 Swift 包管理器玩得并不好–它总是会寻找 main.swift 文件。 通过这次修改，我们现在可以删除main.swift而使用@main来代替。注意：你必须在你的Package.swift文件中指定// swift-tools-version:5.4才能获得这个新功能。 自己尝试Swift 5.4可以通过Xcode 12.5获得，Xcode 12.5于2021年2月1日进入测试版。如果你还没有升级到macOS Big Sur，你将无法安装Xcode 12.5，所以你应该从https://swift.org/download/ 下载一个Swift 5.4工具链–你可以将其安装到Xcode 12.4和更早的版本中。 你最期待Swift 5.4的哪些功能？","tags":[{"name":"Swift","slug":"Swift","permalink":"http://www.jifu.io/tags/Swift/"},{"name":"新特性","slug":"新特性","permalink":"http://www.jifu.io/tags/新特性/"}],"categories":[{"name":"iOS Development","slug":"iOS-Development","permalink":"http://www.jifu.io/categories/iOS-Development/"}]},{"title":"快速改善用户界面的10个技巧","date":"2021-02-14T02:35:19.000Z","path":"posts/729727978/","text":"创建美观、好用和高效的 UI 需要花费时间，并且需要不断的调整修正，才能产生让用户和自己真正满意的设计。在本文中，总结了一些简单易用的设计小技巧，通过进行一些简单的视觉调整，可以快速改善你要创建的视觉效果。 1. 减轻文本的字重当涉及到长篇内容时，某些常规的粗体字看起来会有些沉重和生硬，可以通过选择深灰色（Dark Gray），比如＃4F4F4F 来解决这个问题，让文本看起来更美观一些。 2. 字号越小，行高越高当你的字号减小时，增加行高可以达到更好的、全面的易读性；当字号增加时，只需降低行高也可以达到同样的效果。 3. 选择基色，使用色调和阴影来增加一致性你不必总是用多种颜色来填充你的设计，如果项目允许，则只需使用一个固定的调色板，通过选择一个基础色，然后使用色调和阴影，就可以用最简单的方式增加设计的一致性。 4. 突出最重要的元素通过使用字号、粗细和颜色的组合，你可以轻松的在 UI 中突出最重要的元素，通过简单的调整即可使用户体验更好。 5. 为了保持一致性，确保图标具有相同的视觉样式在 UI 中设计图标时，要确保它们具有相同的视觉风格，相同的字重，填充或描边，不要混搭。 6. 始终将 CTA（行动召唤）按钮放在屏幕中最突出的位置通过使用颜色对比、大小和标签，确保 “行动召唤” 尽可能突出。如果可以的话，不要总是只依赖图标，也可以使用文本标签，让用户能够更好地理解。 7. 为表单错误添加额外的视觉帮助当用户填写任何类型的表单时，在用户刚刚执行的操作附近添加错误消息是一种简单且非常有用的额外视觉帮助。 8. 突出显示菜单中最常用的操作当设计一个在应用程序内部使用的菜单时，在屏幕最明显的位置，要确保给出最常用的操作 (例如：上传图片，添加文件等)。 9. 限制使用居中文字尽量只在标题和小段文字中使用居中文字。对于所有其它的文本内容，都要保持左对齐。 10. 巧妙地使用留白适度地使用留白，即使是少量的留白，也能让你的设计更加亮丽。这是改进设计最快速、最简单的方法之一。 以上是关于快速改善用户界面的 10 个小技巧，希望在你认真做设计的时候可以给你带来灵感，如果你也收藏了很多小技巧，欢迎在下方留言，我们一起学习！","tags":[{"name":"改善","slug":"改善","permalink":"http://www.jifu.io/tags/改善/"},{"name":"用户界面","slug":"用户界面","permalink":"http://www.jifu.io/tags/用户界面/"},{"name":"技巧","slug":"技巧","permalink":"http://www.jifu.io/tags/技巧/"}],"categories":[{"name":"Design","slug":"Design","permalink":"http://www.jifu.io/categories/Design/"}]},{"title":"MySQL 排序的艺术：你真的懂 Order By 吗？","date":"2021-02-08T09:50:55.000Z","path":"posts/554387356/","text":"前言业务中的各种查询通常对应了用户所看到的各项列表，列表一般是根据某个维度进行排序。 换句话说，业务中使用 SELECT 语句的时候除了不可避免的搭配 WHERE 以外，还会配合 ORDER BY 进行使用。 今天来好好聊聊 MySQL 的 ORDER BY 排序。 排序算法说到排序算法，有插入排序、选择排序、归并排序、堆排序、快速排序、计数排序、桶排序、基数排序、冒泡排序、希尔排序、梳排序 … 关于各种排序算法的排序流程和具体实现，不是本篇博客的重点，不作详细说明。 这里直接贴各类排序算法的时空复杂度： 通常我们实现的这些排序算法，都是在”纯内存“环境中进行。 MySQL 作为数据库难道是在先将所有要排序的数据加载到内存，再应用排序算法吗？ MySQL 的排序方案在分析 MySQL 的不同的排序方案之前，先来了解 sort buffer 概念。 MySQL 会为每个线程分配固定大小的 sort buffer 用作排序。 sort buffer 是具有逻辑概念的内存区域，大小由 sort_buffer_size 参数控制，默认为 256 kb。 由于 sort buffer 大小固定，而 data（待排序的数据量）并不固定，所以根据 sort buffer 与 data（待排序数据量）的大小差值，可分为内部排序和外部排序： data &lt;= sort buffer：即 sort buffer 够用，这时候 MySQL 只需要在内存中进行排序即可。内部排序使用的是快速排序 data &gt; sort buffer：这时候 sort buffer 不够用，MySQL 需要借助外部“容器”（通常是文件）进行排序。通常会将待排序数据分成多个“小文件”，对各个“小文件”进行排序，再汇总成一个有序的“大文件”。外部排序使用的是归并排序 如何验证当前执行的排序语句使用的是内部排序还是外部排序？ 可以通过 EXPLAIN 命令来查看，如果在分析结果中的 Extra 字段里包含 Using filesort 字眼，说明执行了外部排序操作。 全字段排序「全字段排序是指，只要与最终结果集有关的字段都会被放进 sort buffer，而不管该字段本身是否参与排序。」 以下面的 SQL 为例子： SELECT nick_name, age, phone FROM t_user WHERE city = \"深圳\" ORDER BY nick_name; 假设 city 字段上有索引，全字段排序的过程： 从 city 索引树上找到第一条值为深圳的数据，取得 id 之后回表（回到主键索引）取得 nick_name、age、phone 三个字段放入 sort buffer 从 city 索引树取下一条值为深圳的数据，重复 1 过程，直到下一条数据不满足值为深圳条件 到这一步，所有 city = 深圳 的数据都在 sort buffer 了。对 nick_name 执行快速排序 将排序结果返回 可以看到当查询条件本身有索引可用的话，全字段排序的排序过程都在 sort buffer（内存）进行，回表次数为符合条件的数据个数。 当然，如果我们建立的是 city、nick_name、age、phone 的联合索引，还可以实现“索引覆盖”，即在一棵索引树上取得全部所需数据，减少回表（随机读）次数。 不过针对每个查询或排序语句建立联合索引，会导致索引过多，大大降低写入更新数据的速度，以及大大提升数据所需要的存储空间。 生产上对索引的建立修改需要格外谨慎。 rowId 排序rowId 就是 MySQL 对每行数据的唯一标识符。 当数据表有主键时，rowId 就是表主键；当数据表没有主键或者主键被删除时，MySQL 会自动生成一个长度为 6 字节的 rowId 为作为 rowId。 「rowId 排序是指只将与排序相关的字段和 rowId 放入 sort buffer，其余结果集需要用到的数据在排序完成后，通过 rowId 回表取得。」 全字段排序的流程看着已经十分合理，为什么还需要有个 rowId 排序？ 这是我们只需要输出三个字段的情况，假如我们有上百个字段需要返回呢？sort buffer 默认只有 256 kb。能够装下多少行的原始数据行？ 所以当待排序的数据行很大的时候，使用全字段排序必然会导致“外部排序”。而且是使用很多临时文件的“外部排序”，效率很低下。 相比全字段排序，rowId 排序的好处是在 sort buffer 大小固定的情况下，sort buffer 能够容纳更多的数据行，能够避免使用或者少使用“外部排序文件”。 缺点是最终返回结果集的时候，需要再次进行回表。 还是之前那个例子： SELECT nick_name, age, phone FROM t_user WHERE city = \"深圳\" ORDER BY nick_name; rowId 排序全过程 从 city 索引树上找到第一条值为深圳的数据，取得 id 之后回表（回到主键索引）取得 nick_name 这个与排序相关的字段和主键 id 一起放入 sort buffer 从 city 索引树取下一条值为深圳的数据，重复 1 过程，直到下一条数据不满足值为深圳条件 这时候，所有 city = 深圳 的数据都在 sort buffer 了（sort buffer 里面的数据包含两个字段： id 和 nick_name）。对 nick_name 执行快速排序 利用排序好的数据，使用主键 id 再次回表取其他字段，将结果返回 注意：在步骤 4 中不会等所有排序好的 id 回表完再返回，而是每个 id 回表一次，取得该行数据之后立即返回，所以不会消耗额外的内存。 优先队列排序无论是使用全字段排序还是 rowId 排序，都不可避免了对所有符合 WHRER 条件的数据进行了排序。 有读者可能会认为，那不是应该的吗？ 设想一下，如果我们还搭配着 LIMIT 使用呢？ 例如我们在排序语句后添加 LIMIT 3 ，哪怕查出来的数据有 10W 行，我们也只需要前 3 行有序。 为了得到前 3 行数据，而不得不将 10W 行数据载入内存，大大降低了 sort buffer 的利用率。 这时候你可能想到利用“最小堆”、“最大堆”来进行排序。 没错，这正是 MySQL 针对带有 LIMIT 的 ORDER BY 语句的优化：使用优先队列进行排序。 以下面的 SQL 为例子： SELECT nick_name, age, phone FROM t_user WHERE city = \"深圳\" ORDER BY nick_name LIMIT 3; 优先队列进行排序的流程 在所有待排序的数据，取数量为 LIMIT （本例中为 3）的数据，构建一个堆 不断的取下一行数据，更新堆节点 当所有行的扫描完，得到最终的排序结果 如何选择?现在我们知道有全字段排序和 rowId 排序，那么 MySQL 是如何在这两种排序方案中做选择呢？ 由于 rowId 排序相对于全字段排序，不可避免的多了一次回表操作，回表操作意味着随机读，而随机 IO 是数据库中最昂贵的操作。 所以 MySQL 会在尽可能的情况下选择全字段排序。 那么什么情况下 MySQL 会选择 rowId 排序呢，是否有具体的值可以量度？ 答案是有的，通过参数 max_length_for_sort_data 可以控制用于排序的行数据最大长度，默认值为 1024 字节。 当单行数据长度超过该值，MySQL 就会觉得如果还用全字段排序，会导致 sort buffer 容纳下的行数太少，从而转为使用 rowId 排序。 临时表排序通常对于一个执行较慢的排序语句，在使用 EXPLAIN 进行执行过程分析的时候除了能看到 Using filesort 以外，还能看到 Using temporary，代表在排序过程中使用到了临时表。 内存临时表排序MySQL 优先使用内存临时表。当 MySQL 使用内存临时表时，临时表存储引擎为 memory 。 如果当前 MySQL 使用的是内存临时表的话，将会直接使用 rowId 排序，因为这时候所谓的“回表”只是在内存表中读数据，操作不涉及硬盘的随机 IO 读。 使用 rowId 可以在 sort buffer 容纳给多的行，避免或减少外部排序文件的使用。 磁盘临时表排序如果系统中很多需要使用临时表的排序语句执行，而又不加以限制，全都使用临时表的话，内存很快就会被打满。 所以 MySQL 提供了 tmp_table_size 参数限制了内存临时表的大小，默认值是 16M。 如果临时表大小超过了tmp_table_size，那么内存临时表就会转成磁盘临时表。 当使用磁盘临时表的时候，表储存引擎将不再是 memory，而是由 internal_tmp_disk_storage_engine 参数控制，默认为 InnoDB 。 这时候 MySQL 会根据单行大小是否超过 max_length_for_sort_data 决定采用全字段排序还是 rowId 排序。 总#结总结一下，MySQL 总是使用 「“最快”」 的排序方案： 当排序数据量不超过 sort buffer 容量时，MySQL 将会在内存使用快速排序算法进行排序（内部排序）；当排序数据量超过 sort buffer 容量时，MySQL 将会借助临时磁盘文件使用归并排序算法进行排序（外部排序） 在进行真正排序时，MySQL 又会根据数据单行长度是否超过 max_length_for_sort_data而决定使用 rowId 排序还是全字段排序，优先选择全字段排序，以减少回表次数 当需要借助临时表的时候，MySQL 会优先使用内存临时表（此时表引擎为 memory 引擎），回内存临时表取数据并不涉及随机读，也不涉及扫描行，效率较高。所以在配合内存临时表的时候，会使用 rowId 排序方式；当内存临时表大小超过 tmp_table_size 限制时，则需要将内存临时表转换为磁盘临时表，这时候由于回表意味着随机读，所以会搭配全字段排序方式","tags":[{"name":"排序","slug":"排序","permalink":"http://www.jifu.io/tags/排序/"},{"name":"MySQL","slug":"MySQL","permalink":"http://www.jifu.io/tags/MySQL/"},{"name":"Order by","slug":"Order-by","permalink":"http://www.jifu.io/tags/Order-by/"}],"categories":[{"name":"back-end","slug":"back-end","permalink":"http://www.jifu.io/categories/back-end/"},{"name":"Middle-ware","slug":"back-end/Middle-ware","permalink":"http://www.jifu.io/categories/back-end/Middle-ware/"},{"name":"MySQL","slug":"back-end/Middle-ware/MySQL","permalink":"http://www.jifu.io/categories/back-end/Middle-ware/MySQL/"}]},{"title":"Mac OS X设置SMB进行文件共享","date":"2021-02-08T09:42:05.000Z","path":"posts/2776773816/","text":"新增共享用户进入系统偏好设置，点击用户和群组，添加共享用户。 设置共享进入系统偏好设置，点击共享，设置共享相关配置。 访问共享在windows中访问Mac OS的共享文件。","tags":[{"name":"Mac OS","slug":"Mac-OS","permalink":"http://www.jifu.io/tags/Mac-OS/"},{"name":"SMB","slug":"SMB","permalink":"http://www.jifu.io/tags/SMB/"},{"name":"文件共享","slug":"文件共享","permalink":"http://www.jifu.io/tags/文件共享/"}],"categories":[{"name":"OPS","slug":"OPS","permalink":"http://www.jifu.io/categories/OPS/"},{"name":"MacOS","slug":"OPS/MacOS","permalink":"http://www.jifu.io/categories/OPS/MacOS/"}]},{"title":"苹果 Mac 重置 SMC、NVRAM、PRAM 方法教程 - 解决 macOS 卡顿或无法启动","date":"2021-02-06T09:02:47.000Z","path":"posts/3653564083/","text":"简介使用苹果 mac 或 MacBook 电脑的过程中，经常会遇到各种各样的问题和疑难杂症，比如系统卡顿、无法启动等。如果联系苹果客服技术支持，很多时候他们都会引导你首先尝试重置 SMC、重置 NVRAM 和 PRAM 等措施。 很多疑难杂症在经过重置 SMC、NVRAM、PRAM 之后都神奇地解决了。所以如果你的 Mac 也遇到了一些奇奇怪怪的问题，不妨自行尝试重置一下，有时真的会有奇效。注意：本文仅适合搭载 Intel 处理器的 Mac 电脑，配备 M1 芯片的 Mac 并不适用。 Mac 重置 SMC 方法教程SMC 系统管理控制器，重置系统管理控制器 (SMC) 可以解决某些与电源、电池和其他功能相关的问题。包括比如电源按钮、USB 端口的电源；电池和充电；风扇和其他热能管理功能；指示灯或感应器，例如状态指示灯（睡眠状态、电池充电状态等）、突发移动感应器、环境光传感器和键盘背光；打开和合上笔记本电脑盖时的行为等等…… 检查你的 Mac 是否配备 T2 芯片点击左上角菜单的  →“关于本机”→“系统报告”→“控制器” 中就能看到你的 Mac 是否配备 Apple T2 芯片了。 配备 T2 芯片的 Mac 重置 SMC 方法教程配备 T2 芯片的笔记本电脑的重置方法 (MacBook 等)重置 SMC 之前，请尝试以下步骤： 将 Mac 关机。 按住电源按钮 10 秒钟，然后松开这个按钮。 等待几秒钟，然后按下电源按钮以将 Mac 开机。 如果问题仍然存在，请按照以下步骤重置 SMC： 将 Mac 关机。 在内建键盘上，同时按住左侧的 Control + Option (Alt) +Shift。Mac 可能会开机。 按住全部三个按键 7 秒钟，然后在不松开按键的情况下按住电源按钮。如果 Mac 处于开机状态，它将在您按住这些按键时关机。 继续按住全部四个按键 7 秒钟，然后松开这些按键。 等待几秒钟，然后按下电源按钮以将 Mac 开机。 配备 T2 芯片的台式电脑 (iMac / Mac Mini / Mac Pro 等) 将 Mac 关机，然后拔下电源线。 等待 15 秒钟，然后重新接回电源线。 等待 5 秒钟，然后按下电源按钮以将 Mac 开机。 其他 Mac 上重置 SMC 方法教程 (无 T2 芯片)：如果您的 Mac 没有配备 Apple T2 安全芯片，请按照以下步骤操作。 装有不可拆卸电池的笔记本电脑 (MacBook)这类电脑包括 2009 年中至 2017 年推出的 MacBook 机型、2017 年或之前推出的 MacBook Air 机型，以及所有 MacBook 机型，但 MacBook（13 英寸，2009 年中）除外。 将 Mac 关机。 在内建键盘上，同时按住键盘左侧的 Shift + Control + Option (Alt) 在按住全部三个按键的情况下，按住电源按钮。 全部 4 个按键已被按下的笔记本电脑键盘 按住全部四个按键 10 秒钟。 松开所有按键，然后按下电源按钮以将 Mac 开机。 装有可拆卸电池的笔记本电脑 (早期型号)这类电脑包括 2009 年初或之前推出的所有 MacBook Pro 和 MacBook 机型，以及 MacBook（13 英寸，2009 年中）。 将 Mac 关机。 拆下电池。 按住电源按钮 5 秒钟。 重新安装电池。 按下电源按钮以将 Mac 开机。 台式电脑 (iMac / Mac Pro / Mac Mini 等) 将 Mac 关机，然后拔下电源线。 等待 15 秒钟，然后重新接回电源线。 等待 5 秒钟，然后按下电源按钮以将 Mac 开机。 重置 Mac 上的 NVRAM 或 PRAM 方法教程NVRAM（非易失性随机访问存储器）是一小部分内存，Mac 使用这些内存来储存某些设置。同样，PRAM（参数 RAM）也储存着类似的信息，且 NVRAM 和 PRAM 的重置步骤完全相同。 重置 NVRAM / PRAM 可以解决一些设置问题，包括音量、显示屏分辨率、启动磁盘选择、时区，以及最近的内核崩溃信息；或者解决 Mac 系统无法启动的问题。 怎样重置 Mac 的 NVRAM 和 PRAM 将 Mac 关机 然后开机并立即同时按住以下四个按键：Option + Command + P + R 您可以在大约 20 秒后松开这些按键，在此期间您的 Mac 可能看似在重新启动。 如果 Mac 电脑发出启动声，您可以在第二次启动声过后松开这些按键。 在搭载 Apple T2 安全芯片的 Mac 电脑上，您可以在 Apple 标志第二次出现并消失后松开这些按键。 注意：如果您的 Mac 使用了 固件密码 这个组合键将不起任何作用或导致您的 Mac 从 MacOS 恢复功能启动。要重置 NVRAM，请先关闭固件密码。 如果你重置了 NVRAM 和 PRAM，在您的 Mac 启动后，您可能需要打开 “系统偏好设置” 并调整已重置的任何设置，例如音量、显示屏分辨率、启动磁盘选择或时区。 如果您使用的是 Mac 台式电脑而非笔记本电脑，并且每次关闭 Mac 并断开 Mac 电源时，音量或时区等设置均会重置，则您可能需要更换 Mac 中的电池。这个小电池位于电脑的主板上，用于在断开 Mac 电源连接时帮助 NVRAM 保存设置。您可以携 Mac 前往 Apple 服务提供商处来更换该电池。 如果遇到了与睡眠、唤醒、电源、为 Mac 笔记本电脑电池充电有关的问题或其他与电源相关的症状，您可能需要根据本文前面的方法重置 SMC（系统管理控制器）。","tags":[{"name":"Mac OS","slug":"Mac-OS","permalink":"http://www.jifu.io/tags/Mac-OS/"},{"name":"Mac","slug":"Mac","permalink":"http://www.jifu.io/tags/Mac/"},{"name":"NVRAM","slug":"NVRAM","permalink":"http://www.jifu.io/tags/NVRAM/"},{"name":"SMC","slug":"SMC","permalink":"http://www.jifu.io/tags/SMC/"},{"name":"PRAM","slug":"PRAM","permalink":"http://www.jifu.io/tags/PRAM/"},{"name":"卡顿","slug":"卡顿","permalink":"http://www.jifu.io/tags/卡顿/"}],"categories":[{"name":"OPS","slug":"OPS","permalink":"http://www.jifu.io/categories/OPS/"},{"name":"MacOS","slug":"OPS/MacOS","permalink":"http://www.jifu.io/categories/OPS/MacOS/"}]},{"title":"深入了解 gradle 和 maven 的区别","date":"2021-02-06T08:45:53.000Z","path":"posts/1797699998/","text":"介绍gradle 和 maven 都可以用来构建 java 程序，甚至在某些情况下，两者还可以互相转换，那么他们两个的共同点和不同点是什么？我们如何在项目中选择使用哪种技术呢？一起来看看吧。 虽然 gradle 和 maven 都可以作为 java 程序的构建工具。但是两者还是有很大的不同之处的。我们可以从下面几个方面来进行分析。 可扩展性Google 选择 gradle 作为 android 的构建工具不是没有理由的，其中一个非常重要的原因就是因为 gradle 够灵活。一方面是因为 gradle 使用的是 groovy 或者 kotlin 语言作为脚本的编写语言，这样极大的提高了脚本的灵活性，但是其本质上的原因是 gradle 的基础架构能够支持这种灵活性。 你可以使用 gradle 来构建 native 的 C/C++ 程序，甚至扩展到任何语言的构建。 相对而言，maven 的灵活性就差一些，并且自定义起来也比较麻烦，但是 maven 的项目比较容易看懂，并且上手简单。 所以如果你的项目没有太多自定义构建需求的话还是推荐使用 maven，但是如果有自定义的构建需求，那么还是投入 gradle 的怀抱吧。 性能比较虽然现在大家的机子性能都比较强劲，好像在做项目构建的时候性能的优势并不是那么的迫切，但是对于大型项目来说，一次构建可能会需要很长的时间，尤其对于自动化构建和 CI 的环境来说，当然希望这个构建是越快越好。 Gradle 和 Maven 都支持并行的项目构建和依赖解析。但是 gradle 的三个特点让 gradle 可以跑的比 maven 快上一点： 增量构建gradle 为了提升构建的效率，提出了增量构建的概念，为了实现增量构建，gradle 将每一个 task 都分成了三部分，分别是 input 输入，任务本身和 output 输出。下图是一个典型的 java 编译的 task。 以上图为例，input 就是目标 jdk 的版本，源代码等，output 就是编译出来的 class 文件。 增量构建的原理就是监控 input 的变化，只有 input 发送变化了，才重新执行 task 任务，否则 gradle 认为可以重用之前的执行结果。 所以在编写 gradle 的 task 的时候，需要指定 task 的输入和输出。 并且要注意只有会对输出结果产生变化的才能被称为输入，如果你定义了对初始结果完全无关的变量作为输入，则这些变量的变化会导致 gradle 重新执行 task，导致了不必要的性能的损耗。 还要注意不确定执行结果的任务，比如说同样的输入可能会得到不同的输出结果，那么这样的任务将不能够被配置为增量构建任务。 构建缓存gradle 可以重用同样 input 的输出作为缓存，大家可能会有疑问了，这个缓存和增量编译不是一个意思吗？ 在同一个机子上是的，但是缓存可以跨机器共享. 如果你是在一个 CI 服务的话，build cache 将会非常有用。因为 developer 的 build 可以直接从 CI 服务器上面拉取构建结果，非常的方便。 Gradle 守护进程gradle 会开启一个守护进程来和各个 build 任务进行交互，优点就是不需要每次构建都初始化需要的组件和服务。 同时因为守护进程是一个一直运行的进程，除了可以避免每次 JVM 启动的开销之外，还可以缓存项目结构，文件，task 和其他的信息，从而提升运行速度。 我们可以运行 gradle –status 来查看正在运行的 daemons 进程。 从 Gradle 3.0 之后，daemons 是默认开启的，你可以使用 org.gradle.daemon=false 来禁止 daemons。 我们可以通过下面的几个图来直观的感受一下 gradle 和 maven 的性能比较： 使用 gradle 和 maven 构建 Apache Commons Lang 3 的比较 使用 gradle 和 maven 构建小项目（10 个模块，每个模块 50 个源文件和 50 个测试文件）的比较 使用 gradle 和 maven 构建大项目（500 个模块，每个模块 100 个源文件和 100 个测试文件）的比较 可以看到 gradle 性能的提升是非常明显的。 依赖的区别gradle 和 maven 都可以本地缓存依赖文件，并且都支持依赖文件的并行下载。 在 maven 中只可以通过版本号来覆盖一个依赖项。而 gradle 更加灵活，你可以自定义依赖关系和替换规则，通过这些替换规则，gradle 可以构建非常复杂的项目。 因为 maven 出现的时间比较早，所以基本上所有的 java 项目都支持 maven，但是并不是所有的项目都支持 gradle。如果你有需要把 maven 项目迁移到 gradle 的想法，那么就一起来看看吧。 根据我们之前的介绍，大家可以发现 gradle 和 maven 从本质上来说就是不同的，gradle 通过 task 的 DAG 图来组织任务，而 maven 则是通过 attach 到 phases 的 goals 来执行任务。 虽然两者的构建有很大的不同，但是得益于 gradle 和 maven 相识的各种约定规则，从 maven 移植到 gradle 并不是那么难。 要想从 maven 移植到 gradle，首先要了解下 maven 的 build 生命周期，maven 的生命周期包含了 clean，compile，test，package，verify，install 和 deploy 这几个 phase。 我们需要将 maven 的生命周期 phase 转换为 gradle 的生命周期 task。这里需要使用到 gradle 的 Base Plugin，Java Plugin 和 Maven Publish Plugin。 先看下怎么引入这三个 plugin： plugins { id 'base' id 'java' id 'maven-publish'} clean 会被转换成为 clean task，compile 会被转换成为 classes task，test 会被转换成为 test task，package 会被转换成为 assemble task，verify 会被转换成为 check task，install 会被转换成为 Maven Publish Plugin 中的 publishToMavenLocal task，deploy 会被转换成为 Maven Publish Plugin 中的 publish task。 有了这些 task 之间的对应关系，我们就可以尝试进行 maven 到 gradle 的转换了。 自动转换我们除了可以使用 gradle init 命令来创建一个 gradle 的架子之外，还可以使用这个命令来将 maven 项目转换成为 gradle 项目，gradle init 命令会去读取 pom 文件，并将其转换成为 gradle 项目。 转换依赖gradle 和 maven 的依赖都包含了 group ID, artifact ID 和版本号。两者本质上是一样的，只是形式不同，我们看一个转换的例子： &lt;dependencies> &lt;dependency> &lt;groupId>log4j&lt;/groupId> &lt;artifactId>log4j&lt;/artifactId> &lt;version>1.2.12&lt;/version> &lt;/dependency> &lt;/dependencies> 上是一个 maven 的例子，我们看下 gradle 的例子怎写： dependencies { implementation 'log4j:log4j:1.2.12' } 可以看到 gradle 比 maven 写起来要简单很多。 注意这里的 implementation 实际上是由 Java Plugin 来实现的。 我们在 maven 的依赖中有时候还会用到 scope 选项，用来表示依赖的范围，我们看下这些范围该如何进行转换： compile在 gradle 可以有两种配置来替换 compile，我们可以使用 implementation 或者 api。 前者在任何使用 Java Plugin 的 gradle 中都可以使用，而 api 只能在使用 Java Library Plugin 的项目中使用。 当然两者是有区别的，如果你是构建应用程序或者 webapp，那么推荐使用 implementation，如果你是在构建 Java libraries，那么推荐使用 api。 runtime可以替换成 runtimeOnly 。 testgradle 中的 test 分为两种，一种是编译 test 项目的时候需要，那么可以使用 testImplementation，一种是运行 test 项目的时候需要，那么可以使用 testRuntimeOnly。 provided可以替换成为 compileOnly。 import在 maven 中，import 经常用在 dependencyManagement 中，通常用来从一个 pom 文件中导入依赖项，从而保证项目中依赖项目版本的一致性。 在 gradle 中，可以使用 platform() 或者 enforcedPlatform() 来导入 pom 文件： dependencies { implementation platform('org.springframework.boot:spring-boot-dependencies:1.5.8.RELEASE') implementation 'com.google.code.gson:gson' implementation 'dom4j:dom4j' } 比如上面的例子中，我们导入了 spring-boot-dependencies。因为这个 pom 中已经定义了依赖项的版本号，所以我们在后面引入 gson 的时候就不需要指定版本号了。 platform 和 enforcedPlatform 的区别在于，enforcedPlatform 会将导入的 pom 版本号覆盖其他导入的版本号： dependencies { // import a BOM. The versions used in this file will override any other version found in the graph implementation enforcedPlatform('org.springframework.boot:spring-boot-dependencies:1.5.8.RELEASE') // define dependencies without versions implementation 'com.google.code.gson:gson' implementation 'dom4j:dom4j' // this version will be overridden by the one found in the BOM implementation 'org.codehaus.groovy:groovy:1.8.6' } 转换 repositories 仓库gradle 可以兼容使用 maven 或者 lvy 的 repository。gradle 没有默认的仓库地址，所以你必须手动指定一个。 你可以在 gradle 使用 maven 的仓库： repositories { mavenCentral() } 我们还可以直接指定 maven 仓库的地址： repositories { maven { url \"http://repo.mycompany.com/maven2\" } } 如果你想使用 maven 本地的仓库，则可以这样使用： repositories { mavenLocal() } 但是 mavenLocal 是不推荐使用的，为什么呢？ mavenLocal 只是 maven 在本地的一个 cache，它包含的内容并不完整。比如说一个本地的 maven repository module 可能只包含了 jar 包文件，并没有包含 source 或者 javadoc 文件。那么我们将不能够在 gradle 中查看这个 module 的源代码，因为 gradle 会首先在 maven 本地的路径中查找这个 module。 并且本地的 repository 是不可信任的，因为里面的内容可以轻易被修改，并没有任何的验证机制。 控制依赖的版本如果同一个项目中对同一个模块有不同版本的两个依赖的话，默认情况下 Gradle 会在解析完 DAG 之后，选择版本最高的那个依赖包。 但是这样做并不一定就是正确的， 所以我们需要自定义依赖版本的功能。 首先就是上面我们提到的使用 platform() 和 enforcedPlatform() 来导入 BOM（packaging 类型是 POM 的）文件。 如果我们项目中依赖了某个 module，而这个 module 又依赖了另外的 module，我们叫做传递依赖。在这种情况下，如果我们希望控制传递依赖的版本，比如说将传递依赖的版本升级为一个新的版本，那么可以使用 dependency constraints： dependencies { implementation 'org.apache.httpcomponents:httpclient' constraints { implementation('org.apache.httpcomponents:httpclient:4.5.3') { because 'previous versions have a bug impacting this application' } implementation('commons-codec:commons-codec:1.11') { because 'version 1.9 pulled from httpclient has bugs affecting this application' } } } 注意，dependency constraints 只对传递依赖有效，如果上面的例子中 commons-codec 并不是传递依赖，那么将不会有任何影响。 同时 Dependency constraints 需要 Gradle Module Metadata 的支持，也就是说只有你的 module 是发布在 gradle 中才支持这个特性，如果是发布在 maven 或者 ivy 中是不支持的。 上面讲的是传递依赖的版本升级。同样是传递依赖，如果本项目也需要使用到这个传递依赖的 module，但是需要使用到更低的版本（因为默认 gradle 会使用最新的版本），就需要用到版本降级了。 dependencies { implementation 'org.apache.httpcomponents:httpclient:4.5.4' implementation('commons-codec:commons-codec') { version { strictly '1.9' } } } 我们可以在 implementation 中指定特定的 version 即可。 strictly 表示的是强制匹配特定的版本号，除了 strictly 之外，还有 require，表示需要的版本号大于等于给定的版本号。prefer，如果没有指定其他的版本号，那么就使用 prefer 这个。reject，拒绝使用这个版本。 除此之外，你还可以使用 Java Platform Plugin 来指定特定的 platform，从而限制版本号。 最后看一下如何 exclude 一个依赖： dependencies { implementation('commons-beanutils:commons-beanutils:1.9.4') { exclude group: 'commons-collections', module: 'commons-collections' } } 多模块项目maven 中可以创建多模块项目： &lt;modules> &lt;module>simple-weather&lt;/module> &lt;module>simple-webapp&lt;/module> &lt;/modules> 我们可以在 gradle 中做同样的事情 settings.gradle： rootProject.name = 'simple-multi-module' include 'simple-weather', 'simple-webapp' profile 和属性maven 中可以使用 profile 来区别不同的环境，在 gradle 中，我们可以定义好不同的 profile 文件，然后通过脚本来加载他们： build.gradle： if (!hasProperty('buildProfile')) ext.buildProfile = 'default' apply from: \"profile-${buildProfile}.gradle\" task greeting { doLast { println message } } profile-default.gradle： ext.message = 'foobar' profile-test.gradle： ext.message = 'testing 1 2 3' 我们可以这样来运行： > gradle greetingfoobar> gradle -PbuildProfile=test greetingtesting 1 2 3 资源处理在 maven 中有一个 process-resources 阶段，可以执行 resources:resources 用来进行 resource 文件的拷贝操作。 在 Gradle 中的 Java plugin 的 processResources task 也可以做相同的事情。 比如我可以执行 copy 任务： task copyReport(type: Copy) { from file(\"buildDir/reports/my-report.pdf\") into file(\"buildDir/toArchive\") } 更加复杂的拷贝： task copyPdfReportsForArchiving(type: Copy) { from \"buildDir/reports\" include \"*.pdf\" into \"buildDir/toArchive\" } 当然拷贝还有更加复杂的应用。这里就不详细讲解了。","tags":[{"name":"Android","slug":"Android","permalink":"http://www.jifu.io/tags/Android/"},{"name":"gradle","slug":"gradle","permalink":"http://www.jifu.io/tags/gradle/"}],"categories":[{"name":"Android Development","slug":"Android-Development","permalink":"http://www.jifu.io/categories/Android-Development/"}]},{"title":"在 M1 芯片 Mac 上使用 Homebrew","date":"2021-01-02T11:00:00.000Z","path":"posts/1525358532/","text":"Homebrew 是 Mac 上管理软件包的最实用工具之一。但截至目前，它还没有对搭载 Apple silicon 的新 Mac 机型完成适配。根据维护者在 GitHub 上发布的说明，Homebrew 正在积极适配新架构的过程中，但目前还面临一些较大障碍，如缺少基于 ARM 架构的持续集成框架、很多软件包依赖的框架或编译器（go、gcc、qt）未适配等。 但是，Homebrew 目前在新 Mac 上仍然是可用的，并且已经发布了原生支持 ARM 架构的实验性版本。本文总结我在设置过程中探索出可行、相对实用的做法。 概括而言： 在不同路径分别安装针对 X86 和 ARM 架构的两个 Homebrew 版本； 优先使用 ARM 版 Homebrew 安装软件包，用 X86 版 Homebrew 安装尚未支持新平台的命令行软件； 使用 Homebrew Bundle 功能从旧 Mac 或 X86 版 Homebrew 迁移软件包。 后文将展开说明具体步骤。由于 ARM 版 Homebrew 仍然处于早期开发阶段，且我对终端环境下系统管理的了解相对粗浅，文章内容难免存在过时或不准确之处，请不吝指正。 1. 安装 ARM 版 Homebrew根据官方规划，ARM 版 Homebrew 必须安装在 /opt/homebrew 路径下，而非此前的 /usr/local/Homebrew。由于官方的安装脚本还未更新，可以通过如下命令手动安装： cd /opt # 切换到 /opt 目录 mkdir homebrew # 创建 homebrew 目录 curl -L https://github.com/Homebrew/brew/tarball/master | tar xz --strip 1 -C homebrew （注： 如果安装和使用过程中报错，可能是因为当前用户对于 /opt/homebrew 路径没有权限。对此，可以通过 sudo chown -R $(whoami) /opt/homebrew 接管该目录。） 虽然上面的步骤已经安装了 ARM 版 Homebrew，但此时在终端中运行 brew 命令并不能直接启动该版本。这是因为默认情况下，ARM 版 Homebrew 用来安装程序的路径 /opt/homebrew/bin 并不在环境变量 PATH 中，因此终端无法检索到该路径下的 brew 程序。 为此，编辑配置文件 ~/.zshrc，加入如下内容： path=('/opt/homebrew/bin' $path) export PATH （注： 本文推定读者使用 macOS Big Sur 的默认终端 zsh，如使用 bash 或 fish，则修改 ~/.bashrc 或 ~/.config/fish/config.fish，后同。） 然后重新启动终端。这样，直接执行 brew 就可以启动 ARM 版的 Homebrew 了。 跑题：为什么 ARM 版 Mac 要使用 /opt 路径？根据《文件系统层次结构标准》（Filesystem Hierarchy Standard，主要为 Linux 系统制定，但对具有共同 UNIX 基因的 macOS 也有参考价值）： /usr/local 目录用于系统管理员在本地安装软件。系统软件更新时，该目录应免于被覆盖。 /opt 目录留作附加应用程序（add-on application）软件包的安装。安装在该目录下的软件包必须将其静态文件放置在单独的 /opt/&lt;package&gt; 或 /opt/&lt;provider&gt; 路径下。 历史上，/usr/local 主要用于放置在本地编译并另行安装的程序，避免和 /usr 下的系统自带版本冲突；而 /opt 则用于安装非系统自带的、第三方预先编译并发行的独立软件包。 显然，在如今的 macOS 使用场景下，用户很少会需要自行编译软件包，/usr/local 和 /opt 的区分一定程度上已经成为名义上的了。Homebrew 启用 /opt 作为 ARM 版的安装路径，可能更多是出于确保与 X86 版相互区隔的考虑。 2. 安装 X86 版 Homebrew如上所述，由于很多软件包目前还没有适配 ARM 架构（可以在 Homebrew 的 Apple silicon issue 页面查询），无法通过 ARM 版 Homebrew 安装，因此我们还需要安装一份 X86 版的 Homebrew 备用。 X86 版 Homebrew 无法在 ARM 环境下安装。为此，需要先启动一个 X86 环境的终端。网络上传播较广的方法是创建一个 Terminal.app 的副本，然后令其在 Rosetta 兼容模式下运行，显得有些麻烦。 其实，注意到在任何命令前增加 arch -x86_64，就可以以 X86 模式运行该命令。因此，运行： arch -x86_64 $SHELL 就可以启动一个 X86 模式终端，使得之后运行的命令都在 X86 模式下运行。 此时，运行 Homebrew 的官方安装脚本 /bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\" 就可以完成 X86 版 Homebrew 的安装。 3. ARM 和 X86 版 Homebrew 的共存问题经过上面的步骤，系统中目前有了两个 brew 程序，即 X86 版的 /usr/local/bin/brew 和 ARM 版的 /opt/homebrew/bin/brew。那么，当在终端中执行 brew 命令时，系统会以哪个为准呢？ 当存在重名程序时，终端会按照重名程序在环境变量 PATH 中的先后顺序选择要执行的版本。由于之前配置 ~/.zshrc 时，将 ARM 版 Homebrew 的路径放在了 PATH 的最前面，因此执行 brew 时，位于 /opt/homebrew/bin/brew 的 ARM 版将被优先运行。如果要运行 X86 版，则需要手动输入完整路径 arch -x86_64 /usr/local/bin/brew。 如果觉得输入这么长的命令过于麻烦，可以在 ~/.zshrc 中为两个版本分别设置简称（alias）： abrew='/opt/homebrew/bin/brew' # ARM Homebrew ibrew='arch -x86_64 /usr/local/bin/brew' # X86 Homebrew 这样，执行 abrew install &lt;package&gt; 就可以调用 ARM 版 Homebrew 安装软件包，执行 ibrew install &lt;package&gt; 就可以调用 X86 版，从而不容易混淆。 至于应该使用哪个版本的 Homebrew 安装软件包，需要区别考虑： 对于命令行（CLI）程序：可以优先尝试使用 ARM 版 Homebrew 安装，保证获得针对新架构编译的版本，实现最佳的运行效果。但注意： 有的软件包已经兼容新架构、但还没有发布相应的编译版，需要安装的过程中在本地编译，耗时会相对很长； 如果软件包还没有兼容新架构，使用 ARM 版 Homebrew 安装会报错，此时可以换用 X86 版 Homebrew 安装。 对于图形界面（GUI）程序，即通过 Homebrew Cask 安装的 .app 程序：对于这类软件，Homebrew 起的作用只是从官方渠道下载这些软件的安装包，然后安装到 /Applications 路径（及执行安装脚本，如果有）。因此无论其是否针对新架构优化，通过任一版本 Homebrew 都可以安装。考虑到日后维护方便，建议直接用 ARM 版 Homebrew 安装即可。 4. 从旧 Mac（或 X86 版 Homebrew）迁移软件包如果你在拿到 M1 版 Mac 以后，选择了从旧 Mac 迁移数据、或恢复 Time Machine 备份，那么系统中可能已经有了遗留的 X86 版 Homebrew 和用它安装的软件包。此外，你可能也希望将以往惯用的软件包无遗漏地迁移到新 Mac。这些情况下，可以使用 Homebrew Bundle 功能辅助迁移工作。 要导出使用 X86 版 Homebrew 安装的软件包列表，运行： /usr/local/bin/brew bundle dump 就能在当前目录下得到一个名为 Brewfile 的备份文件。该文件可以用普通文本编辑器打开，列举了所有已安装软件包、添加的第三方软件源（tap）、Homebrew Cask 管理的 GUI 程序和 mas-cli 管理的 Mac App Store 程序： tap \"homebrew/bundle\" tap \"homebrew/cask\" […] brew \"dash\" brew \"ffmpeg\" […] cask \"bartender\" cask \"bettertouchtool\" […] mas \"Apple Configurator 2\", id: 1037126344 mas \"Aviary\", id: 1522043420 […] 记下 Brewfile 的路径。然后，使用 ARM 版 Homebrew 导入其内容并安装： /opt/homebrew/bin/brew bundle --file /path/to/Brewfile 就完成了迁移。 需要注意的是，如果你是在同一台机器的两版 Homebrew 间迁移，那么并不需要迁移通过 Homebrew Cask 和 App Store 安装的 GUI 程序（Homebrew 也不会允许覆盖安装）。这时，可以手动编辑上述 Brewfile，将以 cask 和 mas 开头的记录删除，然后再通过 brew bundle 导入。 如果想让 ARM 版 Homebrew 接管已经安装的 Homebrew Cask 软件，只要将位于 /usr/local/Caskroom 下的各文件夹移动到 /opt/homebrew/Caskroom 即可： mv /usr/local/Caskroom/* /opt/homebrew/Caskroom","tags":[{"name":"Homebrew","slug":"Homebrew","permalink":"http://www.jifu.io/tags/Homebrew/"},{"name":"Mac","slug":"Mac","permalink":"http://www.jifu.io/tags/Mac/"},{"name":"M1","slug":"M1","permalink":"http://www.jifu.io/tags/M1/"},{"name":"Mac Silicon","slug":"Mac-Silicon","permalink":"http://www.jifu.io/tags/Mac-Silicon/"}],"categories":[{"name":"OPS","slug":"OPS","permalink":"http://www.jifu.io/categories/OPS/"},{"name":"MacOS","slug":"OPS/MacOS","permalink":"http://www.jifu.io/categories/OPS/MacOS/"}]},{"title":"REST Client 简单好用的接口测试辅助工具","date":"2020-09-26T01:00:23.000Z","path":"posts/4165683660/","text":"介绍今天给大家介绍一个后端开发辅助的好工具 —— REST Client，插件如其名这就是一个 REST 的客户端插件，把我们的 VSCode 转化为一个 REST 接口测试的利器 我们一般都会用 PostMan 来完成接口测试的工作，因为用起来十分简单快捷，但是一直以来我也在寻找更好的方案，一个不用切换窗口多开一个 app 的方案 —— 终于在使用 VSCode 一段时版本间，我找到了 REST Client 插件，初看 REST Client 插件的时候，会觉得他十分的简陋，但是在使用一段时间后会发现在 REST Client 插件中已经有完成接口测试所需的所有东西 优势 基于 HTTP 语言，HTTP 语言是一门非常简单的语言，使用 HTTP 语言可以轻松的描述请求 纯文本记录，不同于 PostMan 保存在云端，或是 Paw 那样保存二进制文件，并且纯文本可以使用 git 追踪内容的变化 无需切换窗口，测试，调试，代码编辑都在一个 VSCode 中完成 劣势 操作和使用不像 PostMan 之类的图形化工具那么直观 不支持请求前后对数据进行操作的脚本，不过这个已经在作者的开发计划中 很多时候我们只是需要写完代码后手边有一个小工具可以轻松愉快的看一眼接口是否正常，那么 REST Client 就是我们的首选了 使用介绍安装和入门插件的安装非常简单，搜索 rest client 即可安装 安装完成后，可以在命令菜单中找到 REST Client 相关的功能 简单请求我们先从发送最简单的请求开始 首先需要新建一个 http 文件，创建文件时后缀为 http 即可，例如 test.http 之后输入下面的内容： GET http://localhost:8000/api/v1/public/echo?msg=1345asdf HTTP/1.1 echo 是一个测试服务，他会返回你传入的 msg 的内容，输入完上面的 这时候请求上面会显示一个 “Send Request” 按钮，点击即可发送请求，请求完成后，插件会分割当前窗口将新的结果打开在右侧的窗口中，下图中显示了请求的所有相关信息 HTTP 语言基础语言入门HTTP 是一个非常简单的语言，入门仅需几分钟 最基本的 HTTP 语言语法入门可以参看上面的内容，配合 VSCode 的自动提示功能，用起来简直不要太快 也不用担心是否记得 header 里面那些选项，想不起来的时候 Ctrl + 空格 调出自动提示即可 要注意的地方 请求文本最后面需要有一个空行，或者一个 # 开头的行，建议空行，这样多个请求看起来会非常好看 如果需要把 form 类型的参数拆分为多行，那么第二个参数开始必须以 &amp; 开始（如图） GET 请求也可以将参数拆分多行，每行开头必须以 ? 或者 &amp; 开始 发送文件一般来说，我们使用 multipart/form-data 请求方式来完成 如图配置，REST Client 就会将文件内容填充到相应的区域完成发送 保存请求结果对于返回图片的接口在 VSCode 中是可以直接预览的，如果是 Excel 之类的二进制文件，那么这里可能会显示乱码（二进制文件） 选中相应结果页，右上角提供了保存结果的按钮 查看请求历史使用 Ctrl + Alt + H（macOS 使用 Cmd + option + H）查看请求历史 使用变量变量的好处，在开发过程中我们都知道，在 HTTP 语言中同样可以使用变量来帮助我们组织请求代码 自定义变量我们可以在 http 文件中直接定义变量，使用 @ 符号开头，以 { {variable name} } 的格式来使用 @host = http://localhost:8000 @token = adsfasdfasdfadsfasdfasdfas ### test GET { {host} }/api/v1/public/echo HTTP/1.1 ?msg=1345asdf &amp;bundle_id=demo &amp;test=1 &amp;token={ {token} } ### test request POST { {host} }/api/v1/public/echo HTTP/1.1 Content-Type: application/x-www-form-urlencoded User-Agent: iPhone test=1 &amp;bundle_id=demo &amp;msg=123123 &amp;token={ {token} } 这样在测试验证不同环境接口正确性的场合，我们可以很方便的在不同服务器之间切换，或是所有接口都使用同一个参数的时候非常方便例如上面的 token 应该是大部分接口都会使用到的 环境变量除了使用自定义变量以外还可以对当前的项目或是创建编辑器全局的环境变量 &quot;rest-client.environmentVariables&quot;: { &quot;$shared&quot;: { &quot;version&quot;: &quot;v1&quot; }, &quot;local&quot;: { &quot;version&quot;: &quot;v2&quot;, &quot;host&quot;: &quot;http://localhost:8000&quot;, &quot;token&quot;: &quot;tokentokentokentoken1&quot; }, &quot;prod&quot;: { &quot;host&quot;: &quot;http://api.xxxxxx.com&quot;, &quot;token&quot;: &quot;tokentokentoken2&quot; } } 上面 $shared 中的变量表示在所有环境设置中都可以使用的 设置后可通过 Ctrl + Alt + E（Cmd + option + E）切换环境 系统变量REST Client 提供了一些自带的系统变量，方便我们直接使用（这里由于我没有使用过 Azure 所以跳过了 Azure 相关的变量，大家可以参考文档使用） { { $guid} }: 生成一个 UUID { { $randomInt min max} }: 生成随机整数 { { $timestamp [offset option]} }: 生成时间戳，可以使用类似 { { $timestamp -3 d} } 生成3天前的时间戳，或是使用 { { $timestamp 2 h} } 这样的形式生成2小时后的时间戳 { { $datetime rfc1123|iso8601 [offset option]} }: 生成日期字符串 VSCode 提供的辅助功能VSCode 对我们使用 HTTP 语言提供了包括自动提示，Outline 代码导航功能，方便我们编写接口测试代码 自动提示 Outline 以及代码导航 验证和证书Basic AuthBasic Auth 可以使用已经 Base64 后的 username:password，也可以直接填入 username 和 password，也就是下面两种形式都是可以的 使用 Base64 的结果 POST { { host} } /api/v1/public/echo HTTP/1.1 Authorization: Basic dXNlcm5hbWU6cGFzc3dvcmQ= 使用 username 和 password POST { { host} } /api/v1/public/echo HTTP/1.1 Authorization: Basic username password Digest AuthDigest Auth 直接填入 username 和 password 即可 POST { { host} } /api/v1/public/echo HTTP/1.1 Authorization: Digest username password SSL 证书ssl 证书在设置文件中对特定域名指定证书路径后，就可以自动生效了 \"rest-client.certificates\": { \"localhost:8081\": { \"cert\": \"/Users/demo/Certificates/client.crt\", \"key\": \"/Users/demo/Keys/client.key\" }, \"example.com\": { \"cert\": \"/Users/demo/Certificates/client.crt\", \"key\": \"/Users/demo/Keys/client.key\" } } 每个 host 我们可以设置下面的内容： cert: x509 证书路径 key: 私钥路径 pfx: PKCS #12 或者 PFX 证书路径 passphrase: 证书密码（需要时设置） 代码生成曾经使用 Postman 的时候，Postman 的代码生成功能为我提供了非常多的方便，REST Client 中提供了同样的功能 选中一个请求后，点击右键选择 Copy Request As cURL 可以把当前的请求复制成 curl 的命令，也可以使用 Ctrl + Alt + C（macOS 下Cmd + Option + C）呼出代码生成菜单，选择需要生成的语言 选择语言后选择具体代码调用的方式，比如 python 可以使用 http.client 库或者 Requests 库来发送请求 命名请求之前我们发送的所有请求都是匿名请求，匿名请求和命名请求的区别就是在一个 http 文件内，可以引用命名请求的请求信息和响应信息，在请求之间有依赖关系时这个功能非常有用，例如每次登录成功后其他请求都需要更新登录返回的 token，命名请求可以用过 JSONPath 或者 XPath 获取响应数据 在响应中也会显示使用到当前命名请求的变量值的更新 一些有用的设置设置响应显示内容在 REST Client 设置中的 “Preview Option” 可以设置请求响应显示什么内容，总共有四种，full，body，header，exchang 我们分别来看下四种结果显示什么内容 full：Header + Body body：只显示 Body header：只显示 Header exchange：显示请求 + Header + Body 其他常用的设置选项 rest-client.timeoutinmilliseconds: 设置请求超时，单位毫秒 rest-client.showResponseInDifferentTab: 每个响应请求创建一个新的 tab，为 false 时，每次请求会覆盖上一次的请求结果，设置为 true 时每次请求都会打开一个新的 tab，方便对比多次请求结果 rest-client.previewColumn: 请求结果显示，current 表示显示在当前的编辑器分组 beside 表示显示在侧面编辑器分组（这个侧面根据编辑器的 workbench.editor.openSideBySideDirection 选项会显示在右面或是下面 代理：使用http.proxy 和 http.proxyStrictSSL 最后其实 Postman 和 Paw 都提供更为强力的辅助工具，这里使用 REST Client 单纯觉得 Postman 和 Paw 大部分功能我其实都用不到，因为仅仅验证接口是否正常，业务是否能跑通，所以一直在寻找一个简单的工具，REST Client 刚好满足了我所有的需求","tags":[{"name":"vscode","slug":"vscode","permalink":"http://www.jifu.io/tags/vscode/"},{"name":"restful","slug":"restful","permalink":"http://www.jifu.io/tags/restful/"},{"name":"REST Client","slug":"REST-Client","permalink":"http://www.jifu.io/tags/REST-Client/"},{"name":"Plugin","slug":"Plugin","permalink":"http://www.jifu.io/tags/Plugin/"}],"categories":[{"name":"OPS","slug":"OPS","permalink":"http://www.jifu.io/categories/OPS/"},{"name":"Editor","slug":"OPS/Editor","permalink":"http://www.jifu.io/categories/OPS/Editor/"}]},{"title":"Homebrew：让你从 Mac 切换到 Linux 更轻松","date":"2020-09-25T12:03:23.000Z","path":"posts/581320548/","text":"前言 不管你是想要更舒服地从 Mac 搬到 Linux，还是不满意常规的 Linux 包管理器，都可以试试 Homebrew。 Homebrew 项目最初是为了给 Mac 用户提供一个非官方的 Linux 式的包管理器。用户很快就爱上了它友好的界面以及帮助性的提示，而且，它已经被移植到 Linux 系统 —— 这看起来像是一个奇怪的命运转折。 一开始，有两个分开的项目分别针对 macOS 和 Linux （Homebrew 与 Linuxbrew），但是现在是由 Homebrew 核心管理着这两个操作系统。由于我正 从 Mac 切换到 Linux，所以一直在研究我在 macOS 最常用的开源软件在 Linux 表现如何，最终，我很高兴地发现 Homebrew 对 Linux 的支持太赞了！ 为什么要在 Linux 使用 Homebrew 呢?长期使用 Linux 的用户对 Homebrew 的第一反应是：“为什么不直接使用……呢”，省略号代表他们喜欢的某个 Linux 包管理器。基于 Debian 的系统早就有了 apt，基于 Fedora 的系统则有 dnf 和 yum，并且像 Flatpak 跟 AppImage 这样的项目，在两种系统上都能流畅运行。我花了不少时间尝试这些技术，不得不说，它们都有其强大之处。 那我为什么还要 坚持使用 Homebrew 呢？首先，我对它非常熟悉。在为我过去使用的专有软件寻找开源替代品的过程中，我已经学会了许多使用方法，而保持一些熟悉的东西，比如 Homebrew，可以让我专注于一次学习一件事情，而不是被不同系统间的差异搞垮。 此外，我没有看到哪一个包管理器像 Homebrew 一样，对用户如此友好。正如默认的帮助命令一样，命令井然有序： 1. `$ brew -h` 2. `Example usage:` 3. `brew search [TEXT|/REGEX/]` 4. `brew info [FORMULA...]` 5. `brew install FORMULA...` 6. `brew update` 7. `brew upgrade [FORMULA...]` 8. `brew uninstall FORMULA...` 9. `brew list [FORMULA...]` 11. `Troubleshooting:` 12. `brew config` 13. `brew doctor` 14. `brew install --verbose --debug FORMULA` 16. `Contributing:` 17. `brew create [URL [--no-fetch]]` 18. `brew edit [FORMULA...]` 20. `Further help:` 21. `brew commands` 22. `brew help [COMMAND]` 23. `man brew` 24. `&lt;https://docs.brew.sh>` 过于简短的输出可能会被误解为它功能局限，但是你简单看看每一个子命令，都有很丰富的功能。虽然上面的列表只有短短 23 行，但对高级用户来说，光是子命令 install 就包含整整 79 行的帮助信息： 1. `$ brew --help | wc -l` 2. `23` 3. `$ brew install --help | wc -l` 4. `79` 它可以选择忽略或者安装依赖关系，也可以选择用源代码编译以及用什么编译器来编译某个确切的上游 Git 提交，或者选择应用的官方 “灌装” 版。总而言之，Homebrew 即适合新手，也同样能满足老鸟。 开始在 Linux 使用 Homebrew如果你想要试着使用 Homebrew，可以用这个单行脚本在 Mac 或者 Linux 上进行安装： 1. `$ /bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install.sh)\"` 这条命令会立即开始安装 Homebrew。如果你比较谨慎，可以使用 curl 将该文件下载到本地，检查完毕之后再运行。 1. `$ curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install.sh --output homebrew_installer.sh` 2. `$ more homebrew_installer.sh # 审核该脚本，直到你觉得没问题了` 3. `$ bash homebrew_installer.sh` 对 Linux 的安装步骤还包括如何配置点文件，对于 Debian 系统来说是 ~/.profile，对于 Fedora 系统是 ~/.bash_profile。 1. `$ test -d /home/linuxbrew/.linuxbrew &amp;&amp; eval $(/home/linuxbrew/.linuxbrew/bin/brew shellenv)` 2. `$ test -r ~/.bash_profile &amp;&amp; echo \"eval \\$($(brew --prefix)/bin/brew shellenv)\" >>~/.bash_profile` 3. `$ echo \"eval \\$($(brew --prefix)/bin/brew shellenv)\" >>~/.profile` 为了确认已经安装好，Homebrew 团队提供一个空的 hello “秘方” 供测试： 1. `$ brew install hello` 2. `==> Downloading https://linuxbrew.bintray.com/bottles/hello-2.10.x86_64_linux.bottle.tar.gz` 3. `######################################################################## 100.0%` 4. `==> Pouring hello-2.10.x86_64_linux.bottle.tar.gz` 5. `🍺 /home/linuxbrew/.linuxbrew/Cellar/hello/2.10: 52 files, 595.6KB` 看起来安装毫无问题，让我来试试更多操作。 命令行工具 BrewHomebrew 宣称自己是一款默认只 “安装你需要而 [Linux] 没有的东西”的应用程序。 你可以用 brew 命令安装任何打包在 Homebrew 中的命令行软件。这些包的定义文件叫做 “秘方formula”，而且它们通过“瓶子bottle”来编译并分享。在 Homebrew 的世界里，还有许多 “啤酒方面” 的术语，但这个包管理器主要目的是让软件便于使用。 都有些什么样的软件呢？对我这样的技术玩家（既然你已经在读这篇文章，估计你也是）来说最方便的东西。例如，便利的 tree 命令，可以展示目录结构，或者 pyenv，我用它来 在 Mac 管理不同版本 Python。 你可以用 search 命令查看所有可以安装的“秘方”，在后面加上 wc 命令看看一共有多少： 1. `# -l 选项统计行数` 2. `$ brew search | wc -l` 3. `5087` 迄今为止，一共有 5000 多个 “秘方”，这囊括了很多软件。需要注意的是：并非所有 “秘方” 都能在 Linux 运行。在 brew search --help 输出中有一节提到可以按软件运行的操作系统来筛选软件。它会在浏览器打开用于每个操作系统的软件仓库。我运行的是 Fedora，所以我会用它来试一试： 1. `$ brew search --fedora tree` 浏览器打开了网址 https://apps.fedoraproject.org/packages/s/tree，向我展示了所有 Fedora 的可用选项。你也可以通过其它方法进行浏览。“秘方” 被集中整理到由操作系统划分的核心仓库当中（Mac 在 Homebrew Core，Linux 在 Linux Core）。同样也可以通过 Homebrew API 在网页显示。 即使有这些选择，我还是通过其它用户的推荐找到很多新工具。我列出一些我最喜欢的工具，你可以在里面找点灵感： pyenv、rbenv 和 nodenv 用来管理（相应的） Python、Ruby 和 Node.js 版本 imagemagick 用于脚本化编辑图片 pandoc 用于脚本化转换文档格式（我通常将 .docx 文件转成 .md 或者 .html） hub 为 GitHub 用户提供 更好的 Git 体验 tldr 展示了命令工具的使用范例 想要深入了解 Homebrew，可以去 trldr 页面 看看，比起应用的 man 页面，它要友好得多。使用 search 命令确认你可以安装： 1. `$ brew search tldr` 2. `==> Formulae` 3. `tldr ✔` 太好了！对勾说明你可以安装。那么继续吧： 1. `$ brew install tldr` 2. `==> Downloading https://linuxbrew.bintray.com/bottles/tldr-1.3.0_2.x86_64_linux.bottle.1.tar.gz` 3. `######################################################################## 100.0%` 4. `==> Pouring tldr-1.3.0_2.x86_64_linux.bottle.1.tar.gz` 5. `🍺 /home/linuxbrew/.linuxbrew/Cellar/tldr/1.3.0_2: 6 files, 63.2KB` Homebrew 提供了编译好的二进制文件，所以你不必在本地机器上从源码编译。这能节省很多时间，也不用听 CPU 风扇的噪声。我很欣赏 Homebrew 的另外一点是，你不完全理解每一个选项的含义也不会影响正常使用。若你想自己编译，可以在 brew install 命令后面加上 -s 或者 --build-from-source 标识，这样就能从源码编译 “秘方”（即便已经有一个 “瓶子” 存在）。 同样，软件底层的复杂性也很有意思。使用 info 可以查看 tldr 软件的依赖管理，“秘方” 的源代码存放在磁盘上的何处，甚至还能查看公开分析。 1. `$ brew info tldr` 2. `tldr: stable 1.3.0 (bottled), HEAD` 3. `Simplified and community-driven man pages` 4. `https://tldr.sh/` 5. `Conflicts with:` 6. ``tealdeer (because both install `tldr` binaries)`` 7. `/home/linuxbrew/.linuxbrew/Cellar/tldr/1.3.0_2 (6 files, 63.2KB) *` 8. `Poured from bottle on 2020-06-08 at 15:56:15` 9. `From: https://github.com/Homebrew/linuxbrew-core/blob/master/Formula/tldr.rb` 10. `==> Dependencies` 11. `Build: pkg-config ✔` 12. `Required: libzip ✔, curl ✔` 13. `==> Options` 14. `--HEAD` 15. `Install HEAD version` 16. `==> Analytics` 17. `install: 197 (30 days), 647 (90 days), 1,546 (365 days)` 18. `install-on-request: 197 (30 days), 646 (90 days), 1,546 (365 days)` 19. `build-error: 0 (30 days)` 从 Mac 到 Linux 的一点不足在 macOS，Homebrew 的 cask（“酒桶”）子命令可以让用户使用命令行安装、管理整个应用软件。不幸的是，cask还不能在任何 Linux 发行版上使用。我在安装一个开源工具时发现了这点： 1. `$ brew cask install tusk` 2. `Error: Installing casks is supported only on macOS` 我在 论坛上 问了一下，很快得到其他用户的反馈。总结一下，方案如下： 复刻 Homebrew 项目，构建这个特性，然后像别人展示其价值 给该软件写一个 “秘方”，然后从源代码编译 为该软件创建一个第三方仓库 最后一个是我最感兴趣的。Homebrew 通过 创建并维护 “水龙头tap” （另一个受啤酒影响的术语）管理第三方仓库。随着你对系统越来越熟悉，并想加入生态系统， “水龙头” 是值得研究的。 备份 Homebrew 的安装记录我最中意的 Homebrew 特性之一就是你可以像其它任何 用版本控制工具来备份点文件 一样备份你的安装记录。为了实现这个目的，Homebrew 提供 bundle（“捆扎”）子命令，它可以控制一个叫 dump（“倾倒”）的子命令生成一个 Brewfile。这个文件包含你目前所有安装的工具列表，可以重复使用。进入你想使用的目录然后运行命令，它会根据你所安装的软件生成 Brewfile： 1. `$ cd ~/Development/dotfiles # This is my dotfile folder` 2. `$ brew bundle dump` 3. `$ ls Brewfile` 4. `Brewfile` 当我换了一台机器，想要安装一样的软件时，进入含有 Brewfile 的文件夹，然后重新安装： 1. `$ ls Brewfile` 2. `Brewfile` 3. `$ brew bundle` 它会在我的新机器上安装所有列出的 “秘方”。 在 Mac 和 Linux 同时管理 BrewfileBrewfile 非常适合备份你目前的安装记录，但是如果某些在 Mac 上运行的软件无法运行在 Linux 呢？或者刚好相反？我发现不管是 Mac 还是 Linux，如果软件无法在当前操作系统运行，Homebrew 会优雅地忽略那一行。如果它遇到不兼容的请求（比如使用 brew 在 Linux 安装 “酒桶cask” 时），它会选择跳过，继续安装过程： 1. `$ brew bundle --file=Brewfile.example` 3. `Skipping cask licecap (on Linux)` 4. `Skipping cask macdown (on Linux)` 5. `Installing fish` 6. `Homebrew Bundle complete! 1 Brewfile dependency now installed.` 为了保持配置文件的简洁，我在两个操作系统上使用同一份 Brewfile，因为它只安装与操作系统相关的版本，所以我一直没有遇到任何问题。 使用 Homebrew 管理软件包Homebrew 已经成了我必备的命令行工具，由于我很熟悉它，所以在 Linux 上的体验也充满乐趣。Homebrew 让我的工具井然有序，并且时刻保持更新，我愈发欣赏它在实用性与功能上找到的平衡点。我更喜欢将软件包管理的细节保持在用户需要了解的最小程度，大多数人都会从中受益。如果你已经很熟悉 Linux 包管理器了，Homebrew 可能会让你觉得很基础，但稍微深入一点看，就会发现它的高级选项远远超过本文的内容。 对 Linux 用户来说，他们有很多包管理器可以选择。如果你来自 MacOS，Homebrew 会让你宾至如归。","tags":[{"name":"command","slug":"command","permalink":"http://www.jifu.io/tags/command/"},{"name":"MacOS","slug":"MacOS","permalink":"http://www.jifu.io/tags/MacOS/"},{"name":"Homebrew","slug":"Homebrew","permalink":"http://www.jifu.io/tags/Homebrew/"}],"categories":[{"name":"OPS","slug":"OPS","permalink":"http://www.jifu.io/categories/OPS/"},{"name":"MacOS","slug":"OPS/MacOS","permalink":"http://www.jifu.io/categories/OPS/MacOS/"}]},{"title":"命令行信息截图工具 - ScreenFetch","date":"2020-08-11T05:17:21.000Z","path":"posts/3895039994/","text":"摘要screenFetch 是一个“命令行信息截图工具”。它可以在终端上显示系统信息，并进行桌面截图。它能生成漂亮的文本的系统信息和ASCII艺术的发行版LOGO，然后显示在截屏图片中。 它会自动检测你的发行版并显示其ASCII版本的LOGO，在其右侧显示系统信息。可以通过选项来指定是否显示LOGO、指定颜色，进行截图，甚至可以自定义截图的命令。screenFectch非常容易添加和扩展。 screenFetch将显示以下系统信息 当前登录用户 操作系统版本 内核版本 总计运行时间 已安装包数量 当前shell详情 当前屏幕分辨率 当前桌面环境 当前窗口管理器（文件管理器） 总计及空闲磁盘使用百分比 CPU详情，如处理器速度、类型 总计及当前内存使用量 在Linux上安装screenFectch您可以通过直接从项目页下载源码包的方式安装，或者从screenFetch git库克隆。 源码安装下载 最新版. 我下载并安装在/home/sk/Downloads目录. 用命令解压： $unzip Downloads/screenfetch-3.1.0.zip 进入screenFectch目录，并设置执行权限. $cd screenfetch-3.1.0/ $chmod +x screenfetch-dev 在命令行运行： $./screenfetch-dev 输出示例： 通过git库安装首先确认你是否安装了git. 如果没有安装，基于RHEL系统的用户用以下命令安装： # yum install git 基于Debian系统的用户用以下命令安装: # apt-get install git 使用命令克隆screenFectch库: # git clone git://github.com/KittyKatt/screenFetch.git screenfetch 复制文件到/usr/bin/目录，并设置执行权限: # cp screenfetch/screenfetch-dev /usr/bin/screenfetch # chmod +x /usr/bin/screenfetch 运行screenFectch: # screenfetch 您将会看到如上面截图所示的结果.","tags":[{"name":"screenfetch","slug":"screenfetch","permalink":"http://www.jifu.io/tags/screenfetch/"},{"name":"command","slug":"command","permalink":"http://www.jifu.io/tags/command/"},{"name":"系统信息","slug":"系统信息","permalink":"http://www.jifu.io/tags/系统信息/"}],"categories":[{"name":"OPS","slug":"OPS","permalink":"http://www.jifu.io/categories/OPS/"},{"name":"Others","slug":"OPS/Others","permalink":"http://www.jifu.io/categories/OPS/Others/"}]},{"title":"用好这些隐藏「小开关」，让 Chrome 浏览器更好用","date":"2019-12-17T13:14:30.000Z","path":"posts/1413974522/","text":"相比移动端的 Chrome 浏览器，功能性能更强更全面的桌面端 Chrome 可能是你我每天使用频次最多的桌面软件。多端数据同步、实用的扩展插件都让其成为电脑上的「超级应用」。近乎无限制的桌面平台也让其可以在第一时间运用起新的功能和技术，这也是限制重重的移动端 Chrome 所无法比拟的。 当然因为桌面端 Chrome 的广泛使用性，新功能的推出和运用反而会更为谨慎。如果想要尝鲜新功能一样是通过 Feature flags —— 当然比起移动端，桌面端的新功能主要针对的键鼠操作，和移动端有相当大的区别。 尝鲜新功能，善用 Chrome flagsChrome 之所以被认为是「超级应用」，很大程度上在于起功能增添和更新上像极了操作系统，新功能会首先出现在 Dev 版、然后经过 Beta 测试后，最后推送到稳定通道中。而新开发的功能则被隐藏在 Chrome flags —— 作为新功能的试验田，通过开启特定的 flags 来在稳定版中尝鲜新功能，即可以尝鲜也避免了可能的不稳定风险，下面我们挑选了一些稳定性尚可且比较实用的 flags， 通过开启对应的开关来让 电脑版的 Chrome 变得更好用。 注：本文 Chrome 版本为稳定通道 v78，电脑系统为 Windows 10 v1909 开启并行下载功能移动端 Chrome 考虑到带宽和设备性能问题，只允许单进程下载其实并无不妥，而桌面端至今依旧默认单进程下载似乎就有点说不过去了，所以相比移动端，在桌面端开启并行下载功能要更为迫切一些。 开启方法和移动端一样， 在 Chrome flags 上搜索「Parallel downloading」来开启 Chrome 的并行下载功能，你可以尝试下大个文件以及多个文件，你会发现速度会提高那么一些。当然如果有条件的话，选择第三方下载工具进行资源下载反而更为合适。 开启方法chrome://flags/#enable-parallel-downloading 给标签页进行分组多标签页浏览器有时也会给我们带来烦恼——我们会不自觉的打开 n 多标签页，时间一长就会忘记哪些标签页是有关联的，比如像我就经常遇到已经打开了某个标签页但最后又重复打开的，其实对标签页分组就可以妥善解决这些问题。 这个很实用的功能同样也是默认隐藏，需要在 Chrome Flags 中搜索「Tab Groups」开启，之后将开启自动分组功能。自动分组功能将根据你的打开新标签页的方式，比如从少数派中打开的新内容页面将会自动添加到一个组中，这时会在标签页前面出现一个「组标记点」。 你还可以手动创建新的组或者将当前标签页加入组中，通过拖拽的标签页将起放在「组标记点」后面就可以添加到当前组，而移除则只需要将标签页从组中拖拽出即可，而为了标记的更清楚，点击组的标记点还可以更改颜色，也可以为组进行命名让其更明显。 开启方式chrome://flags/#tab-groups 桌面端开启阅读模式无论是 Firefox 还是旧版本的 Edge 浏览器，都内置有阅读模式，这些功能并非是多此一举，而是可以极大的提高内容阅读体验，去除广告、无关的框架样式等干扰性元素，内容重新排版之后方便进一步的深入阅读，即便不使用稍后读服务也能做到类似的信息阅读体验。 奇怪的是这个功能在桌面端的 Chrome 中依旧被隐藏在 flag 中，而开启方式是在 Chrome Flags 中找到「Enable Reader Mode 」来开启这个功能，打开之后重启浏览器，在地址栏的最右侧会出现一个新的图标，点击之后就会直接将当前网页转换成阅读模式，不过比起移动端功能丰富的设置项，桌面端的阅读模式要简陋很多，也无法对主题、字体和字号大小进行调整。 开启方式chrome://flags/#enable-reader-mode 让网页内容强制显示为深色主题macOS Mojave 开始支持系统深色主题的同时，Safari 也加入了一个新的 API，允许已经加入深色主题的网站跟随系统调整深色主题，只不过目前绝大多数的网站并不支持这一特性，而在 Chrome 中其实也支持类似功能，只不过该选项并非是默认开启同样需要通过在 Chrome flags 中手动开启。 在 Chrome Flags 中搜索「Force Dark Mode」就可以看到设置选项，并且提供了相当多的显示效果选择，选择「Enable」重启后就可以看到强制开启后的基本效果，对于没有提供网页深色主题的网站，强制开启可以认为是原先网页配色在色环上对应的反色，所以看上去的展示效果比较一般，并且不同的网站的深色主题展示效果不佳，有些网站甚至完全无法用，只能用来进行一定程度的尝鲜。 开启方式chrome://flags/#enable-force-dark 开启全局媒体播放控制播放在线多媒体时，如果需要暂停，快进等操作都要进入到标签页中进行调整，有时候标签页开的多，实在没法立即定位到播放页面就会很麻烦。有一个全局媒体播放控制可以简化这些步骤，这样就不用打开对应的标签页也可进行全局控制。 开启方法也很简单，同样是在 Chrome Flags 中搜索「 Global Media Controls 」找到之后选择「Enable」重启浏览器，这时候你打开一个视频播放页面并播放视频，同时在工具栏中就会出现一个多媒体按钮，点击就可以看到一个媒体播放选项卡，无需打开对应标签页就可以控制多媒体内容播放。 开启方式chrome://flags/#global-media-controls 鼠标悬停标签页展示网页预览图开的标签页多了之后会逐步挤占标签页的标题文本信息，想要知道里面网页内容就只能切换到该标签页查看，那么如何不切换到当前标签页就能看到到网页里面的大致内容呢？这项早已出现在经典版 Edge 浏览器上的功能在 Chrome 竟然也是隐藏功能，开启方式当然还是在 Chrome Flag —— 搜素「Tab Hover Card Images」选择开启就可以看到效果了。 开启之后当鼠标悬停在标签页时将可以看到网页内容的预览窗口了，不用切换标签页就可以看到内容可以说更为方便一些，不过这项功能对系统性能有一定的要求，如果想要更好的浏览体验可以酌情开启。 开启方式chrome://flags/#tab-hover-card-images","tags":[{"name":"技巧","slug":"技巧","permalink":"http://www.jifu.io/tags/技巧/"},{"name":"Chrome","slug":"Chrome","permalink":"http://www.jifu.io/tags/Chrome/"},{"name":"Chrome flags","slug":"Chrome-flags","permalink":"http://www.jifu.io/tags/Chrome-flags/"}],"categories":[{"name":"OPS","slug":"OPS","permalink":"http://www.jifu.io/categories/OPS/"},{"name":"Others","slug":"OPS/Others","permalink":"http://www.jifu.io/categories/OPS/Others/"}]},{"title":"Linux swap分区及作用详解","date":"2019-11-16T03:44:24.000Z","path":"posts/4024224000/","text":"我们在安装系统的时候已经建立了 swap 分区。swap 分区通常被称为交换分区，这是一块特殊的硬盘空间，即当实际内存不够用的时候，操作系统会从内存中取出一部分暂时不用的数据，放在交换分区中，从而为当前运行的程序腾出足够的内存空间。 也就是说，当内存不够用时，我们使用 swap 分区来临时顶替。这种“拆东墙，补西墙”的方式应用于几乎所有的操作系统中。 使用 swap 交换分区，显著的优点是，通过操作系统的调度，应用程序实际可以使用的内存空间将远远超过系统的物理内存。由于硬盘空间的价格远比 RAM 要低，因此这种方式无疑是经济实惠的。当然，频繁地读写硬盘，会显著降低操作系统的运行速率，这也是使用 swap 交换分区最大的限制。 相比较而言，Windows 不会为 swap 单独划分一个分区，而是使用分页文件实现相同的功能，在概念上，Windows 称其为虚拟内存，从某种意义上将，这个叫法更容易理解。因此，初学者将 swap 交换分区理解为虚拟内存是没有任何问题的。 具体使用多大的 swap 分区，取决于物理内存大小和硬盘的容量。一般来讲，swap 分区容量应大于物理内存大小，建议是内存的两倍，但不超过 2GB。但是，有时服务器的访问量确实很大，有可能出现 swap 分区不够用的情况，所以我们需要学习 swap 分区的构建方法。 建立新的 swap 分区，只需要执行以下几个步骤。 分区：不管是 fdisk 命令还是 parted 命令，都需要先区。 格式化：格式化命令稍有不同，使用 mkswap 命令把分区格式化成 swap 分区。 使用 swap 分区。 分区[root@localhost ~]# fdisk /dev/sdb #以/dev/sdb分区为例 WARNING: DOS-compatible mode is deprecated.It's strongly recommended to switch off the mode (command 'c') and change display units to sectors (command 'u'). Command (m for help): n #新建 Command action e extended p primary partition (1-4) P #主分区 Partition number (1-4): 1 #分区编号 First cylinder (1-2610, default 1): #起始柱面 Using default value 1 Last cylinder, +cylinders or +size{K, M, G} (1-2610, default 2610): +500M #大小 Command (m for help): p #查看一下 Disk /dev/sdb: 21.5GB, 21474836480 bytes 255 heads, 63 sectors/track, 2610 cylinders Units = cylinders of 16065 *512 = 8225280 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes 1512 bytes Disk identifier: OxOOOOOebd Device Boot Start End Blocks Id System /dev/sdb1 1 65 522081 83 Linux #刚分配的分区ID是83，是Linux分区，我们在这里要分配swap分区 Command (m for help): t #修改分区的系统ID Selected partition 1 #只有一个分区，所以不用选择分区了 Hex code (type L to list codes): 82 #改为swap分区的ID Changed system type of partition 1 to 82 (Linux swap / Solaris) Command (m for help): p #再查看一下 Disk /dev/sdb: 21.5 GB, 21474836480 bytes 255 heads, 63 sectors/track, 2610 cylinders Units = cylinders of 16065 *512 = 8225280 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes 1512 bytes Disk identifier: OxOOOOOebd Device Boot Start End Blocks Id System /dev/sdb1 1 65 522081 82 Linux swap / Solaris #修改过来了 Command (m for help): w #记得保存退出 The partition table has been altered! Calling ioctl() to re-read partition table. Syncing disks. 仍以 /dev/sdb 分区作为实验对象。不过，如果分区刚刚使用 parted 命令转变为 GPT 分区表，则记得转换回 MBR 分区表，fdisk 命令才能识别，否则干脆新添加一块硬盘做实验。 格式化因为要格式化成 swap 分区，所以格式化命令是 mkswap。命令如下： [root@localhost ~]# mkswap /dev/sdb1 Setting up swapspace version 1, size = 522076 KiB no label, UUID=c3351 dc3-f403-419a-9666-c24615e170fb 使用swap分区在使用 swap 分区之前，我们先来说说 free 命令。命令如下： [root@localhost ~]#free total used free shared buffers cached Mem: 1030796 130792 900004 0 15292 55420 -/+ buffers/cache: 60080 970716 Swap: 2047992 0 2047992 free 命令主要是用来查看内存和 swap 分区的使用情况的，其中： 参数 含义 total 是指总数 used 是指已经使用的 free 是指空闲的 shared 是指共享的 buffers 是指缓冲内存数 cached 是指缓存内存数，单位是KB 我们需要解释一下 buffers（缓冲）和 cached（缓存）的区别。简单来讲，cached 是给读取数据时加速的，buffers 是给写入数据加速的。cached 是指把读取出来的数据保存在内存中，当再次读取时，不用读取硬盘而直接从内存中读取，加速了数据的读取过程；buffers 是指在写入数据时，先把分散的写入操作保存到内存中，当达到一定程度后再集中写入硬盘，减少了磁盘碎片和硬盘的反复寻道，加速了数据的写入过程。 我们已经看到，在加载进新的 swap 分区之前，swap 分区的大小是 2000MB，接下来只要加入 swap 分区就可以了，使用命令 swapon。命令格式如下： [root@localhost ~]# swapon 分区设备文件名 例如： [root@localhost ~]# swapon /dev/sdb1 swap分区已加入，我们查看一下。 [root@localhost ~]#free total used free shared buffers cached Mem: 1030796 131264 899532 0 15520 55500 -/+ buffers/cache: 60244 970552 Swap: 2570064 0 2570064 swap 分区的大小变成了 2500MB，加载成功了。如果要取消新加入的 swap 分区，则也很简单，命令如下： [root@localhost ~]# swapoff /dev/sdb1 如果想让 swap 分区开机之后自动挂载，就需要修改 /etc/fstab 文件，命令如下： [root@localhost ~]#vi /etc/fstab UUID=c2ca6f57-b15c-43ea-bca0-f239083d8bd2 / ext4 defaults 1 1 UUID=0b23d315-33a7-48a4-bd37-9248e5c443451 boot ext4 defaults 1 2 UUID=4021be19-2751-4dd2-98cc-383368c39edb swap swap defaults 0 0 tmpfs /dev/shm tmpfs defaults 0 0 devpts /dev/pts devpts gid=5, mode=620 0 0 sysfs /sys sysfs defaults 0 0 proc /proc proc defaults 0 0 /dev/sdb1 swap swap defaults 0 0 #加入新swap分区的相关内容，这里直接使用分区的设备文件名，也可以使用UUID。","tags":[{"name":"swap","slug":"swap","permalink":"http://www.jifu.io/tags/swap/"}],"categories":[{"name":"OPS","slug":"OPS","permalink":"http://www.jifu.io/categories/OPS/"},{"name":"Linux","slug":"OPS/Linux","permalink":"http://www.jifu.io/categories/OPS/Linux/"},{"name":"System Service","slug":"OPS/Linux/System-Service","permalink":"http://www.jifu.io/categories/OPS/Linux/System-Service/"}]},{"title":"VScdoe error:Could not create temporary directory Permission denied","date":"2019-10-28T08:42:49.000Z","path":"posts/151598530/","text":"Could not create temporary directory: Permission deniedThis error looks familiar? ProblemIf you happen to not being able to update VScode anymore after upgrading to macOS is may be due to some permission issues. SolutionIf you are using normal VScodesudo chown $USER ~/Library/Caches/com.microsoft.VSCode.ShipIt If you are using insiders versionsudo chown $USER ~/Library/Caches/com.microsoft.VSCodeInsiders.ShipIt These commands will change the permissions of vscode folders to the current user.","tags":[{"name":"vscode","slug":"vscode","permalink":"http://www.jifu.io/tags/vscode/"},{"name":"error","slug":"error","permalink":"http://www.jifu.io/tags/error/"},{"name":"Permission denied","slug":"Permission-denied","permalink":"http://www.jifu.io/tags/Permission-denied/"}],"categories":[{"name":"OPS","slug":"OPS","permalink":"http://www.jifu.io/categories/OPS/"},{"name":"Editor","slug":"OPS/Editor","permalink":"http://www.jifu.io/categories/OPS/Editor/"}]},{"title":"Mac 时间机器 Time Machine 备份速度太慢的解决方法 (加速备份命令)","date":"2019-10-28T08:28:37.000Z","path":"posts/4147446761/","text":"相信用过一段时间电脑的人，都知道经常备份的重要性了。特别最近很多人需要将 Mac 升级到最新版本的 macOS Catalina，为防意外发生，就更需要在动手前做好备份了。 macOS 时光机器macOS 自带的「时间机器」(Time Machine)绝对就是 Mac 上最方便的备份工具了，一来完全免费，可以“无感”地替你默默在后台备份，而且因为它是苹果自家开发的，兼容性也最好，所以推荐大家都使用“时间机器”来备份 Mac 电脑。 解决时间机器备份速度太慢的问题然而部分同学在尝试使用时间机器备份系统资料时，却发现它的首次备份速度非常慢，跟自己的网络和机器配置似乎并不匹配，甚至有时花费超过 48 小时都无法完成，即便接了网线、关掉所有 APP 后，备份速度都没有明显提升。 其实，时光机器备份太慢是由于 macOS 本身对其进行了限流的措施，对硬盘读写的频率和内存使用都做了一定的限制，主要是为了防止在备份期间影响了用户正常使用电脑工作。但如果你正在等它完成备份，再去进行系统升级或其他操作，就比较悲剧了。 macOS 时光机器备份加速命令如果你真的打算让时光机器全力全速工作，那也是有办法的，就是通过命令行，用命令强制关闭系统对时光机器的限流，俗称“解除封印”。打开终端，输入以下命令： sudo sysctl debug.lowpri_throttle_enabled=0 这时你就会发现时光机器的备份速度变快很多很多了！！基本能达到网络和硬盘读写的应有的速度了。等它完成了首次的备份之后，你可以再执行下面的命令，恢复到原本限流的状态，以保证日后使用电脑时不被时光机器备份占去太多的资源导致变卡。 sudo sysctl debug.lowpri_throttle_enabled=1 当然了，如果你的时光机器备份是保存在 NAS 或路由器上网络存储的，都推荐连接“网线”进行首次备份，比起 WiFi 的速度很稳定性都是要高很多。另外，如果你使用 MacBook 的话，记得还要接通电源再备份才能获得最好的速度哦.","tags":[{"name":"Mac","slug":"Mac","permalink":"http://www.jifu.io/tags/Mac/"},{"name":"Time Machine","slug":"Time-Machine","permalink":"http://www.jifu.io/tags/Time-Machine/"},{"name":"加快备份","slug":"加快备份","permalink":"http://www.jifu.io/tags/加快备份/"}],"categories":[{"name":"OPS","slug":"OPS","permalink":"http://www.jifu.io/categories/OPS/"},{"name":"MacOS","slug":"OPS/MacOS","permalink":"http://www.jifu.io/categories/OPS/MacOS/"}]},{"title":"提高效率！24 个高手常用的 Sketch 技巧合集（附实用快捷键）","date":"2019-09-27T02:49:41.000Z","path":"posts/1525329016/","text":"Sketch 是一款轻量、易用的矢量设计工具，它为数字设计而生，小巧但功能强大，今天我总结并整理了一些 Sketch 不为人知的快捷操作，希望你可以在实际工作中得以应用。 形状的描边和填充 形状的描边快捷键是 B，填充的快捷键是 F，其实就是 Borders 和 Fills 首字母。绘制形状在默认时是带填充和描边的，按一下 B 取消描边，再按一下添加描边，填充也是同理。 直接吸取颜色 直接吸色快捷键 Control+C，Sketch 吸管工具可以吸取屏幕上任何地方的色彩。 拷贝样式 Command + Alt + C 拷贝样式，Command + Alt + V 粘贴样式。当我们设计中使用相同的样式可以调整一处，其他可以用这个快捷键来操作。样式可以包含填充、描边、颜色、阴影、字体样式等。 数值框直接进行数学运算 Sketch 支持直接在输入框内进行加减乘除的数学运算。长宽、坐标和圆角的数值是可以计算的，透明度和色值等是不可以进行计算的。 按住Shift+方向键可以每次移动10个像素 这个操作在 Photoshop 里面也有，可以增加移动步长，如果你想自定义移动的像素，可以使用 Nudged 插件来定义方向键（Arrow keys）的移动像素个数，也可以定义 Shift + 方向键（Arrow keys）的移动像素个数。 对齐的特别用法（锁定对齐） Sketch 中的对齐有上下左右居中五种对齐方式，单个对象对齐默认是以每个画板为参照物进行上下左右居中对齐，两个对象对齐时大的包含小的会依据大的为参照物进行对齐，当两个对象没有任何关系时可以锁定（Command + Shift + L）一个对象并以它为参照物进行对齐。 重新定义对象大小 选中一个对象，按住 Command + 方向键 来改变对象大小。按住 Command + Shift + 方向键，可以每次以加减 10 个像素改变对象大小。选中一个对象，按住 Alt 缩放时，矩形两侧会同时进行缩放。 快速复制元素 按住 Alt 键拖拽复制一个相同元素，你可以继续按住 Command + D 复制更多的相同元素。 组合对象 选中要组合的多个元素，Command + G 编组。Command + Shift + G 取消编组。 直接选取和框选 按住 Command 直接点选需要的对象，按住 Command + Shift 可以多选也可以直接框选。两个图层叠加在一起的时候（底下图层被覆盖），想要选择底下图层？按住 Alt 键，Sketch 会忽略上层而选择下层。 显示实际100%大小视图 查看实际大小 100% 视图，快捷键 Command + 0 （数值 0）。 显示所有画板 查看所有画板视图，快捷键 Command + 1。 显示选中的对象 显示所有选中对象视图，快捷键 Command + 2。 改变图层上下位置 选中一个对象，按住 Alt + Command + 方向键，移动对象上下图层的位置，按住 Control + Alt + Command + 方向键，移动到画板的最上层或最下层。 重命名图层 选中图层 Command + R 重命名图层。 隐藏图层和锁定图层 选中图层 Command + Shift + H 隐藏图层，Command + Shift + L 锁定图层。当界面中元素较多时需要修改，我们就可以锁定背景图层，进行框选需要修改的对象。 智能提示 选中一个对象，按住 Alt 键，通过鼠标可以测量与其他对象的像素距离，按下 Alt 键的时候还可以移动对象进行测量和排列；按住 Alt + Command 键可以测量组与组或者跨面板的组与组里面的对象的像素距离。 数字键快速设置透明度 1 到 10 不同的数字键分别代表不同透明度比例（1=10% 的透明度，以此类推）。 圆角半径 选中对象，点击面板中的圆角 Radius 设置可以通过一组数值（如16、16、0、0 ）依次对应对象上左、上右、下左、下右的每个角的半径值。 切片工具 切片工具（快捷键 S）可以导出选区内的内容。选区范围是方形的。在切图标的时候我们可以不用按照实际尺寸进行导出，可以适当增加热区，包含进去进行导出。 设置线段的中点 双击绘制完成的 Vector 图层，按住 Shift 键，会出现中点提示。 点击 Vector 时，想让其以45°角度进行变化？ 按 V 键进入到 Vector 模式，按住 Shift 此时箭头提示会以 45° 变化。 Symbol分类命名方便查找 使用 / 可以对 Symbol 进行分类，方便查找。 用矩形画1px，用内阴影画0.5px 用矩形工具来画一个 1 像素宽的线条，这样就可以既保证视觉上对齐，数据中也是整数。比 Line 直接画直线会有小数点更方便 。用内阴影画 0.5 px 的线条。 如何设置Sketch快捷键 你可以为你经常用的一些功能自定义快捷键。打开 Mac 系统设置 – 键盘 – 快捷键，然后点击 「应用快捷键 」。从下拉菜单里选中 Sketch ，自定义你需要的快捷键。你也可以用同样的方法给你的 Mac 其他应用自定义快捷键。 快捷键设置 总结在工作中还是需要重视效率，在做任何事之前我们是否有用心的去思考下当前的工作有没有更方便快捷的办法，可能前期会花去很多研究的时间，或者花很多时间研究的方法也不一定管用，但是这是更好提高我们效率的必经之路，发现好的方法分享给团队的成员会更有助于大家的协作。 当然本文总结的只是很小的一部分，在做产品设计的道路上，我们还需要系统思维、前端思维、批判性思维等帮助我们更好地解决问题。","tags":[{"name":"Cheat Sheets","slug":"Cheat-Sheets","permalink":"http://www.jifu.io/tags/Cheat-Sheets/"},{"name":"技巧","slug":"技巧","permalink":"http://www.jifu.io/tags/技巧/"},{"name":"Sketch","slug":"Sketch","permalink":"http://www.jifu.io/tags/Sketch/"}],"categories":[{"name":"Design","slug":"Design","permalink":"http://www.jifu.io/categories/Design/"}]},{"title":"Mac使用SSH登录Google Cloud Platform","date":"2019-09-24T10:01:05.000Z","path":"posts/3897848060/","text":"启用root账户及密码自动验证使用Google Cloud网页版ssh，切换到rootsudo -i 编辑ssh配置文件vi /etc/ssh/sshd_config 修改以下的内容PermitRootLogin yes PasswordAuthentication yes 重启sshservice sshd restart 修改当前账户和root账户的密码设置当前账户新密码sudo passwd ${whoami} 设置root账户新密码sudo passwd root 使用Mac自带的SSH进行连接打开终端，新建远程连接，填写ip地址以及账户名 使用刚才修改的密码进行登录","tags":[{"name":"SSH","slug":"SSH","permalink":"http://www.jifu.io/tags/SSH/"},{"name":"Google Cloud","slug":"Google-Cloud","permalink":"http://www.jifu.io/tags/Google-Cloud/"}],"categories":[{"name":"OPS","slug":"OPS","permalink":"http://www.jifu.io/categories/OPS/"},{"name":"Linux","slug":"OPS/Linux","permalink":"http://www.jifu.io/categories/OPS/Linux/"}]},{"title":"WordPress启用memcached动态缓存以及报错解决","date":"2019-09-22T11:22:57.000Z","path":"posts/1067246247/","text":"Memcahced | Memcachephp有memcached和memcache两个类似组件，百度搜出来的文章，大部分是教你如何安装memcache(d)，却步解释二者的区别。 memcache是 pecl 扩展库版本，原生支持php，出现更早，是老前辈； memcached是 libmemcached 版本，出现较后，是新一代，因此也更加完善，推荐使用。 Ps：如果想更深入了解，可以搜索下 memcache vs memcached 其实，我们这种小网站的话，二选一即可，这点QPS还不至于纠结。不过一旦选择了，安装的时候就要注意区分，一对一配套安装，别搞的牛头不对马嘴，出现上面那位仁兄的困惑（后文有相关说明）。 这里，我果断选择了带d的，继续分享。 部署memcached安装memcached Ps：这里的memcached是指Mencached的服务端，用来处理缓存数据，名字也是容易混淆。 下面2种安装方式任选其一： 在线安装# Centos直接使用yum安装即可，其他系统自行搜索安装命令，比如ubuntu yum -y install memcached # 启动memcached service memcached start # 开机启动 chkconfig memcached on 编译安装相比在线安装，很多时候编译安装更加灵活，非常类似Windows平台的自定义安装或绿色安装，推荐熟悉 Linux 系统的朋友使用： # 从官方下载最新源码包 wget http://memcached.org/files/memcached-1.4.25.tar.gz #解压开始编译安装 tar xzvf memcached-1.4.15.tar.gz cd memcached-1.4.15 ./configure --prefix=/usr/local/memcached make &amp;&amp; make install cd .. #设置环境 ln -s /usr/local/memcached/bin/memcached /usr/bin/memcached cp scripts/memcached.sysv /etc/init.d/memcached #改为监听127.0.0.1，并关闭UDP连接方式，若为远程服务调用或不需要的话请跳过此行 sed -i 's/OPTIONS=\"\"/OPTIONS=\"-l 127.0.0.1 -U 0\"/g' /etc/init.d/memcached sed -i 's@chown@#chown@' /etc/init.d/memcached sed -i 's@/var/run/memcached/memcached.pid@/var/run/memcached.pid@' /etc/init.d/memcached #启动并设置开机服务 chmod +x /etc/init.d/memcached service memcached start chkconfig --add memcached chkconfig memcached on 至此memcached的服务端就安装好了。 集成php-memcached拓展先安装libmemcached提前分享一个问题，如果直接按照网上的教程安装php-memcached可能会报如下错误： configure: error: no, sasl.h is not available. Run configure with –disable-memcached-sasl to disable this check 大部分教程会使用 –disable-memcached-sasl 参数来禁用这个功能，作为一个强迫症，我还是从国外的论坛扒到了解决方法，很简单，在编译libmemcached之前，先安装cyrus-sasl-devel即可解决 yum install cyrus-sasl-devel 接着开始编译安装libmemcached： wget https://launchpad.net/libmemcached/1.0/1.0.18/+download/libmemcached-1.0.18.tar.gz tar xzf libmemcached-1.0.18.tar.gz cd libmemcached-1.0.18 ./configure --with-memcached=/usr/local/memcached --prefix=/usr/local/libmemcached make &amp;&amp; make install cd .. 安装php-memcached组件下载和解压这步，我们要区分下是php7还是之前的版本： 1、如果当前环境是php7 ： #从github下载PHP7专用的memcached组件分支 wget https://github.com/php-memcached-dev/php-memcached/archive/php7.zip #解压备用 unzip php7.zip cd php-memcached-php7 2、如果是旧的的php版本： #从官方下载php-memcached的最新源码包 wget http://pecl.php.net/get/memcached-2.2.0.tgz #解压和编译 tar zxvf memcached-2.2.0.tgz cd memcached-2.2.0 接下来开始编译： #注意已有php的实际路径 /usr/local/php/bin/phpize ./configure --with-php-config=/usr/local/php/bin/php-config make &amp;&amp; make install 编辑php.ini文件，在最后插入如下参数 extension=memcached.so Ps：\b如果不知道php.ini在哪个位置 ？ 执行命令：php –ini 即可找到。 保存后，执行如下命令看看是否加载成功： php -m | grep memcached 如果输出memcached则表示成功。 最后，如果是Nginx就 service php-fpm reload ，如果是Apache就重启Apache完成安装。 测试缓存&lt;?php $m = new Memcached(); $m->addServer( '127.0.0.1', 11211 ); $m->set( 'foo', 100 ); echo $m->get( 'foo' ) . \"\\n\"; 将上述代码保存为 test.php，然后执行 php -f test.php，如果能输出100表示安装成功。 WordPress缓存做完上述所有步骤，系统环境就已经支持memcached缓存了。下面分享如何应用到WordPress 安装插件访问github项目页面下载插件包： https://github.com/tollmanz/wordpress-pecl-memcached-object-cache 下载并解压得到的 object-cache.php，上传到 wp-content 目录即可开启memcached缓存。 值得说明的是，这里还有一个大坑等着你来踩： WordPress官网上的object-cache.php虽然也号称Memcached 插件，然而它只支持Memcache，不支持新版的，所以不能使用。如果错误地将object-cache.php和Memcached混用的话，则会出现WordPress打不开，前台后台页面一片空白的现象。 这也就是经常有站长反馈WordPress启用memcached功能后，页面空白的错误原因了。不巧，张戈在测试的时候也踩坑了，所以特别提出来，希望大家了解错误的原因，规避掉！ 查看效果做完第2步之后，你可以去网站前台刷新几次，产生缓存，然后从官方下载探针： http://pecl.php.net/get/memcache-3.0.8.tgz 解压后，里面有一个memcache.php文件，编辑并找到如下代码： define('ADMIN_USERNAME','memcache'); // Admin Username define('ADMIN_PASSWORD','password'); // Admin Password define('DATE_FORMAT','Y/m/d H:i:s'); define('GRAPH_SIZE',200); define('MAX_ITEM_DUMP',50); $MEMCACHE_SERVERS[] = 'mymemcache-server1:11211'; // add more as an array $MEMCACHE_SERVERS[] = 'mymemcache-server2:11211'; // add more as an array 修改如下： define('ADMIN_USERNAME','memcache'); // Admin Username 登录名称，自行修改 define('ADMIN_PASSWORD','password'); // Admin Password 登录密码，自行修改 define('DATE_FORMAT','Y/m/d H:i:s'); define('GRAPH_SIZE',200); define('MAX_ITEM_DUMP',50); //下面是定义memcached服务器，一般我们是单机部署，所以注释掉一行，并将服务器地址根据实际修改，比如本文是127.0.0.1 $MEMCACHE_SERVERS[] = '127.0.0.1:11211'; // add more as an array //$MEMCACHE_SERVERS[] = 'mymemcache-server2:11211'; // add more as an array 上传到网站私密目录（临时测试可以放到根目录），然后通过前台访问memcache.php这个文件，输入上面的用户名和密码即可看到memcached状态： 其他设置如果发现页面可以打开，但是里面没有Hits数据，说明WordPress并没有成功连接到memcached，这时候我们可以在wp-config.php加入如下参数： global $memcached_servers; $memcached_servers = array( array( '127.0.0.1', // Memcached server IP address 11211 // Memcached server port ) ); 实际的memcached监听IP和端口，你可以通过如下命令查看： netstat -nutlp | grep memcache 纯静态缓存实际上memcached可以缓存动态查询数据，他也可以缓存html内容！因此，memcached也能实现和其他方案一样的html纯净态缓存！ 实现原理和我之前分享的php代码缓存html方案类似，不过后者更好的是将缓存内容放在了内存当中，速度比放硬盘快的绝对不是一点点。 如何将前台页面html都缓存到memcached中呢？这里，我们需要用到 batcache 这款插件。 下载安装直接在WordPress后台搜索安装 batcache ，也可以从官方下载插件包： https://wordpress.org/plugins/batcache/ 然后解压得到 advanced-cache.php 上传到wp-content即可。 启用缓存在wp-config.php中启用缓存： define('WP_CACHE', true); 不过，插件默认只会对游客缓存，显然也是怕影响到前台登录态。缓存和动态判断一直是矛与盾、鱼和熊掌，看个人抉择吧。 参数调整var $max_age = 3600; // Expire batcache items aged this many seconds (zero to disable batcache) var $remote = 0; // Zero disables sending buffers to remote datacenters (req/sec is never sent) var $times = 2; // Only batcache a page after it is accessed this many times... (two or more) var $seconds = 0; // ...in this many seconds (zero to ignore this and use batcache immediately) max_age代表缓存过期时间（以秒为单位），times表示访问多少次才创建缓存（2是最小值），seconds表示在多少秒之后才创建缓存（0表示立即）","tags":[{"name":"WordPress","slug":"WordPress","permalink":"http://www.jifu.io/tags/WordPress/"},{"name":"memcached","slug":"memcached","permalink":"http://www.jifu.io/tags/memcached/"},{"name":"缓存","slug":"缓存","permalink":"http://www.jifu.io/tags/缓存/"}],"categories":[{"name":"OPS","slug":"OPS","permalink":"http://www.jifu.io/categories/OPS/"},{"name":"Wordpress","slug":"OPS/Wordpress","permalink":"http://www.jifu.io/categories/OPS/Wordpress/"}]},{"title":"Nginx配置跨域请求 Access-Control-Allow-Origin *","date":"2019-09-21T22:16:59.000Z","path":"posts/3996389515/","text":"问题描述当出现403跨域错误的时候 No ‘Access-Control-Allow-Origin’ header is present on the requested resource，需要给Nginx服务器配置响应的header参数： 解决方案只需要在Nginx的配置文件中配置以下参数： location / { add_header Access-Control-Allow-Origin *; add_header Access-Control-Allow-Methods 'GET, POST, OPTIONS'; add_header Access-Control-Allow-Headers 'DNT,X-Mx-ReqToken,Keep-Alive,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Authorization'; if ($request_method = 'OPTIONS') { return 204; } } 上面配置代码即可解决问题了，不想深入研究的，看到这里就可以啦=-= 参数解释Access-Control-Allow-Origin 服务器默认是不被允许跨域的。给Nginx服务器配置Access-Control-Allow-Origin *后，表示服务器可以接受所有的请求源（Origin）,即接受所有跨域的请求。 Access-Control-Allow-Headers是为了防止出现以下错误： Request header field Content-Type is not allowed by Access-Control-Allow-Headers in preflight response. 这个错误表示当前请求Content-Type的值不被支持。其实是我们发起了”application/json”的类型请求导致的。这里涉及到一个概念：预检请求（preflight request）,请看下面”预检请求”的介绍。 Access-Control-Allow-Methods是为了防止出现以下错误： Content-Type is not allowed by Access-Control-Allow-Headers in preflight response. OPTIONS添加204的返回，是为了处理在发送POST请求时Nginx依然拒绝访问的错误 发送”预检请求”时，需要用到方法 OPTIONS ,所以服务器需要允许该方法。 预检请求（preflight request）其实上面的配置涉及到了一个W3C标准：CROS,全称是跨域资源共享 (Cross-origin resource sharing)，它的提出就是为了解决跨域请求的。 跨域资源共享(CORS)标准新增了一组 HTTP 首部字段，允许服务器声明哪些源站有权限访问哪些资源。另外，规范要求，对那些可能对服务器数据产生副作用的HTTP 请求方法（特别是 GET 以外的 HTTP 请求，或者搭配某些 MIME 类型的 POST 请求），浏览器必须首先使用 OPTIONS 方法发起一个预检请求（preflight request），从而获知服务端是否允许该跨域请求。服务器确认允许之后，才发起实际的 HTTP 请求。在预检请求的返回中，服务器端也可以通知客户端，是否需要携带身份凭证（包括 Cookies 和 HTTP 认证相关数据）。 其实Content-Type字段的类型为application/json的请求就是上面所说的搭配某些 MIME 类型的 POST 请求,CORS规定，Content-Type不属于以下MIME类型的，都属于预检请求： application/x-www-form-urlencoded multipart/form-data text/plain 所以 application/json的请求 会在正式通信之前，增加一次”预检”请求，这次”预检”请求会带上头部信息 Access-Control-Request-Headers: Content-Type： OPTIONS /api/test HTTP/1.1 Origin: http://foo.example Access-Control-Request-Method: POST Access-Control-Request-Headers: Content-Type ... 省略了一些 服务器回应时，返回的头部信息如果不包含Access-Control-Allow-Headers: Content-Type则表示不接受非默认的的Content-Type。即出现以下错误： Request header field Content-Type is not allowed by Access-Control-Allow-Headers in preflight response.","tags":[{"name":"Nignx","slug":"Nignx","permalink":"http://www.jifu.io/tags/Nignx/"},{"name":"跨域","slug":"跨域","permalink":"http://www.jifu.io/tags/跨域/"}],"categories":[{"name":"back-end","slug":"back-end","permalink":"http://www.jifu.io/categories/back-end/"},{"name":"Middle-ware","slug":"back-end/Middle-ware","permalink":"http://www.jifu.io/categories/back-end/Middle-ware/"},{"name":"Nginx","slug":"back-end/Middle-ware/Nginx","permalink":"http://www.jifu.io/categories/back-end/Middle-ware/Nginx/"}]},{"title":"linux下测试磁盘的读写IO速度(IO物理测速)","date":"2019-08-25T03:50:00.000Z","path":"posts/1073812833/","text":"hdparm命令这是一个是用来获取ATA/IDE硬盘的参数的命令,是由早期Linux IDE驱动的开发和维护人员 Mark Lord开发编写的( hdparm has been written by Mark Lord &#x6d;&#108;&#x6f;&#114;&#100;&#x40;&#112;&#111;&#98;&#x6f;&#x78;&#x2e;&#x63;&#x6f;&#x6d;, the primary developer and maintainer of the (E)IDE driver for Linux, with suggestions from many netfolk).该命令应该也是仅用于Linux系统,对于UNIX系统，ATA/IDE硬盘用的可能比较少，一般大型的系统都是使用磁盘阵列的. 使用方法# hdparm -Tt /dev/sda /dev/sda: Timing cached reads: 6676 MB in 2.00 seconds = 3340.18 MB/sec Timing buffered disk reads: 218 MB in 3.11 seconds = 70.11 MB/sec 可以看到,2秒钟读取了6676MB的缓存,约合3340.18 MB/sec;在3.11秒中读取了218MB磁盘(物理读),读取速度约合70.11 MB/sec dd命令这不是一个专业的测试工具，不过如果对于测试结果的要求不是很苛刻的话,平时可以使用来对磁盘的读写速度作一个简单的评估.另外由于这是一个免费软件,基本上×NIX系统上都有安装,对于Oracle裸设备的复制迁移,dd工具一般都是首选. 首先了解两个特殊设备/dev/null 伪设备，回收站.写该文件不会产生IO/dev/zero 伪设备，会产生空字符流，对它不会产生IO 测试方法测试磁盘的IO写速度time dd if=/dev/zero of=test.dbf bs=8k count=300000 如果要测试实际速度 还要在末尾加上 oflag=direct测到的才是真实的IO速度 测试磁盘的IO读速度dd if=test.dbf bs=8k count=300000 of=/dev/null #表示 每次写入/读取8k的数据，执行300000次 dd命令可以通用，但不够专业，也没有考虑到缓存和物理读的区分，测试的数据也是仅作参考，不能算是权威。 dd命令解释dd if= of= bs= skip= seek= conv= 一定不要搞混 source 和 target，不然数据会丢失。所以 dd 平时用着顺手就叫它 dd，但是不小心把数据弄没了就该哭着叫它 Data Destroyer 了。 一般它的常用参数有 bs=n，block size，每次读取 n bytes 写入，可与 count 联用； ibs=n，一次读入 bytes 个字节 (default is 512)； obs=n，一次性写 n bytes 个字节 (default is 512)； bs 可以同时设置上边两个参数； cbs=n，一次转换 n 个 bytes，即转换缓冲区大小。； count=n， bs 操作的次数，仅拷贝 n 个块，如 dvd: bs=1M count=4430； skip=n，指 if 后面的原文件跳过 n bytes 再开始读取； seek=n，指 of 后面的目标文件跳过 n bytes 再开始写入； 测试IO同时读和写的速度# time dd if=/dev/sda1 of=test.dbf bs=8k 13048+1 records in 13048+1 records out 3.73s real 0.04s user 2.39s system # du -sm test.dbf 500 test.dbf （同事测试读写速度时生成一个大小500M的 test.dbf文件） 上面测试的数据量比较小，仅作为参考. 相比两种方法前者是linux上专业的测试IDE/ATA磁盘的工具,但是使用范围有局限性;(此试验仅仅使用了测试磁盘IO的参数,对于其他参数及解释参考man手册)后者可以通用,但不够专业,也没有考虑到缓存和物理读的区分，测试的数据也是仅作参考，不能算是权威. 如果用dd测试，需要加oflag＝direct，测到的才是真实的磁盘io","tags":[{"name":"Linux","slug":"Linux","permalink":"http://www.jifu.io/tags/Linux/"},{"name":"IO速度","slug":"IO速度","permalink":"http://www.jifu.io/tags/IO速度/"},{"name":"磁盘读写","slug":"磁盘读写","permalink":"http://www.jifu.io/tags/磁盘读写/"}],"categories":[{"name":"OPS","slug":"OPS","permalink":"http://www.jifu.io/categories/OPS/"},{"name":"Others","slug":"OPS/Others","permalink":"http://www.jifu.io/categories/OPS/Others/"}]},{"title":"Mac VSCode 禁用GPU加速","date":"2019-08-22T07:02:56.000Z","path":"posts/3837318570/","text":"某些老型号mac或者黑苹果使用VSCode时非常卡顿，有可能是GPU加速造成的。原理用新的脚本替换vscode执行程序 cd到VSCode执行程序所在目录cd /Applications/Visual\\ Studio\\ Code.app/Contents/MacOS/ 将Electron(VSCode可以行程序)重名了为Electron.realmv Electron Electron.real 在该目录新建一个文件名为Electron文本文件（没有后缀），并将下面的内容粘贴到文件里#!/bin/bash cd \"/Applications/Visual Studio Code.app/Contents/MacOS\" \"/Applications/Visual Studio Code.app/Contents/MacOS/Electron.real\" --disable-gpu \"$@\" 为Electron添加执行权限chmod -R a+x Electron 大功告成，现在直接打开vscode已经是禁用gpu了//可已经将自己创建的Electron文件备份到其他目录//vscode升级后只需要执行第二部将Electron(VSCode可以行程序)重名了为Electron.real//然后在把备份的Electron复制到该目录即可","tags":[{"name":"Mac OS","slug":"Mac-OS","permalink":"http://www.jifu.io/tags/Mac-OS/"},{"name":"VSCode","slug":"VSCode","permalink":"http://www.jifu.io/tags/VSCode/"},{"name":"禁用GPU加速","slug":"禁用GPU加速","permalink":"http://www.jifu.io/tags/禁用GPU加速/"}],"categories":[{"name":"OPS","slug":"OPS","permalink":"http://www.jifu.io/categories/OPS/"},{"name":"MacOS","slug":"OPS/MacOS","permalink":"http://www.jifu.io/categories/OPS/MacOS/"}]},{"title":"通过编写 chroot 来认识 chroot 发挥的作用和它带来的好处","date":"2019-08-04T13:01:46.000Z","path":"posts/3241041753/","text":"什么是 chrootchroot，即 change root directory (更改 root 目录)。在 linux 系统中，系统默认的目录结构都是以 /，即是以根 (root) 开始的。而在使用 chroot 之后，系统的目录结构将以指定的位置作为 / 位置。 为何使用 chroot在经过 chroot 之后，系统读取到的目录和文件将不在是旧系统根下的而是新根下(即被指定的新的位置)的目录结构和文件，因此它带来的好处大致有以下3个： 增加了系统的安全性，限制了用户的权力； 在经过 chroot 之后，在新根下将访问不到旧系统的根目录结构和文件，这样就增强了系统的安全性。这个一般是在登录 (login) 前使用 chroot，以此达到用户不能访问一些特定的文件。 建立一个与原系统隔离的系统目录结构，方便用户的开发； 使用 chroot 后，系统读取的是新根下的目录和文件，这是一个与原系统根下文件不相关的目录结构。在这个新的环境中，可以用来测试软件的静态编译以及一些与系统不相关的独立开发。 切换系统的根目录位置，引导 Linux 系统启动以及急救系统等。 chroot 的作用就是切换系统的根位置，而这个作用最为明显的是在系统初始引导磁盘的处理过程中使用，从初始 RAM 磁盘 (initrd) 切换系统的根位置并执行真正的 init。另外，当系统出现一些问题时，我们也可以使用 chroot 来切换到一个临时的系统。 chroot 的使用为了更好的理解 chroot 发挥的作用，我们将尝试指定一个特定的位置进行根目录切换。但是由于在经过 chroot 之后，系统读取到的 bin/ 等与系统相关目录将不再是旧系统根目录下的，而是切换后新根下的目录结构和文件，因此我们有必要准备一些目录结构以及必要的文件。 清单 1. 准备切换的目录结构 Busybox 被称为是嵌入式 Linux 中的瑞士军刀。Busybox 包含了许多有用的命令，如 cat、find 等，但是它的体积却非常的小。 $ pwd /home/wstone/Build/work $ tree . . |-- bin | |-- ash -> busybox | |-- bash | `-- busybox |-- etc `-- newhome 这里使用了静态编译后的 busybox 来提供必要的命令，使用静态编译仅是为了避免动态库文件的拷贝。当然我们也可以拷贝旧系统的下的命令到新的目录结构中使用，但是那些命令通常是动态编译的，这就意味着我们不得不拷贝相关的动态库文件到相应的目录结构中。同时这里的 bash 也非真正的 Bourne Again shell，而是一个执行 ash 的 shell 脚本。在清单 2中，展示了位于旧系统中的 chroot 命令的使用。需要注意的是在使用 chroot 时，要求拥有相关的操作权限。 清单 2. 位于系统中的 chroot 的使用$ pwd /home/wstone/Build/work # chroot . # pwd / # ls ash: ls: not found # busybox ls bin etc newhome 3 directories, 3 files 我们可以看到当前路径(/home/wstone/Build/work/)，在经过 chroot 后转变成了 / 目录，同时从新根下读取了与系统相关的目录结构。使用 ls 命令失败是由于我们创建的测试目录结构中并没有包含命令 ls，但是我们成功的使用了 busybox 中的 ls。以上看到的只是 chroot 的一种使用方式，其实标准的 chroot (Coreutils - GNU core utilities 提供的 chroot)使用方式有2种： 清单 3. 标准 chroot 的2种使用方式[1] chroot NEWROOT [COMMAND...] [2] chroot OPTION 刚才我们使用的是方式[2]。这将在没有给定环境时，默认执行 /bin/sh，但是当给定环境后，将运行 ${SHELL} –i，即与环境相同的可交互的 shell。我们的目录结构中并没有包含sh，显然清单 2中的 chroot 运行了 ${SHELL} –i。当然我们也可以在进行切换时指定需要的命令，即使用方式[1]。 清单 4. chroot 另一种方式的使用# chroot . /bin/ash 在清单 4 中，尝试了在经过 chroot 后，执行新目录结构下的 ash shell。不得不说的是，如果新根下的目录结构和文件准备的够充分，那么一个新的简单的 Linux 系统就可以使用了。其实更为常见的是在初始 RAM 磁盘 (initrd)中使用 chroot，以此来执行系统的 init。清单 5 中，展示的是在 Linux 2.4 内核 initrd 中使用 chroot。 清单 5. 在 Linux 2.4 内核 initrd 中使用 chroot 的示例mount /dev/hda1 /new-root cd /new-root pivot_root . old-root exec chroot . /sbin/init &lt;dev/console >dev/console 2>&amp;1 umount /old-root 由于 Linux 内核的升级，initrd 处理机制和格式发生了变化，在 Linux 2.6 内核 initrd 中不能再使用 pivot_root，因此一般也不再使用 chroot，而是选择使用 busybox 提供的 switch_root 或者 klibc 提供的 run-init 进行根目录的切换。(这并不是说不能在 Linux 2.6内核 initrd 中使用 chroot，选择 switch_root 或 run-init 仅是出于习惯和方便的考虑。)但是实质上，它们仅是将 chroot 的功能进行了封装，以此更加方便简单的切换根目录。 清单 6. 在 Linux 2.6 内核 initrd 中 chroot 的使用[1] find -xdev / -exec rm '{}' '; [2] cd /newmount; mount --move . /; chroot . switch_root 和 run-init 完成了类似清单 6中的功能，删除 rootfs 的全部内容以释放空间，以及挂载新的根文件系统并进行切换。在 busybox 和 klibc中也有提供 chroot 命令，只是功能上与 Coreutils (GNU core utilities) 包含的 chroot 有稍许差异。编写一个 chroot 上面介绍了 chroot 及其使用，但是编写一个简单的 chroot 并不复杂，下面我们就尝试编写chroot 以此来更好的认识 chroot 的处理过程，先编写一个粗略的 chroot 然后再完善它的功能。chroot 的编写涉及了2个函数，chroot() 以及 chdir()，它们都包含在 unistd.h 头文件中。 清单 7. 编写 chroot 涉及的2个函数#include &lt;unistd.h> int chroot(const char *path); int chdir(const char *path); chroot() 将切换参数 path 所指位置为根目录 (/)，chdir() 用来将当前的工作目录改变成以参数path 所指的目录。以此我们可以编写一个非常粗略的 chroot。 清单 8. 粗略的 chroot#include &lt;unistd.h> int main(int argc, char *argv[]) { chroot(\".\"); chdir(\"/\"); char *arrays[]={\"ash\",NULL}; execvp(\"ash\", arrays); return 0; } 这个粗略的 chroot 仅能切换当前位置为根目录，同时默认执行 ash shell，不包含任何的错误处理及警告。编写并保存代码为 test.c。在清单 9 中，展示了这个粗略 chroot 的使用情况，成功的进行了根目录的切换。 清单 9. 粗略 chroot 的使用$ gcc -Wall test.c -o test # ./test # ls ash: ls: not found # busybox ls bin etc newhome test test.c 下面给出功能将近完整的 chroot ，加上了一些错误处理并新增了可执行指定命令的功能。当在没有给出 chroot 切换后要执行的命令时，默认执行 /bin/sh，同时检测环境以确认使用何种 shell。 清单 10. 功能完整的 chroot#include &lt;stdio.h> #include &lt;unistd.h> #include &lt;stdlib.h> int main(int argc, char *argv[]) { if(argc&lt;2){ printf(\"Usage: chroot NEWROOT [COMMAND...] \\n\"); return 1; } printf(\"newroot = %s\\n\", argv[1]); if(chroot(argv[1])) { perror(\"chroot\"); return 1; } if(chdir(\"/\")) { perror(\"chdir\"); return 1; } if(argc == 2) { argv[0] = getenv(\"SHELL\"); if(!argv[0]) argv[0] = (char *)\"/bin/sh\"; argv[1] = (char *) \"-i\"; argv[2] = NULL; } else { argv += 2; } execvp (argv[0], argv); printf(\"chroot: cannot run command `%s`\\n\", *argv); return 0; } 保存以上代码为 newchroot.c 文件，编译后运行测试其功能。最后要指出的是，本文中的 chroot 并没有使用静态编译。如果有必要(如，在 initrd 中使用 chroot)，chroot 应该使用静态编译，若是使用动态编译，那么要拷贝相关的动态库文件到相应目录结构中。 清单 11. newchroot 的测试$ gcc -Wall newchroot.c -o newchroot # ./newchroot . /bin/ash newroot = . 结束语在 Linux 系统初始引导的过程中，通常都有使用 chroot。但是 chroot 的好处不仅于此，它还增加了系统的安全性等。而通过本文后半部分对 chroot 的认识，我相信读者可以更好的发挥chroot 的作用。","tags":[{"name":"chroot","slug":"chroot","permalink":"http://www.jifu.io/tags/chroot/"}],"categories":[{"name":"OPS","slug":"OPS","permalink":"http://www.jifu.io/categories/OPS/"},{"name":"command","slug":"OPS/command","permalink":"http://www.jifu.io/categories/OPS/command/"}]},{"title":"MySQL 调优/优化的 101 个建议","date":"2019-07-19T08:37:26.000Z","path":"posts/4284065059/","text":"介绍MySQL是一个强大的开源数据库。随着MySQL上的应用越来越多，MySQL逐渐遇到了瓶颈。这里提供 101 条优化 MySQL 的建议。有些技巧适合特定的安装环境，但是思路是相通的。我已经将它们分成了几类以帮助你理解。 Mysql 监控MySQL服务器硬件和OS（操作系统）调优 有足够的物理内存，能将整个InnoDB文件加载到内存里 —— 如果访问的文件在内存里，而不是在磁盘上，InnoDB会快很多。 全力避免 Swap 操作 — 交换（swapping）是从磁盘读取数据，所以会很慢。 使用电池供电的RAM（Battery-Backed RAM）。 使用一个高级磁盘阵列 — 最好是 RAID10 或者更高。 避免使用RAID5 — 和校验需要确保完整性，开销很高。 将你的操作系统和数据分开，不仅仅是逻辑上要分开，物理上也要分开 — 操作系统的读写开销会影响数据库的性能。 将临时文件和复制日志与数据文件分开 — 后台的写操作影响数据库从磁盘文件的读写操作。 更多的磁盘空间等于更高的速度。 磁盘速度越快越好。 SAS优于SATA。 小磁盘的速度比大磁盘的更快，尤其是在 RAID 中。 使用电池供电的缓存 RAID（Battery-Backed Cache RAID）控制器。 避免使用软磁盘阵列。 考虑使用固态IO卡（不是磁盘）来作为数据分区 — 几乎对所有量级数据，这种卡能够支持 2 GBps 的写操作。 在 Linux 系统上，设置 swappiness 的值为0 — 没有理由在数据库服务器上缓存文件，这种方式在Web服务器或桌面应用中用的更多。 尽可能使用 noatime 和 nodirtime 来挂载文件系统 — 没有必要为每次访问来更新文件的修改时间。 使用 XFS 文件系统 — 一个比ext3更快的. 更小的文件系统，拥有更多的日志选项，同时，MySQL在ext3上存在双缓冲区的问题。 优化你的 XFS 文件系统日志和缓冲区参数 – -为了获取最大的性能基准。 在Linux系统中，使用 NOOP 或 DEADLINE IO 调度器 — CFQ 和 ANTICIPATORY 调度器已经被证明比 NOOP 和 DEADLINE 慢。 使用 64 位操作系统 — 有更多的内存能用于寻址和 MySQL 使用。 将不用的包和后台程序从服务器上删除 — 减少资源占用。 将使用 MySQL 的 host 和 MySQL自身的 host 都配置在一个 host 文件中 — 这样没有 DNS 查找。 永远不要强制杀死一个MySQL进程 — 你将损坏数据库，并运行备份。 让你的服务器只服务于MySQL — 后台处理程序和其他服务会占用数据库的 CPU 时间。 Mysql 配置 使用 innodb_flush_method=O_DIRECT 来避免写的时候出现双缓冲区。 避免使用 O_DIRECT 和 EXT3 文件系统 — 这会把所有写入的东西序列化。 分配足够 innodb_buffer_pool_size ，来将整个InnoDB 文件加载到内存 — 减少从磁盘上读。 不要让 innodb_log_file_size 太大，这样能够更快，也有更多的磁盘空间 — 经常刷新有利降低发生故障时的恢复时间。 不要同时使用 innodb_thread_concurrency 和 thread_concurrency 变量 — 这两个值不能兼容。 为 max_connections 指定一个小的值 — 太多的连接将耗尽你的RAM，导致整个MySQL服务器被锁定。 保持 thread_cache 在一个相对较高的数值，大约是 16 — 防止打开连接时候速度下降。 使用 skip-name-resolve — 移除 DNS 查找。 如果你的查询重复率比较高，并且你的数据不是经常改变，请使用查询缓存 — 但是，在经常改变的数据上使用查询缓存会对性能有负面影响。 增加 temp_table_size — 防止磁盘写。 增加 max_heap_table_size — 防止磁盘写。 不要将 sort_buffer_size 的值设置的太高 — 可能导致连接很快耗尽所有内存。 监控 key_read_requests 和 key_reads，以便确定 key_buffer 的值 — key 的读需求应该比 key_reads 的值更高，否则使用 key_buffer 就没有效率了。 设置 innodb_flush_log_at_trx_commit = 0 可以提高性能，但是保持默认值（1）的话，能保证数据的完整性，也能保证复制不会滞后。 有一个测试环境，便于测试你的配置，可以经常重启，不会影响生产环境。 Mysql Schema优化 保证你的数据库的整洁性。 归档老数据 — 删除查询中检索或返回的多余的行 在数据上加上索引。 不要过度使用索引，评估你的查询。 压缩 text 和 blob 数据类型 — 为了节省空间，减少从磁盘读数据。 UTF 8 和 UTF16 比 latin1 慢。 有节制的使用触发器。 保持数据最小量的冗余 — 不要复制没必要的数据. 使用链接表，而不是扩展行。 注意你的数据类型，尽可能的使用最小的。 如果其他数据需要经常需要查询，而 blob/text 不需要，则将 blob/text 数据域其他数据分离。 经常检查和优化表。 经常做重写 InnoDB 表的优化。 有时，增加列时，先删除索引，之后在加上索引会更快。 为不同的需求选择不同的存储引擎。 日志表或审计表使用ARCHIVE存储引擎 — 写的效率更高。 将 session 数据存储在 memcache 中，而不是 MySQL 中 — memcache 可以设置自动过期，防止MySQL对临时数据高成本的读写操作。 如果字符串的长度是可变的，则使用VARCHAR代替CHAR — 节约空间，因为CHAR是固定长度，而VARCHAR不是（utf8 不受这个影响）。 逐步对 schema 做修改 — 一个小的变化将产生的巨大的影响。 在开发环境测试所有 schema 变动，而不是在生产环境的镜像上去做。 不要随意改变你的配置文件，这可能产生非常大的影响。 有时候，少量的配置会更好。 质疑使用通用的MySQL配置文件。 Mysql 查询优化 使用慢查询日志，找出执行慢的查询。 使用 EXPLAIN 来决定查询功能是否合适。 经常测试你的查询，看是否需要做性能优化 — 性能可能会随着时间的变化而变化。 避免在整个表上使用count(*) ，它可能会将整个表锁住。 保持查询一致，这样后续类似的查询就能使用查询缓存了。 如果合适，用 GROUP BY 代替 DISTINCT。 在 WHERE. GROUP BY 和 ORDER BY 的列上加上索引。 保证索引简单，不要在同一列上加多个索引。 有时，MySQL 会选择错误的索引，这种情况使用 USE INDEX。 使用 SQL_MODE=STRICT 来检查问题。 索引字段少于5个时，UNION 操作用 LIMIT，而不是 OR。 使用 INSERT ON DUPLICATE KEY 或 INSERT IGNORE 来代替 UPDATE，避免 UPDATE 前需要先 SELECT。 使用索引字段和 ORDER BY 来代替 MAX。 避免使用 ORDER BY RAND()。 LIMIT M,N 在特定场景下会降低查询效率，有节制使用。 使用 UNION 来代替 WHERE 子句中的子查询。 对 UPDATE 来说，使用 SHARE MODE 来防止排他锁。 重启 MySQL 时，记得预热数据库，确保将数据加载到内存，提高查询效率。 使用 DROP TABLE ，然后再 CREATE TABLE ，而不是 DELETE FROM ，以删除表中所有数据。 最小化你要查询的数据，只获取你需要的数据，通常来说不要使用 *。 考虑持久连接，而不是多次建立连接，已减少资源的消耗。 基准查询，包括服务器的负载，有时一个简单的查询会影响其他的查询。 当服务器的负载增加时，使用SHOW PROCESSLIST来查看慢的/有问题的查询。 在存有生产环境数据副本的开发环境中，测试所有可疑的查询。 Mysql 备份过程 在二级复制服务器上进行备份。 备份过程中停止数据的复制，以防止出现数据依赖和外键约束的不一致。 彻底停止MySQL之后，再从数据文件进行备份。 如果使用MySQL dump进行备份，请同时备份二进制日志 — 确保复制过程不被中断。 不要信任 LVM 快照的备份 — 可能会创建不一致的数据，将来会因此产生问题。 为每个表做一个备份，这样更容易实现单表的恢复 — 如果数据与其他表是相互独立的。 使用 mysqldump 时，指定 -opt 参数。 备份前检测和优化表。 临时禁用外键约束，来提高导入的速度。 临时禁用唯一性检查，来提高导入的速度。 每次备份完后，计算数据库/表数据和索引的大小，监控其增长。 使用定时任务（cron）脚本，来监控从库复制的错误和延迟。 定期备份数据。 定期测试备份的数据。 执行MySQL 监控: Monitis Unveils The World’s First Free On-demand MySQL Monitoring。","tags":[{"name":"优化","slug":"优化","permalink":"http://www.jifu.io/tags/优化/"},{"name":"MySQL","slug":"MySQL","permalink":"http://www.jifu.io/tags/MySQL/"},{"name":"调优","slug":"调优","permalink":"http://www.jifu.io/tags/调优/"}],"categories":[{"name":"back-end","slug":"back-end","permalink":"http://www.jifu.io/categories/back-end/"},{"name":"Middle-ware","slug":"back-end/Middle-ware","permalink":"http://www.jifu.io/categories/back-end/Middle-ware/"},{"name":"MySQL","slug":"back-end/Middle-ware/MySQL","permalink":"http://www.jifu.io/categories/back-end/Middle-ware/MySQL/"}]},{"title":"Mac版迅雷优化,删除无用插件","date":"2019-07-17T12:37:22.000Z","path":"posts/294187676/","text":"介绍使用最新版Mac迅雷，通过删除无用插件达到优化目的。 迅雷插件列表 插件名 功能 advertising 广告 featuredpage 主页 feedback 反馈 iOSThunder 手机迅雷 activitycenter 活动中心 myvip 会员中心 softmanager 软件管家 viprenew 会员开通 viptips 会员提示 xlbrowser 内置浏览器 xlplayer 迅雷影音 livestream 直播 bbassistant 迅雷快鸟 lixianspace 离线空间 viptask 会员权限 userlogin 登陆迅雷账户 subtitle 内嵌字幕下载 browserhelper 配合浏览器 xiazaibao 下载宝 可选装插件针对不同的需求，可以酌情处理以下插件：需使用迅雷快鸟进行宽带提速的，请保留 bbassistant插件需要使用迅雷离线空间的，请保留 lixianspace 插件，不需要的可以删除；需要使用会员权限的，请保留 viptask 插件，不需要的可以删除；需要登陆迅雷账户的，请保留 userlogin 插件，不需要的可以删除；需要使用内置的字幕下载功能的，请保留 subtitle 插件，不需要的可以删除；需要搭配浏览器使用的，请保留 browserhelper 插件，不需要的可以删除；下载宝（或玩客云）用户请保留 xiazaibao 插件，不需要的可以删除。 删除插件* rm -rf /Applications/Thunder.app/Contents/PlugIns/{插件名}.xlplugin 脚本无用插件删除脚本#!/bin/bash rm -rf /Applications/Thunder.app/Contents/PlugIns/advertising.xlplugin rm -rf /Applications/Thunder.app/Contents/PlugIns/featuredpage.xlplugin rm -rf /Applications/Thunder.app/Contents/PlugIns/activitycenter.xlplugin rm -rf /Applications/Thunder.app/Contents/PlugIns/iOSThunder.xlplugin rm -rf /Applications/Thunder.app/Contents/PlugIns/livestream.xlplugin rm -rf /Applications/Thunder.app/Contents/PlugIns/myvip.xlplugin rm -rf /Applications/Thunder.app/Contents/PlugIns/softmanager.xlplugin rm -rf /Applications/Thunder.app/Contents/PlugIns/xiazaibao.xlplugin rm -rf /Applications/Thunder.app/Contents/PlugIns/xlbrowser.xlplugin rm -rf /Applications/Thunder.app/Contents/PlugIns/xlplayer.xlplugin rm -rf /Applications/Thunder.app/Contents/PlugIns/activitycenter.xlplugin rm -rf /Applications/Thunder.app/Contents/PlugIns/onethingcloud.xlplugin 选装插件删除脚本#!/bin/bash rm -rf /Applications/Thunder.app/Contents/PlugIns/bbassistant.xlplugin rm -rf /Applications/Thunder.app/Contents/PlugIns/lixianspace.xlplugin rm -rf /Applications/Thunder.app/Contents/PlugIns/viptask.xlplugin rm -rf /Applications/Thunder.app/Contents/PlugIns/userlogin.xlplugin rm -rf /Applications/Thunder.app/Contents/PlugIns/subtitle.xlplugin rm -rf /Applications/Thunder.app/Contents/PlugIns/browserhelper.xlplugin rm -rf /Applications/Thunder.app/Contents/PlugIns/xiazaibao.xlplugin","tags":[{"name":"Mac OS","slug":"Mac-OS","permalink":"http://www.jifu.io/tags/Mac-OS/"},{"name":"迅雷","slug":"迅雷","permalink":"http://www.jifu.io/tags/迅雷/"},{"name":"优化","slug":"优化","permalink":"http://www.jifu.io/tags/优化/"}],"categories":[{"name":"OPS","slug":"OPS","permalink":"http://www.jifu.io/categories/OPS/"},{"name":"MacOS","slug":"OPS/MacOS","permalink":"http://www.jifu.io/categories/OPS/MacOS/"}]},{"title":"修复破解Mac应用启动时闪退（原因是由于苹果移除了TNT证书）","date":"2019-07-17T11:06:31.000Z","path":"posts/1623087360/","text":"Apple removed TNT’s certificate, so the app will crash after July 12th. The current solution is to sign it yourself. Run in Terminalcodesign --force --deep --sign - /Applications/name.app Requisite: Xcode or the Apple Command Line ToolsTo install, execute xcode-select --install in the terminal emulator of your choice, and the macOS GUI will give you the option to install Xcode (from the Mac App Store) or the CLTs. If you install Xcode, launch it at least once to complete the installation and agree to the license. Alternatively, you can use CodeSigner to sign some apps. Installation instructions downloaded CodeSigner, then mount the DMG volume Copy CodeSigner.app from the mounted DMG volume into one of your applications paths; recommended: ~/Applications/Utilities/ If you are using macOS Finder or a similar application with Services support as your main file manager, double-click the CodeSigner workflow: a window titled Quick Action Installer will appear asking you if you want to install it; click Install. You can assign a keyboard shortcut to the Quick Action in System Preferences &gt; Keyboard &gt; Shortcuts &gt; Services &gt; Files and Folders &gt; CodeSigner If you also want the ability to manually run CodeSigner in a terminal emulator—example: codesigner /Applications/Parallels\\ Desktop.app —copy the codesigner shell script into your $PATH, e.g. /usr/local/bin/ On Mojave please allow CodeSigner to control System Events; this is necessary for GUI prompts to work via AppleScript What’s NewVersion 0.9.3 beta 4: CodeSigner will now grab an application’s or file’s icon for the notifications Bug fix: account for terminal-notifier display error in case of filenames with leading double-quotes (thanks to roryokane) If codesigner doesn’t execute as a Platypus app, it will search for terminal-notifier only in the default macOS Applications paths, and in installation directories for Homebrew, MacPorts and Fink (thanks to roryokane) CompatibilityOS X 10.8 or later, 64-bit processor Screenshots","tags":[{"name":"闪退","slug":"闪退","permalink":"http://www.jifu.io/tags/闪退/"},{"name":"Crashes","slug":"Crashes","permalink":"http://www.jifu.io/tags/Crashes/"},{"name":"TNT’s certificate","slug":"TNT’s-certificate","permalink":"http://www.jifu.io/tags/TNT’s-certificate/"}],"categories":[{"name":"OPS","slug":"OPS","permalink":"http://www.jifu.io/categories/OPS/"},{"name":"MacOS","slug":"OPS/MacOS","permalink":"http://www.jifu.io/categories/OPS/MacOS/"}]},{"title":"深入分析Redis特点及应用场景","date":"2019-07-13T10:08:15.000Z","path":"posts/2864310564/","text":"Redis的特点Redis 与其他 key - value 缓存产品有以下三个特点 Redis支持数据的持久化，可以将内存中的数据保存在磁盘中，重启的时候可以再次加载进行使用。 Redis不仅仅支持简单的key-value类型的数据，同时还提供list，set，zset，hash等数据结构的存储。 Redis支持数据的备份，即master-slave模式的数据备份。 Redis的优势 性能极高 – Redis能读的速度是110000次/s,写的速度是81000次/s 。 丰富的数据类型 – Redis支持二进制案例的 Strings, Lists, Hashes, Sets 及 Ordered Sets 数据类型操作。 原子 – Redis的所有操作都是原子性的，同时Redis还支持对几个操作全并后的原子性执行。 丰富的特性 – Redis还支持 publish/subscribe, 通知, key 过期等等特性。 Redis与其他key-value存储有什么不同？Redis有着更为复杂的数据结构并且提供对他们的原子性操作，这是一个不同于其他数据库的进化路径。Redis的数据类型都是基于基本数据结构的同时对程序员透明，无需进行额外的抽象。 Redis运行在内存中但是可以持久化到磁盘，所以在对不同数据集进行高速读写时需要权衡内存，因为数据量不能大于硬件内存。在内存数据库方面的另一个优点是，相比在磁盘上相同的复杂的数据结构，在内存中操作起来非常简单，这样Redis可以做很多内部复杂性很强的事情。同时，在磁盘格式方面他们是紧凑的以追加的方式产生的，因为他们并不需要进行随机访问。 Redis应用场景显示最新的项目列表下面这个语句常用来显示最新项目，随着数据多了，查询毫无疑问会越来越慢。 SELECT * FROM foo WHERE ... ORDER BY time DESC LIMIT 10 在Web应用中，“列出最新的回复”之类的查询非常普遍，这通常会带来可扩展性问题。这令人沮丧，因为项目本来就是按这个顺序被创建的，但要输出这个顺序却不得不进行排序操作。 类似的问题就可以用Redis来解决。比如说，我们的一个Web应用想要列出用户贴出的最新20条评论。在最新的评论边上我们有一个“显示全部”的链接，点击后就可以获得更多的评论。 我们假设数据库中的每条评论都有一个唯一的递增的ID字段。我们可以使用分页来制作主页和评论页，使用Redis的模板： 每次新评论发表时，我们会将它的ID添加到一个Redis列表： LPUSH latest.comments &lt;ID> 我们将列表裁剪为指定长度，因此Redis只需要保存最新的5000条评论： LTRIM latest.comments 0 5000 每次我们需要获取最新评论的项目范围时，我们调用一个函数来完成（使用伪代码）： FUNCTION get_latest_comments(start,num_items): id_list = redis.lrange(\"latest.comments\",start,start+num_items-1) IF id_list.length &lt; num_items id_list = SQL_DB(\"SELECT ... ORDER BY time LIMIT ...\") END RETURN id_list END 这里我们做的很简单。在Redis中我们的最新ID使用了常驻缓存，这是一直更新的。但是我们做了限制不能超过5000个ID，因此我们的获取ID函数会一直询问Redis。只有在start/count参数超出了这个范围的时候，才需要去访问数据库。我们的系统不会像传统方式那样“刷新”缓存，Redis实例中的信息永远是一致的。SQL数据库（或是硬盘上的其他类型数据库）只是在用户需要获取“很远”的数据时才会被触发，而主页或第一个评论页是不会麻烦到硬盘上的数据库了。 删除与过滤我们可以使用LREM来删除评论。如果删除操作非常少，另一个选择是直接跳过评论条目的入口，报告说该评论已经不存在。 有些时候你想要给不同的列表附加上不同的过滤器。如果过滤器的数量受到限制，你可以简单的为每个不同的过滤器使用不同的Redis列表。毕竟每个列表只有5000条项目，但Redis却能够使用非常少的内存来处理几百万条项目。 排行榜相关另一个很普遍的需求是各种数据库的数据并非存储在内存中，因此在按得分排序以及实时更新这些几乎每秒钟都需要更新的功能上数据库的性能不够理想。 典型的比如那些在线游戏的排行榜，比如一个Facebook的游戏，根据得分你通常想要： 列出前100名高分选手 列出某用户当前的全球排名 这些操作对于Redis来说小菜一碟，即使你有几百万个用户，每分钟都会有几百万个新的得分。 模式是这样的，每次获得新得分时，我们用这样的代码： ZADD leaderboard 你可能用userID来取代username，这取决于你是怎么设计的。 得到前100名高分用户很简单： ZREVRANGE leaderboard 0 99 用户的全球排名也相似，只需要： ZRANK leaderboard 按照用户投票和时间排序排行榜的一种常见变体模式就像Reddit或Hacker News用的那样，新闻按照类似下面的公式根据得分来排序：score = points / time^alpha 因此用户的投票会相应的把新闻挖出来，但时间会按照一定的指数将新闻埋下去。下面是我们的模式，当然算法由你决定。 模式是这样的，开始时先观察那些可能是最新的项目，例如首页上的1000条新闻都是候选者，因此我们先忽视掉其他的，这实现起来很简单。 每次新的新闻贴上来后，我们将ID添加到列表中，使用LPUSH + LTRIM，确保只取出最新的1000条项目。 有一项后台任务获取这个列表，并且持续的计算这1000条新闻中每条新闻的最终得分。计算结果由ZADD命令按照新的顺序填充生成列表，老新闻则被清除。这里的关键思路是排序工作是由后台任务来完成的。 过期项目处理另一种常用的项目排序是按照时间排序。我们使用unix时间作为得分即可。 模式如下： 每次有新项目添加到我们的非Redis数据库时，我们把它加入到排序集合中。这时我们用的是时间属性，current_time和time_to_live。另一项后台任务使用ZRANGE…SCORES查询排序集合，取出最新的10个项目。如果发现unix时间已经过期，则在数据库中删除条目。 计数Redis是一个很好的计数器，这要感谢INCRBY和其他相似命令。 我相信你曾许多次想要给数据库加上新的计数器，用来获取统计或显示新信息，但是最后却由于写入敏感而不得不放弃它们。 好了，现在使用Redis就不需要再担心了。有了原子递增（atomic increment），你可以放心的加上各种计数，用GETSET重置，或者是让它们过期。 例如这样操作： INCR user: EXPIRE user: 60 你可以计算出最近用户在页面间停顿不超过60秒的页面浏览量，当计数达到比如20时，就可以显示出某些条幅提示，或是其它你想显示的东西。 特定时间内的特定项目另一项对于其他数据库很难，但Redis做起来却轻而易举的事就是统计在某段特点时间里有多少特定用户访问了某个特定资源。比如我想要知道某些特定的注册用户或IP地址，他们到底有多少访问了某篇文章。 每次我获得一次新的页面浏览时我只需要这样做： SADD page:day1:&lt;page_id> &lt;user_id> 当然你可能想用unix时间替换day1，比如time()-(time()%3600*24)等等。 想知道特定用户的数量吗？只需要使用 SCARD page:day1:&lt;page_id> 需要测试某个特定用户是否访问了这个页面？ 实时分析正在发生的情况，用于数据统计与防止垃圾邮件等我们只做了几个例子，但如果你研究Redis的命令集，并且组合一下，就能获得大量的实时分析方法，有效而且非常省力。使用Redis原语命令，更容易实施垃圾邮件过滤系统或其他实时跟踪系统。 Pub/Sub 订阅Redis的Pub/Sub非常非常简单，运行稳定并且快速。支持模式匹配，能够实时订阅与取消频道。 队列你应该已经注意到像list push和list pop这样的Redis命令能够很方便的执行队列操作了，但能做的可不止这些：比如Redis还有list pop的变体命令，能够在列表为空时阻塞队列。 缓存Redis的缓存部分值得写一篇新文章，我这里只是简单的说一下。Redis能够替代memcached，让你的缓存从只能存储数据变得能够更新数据，因此你不再需要每次都重新生成数据了。","tags":[{"name":"Redis","slug":"Redis","permalink":"http://www.jifu.io/tags/Redis/"},{"name":"应用场景","slug":"应用场景","permalink":"http://www.jifu.io/tags/应用场景/"},{"name":"分析","slug":"分析","permalink":"http://www.jifu.io/tags/分析/"}],"categories":[{"name":"back-end","slug":"back-end","permalink":"http://www.jifu.io/categories/back-end/"},{"name":"Middle-ware","slug":"back-end/Middle-ware","permalink":"http://www.jifu.io/categories/back-end/Middle-ware/"},{"name":"Redis","slug":"back-end/Middle-ware/Redis","permalink":"http://www.jifu.io/categories/back-end/Middle-ware/Redis/"}]},{"title":"分库分表 vs NewSQL数据库","date":"2019-07-12T12:06:30.000Z","path":"posts/2654174479/","text":"概述最近与同行科技交流，经常被问到分库分表与分布式数据库如何选择，网上也有很多关于中间件+传统关系数据库（分库分表）与NewSQL分布式数据库的文章，但有些观点与判断是我觉得是偏激的，脱离环境去评价方案好坏其实有失公允。 本文通过对两种模式关键特性实现原理对比，希望可以尽可能客观、中立的阐明各自真实的优缺点以及适用场景。 NewSQL数据库先进在哪儿?首先关于“中间件+关系数据库分库分表”算不算NewSQL分布式数据库问题，国外有篇论文pavlo-newsql-sigmodrec，如果根据该文中的分类，Spanner、TiDB、OB算是第一种新架构型，Sharding-Sphere、Mycat、DRDS等中间件方案算是第二种（文中还有第三种云数据库，本文暂不详细介绍）。 基于中间件（包括SDK和Proxy两种形式）+传统关系数据库（分库分表）模式是不是分布式架构？我觉得是的，因为存储确实也分布式了，也能实现横向扩展。但是不是”伪”分布式数据库？从架构先进性来看，这么说也有一定道理。”伪”主要体现在中间件层与底层DB重复的SQL解析与执行计划生成、存储引擎基于B+Tree等，这在分布式数据库架构中实际上冗余低效的。为了避免引起真伪分布式数据库的口水战，本文中NewSQL数据库特指这种新架构NewSQL数据库。 NewSQL数据库相比中间件+分库分表的先进在哪儿？画一个简单的架构对比图： 传统数据库面向磁盘设计，基于内存的存储管理及并发控制，不如NewSQL数据库那般高效利用。 中间件模式SQL解析、执行计划优化等在中间件与数据库中重复工作，效率相比较低； NewSQL数据库的分布式事务相比于XA进行了优化，性能更高； 新架构NewSQL数据库存储设计即为基于paxos（或Raft）协议的多副本，相比于传统数据库主从模式（半同步转异步后也存在丢数问题），在实现了真正的高可用、高可靠（RTO&lt;30s，RPO=0） NewSQL数据库天生支持数据分片，数据的迁移、扩容都是自动化的，大大减轻了DBA的工作，同时对应用透明，无需在SQL指定分库分表键。这些大多也是NewSQL数据库产品主要宣传的点，不过这些看起来很美好的功能是否真的如此？接下来针对以上几点分别阐述下的我的理解。 分布式事务这是把双刃剑 CAP限制想想更早些出现的NoSQL数据库为何不支持分布式事务（最新版的mongoDB等也开始支持了），是缺乏理论与实践支撑吗？并不是，原因是CAP定理依然是分布式数据库头上的颈箍咒，在保证强一致的同时必然会牺牲可用性A或分区容忍性P。为什么大部分NoSQL不提供分布式事务？ 那么NewSQL数据库突破CAP定理限制了吗？并没有。NewSQL数据库的鼻主Google Spanner（目前绝大部分分布式数据库都是按照Spanner架构设计的）提供了一致性和大于5个9的可用性，宣称是一个“实际上是CA”的，其真正的含义是系统处于 CA 状态的概率非常高，由于网络分区导致的服务停用的概率非常小，究其真正原因是其打造私有全球网保证了不会出现网络中断引发的网络分区，另外就是其高效的运维队伍,这也是cloud spanner的卖点。详细可见CAP提出者Eric Brewer写的《Spanner, TrueTime 和CAP理论》。 推荐一篇关于分布式系统有趣的文章，站在巨人的分布式肩膀上，其中提到：分布式系统中，您可以知道工作在哪里，或者您可以知道工作何时完成，但您无法同时了解两者；两阶段协议本质上是反可用性协议。 完备性两阶段提交协议是否严格支持ACID，各种异常场景是不是都可以覆盖？2PC在commit阶段发送异常，其实跟最大努力一阶段提交类似也会有部分可见问题，严格讲一段时间内并不能保证A原子性和C一致性（待故障恢复后recovery机制可以保证最终的A和C）。完备的分布式事务支持并不是一件简单的事情，需要可以应对网络以及各种硬件包括网卡、磁盘、CPU、内存、电源等各类异常，通过严格的测试。之前跟某友商交流，他们甚至说目前已知的NewSQL在分布式事务支持上都是不完整的，他们都有案例跑不过，圈内人士这么笃定，也说明了分布式事务的支持完整程度其实是层次不齐的。 但分布式事务又是这些NewSQL数据库的一个非常重要的底层机制，跨资源的DML、DDL等都依赖其实现，如果这块的性能、完备性打折扣，上层跨分片SQL执行的正确性会受到很大影响。 性能传统关系数据库也支持分布式事务XA，但为何很少有高并发场景下用呢？ 因为XA的基础两阶段提交协议存在网络开销大，阻塞时间长、死锁等问题，这也导致了其实际上很少大规模用在基于传统关系数据库的OLTP系统中。NewSQL数据库的分布式事务实现也仍然多基于两阶段提交协议，例如google percolator分布式事务模型，采用原子钟+MVCC+ Snapshot Isolation（SI），这种方式通过TSO(Timestamp Oracle)保证了全局一致性，通过MVCC避免了锁，另外通过primary lock和secondary lock将提交的一部分转为异步，相比XA确实提高了分布式事务的性能。 SI是乐观锁，在热点数据场景，可能会大量的提交失败。另外SI的隔离级别与RR并非完全相同，它不会有幻想读，但会有写倾斜。但不管如何优化，相比于1PC，2PC多出来的GID获取、网络开销、prepare日志持久化还是会带来很大的性能损失，尤其是跨节点的数量比较多时会更加显著，例如在银行场景做个批量扣款，一个文件可能上W个账户，这样的场景无论怎么做还是吞吐都不会很高。Spanner给出的分布式事务测试数据 虽然NewSQL分布式数据库产品都宣传完备支持分布式事务，但这并不是说应用可以完全不用关心数据拆分，这些数据库的最佳实践中仍然会写到，应用的大部分场景尽可能避免分布式事务。 既然强一致事务付出的性能代价太大，我们可以反思下是否真的需要这种强一致的分布式事务？尤其是在做微服务拆分后，很多系统也不太可能放在一个统一的数据库中。尝试将一致性要求弱化，便是柔性事务，放弃ACID(Atomicity,Consistency, Isolation, Durability)，转投BASE(Basically Available,Soft state,Eventually consistent)，例如Saga、TCC、可靠消息保证最终一致等模型，对于大规模高并发OLTP场景，我个人更建议使用柔性事务而非强一致的分布式事务。关于柔性事务，笔者之前也写过一个技术组件，最近几年也涌现出了一些新的模型与框架（例如阿里刚开源的Fescar），限于篇幅不再赘述，有空再单独写篇文章。 解决分布式事务是否只能用两阶段提交协议？oceanbase1.0中通过updateserver避免分布式事务的思路很有启发性 ，不过2.0版后也变成了2PC。业界分布式事务也并非只有两阶段提交这一解，也有其它方案its-time-to-move-on-from-two-phase(如果打不开，国内有翻译版https://www.jdon.com/51588) HA与异地多活主从模式并不是最优的方式，就算是半同步复制，在极端情况下（半同步转异步）也存在丢数问题，目前业界公认更好的方案是基于paxos分布式一致性协议或者其它类paxos如raft方式，Google Spanner、TiDB、cockcoachDB、OB都采用了这种方式，基于Paxos协议的多副本存储，遵循过半写原则，支持自动选主，解决了数据的高可靠，缩短了failover时间，提高了可用性，特别是减少了运维的工作量，这种方案技术上已经很成熟，也是NewSQL数据库底层的标配。当然这种方式其实也可以用在传统关系数据库，阿里、微信团队等也有将MySQL存储改造支持paxos多副本的，MySQL也推出了官方版MySQL Group Cluster，预计不远的未来主从模式可能就成为历史了。 分布式一致性算法本身并不难，但具体在工程实践时，需要考虑很多异常并做很多优化，实现一个生产级可靠成熟的一致性协议并不容易。例如实际使用时必须转化实现为multi-paxos或multi-raft，需要通过batch、异步等方式减少网络、磁盘IO等开销。 需要注意的是很多NewSQL数据库厂商宣传基于paxos或raft协议可以实现【异地多活】，这个实际上是有前提的，那就是异地之间网络延迟不能太高。以银行“两地三中心”为例，异地之间多相隔数千里，延时达到数十毫秒，如果要多活，那便需异地副本也参与数据库日志过半确认，这样高的延时几乎没有OLTP系统可以接受的。 数据库层面做异地多活是个美好的愿景，但距离导致的延时目前并没有好的方案。之前跟蚂蚁团队交流，蚂蚁异地多活的方案是在应用层通过MQ同步双写交易信息，异地DC将交易信息保存在分布式缓存中，一旦发生异地切换，数据库同步中间件会告之数据延迟时间，应用从缓存中读取交易信息，将这段时间内涉及到的业务对象例如用户、账户进行黑名单管理，等数据同步追上之后再将这些业务对象从黑名单中剔除。由于双写的不是所有数据库操作日志而只是交易信息，数据延迟只影响一段时间内数据，这是目前我觉得比较靠谱的异地度多活方案。 另外有些系统进行了单元化改造，这在paxos选主时也要结合考虑进去，这也是目前很多NewSQL数据库欠缺的功能。 Scale横向扩展与分片机制paxos算法解决了高可用、高可靠问题，并没有解决Scale横向扩展的问题，所以分片是必须支持的。NewSQL数据库都是天生内置分片机制的，而且会根据每个分片的数据负载(磁盘使用率、写入速度等)自动识别热点，然后进行分片的分裂、数据迁移、合并，这些过程应用是无感知的，这省去了DBA的很多运维工作量。以TiDB为例，它将数据切成region，如果region到64M时，数据自动进行迁移。 分库分表模式下需要应用设计之初就要明确各表的拆分键、拆分方式（range、取模、一致性哈希或者自定义路由表）、路由规则、拆分库表数量、扩容方式等。相比NewSQL数据库，这种模式给应用带来了很大侵入和复杂度，这对大多数系统来说也是一大挑战。 分库分表模式也能做到在线扩容，基本思路是通过异步复制先追加数据，然后设置只读完成路由切换，最后放开写操作，当然这些需要中间件与数据库端配合一起才能完成。 这里有个问题是NewSQL数据库统一的内置分片策略（例如tidb基于range）可能并不是最高效的，因为与领域模型中的划分要素并不一致，这导致的后果是很多交易会产生分布式事务。举个例子，银行核心业务系统是以客户为维度，也就是说客户表、该客户的账户表、流水表在绝大部分场景下是一起写的，但如果按照各表主键range进行分片，这个交易并不能在一个分片上完成，这在高频OLTP系统中会带来性能问题。 分布式SQL支持常见的单分片SQL，这两者都能很好支持。NewSQL数据库由于定位与目标是一个通用的数据库，所以支持的SQL会更完整，包括跨分片的join、聚合等复杂SQL。中间件模式多面向应用需求设计，不过大部分也支持带拆分键SQL、库表遍历、单库join、聚合、排序、分页等。但对跨库的join以及聚合支持就不够了。 NewSQL数据库一般并不支持存储过程、视图、外键等功能，而中间件模式底层就是传统关系数据库，这些功能如果只是涉及单库是比较容易支持的。 NewSQL数据库往往选择兼容MySQL或者PostgreSQL协议，所以SQL支持仅局限于这两种，中间件例如驱动模式往往只需做简单的SQL解析、计算路由、SQL重写，所以可以支持更多种类的数据库SQL。 SQL支持的差异主要在于分布式SQL执行计划生成器，由于NewSQL数据库具有底层数据的分布、统计信息，因此可以做CBO，生成的执行计划效率更高，而中间件模式下没有这些信息，往往只能基于规则RBO（Rule-Based-Opimization），这也是为什么中间件模式一般并不支持跨库join，因为实现了效率也往往并不高，还不如交给应用去做。 这里也可以看出中间件+分库分表模式的架构风格体现出的是一种妥协、平衡，它是一个面向应用型的设计；而NewSQL数据库则要求更高、“大包大揽”，它是一个通用底层技术软件，因此后者的复杂度、技术门槛也高很多。 存储引擎传统关系数据库的存储引擎设计都是面向磁盘的，大多都基于B+树。B+树通过降低树的高度减少随机读、进而减少磁盘寻道次数，提高读的性能，但大量的随机写会导致树的分裂，从而带来随机写，导致写性能下降。NewSQL的底层存储引擎则多采用LSM，相比B+树LSM将对磁盘的随机写变成顺序写，大大提高了写的性能。不过LSM的的读由于需要合并数据性能比B+树差，一般来说LSM更适合应在写大于读的场景。当然这只是单纯数据结构角度的对比，在数据库实际实现时还会通过SSD、缓冲、bloom filter等方式优化读写性能，所以读性能基本不会下降太多。NewSQL数据由于多副本、分布式事务等开销，相比单机关系数据库SQL的响应时间并不占优，但由于集群的弹性扩展，整体QPS提升还是很明显的，这也是NewSQL数据库厂商说分布式数据库更看重的是吞吐，而不是单笔SQL响应时间的原因。 成熟度与生态分布式数据库是个新型通用底层软件，准确的衡量与评价需要一个多维度的测试模型，需包括发展现状、使用情况、社区生态、监控运维、周边配套工具、功能满足度、DBA人才、SQL兼容性、性能测试、高可用测试、在线扩容、分布式事务、隔离级别、在线DDL等等，虽然NewSQL数据库发展经过了一定时间检验，但多集中在互联网以及传统企业非核心交易系统中，目前还处于快速迭代、规模使用不断优化完善的阶段。相比而言，传统关系数据库则经过了多年的发展，通过完整的评测，在成熟度、功能、性能、周边生态、风险把控、相关人才积累等多方面都具有明显优势，同时对已建系统的兼容性也更好。 对于互联网公司，数据量的增长压力以及追求新技术的基因会更倾向于尝试NewSQL数据库，不用再考虑库表拆分、应用改造、扩容、事务一致性等问题怎么看都是非常吸引人的方案。 对于传统企业例如银行这种风险意识较高的行业来说，NewSQL数据库则可能在未来一段时间内仍处于探索、审慎试点的阶段。基于中间件+分库分表模式架构简单，技术门槛更低，虽然没有NewSQL数据库功能全面，但大部分场景最核心的诉求也就是拆分后SQL的正确路由，而此功能中间件模式应对还是绰绰有余的，可以说在大多数OLTP场景是够用的。 限于篇幅，其它特性例如在线DDL、数据迁移、运维工具等特性就不在本文展开对比。 总结如果看完以上内容，您还不知道选哪种模式，那么结合以下几个问题，先思考下NewSQL数据库解决的点对于自身是不是真正的痛点： 强一致事务是否必须在数据库层解决？ 数据的增长速度是否不可预估的？ 扩容的频率是否已超出了自身运维能力？ 相比响应时间更看重吞吐？ 是否必须做到对应用完全透明？ 是否有熟悉NewSQL数据库的DBA团队？ 如果以上有2到3个是肯定的，那么你可以考虑用NewSQL数据库了，虽然前期可能需要一定的学习成本，但它是数据库的发展方向，未来收益也会更高，尤其是互联网行业，随着数据量的突飞猛进，分库分表带来的痛苦会与日俱增。当然选择NewSQL数据库你也要做好承担一定风险的准备。 如果你还未做出抉择，不妨再想想下面几个问题： 最终一致性是否可以满足实际场景？ 数据未来几年的总量是否可以预估？ 扩容、DDL等操作是否有系统维护窗口？ 对响应时间是否比吞吐更敏感？ 是否需要兼容已有的关系数据库系统？ 是否已有传统数据库DBA人才的积累？ 是否可容忍分库分表对应用的侵入？ 如果这些问题有多数是肯定的，那还是分库分表吧。在软件领域很少有完美的解决方案，NewSQL数据库也不是数据分布式架构的银弹。相比而言分库分表是一个代价更低、风险更小的方案，它最大程度复用传统关系数据库生态，通过中间件也可以满足分库分表后的绝大多数功能，定制化能力更强。在当前NewSQL数据库还未完全成熟的阶段，分库分表可以说是一个上限低但下限高的方案，尤其传统行业的核心系统，如果你仍然打算把数据库当做一个黑盒产品来用，踏踏实实用好分库分表会被认为是个稳妥的选择。","tags":[{"name":"数据库","slug":"数据库","permalink":"http://www.jifu.io/tags/数据库/"},{"name":"NewSQL","slug":"NewSQL","permalink":"http://www.jifu.io/tags/NewSQL/"},{"name":"关系型数据库","slug":"关系型数据库","permalink":"http://www.jifu.io/tags/关系型数据库/"}],"categories":[{"name":"back-end","slug":"back-end","permalink":"http://www.jifu.io/categories/back-end/"},{"name":"Middle-ware","slug":"back-end/Middle-ware","permalink":"http://www.jifu.io/categories/back-end/Middle-ware/"},{"name":"MySQL","slug":"back-end/Middle-ware/MySQL","permalink":"http://www.jifu.io/categories/back-end/Middle-ware/MySQL/"}]},{"title":"Mac高效使用技巧","date":"2019-07-08T12:19:11.000Z","path":"posts/3366946474/","text":"去格式粘贴复制文本内容的时候经常会带格式（字号、颜色、字体，有时候还有看不见的代码），手动调整会很麻烦， 使用方法Command+C Command+V --> Command + Shift + option + V 通过以上方法就能快速的丢弃原有的格式属性，使其与当前文本格式保持一致 Split Screen分屏功能这依旧是一条提升生产力的功能，习惯一个屏打开IDEA，另外一个开着Google，对于没有外接显示器来说我们可以使用Mac自带的分屏来实现（有的软件可能不支持） 使用方法左键按住一个程序左上方绿色最大化按钮不动，这时会让你选择当前选中App会出现在哪一边，可以是左边也可以是右边，排好之后再点击另一个App就会出现在另一侧，这样一来，同一屏幕中就同时有了两个App的界面。中间有一条分隔线，拖动分割线可以重新划分左右的区域大小，可以让你的注意力更集中在某一方面。 Xcode 和模拟器分屏需要在终端实现以下命令defaults write com.apple.iphonesimulator AllowFullscreenMode -bool YES 应用程序“接力”例：“电脑上复制，手机上粘贴”的通用剪贴板，是不是很NB 条件 所有设备均使用同一 Apple ID 登录 iCloud 所有设备均已开启蓝牙 所有设备均已开启 Wi-Fi 打开接力手机: 设置 –&gt; 通用 –&gt; 接力 MAC：系统偏好设置 –&gt; 通用 –&gt; 允许在这台Mac和iClould设备之间使用“接力”打开iClouds手机打开iCloud：设置 –&gt; 头像 –&gt; iCloud电脑打开iCloud：系统偏好设置 –&gt; iCloud 快捷键切换应用这个应该不用说了吧，大家应该都知道 Command+Tab 使用QQ录屏导出gif图 显示桌面快捷键（类型Windows中的 Win + D效果） 手机投屏两种方式QuickTime Player - (系统自带，有线连接) AirServer （第三方，无线连接）破解地址 快速定位到终端（Go2Shell插件）","tags":[{"name":"技巧","slug":"技巧","permalink":"http://www.jifu.io/tags/技巧/"},{"name":"Mac","slug":"Mac","permalink":"http://www.jifu.io/tags/Mac/"},{"name":"高效","slug":"高效","permalink":"http://www.jifu.io/tags/高效/"}],"categories":[{"name":"OPS","slug":"OPS","permalink":"http://www.jifu.io/categories/OPS/"},{"name":"MacOS","slug":"OPS/MacOS","permalink":"http://www.jifu.io/categories/OPS/MacOS/"}]},{"title":"Axel:命令行下轻量级多线程下载程序","date":"2019-06-10T14:55:18.000Z","path":"posts/2867836530/","text":"介绍Axel 是一个轻量级下载程序，它和其他加速器一样，对同一个文件建立多个连接，每个连接下载单独的文件片段以更快地完成下载。 Axel 支持 HTTP、HTTPS、FTP 和 FTPS 协议。它也可以使用多个镜像站点下载单个文件，所以，Axel 可以加速下载高达 40％（大约，我个人认为）。它非常轻量级，因为它没有依赖并且使用非常少的 CPU 和内存。 Axel 一步到位地将所有数据直接下载到目标文件（LCTT 译注：而不是像其它的下载软件那样下载成多个文件块，然后拼接）。 注意：不支持在单条命令中下载两个文件。 你还可以尝试其他命令行下载管理器/加速器。 aria2 - 超快速下载程序 wget - 标准命令行下载程序 curl - 命令行下载程序 Linux 下的最好的 4 个命令行下载管理器/加速器 Axel安装大多数发行版（Debian、Ubuntu、Mint、Fedora、suse、openSUSE、Arch Linux、Manjaro、Mageia 等）都有 axel 包，所以我们可以从发行版官方仓库轻松安装。对于 CentOS/RHEL，我们需要启用 EPEL Repository。 在 Debian/Ubuntu/LinuxMint 上安装 Axel$sudo apt-get install axel 在 RHEL/CentOS 上安装 Axel$sudo yum install axel 在 Fedora 上安装 Axel$sudo dnf install axel 在 openSUSE 上安装 Axel$sudo zypper install axel 在 Mageia 上安装 Axel$sudo urpmi axel 在基于 Arch Linux 的发行版安装 Axel$sudo pacman -S axel 下载单个文件以下命令将从给定的 URL 下载文件并存储在当前目录中，下载文件时，我们可以看到文件的信息（建立的连接数、下载速度、下载进度、完成下载所花费的时间以及连接完成的时间）。 # axel https://download.owncloud.org/community/owncloud-9.0.0.tar.bz2 Initializing download: https://download.owncloud.org/community/owncloud-9.0.0.tar.bz2 File size: 22678208 bytes Opening output file owncloud-9.0.0.tar.bz2 Starting download [ 0%] .......... .......... .......... .......... .......... [ 146.7KB/s] [ 0%] .......... .......... .......... .......... .......... [ 267.0KB/s] [ 0%] .......... .......... .......... .......... .......... [ 373.9KB/s] [ 0%] .......... .......... .......... .......... .......... [ 406.9KB/s] [ 0%] .......... .......... .......... .......... .......... [ 487.5KB/s] [ 1%] .......... .......... .......... .......... .......... [ 572.6KB/s] [ 1%] .......... .......... .......... .......... .......... [ 650.7KB/s] [ 1%] .......... .......... .......... .......... .......... [ 649.3KB/s] [ 1%] .......... .......... .......... .......... .......... [ 718.1KB/s] [ 2%] .......... .......... .......... .......... .......... [ 769.3KB/s] [ 2%] .......... .......... .......... .......... .......... [ 838.7KB/s] [ 2%] .......... .......... .......... .......... .......... [ 866.0KB/s] Connection 0 finished . . [ 99%] .......... .......... .......... .......... .......... [5721.0KB/s] Connection 2 finished [ 99%] .......... .......... .......... .......... .......... [5733.4KB/s] Connection 1 finished [ 99%] .......... .......... .......... .......... .......... [5745.4KB/s] [100%] .......... .......... .......... .......... ...... Downloaded 21.6 megabytes in 3 seconds. (5755.94 KB/s) 用不同的名称保存文件要使用其他名称来保存文件，启动下载时可以添加 -o（小写字母）选项和文件名。这里我们使用文件名 owncloud.tar.bz2 来保存文件。 # axel -o cloud.tar.bz2 https://download.owncloud.org/community/owncloud-9.0.0.tar.bz2 Initializing download: https://download.owncloud.org/community/owncloud-9.0.0.tar.bz2 File size: 22678208 bytes Opening output file cloud.tar.bz2 Starting download [ 0%] .......... .......... .......... .......... .......... [ 143.0KB/s] [ 0%] .......... .......... .......... .......... .......... [ 264.1KB/s] [ 0%] .......... .......... .......... .......... .......... [ 309.8KB/s] [ 0%] .......... .......... .......... .......... .......... [ 406.3KB/s] [ 0%] .......... .......... .......... .......... .......... [ 495.4KB/s] [ 1%] .......... .......... .......... .......... .......... [ 586.3KB/s] [ 1%] .......... .......... .......... .......... .......... [ 673.1KB/s] [ 1%] .......... .......... .......... .......... .......... [ 647.1KB/s] [ 1%] .......... .......... .......... .......... .......... [ 721.1KB/s] [ 2%] .......... .......... .......... .......... .......... [ 781.3KB/s] Connection 2 finished . . Connection 0 finished [ 98%] .......... .......... .......... .......... .......... [6221.9KB/s] [ 98%] .......... .......... ..... Connection 1 finished ,,,,,,,,,, ,,,,,,,,,, ,,,,,..... .......... .......... [6145.6KB/s] [ 99%] .......... .......... .......... .......... .......... [6159.2KB/s] [ 99%] .......... .......... .......... .......... .......... [6172.0KB/s] [ 99%] .......... .......... .......... .......... .......... [5977.9KB/s] [ 99%] .......... .......... .......... .......... .......... [5989.6KB/s] [100%] .......... .......... .......... .......... ...... Downloaded 21.6 megabytes in 3 seconds. (6001.05 KB/s) 限制下载速度默认情况下 axel 以字节/秒为单位设置下载文件的最大速度。当我们的网络连接速度较慢时，可以使用此选项。只需添加 -s 选项，后面跟字节值。这里我们要限速 512 KB/s 下载一个文件。 # axel -s 512000 https://download.owncloud.org/community/owncloud-9.0.0.tar.bz2 Initializing download: https://download.owncloud.org/community/owncloud-9.0.0.tar.bz2 File size: 22678208 bytes Opening output file owncloud-9.0.0.tar.bz2 Starting download [ 0%] .......... .......... .......... .......... .......... [ 141.5KB/s] [ 0%] .......... .......... .......... .......... .......... [ 266.1KB/s] [ 0%] .......... .......... .......... .......... .......... [ 308.0KB/s] [ 0%] .......... .......... .......... .......... .......... [ 405.9KB/s] [ 0%] .......... .......... .......... .......... .......... [ 496.7KB/s] [ 1%] .......... .......... .......... .......... .......... [ 526.4KB/s] [ 1%] .......... .......... .......... .......... .......... [ 507.0KB/s] [ 1%] .......... .......... .......... .......... .......... [ 505.6KB/s] [ 1%] .......... .......... .......... .......... .......... [ 504.8KB/s] [ 2%] .......... .......... .......... .......... .......... [ 503.9KB/s] [ 2%] .......... .......... .......... .......... .......... [ 503.4KB/s] . . [ 99%] .......... .......... .......... .......... .......... [ 497.0KB/s] [ 99%] .......... .......... .......... .......... .......... [ 496.9KB/s] [100%] .......... .. Connection 0 finished ,,,,,,,,,, ,,..... Connection 1 finished Connection 3 finished ,,,,,,,,,, ,,,,,,,... .......... .......... ...... Downloaded 21.6 megabytes in 44 seconds. (494.54 KB/s) 限制连接数axel 默认建立 4 个连接以从不同的镜像获取文件。此外，我们可以通过使用 -n 选项添加更多的连接，后跟连接数 10 来提高下载速度。保险起见，我们添加了十个连接，但不幸的是，它花了更多时间来下载文件。 # axel -n 10 https://download.owncloud.org/community/owncloud-9.0.0.tar.bz2 Initializing download: https://download.owncloud.org/community/owncloud-9.0.0.tar.bz2 File size: 22678208 bytes Opening output file owncloud-9.0.0.tar.bz2 Starting download [ 0%] .......... .......... .......... .......... .......... [ 140.8KB/s] [ 0%] .......... .......... .......... .......... .......... [ 265.7KB/s] [ 0%] .......... .......... .......... .......... .......... [ 305.4KB/s] [ 0%] .......... .......... .......... .......... .......... [ 402.1KB/s] [ 0%] .......... .......... .......... .......... .......... [ 496.3KB/s] [ 1%] .......... .......... .......... .......... .......... [ 522.1KB/s] [ 1%] .......... .......... .......... .......... .......... [ 567.5KB/s] [ 1%] .......... .......... .......... .......... .......... [ 640.5KB/s] [ 1%] .......... .......... .......... .......... .......... [ 710.8KB/s] [ 2%] .......... .......... .......... .......... .......... [ 780.5KB/s] . . [ 98%] .......... .......... .......... .......... .......... [7544.9KB/s] [ 98%] .......... .......... .......... .......... .......... [7557.9KB/s] [ 98%] .......... .......... .......... .......... .......... [7570.4KB/s] [ 98%] .......... .......... .......... .......... .......... [7495.3KB/s] [ 99%] .......... .......... .......... .......... ...... Connection 2 finished ,,,,,,,,,, ,,,,,,,,,, ,,,,,,,,,, ,,,,,,,,,, ,,,,,,.... [7311.6KB/s] [ 99%] .......... .......... .......... .......... .......... [7318.9KB/s] [ 99%] .......... .......... .......... .......... .......... Connection 9 finished ,,,,,,,,,, ,,,,,,,,,, ,,,,,,,,,, ,,,,,,,,,, ,,,,,,,,,, [7331.0KB/s] [ 99%] .......... .......... .......... .......... Connection 3 finished ,,,,,,,,,, ,,,,,,,,,, ,,,,,,,,,, ,,,,,,,,,, .......... [4300.7KB/s] [100%] .......... .......... .......... .......... ...... Downloaded 21.6 megabytes in 5 seconds. (4109.41 KB/s) 恢复未完成的下载axel 默认具有恢复未完成的下载的行为。Axel 在下载文件时定期更新状态文件（扩展名为 .st）。由于某些原因，下载中途停止了？不用担心，只要使用相同的 axel 命令，它将会检查 file 和 file.st，如果找到，它会从停止处恢复下载。 # axel https://download.owncloud.org/community/owncloud-9.0.0.tar.bz2 Initializing download: https://download.owncloud.org/community/owncloud-9.0.0.tar.bz2 File size: 22678208 bytes Opening output file owncloud-9.0.0.tar.bz2 Starting download [ 0%] .......... .......... .......... .......... .......... [ 140.8KB/s] [ 0%] .......... .......... .......... .......... .......... [ 265.7KB/s] [ 0%] .......... .......... .......... .......... .......... [ 305.4KB/s] [ 0%] .......... .......... .......... .......... .......... [ 402.1KB/s] [ 0%] .......... .......... .......... .......... .......... [ 496.3KB/s] [ 1%] .......... .......... .......... .......... .......... [ 522.1KB/s] [ 1%] .......... .......... .......... .......... .......... [ 567.5KB/s] [ 1%] .......... .......... .......... .......... .......... [ 640.5KB/s] [ 1%] .......... .......... .......... .......... .......... [ 710.8KB/s] [ 2%] .......... .......... .......... .......... .......... [ 780.5KB/s] . . [ 84%] .......... .......... .......... .......... .......... [7100.7KB/s] [ 84%] .......... .......... .......... .......... .......... [7104.3KB/s] [ 84%] .......... .......... .......... .^C Downloaded 18.3 megabytes in 2 seconds. (7009.79 KB/s) 上面的输出清晰地显示了在下载断开时有两个文件 owncloud-9.0.0.tar.bz2 和 owncloud-9.0.0.tar.bz2.st。当重新开始下载时，它会从停止处开始下载。 # ls -lh total 19M -rw------- 1 root root 22M Dec 27 08:33 owncloud-9.0.0.tar.bz2 -rw------- 1 root root 44 Dec 27 08:33 owncloud-9.0.0.tar.bz2.st # axel https://download.owncloud.org/community/owncloud-9.0.0.tar.bz2 Initializing download: https://download.owncloud.org/community/owncloud-9.0.0.tar.bz2 File size: 22678208 bytes Opening output file owncloud-9.0.0.tar.bz2 State file found: 19180828 bytes downloaded, 3497380 to go. Starting download ,,,,,,,,,, ,,,,,,,,,, ,,,,,,,,,, ,......... .......... [ 66.5KB/s] [ 84%] .......... .......... .......... .......... .......... [ 186.0KB/s] [ 85%] .......... .......... .......... .......... .......... [ 241.7KB/s] [ 85%] .......... .......... .......... .......... .......... [ 335.6KB/s] [ 85%] .......... .......... .......... .......... .......... [ 351.5KB/s] [ 85%] .......... .......... .......... .......... .......... [ 427.1KB/s] [ 85%] .......... .......... .......... .......... .......... [ 427.4KB/s] [ 86%] .......... .......... .......... .......... .......... [ 491.5KB/s] . . [ 98%] ... Connection 0 finished ,,,....... .......... .......... .......... .......... [2106.6KB/s] [ 99%] .......... .......... .......... .......... .......... [2140.5KB/s] [ 99%] .......... .......... .......... .......... .......... [2172.4KB/s] [ 99%] .......... .......... .......... .......... .......... [2203.2KB/s] [ 99%] .......... .......... .......... .......... .......... [2236.2KB/s] [100%] .......... .......... .......... .......... ...... Downloaded 3415.4 kilobytes in 1 second. (2264.93 KB/s) 不显示文件下载进度如果你不想要看到文件的下载进度，只要在 axel 命令中加入 -q 选项。 # axel -q https://download.owncloud.org/community/owncloud-9.0.0.tar.bz2 替换进度条如果你不喜欢默认的进度条，你可以使用 -a 选项来替换进度条。 # axel -a https://download.owncloud.org/community/owncloud-9.0.0.tar.bz2 Initializing download: https://download.owncloud.org/community/owncloud-9.0.0.tar.bz2 File size: 22678208 bytes Opening output file owncloud-9.0.0.tar.bz2 Starting download [ 66%] [......0 ...1 ..........2 ...........3] [ 5.8MB/s] [00:01]^C Downloaded 14.3 megabytes in 2 seconds. (5916.11 KB/s) 我们中断了上面的下载，以便在下载文件时能清楚地显示替代进度条状态。一旦文件成功下载后，你可以看到相同的输出，如下所示。 # axel -a https://download.owncloud.org/community/owncloud-9.0.0.tar.bz2 File size: 22678208 bytes Opening output file owncloud-9.0.0.tar.bz2 Starting download Connection 2 finished ] Connection 1 finished ] Connection 3 finished ] Connection 0 finished ] Downloaded 21.6 megabytes in 4 seconds. (5062.32 KB/s) 了解关于 axel 的更多信息如果你想要了解更多关于 axel 的选项，只需要进入它的手册。 # man axel 或者 # axel --help","tags":[{"name":"Axel","slug":"Axel","permalink":"http://www.jifu.io/tags/Axel/"},{"name":"多线程","slug":"多线程","permalink":"http://www.jifu.io/tags/多线程/"},{"name":"命令行","slug":"命令行","permalink":"http://www.jifu.io/tags/命令行/"},{"name":"下载","slug":"下载","permalink":"http://www.jifu.io/tags/下载/"}],"categories":[{"name":"OPS","slug":"OPS","permalink":"http://www.jifu.io/categories/OPS/"},{"name":"Others","slug":"OPS/Others","permalink":"http://www.jifu.io/categories/OPS/Others/"}]},{"title":"解决“Mac应用”已损坏，无法打开的问题","date":"2019-05-28T01:50:52.000Z","path":"posts/558776221/","text":"问题描述在Mac下安装一些软件时提示”来自身份不明开发者”，其实这是Mac新系统启用了新的安全机制。默认只信任 Mac App Store 下载的软件和拥有开发者 ID 签名的应用程序。换句话说就是 Mac 系统默认只能安装靠谱渠道（有苹果审核的 Mac App Store）下载的软件或被认可的人开发的软件。 这当然是为了用户不会稀里糊涂安装流氓软件中招，但没有开发者签名的 “老实软件” 也受影响了，安装就会弹出下图所示警告框：“xxx已损坏，打不开。您应将它移到废纸篓”或者“打不开 xxx，因为它来自身份不明的开发者”。 方案1: 开放系统安装来源使用命令行打开设置选项macOS Sierra 10.12及以上系统默认是不开启这个设置选项，需要通过命令行手动显示。 在终端内执行sudo spctl --master-disable 修改系统配置修改系统配置：系统偏好设置… -&gt; 安全性与隐私。 系统偏好设置 安全性与隐私 认证 修改未任意来源 方案2: 使用xattr命令修复App权限Use xattr on the App Throwing the Damaged ErrorThis is sort of a last resort and is only recommended for advanced Mac users. Generally speaking if the app is still throwing a ‘damaged’ error message you might want to not use it. Use this at your own risk. With the command line you can use xattr to view and remove extended attributes from a file on the Mac including the application throwing the “Appname.app is damaged and can’t be opened. You should move it to the Trash.” error message. Launch Terminal and then issue the following command: xattr -cr /path/to/application.app For example: xattr -cr /Applications/Signal.app The -c flag removes all attributes, whereas -r applies recursively for the entire targeted .app directory contents. The xattr command can also be used to remove the ‘application downloaded from the internet’ error message on the Mac too. Again this is only recommended to advanced users because modifying extended attributes may have unintended consequences, and again you might be attempting to run an app that you should not be running, either for stability, privacy, security, or other reasons. Did the tricks above work to resolve the “Appname.app is damaged and can’t be opened. You should move it to the Trash.” error on the Mac for you? Do you know of another workaround or solution to resolving this error message? Share with us in the comments!","tags":[{"name":"Error","slug":"Error","permalink":"http://www.jifu.io/tags/Error/"},{"name":"无法打开","slug":"无法打开","permalink":"http://www.jifu.io/tags/无法打开/"},{"name":"已损坏","slug":"已损坏","permalink":"http://www.jifu.io/tags/已损坏/"},{"name":"Application is damaged and can't be opened!","slug":"Application-is-damaged-and-can-t-be-opened","permalink":"http://www.jifu.io/tags/Application-is-damaged-and-can-t-be-opened/"}],"categories":[{"name":"OPS","slug":"OPS","permalink":"http://www.jifu.io/categories/OPS/"},{"name":"MacOS","slug":"OPS/MacOS","permalink":"http://www.jifu.io/categories/OPS/MacOS/"}]},{"title":"sys.stdout.write实现Python控制台实时刷新打印","date":"2019-05-28T01:22:38.000Z","path":"posts/272954362/","text":"前言我们先来看看Print方法打印的效果from datetime import datetime as dt import sys import time for i in range(5): print(dt.now()) time.sleep(1) 输出结果C:\\Users\\Administrator\\PycharmProjects\\untitled\\venv\\Scripts\\python.exe C:/Users/Administrator/PycharmProjects/untitled/test.py 2018-08-06 16:46:46.636256 2018-08-06 16:46:47.636313 2018-08-06 16:46:48.636370 2018-08-06 16:46:49.636427 2018-08-06 16:46:50.637484 Process finished with exit code 0 可以看到，用print打印出来自动换行且不会清除上一个结果 help查看help（print） 输出结果print(...) print(value, ..., sep=' ', end='\\n', file=sys.stdout, flush=False) Prints the values to a stream, or to sys.stdout by default. Optional keyword arguments: file: a file-like object (stream); defaults to the current sys.stdout. sep: string inserted between values, default a space. end: string appended after the last value, default a newline. flush: whether to forcibly flush the stream. 可以看到end=“\\n”表示了print自带换行 如果我想要在一行中打印一串信息，并且在下一次执行的时候删除这一行再重新打印（效果类似如此），该如何做呢？尝试清屏可不可以? 清屏操作清屏试一试，查阅别的博客的方法有如下代码： import os os.system('cls') 但这是在命令行里使用的，用在编译器里不行。 解决办法这时候就要用到sys.stdout.write了 方法1from datetime import datetime as dt import sys import time while True: a = dt.now() sys.stdout.write(\"\\r{0}\".format(a)) sys.stdout.flush() time.sleep(1) 方法2from datetime import datetime as dt import sys import time for i in range(20): a = dt.now() sys.stdout.write(\"\\r{0}\".format(a)) sys.stdout.flush() sys.stdout.write('\\033[4A') time.sleep(1) 其关键就在于使用’\\r’这个转义字符（回到行首), sys.stdout.write首先打印这一行后不带任何结尾（前文已经说过print打印结尾带end=”\\n”，表示自带换行，换行了就不能在对已经打印的这一行进行更改编辑），使用了转移字符”\\r”使得光标回到行首，再把缓冲区显示出来，就得到了我们所需要的效果。 C:\\Users\\Administrator\\PycharmProjects\\untitled\\venv\\Scripts\\python.exe C:/Users/Administrator/PycharmProjects/untitled/test.py 2018-08-06 18:26:21.264878 Run只会显示这一个,并且一秒钟更新一次。 进度条实现进度条的特点 有标刻度显示所占总进度比例 有百分比显示所占比例 实现import time,sys for i in range(100): percent = i / 100 sys.stdout.write(\"\\r{0}{1}\".format(\"|\"*i , '%.2f%%' % (percent * 100))) sys.stdout.flush() time.sleep(1) 输出效果|||||||||||||||||||||||||||||||||33.00%","tags":[{"name":"Python","slug":"Python","permalink":"http://www.jifu.io/tags/Python/"},{"name":"Print","slug":"Print","permalink":"http://www.jifu.io/tags/Print/"},{"name":"实时刷新","slug":"实时刷新","permalink":"http://www.jifu.io/tags/实时刷新/"},{"name":"控制台","slug":"控制台","permalink":"http://www.jifu.io/tags/控制台/"},{"name":"stdout","slug":"stdout","permalink":"http://www.jifu.io/tags/stdout/"}],"categories":[{"name":"back-end","slug":"back-end","permalink":"http://www.jifu.io/categories/back-end/"},{"name":"Python","slug":"back-end/Python","permalink":"http://www.jifu.io/categories/back-end/Python/"}]},{"title":"如何编写开源项目的README文档","date":"2019-05-25T09:11:42.000Z","path":"posts/467054247/","text":"运营一个开源项目就像在运营着一家 Startup，你期待更多人来使用你的项目，并给你的项目加 Star/提交 PR，但好的项目除了其自身真正契合了开发者的需求外，还需要一个好的 README。 有好的 README 文档的项目不一定是一个好开源项目，但一个好开源项目一定有一个好的 README。 目前 README 文档编写并没有规范，但一个友好的 README 是有其特征的，我们来看看一个好的 README 的必备要素。 国际化问题首先要注意的是国际化问题，如果你希望自己的项目能获得更多人的使用，提供中英两种 README 文档是非常赞的。你可以在项目头部注明它。如 Coding 的 WebIDE 项目： 项目名及简介好的项目名及简介是好项目必不可少的。开源项目名不宜过长（除非你有特别的理由这么做），如果你不知道如何给自己的项目起名，可以使用 随机项目名产生器（适用于 Javascript 项目）；项目简介可以是简单的几句话，但项目简介要说明几个你的开源项目用户想迫切了解的问题，这包括： 这个开源项目是做什么的？ 这个项目是什么语言编写的？ 项目维护、CI、依赖更新状态（如果有） 项目可用版本及其他版本 Demo 或官网地址（如果有） 如 Coding 的 WebIDE 项目： 此外你还可以给项目增加一些图标以提高可读性，推荐使用 Shields.io 项目 Logo 和使用截图你还可以将项目 Logo（如果有的话）放置在 REAME 顶部（这里推荐一个在线制作 Logo 的网站 Canva ），项目截图（Gif 动图更佳）也可以帮助你的用户更快速更直观地了解你的开源项目。 功能你可以注明这个项目的功能特点，亮点特色会大大提高访客使用这个项目的概率。 如 Coding 的 WebIDE 项目。 用法这是 README 中最重要的部分，你需要说明这个项目如何使用，这包括： 如何下载这个项目：一般情况下 git clone 该项目地址即可，当然你也可以提供其他包管理下载安装方式； 项目依赖：你需要说明编译运行这个项目前需要哪些依赖； 安装：你需要说明如何编译安装/运行这个项目； 部署：如果这个项目可以部署的话，请最好注明部署要注意的事项； Debug 方法：理想状况下，你的用户会顺利编译并运行这个项目，但你要确保用户遇到了问题不会来打扰你（如提交 Issues），你还需要提供用户可能会遇到的常见问题； 贡献对于一个开源项目来说，令其作者最开心的莫过于有人提交 Pull Request 了。加入一个 CONTRIBUTING 文档将大大提高他人贡献你的项目的概率。 你可以说明你的代码规范，项目架构，如何测试和提交 Pull Request 的正确格式，以及其他有利于开发者进行贡献的信息，这将会使你的项目变得更加的规整如一。你可以在项目根目录新建一个 CONTRIBUTING 进行详细的说明并在 README 中添加其文件锚链接。如 Google 的 Template： 版权版权是非常重要的，如果没有声明版权，很多用户特别是企业级用户将受制于法律问题，无法使用你的项目。关于如何选择开源项目许可证，推荐阅读这篇文章：《如何选择开源许可证？》 如 Coding 开源的 帮助文档 版权： 鸣谢你还可以感谢直接或间接为这个项目做出贡献的人、项目。 如 ttyd 项目： 其他我们推荐使用 Markdown 编写你的 README，请最好注意排版问题以增加文档可读性，推荐阅读 Coding 的 《文案排版规范》。 这就是一个好的 README 所需元素了，当然你还可以增加其他任何利于开发者的信息如 Roadmap 等等，这因项目而异。现在，去完善你的开源项目信息或开始做一个开源项目吧！ 一些建议：选择一个好的代码托管平台/社区可以让你的开源项目获得更多曝光，你可以在 Coding 的 冒泡社区（可以理解为程序员的朋友圈）发布你的项目简介，截图和地址，与 30 万中国开发者分享你的开源项目；另外我们推荐同时 push 项目到 Coding 和 GitHub（可参考 该回答 ），得益于 Coding 遍布全国的 CDN，国内用户 clone 你的项目时的速度将大大提升。","tags":[{"name":"README","slug":"README","permalink":"http://www.jifu.io/tags/README/"},{"name":"文档","slug":"文档","permalink":"http://www.jifu.io/tags/文档/"},{"name":"开源项目","slug":"开源项目","permalink":"http://www.jifu.io/tags/开源项目/"}],"categories":[{"name":"Soft engineering","slug":"Soft-engineering","permalink":"http://www.jifu.io/categories/Soft-engineering/"},{"name":"Project","slug":"Soft-engineering/Project","permalink":"http://www.jifu.io/categories/Soft-engineering/Project/"}]},{"title":"8大排序算法图文讲解","date":"2019-05-24T09:58:24.000Z","path":"posts/1453950584/","text":"排序算法简介排序算法可以分为内部排序和外部排序，内部排序是数据记录在内存中进行排序，而外部排序是因排序的数据很大，一次不能容纳全部的排序记录，在排序过程中需要访问外存。 常见的内部排序算法插入排序、希尔排序、选择排序、冒泡排序、归并排序、快速排序、堆排序、基数排序等。 本文将依次介绍上述八大排序算法 算法一：插入排序 算法二：希尔排序 算法三：选择排序 算法四：冒泡排序 算法五：归并排序 算法六：快速排序 算法七：堆排序 算法八：基数排序 算法一：插入排序 插入排序是一种最简单直观的排序算法，它的工作原理是通过构建有序序列，对于未排序数据，在已排序序列中从后向前扫描，找到相应位置并插入。 算法步骤 将第一待排序序列第一个元素看做一个有序序列，把第二个元素到最后一个元素当成是未排序序列。 从头到尾依次扫描未排序序列，将扫描到的每个元素插入有序序列的适当位置。(如果待插入的元素与有序序列中的某个元素相等，则将待插入元素插入到相等元素的后面。) 算法二：希尔排序序 希尔排序，也称递减增量排序算法，是插入排序的一种更高效的改进版本。但希尔排序是非稳定排序算法。 希尔排序是基于插入排序的以下两点性质而提出改进方法的： 插入排序在对几乎已经排好序的数据操作时， 效率高， 即可以达到线性排序的效率 但插入排序一般来说是低效的， 因为插入排序每次只能将数据移动一位希尔排序的基本思想是：先将整个待排序的记录序列分割成为若干子序列分别进行直接插入排序，待整个序列中的记录“基本有序”时，再对全体记录进行依次直接插入排序。 算法步骤 选择一个增量序列t1，t2，…，tk，其中ti&gt;tj，tk=1； 按增量序列个数k，对序列进行k 趟排序； 每趟排序，根据对应的增量ti，将待排序列分割成若干长度为m 的子序列，分别对各子表进行直接插入排序。仅增量因子为1 时，整个序列作为一个表来处理，表长度即为整个序列的长度。 算法三：选择排序 选择排序(Selection sort)也是一种简单直观的排序算法。 算法步骤 首先在未排序序列中找到最小(大)元素，存放到排序序列的起始位置 再从剩余未排序元素中继续寻找最小(大)元素，然后放到已排序序列的末尾。 重复第二步，直到所有元素均排序完毕。 算法四：冒泡排序 冒泡排序(Bubble Sort)也是一种简单直观的排序算法。它重复地走访过要排序的数列，一次比较两个元素，如果他们的顺序错误就把他们交换过来。走访数列的工作是重复地进行直到没有再需要交换，也就是说该数列已经排序完成。这个算法的名字由来是因为越小的元素会经由交换慢慢“浮”到数列的顶端。 算法步骤 比较相邻的元素。如果第一个比第二个大，就交换他们两个。 对每一对相邻元素作同样的工作，从开始第一对到结尾的最后一对。这步做完后，最后的元素会是最大的数。 针对所有的元素重复以上的步骤，除了最后一个。 持续每次对越来越少的元素重复上面的步骤，直到没有任何一对数字需要比较。 算法五：归并排序 归并排序(Merge sort)是建立在归并操作上的一种有效的排序算法。该算法是采用分治法(Divide and Conquer)的一个非常典型的应用。 算法步骤 申请空间，使其大小为两个已经排序序列之和，该空间用来存放合并后的序列 设定两个指针，最初位置分别为两个已经排序序列的起始位置 比较两个指针所指向的元素，选择相对小的元素放入到合并空间，并移动指针到下一位置 重复步骤3直到某一指针达到序列尾 将另一序列剩下的所有元素直接复制到合并序列尾 算法六：快速排序 快速排序是由东尼·霍尔所发展的一种排序算法。在平均状况下，排序 n 个项目要Ο(n log n)次比较。在最坏状况下则需要Ο(n2)次比较，但这种状况并不常见。事实上，快速排序通常明显比其他Ο(n log n) 算法更快，因为它的内部循环(inner loop)可以在大部分的架构上很有效率地被实现出来。 快速排序使用分治法(Divide and conquer)策略来把一个串行(list)分为两个子串行(sub-lists)。 算法步骤 从数列中挑出一个元素，称为 “基准”(pivot)， 重新排序数列，所有元素比基准值小的摆放在基准前面，所有元素比基准值大的摆在基准的后面(相同的数可以到任一边)。在这个分区退出之后，该基准就处于数列的中间位置。这个称为分区(partition)操作。 递归地(recursive)把小于基准值元素的子数列和大于基准值元素的子数列排序。 递归的最底部情形，是数列的大小是零或一，也就是永远都已经被排序好了。虽然一直递归下去，但是这个算法总会退出，因为在每次的迭代(iteration)中，它至少会把一个元素摆到它最后的位置去。 算法七：堆排序 堆排序(Heapsort)是指利用堆这种数据结构所设计的一种排序算法。堆积是一个近似完全二叉树的结构，并同时满足堆积的性质：即子结点的键值或索引总是小于(或者大于)它的父节点。 堆排序的平均时间复杂度为Ο(nlogn)。 算法步骤 创建一个堆H[0..n-1] 把堆首(最大值)和堆尾互换 把堆的尺寸缩小1，并调用shift_down(0),目的是把新的数组顶端数据调整到相应位置 重复步骤2，直到堆的尺寸为1 算法八：基数排序基数排序是一种非比较型整数排序算法，其原理是将整数按位数切割成不同的数字，然后按每个位数分别比较。由于整数也可以表达字符串(比如名字或日期)和特定格式的浮点数，所以基数排序也不是只能使用于整数。 说基数排序之前，我们简单介绍桶排序： 算法思想是将阵列分到有限数量的桶子里。每个桶子再个别排序(有可能再使用别的排序算法或是以递回方式继续使用桶排序进行排序)。桶排序是鸽巢排序的一种归纳结果。当要被排序的阵列内的数值是均匀分配的时候，桶排序使用线性时间(Θ(n))。但桶排序并不是 比较排序，他不受到O(nlogn)下限的影响。 简单来说，就是把数据分组，放在一个个的桶中，然后对每个桶里面的在进行排序。 例如要对大小为[1..1000]范围内的n个整数A[1..n]排序 首先，可以把桶设为大小为10的范围，具体而言，设集合B[1]存储[1..10]的整数，集合B[2]存储 (10..20]的整数，……集合B[i]存储((i-1)10, i10]的整数，i = 1,2,..100。总共有100个桶。 然后，对A[1..n]从头到尾扫描一遍，把每个A[i]放入对应的桶B[j]中。再对这100个桶中每个桶里的数字排序，这时可用冒泡、选择乃至快排，一般来说任何排序法都可以。 最后，依次输出每个桶里面的数字，且每个桶中的数字从小到大输出，这样就得到所有数字排好序的一个序列了。 假设有n个数字，有m个桶，如果数字是平均分布的，则每个桶里面平均有n/m个数字。如果对每个桶中的数字采用快速排序，那么整个算法的复杂度是 O(n + m n/mlog(n/m)) = O(n + nlogn – nlogm) 从上式看出，当m接近n的时候，桶排序复杂度接近O(n) 当然，以上复杂度的计算是基于输入的n个数字是平均分布这个假设的。这个假设是很强的 ，实际应用中效果并没有这么好。如果所有的数字都落在同一个桶中，那就退化成一般的排序了。 前面说的几大排序算法，大部分时间复杂度都是O(n2)，也有部分排序算法时间复杂度是O(nlogn)。而桶式排序却能实现O(n)的时间复杂度。 桶排序的缺点 首先是空间复杂度比较高，需要的额外开销大。排序有两个数组的空间开销，一个存放待排序数组，一个就是所谓的桶，比如待排序值是从0到m-1，那就需要m个桶，这个桶数组就要至少m个空间。 其次待排序的元素都要在一定的范围内等等。 总结各种排序的稳定性，时间复杂度、空间复杂度、稳定性总结如下图： 关于时间复杂度平方阶(O(n2))排序各类简单排序: 直接插入 直接选择 冒泡排序 线性对数阶(O(nlog2n))排序 快速排序 堆排序 归并排序 O(n1+§))排序, §是介于0和1之间的常数。 希尔排序 线性阶(O(n))排序 基数排序 桶排序 箱排序 关于稳定性稳定的排序算法 冒泡排序 插入排序 归并排序 基数排序 不是稳定的排序算法 选择排序 快速排序 希尔排序 堆排序","tags":[{"name":"算法","slug":"算法","permalink":"http://www.jifu.io/tags/算法/"},{"name":"排序","slug":"排序","permalink":"http://www.jifu.io/tags/排序/"}],"categories":[{"name":"Soft engineering","slug":"Soft-engineering","permalink":"http://www.jifu.io/categories/Soft-engineering/"},{"name":"Algorithm","slug":"Soft-engineering/Algorithm","permalink":"http://www.jifu.io/categories/Soft-engineering/Algorithm/"}]},{"title":"Mac的最大连接数限制和端口的相关参数的设置","date":"2019-05-15T08:53:23.000Z","path":"posts/582618556/","text":"最大连接数限制最大连接数限制就是系统所能打开的最大文件数（文件描述符）的限制，分全局和进程两种，相应的命令如下： $sysctl kern.maxfiles 输出：kern.maxfiles: 12288 说明：全局限制，也就是系统默认的最大连接数限制是12288 $sysctl kern.maxfilesperproc 输出：kern.maxfilesperproc: 10240 说明：单个进程默认最大连接数限制是10240 $sudo sysctl -w kern.maxfiles=1048600 输出：kern.maxfiles: 12288 -&gt; 1048600 说明：设置系统最大连接数从12288到1048600 $sudo sysctl -w kern.maxfilesperproc=1048576 输出：kern.maxfilesperproc: 10240 -&gt; 1048576 说明：设置进程连接数限制，进程的最大连接数要小于等于全局连接数 ulimit命令$ulimit -n 输出：2560 说明：“ulimit －n”命令显示当前shell能打开的最大文件数，默认值：2560，该值总是小于kern.maxfilesperproc的值，因为一个shell就是一个进程。 $ulimit -n 1048576 说明：设置当前shell能打开的最大文件数为1048576，该值不能大于kern.maxfilesperproc，否则会提示设置失败。 动态端口范围$sysctl net.inet.ip.portrange 输出： net.inet.ip.portrange.first: 49152 net.inet.ip.portrange.last: 65535 Linux动态端口号默认范围是32768-65535，也就是说，作为客户端连接同一个IP和同一个端口号，最多只能建立30000多个连接，而Mac默认只能建立16000个左右的连接。 $sysctl -w net.inet.ip.portrange.first=32768 说明：设置动态分配起点端口号为32768，这样可以增大客户端可以建立的连接数。 参考： The IANA list of port numbers includes the well-known and registered port numbers and specifies the dynamic port number range. 问题按以上的方式设置参数有个问题，当系统重启后，这些参数又恢复成了默认值，解决办法就是把参数写到/etc/sysctl.conf文件中，但是，默认这个文件是不存在的，所以首先就要创建它： sudo touch /etc/sysctl.conf 然后把参数写到文件里 kern.maxfiles=1048600 kern.maxfilesperproc=1048576 net.inet.ip.portrange.first=49152 net.inet.ip.portrange.last=65535 重启系统，查看结果，显示成功。 至于ulimit -n的值，可以把ulimit －n 1048576写到`.bashrca中实现自动修改。","tags":[{"name":"Mac","slug":"Mac","permalink":"http://www.jifu.io/tags/Mac/"},{"name":"最大连接连接数","slug":"最大连接连接数","permalink":"http://www.jifu.io/tags/最大连接连接数/"},{"name":"参数设置","slug":"参数设置","permalink":"http://www.jifu.io/tags/参数设置/"}],"categories":[{"name":"OPS","slug":"OPS","permalink":"http://www.jifu.io/categories/OPS/"},{"name":"MacOS","slug":"OPS/MacOS","permalink":"http://www.jifu.io/categories/OPS/MacOS/"}]},{"title":"解决Mac修改DNS卡死-命令行修改Mac OS系统DNS设置","date":"2019-05-10T10:22:11.000Z","path":"posts/3430780623/","text":"摘要最近网络总是异常，时不时就打不开网页，开始以为是网络的问题，但是只有自己的电脑网络有问题，手机和其他人的电脑都没问题，怀疑是自己的dns有问题，于是着手修改。可是在系统偏好设置里打开网络准备修改dns的时候却发现无论怎样修改都没办法动弹，只要一点修改就卡死不动了，试了n次也没有修改成功，最后突然想到了命令行的方式修改，成功搞定. 查看系统现有网络networksetup -listallnetworkservices 修改DNS修改wifi的dns为 180.76.76.76networksetup -setdnsservers Wi-Fi 180.76.76.76 再次查看dns确认是否成功networksetup -getdnsservers Wi-Fi 刷新dns方案1dscacheutil -flushcache 管理员强制刷新sudo dscacheutil -flushcache;sudo killall -HUP mDNSResponder;say flushed","tags":[{"name":"命令行","slug":"命令行","permalink":"http://www.jifu.io/tags/命令行/"},{"name":"Mac OS","slug":"Mac-OS","permalink":"http://www.jifu.io/tags/Mac-OS/"},{"name":"卡死","slug":"卡死","permalink":"http://www.jifu.io/tags/卡死/"},{"name":"DNS设置","slug":"DNS设置","permalink":"http://www.jifu.io/tags/DNS设置/"}],"categories":[{"name":"OPS","slug":"OPS","permalink":"http://www.jifu.io/categories/OPS/"},{"name":"MacOS","slug":"OPS/MacOS","permalink":"http://www.jifu.io/categories/OPS/MacOS/"}]},{"title":"Python多线程和锁","date":"2019-05-07T23:41:14.000Z","path":"posts/5/","text":"进程和线程进程是执行中的计算机程序。每个进程都拥有自己的地址空间、内存、数据栈及其它的辅助数据。操作系统管理着所有的进程，并为这些进程合理分配时间。进程可以通过派生新的进程来执行其它任务，不过每个进程都拥有自己的内存和数据栈等，进程之间的数据交换采用 进程间通信(IPC) 方式。 线程在进程之下执行，一个进程下可以运行多个线程，它们之间共享相同上下文。线程包括开始、执行顺序和结束三部分。它有一个指针，用于记录当前运行的上下文。当其它线程执行时，它可以被抢占(中断)和临时挂起(也称睡眠) ——这种做法叫做 让步(yielding)。 一个进程中的各个线程与主进程共享同一片数据空间，与独立进程相比，线程之间信息共享和通信更加容易。线程一般以并发执行，正是由于这种并发和数据共享机制，使多任务间的协作成为可能。当然，这种共享也并不是没有风险的，如果多个线程访问同一数据空间，由于访问顺序不同，可能导致结果不一致，这种情况通常称为竞态条件(race condition)，不过大多数线程库都有同步原语，以允许线程管理器的控制执行和访问；另一个要注意的问题是，线程无法给予公平执行时间，CPU 时间分配会倾向那些阻塞更少的函数。 全局解释器锁(GIL)Python 代码执行由 Python 虚拟机 (又名解释器主循环) 进行控制。Python 在设计时是这样考虑的，在主循环中同时只能有一个控制线程在执行。对 Python 虚拟机的访问由 全局解释器(GIL) 控制，这个锁用于，当有多个线程时保证同一时刻只能有一个线程在运行。 由于 Python 的 GIL 的限制，多线程更适合 I/O 密集型应用( I/O 释放了 GIL，可以允许更多的并发)，对于计算密集型应用，为了实现更好的并行性，适合使用多进程，已便利用 CPU 的多核优势。Python 的多进程相关模块：subprocess、multiprocessing、concurrent.futures threading 模块threading 是 Python 高级别的多线程模块。 threading 模块的函数 active_count() 当前活动的 Thread 对象个数 current_thread() 返回当前 Thread 对象 get_ident() 返回当前线程 enumerater() 返回当前活动 Thread 对象列表 main_thread() 返回主 Thread 对象 settrace(func) 为所有线程设置一个 trace 函数 setprofile(func) 为所有线程设置一个 profile 函数 stack_size([size]) 返回新创建线程栈大小；或为后续创建的线程设定栈大小为 size TIMEOUT_MAX Lock.acquire() , RLock.acquire() , Condition.wait() 允许的最大值 threading 可用对象列表 Thread 表示执行线程的对象 Lock 锁原语对象 RLock 可重入锁对象，使单一进程再次获得已持有的锁(递归锁) Condition 条件变量对象，使得一个线程等待另一个线程满足特定条件，比如改变状态或某个值 Semaphore 为线程间共享的有限资源提供一个”计数器”，如果没有可用资源会被阻塞 Event 条件变量的通用版本，任意数量的线程等待某个时间的发生，在改事件发生后所有线程被激活 Timer 与 Thread 相识，不过它要在运行前等待一段时间 Barrier 创建一个”阻碍”，必须达到指定数量的线程后才可以继续 Thread 类Thread 对象的属性 Thread.name Thread.ident Thread.daemon 详见(The Python Standard Library) Thread 对象方法： Thread.start() Thread.run() Thread.join(timeout=None) Thread.getName Thread.setName Thread.is_alive() Thread.isDaemon() Thread.setDaemon() 详见(The Python Standard Library) 使用 Thread 类很多种方法来创建线程,这里使用常见的两种： 创建 Thread 实例，传给它一个函数。 派生 Thread 子类，并创建子类的实例。 一个单线程栗子#!/usr/bin/env python3 import threading from random import randint from time import sleep, ctime def hi(n): sleep(n) print(\"ZzZzzz, sleep: \", n) # 打印 Sleep 的秒数 def main(): print(\"### Start at: \", ctime()) for i in range(10): hi(randint(1,2)) # 调用十次，每次 Sleep 1秒或2秒 print(\"### Done at: \", ctime()) if __name__ == '__main__': main() 运行结果### Start at: Thu Sep 1 14:11:00 2016 ZzZzzz, sleep: 1 ZzZzzz, sleep: 2 ZzZzzz, sleep: 2 ZzZzzz, sleep: 2 ZzZzzz, sleep: 1 ZzZzzz, sleep: 1 ZzZzzz, sleep: 1 ZzZzzz, sleep: 1 ZzZzzz, sleep: 1 ZzZzzz, sleep: 2 ### Done at: Thu Sep 1 14:11:14 2016 一共是用了14秒。 多线程：创建 Thread 实例传给它一个函数栗子#!/usr/bin/env python3 import threading from random import randint from time import sleep, ctime def hi(n): sleep(n) print(\"ZzZzzz, sleep: \", n) def main(): print(\"### Start at: \", ctime()) threads = [] for i in range(10): rands = randint(1,2) # 实例化每个 Thread 对象，把函数和参数传递进去，返回 Thread 实例 t = threading.Thread(target=hi, args=(rands,)) threads.append(t) # 分配线程 for i in range(10): threads[i].start() # 开始执行多线程 for i in range(10): threads[i].join() # (自旋锁)等待线程结束或超时，然后再往下执行 print(\"### Done at: \", ctime()) if __name__ == '__main__': main() 运行结果### Start at: Thu Sep 1 14:18:00 2016 ZzZzzz, sleep: 1 ZzZzzz, sleep: 1 ZzZzzz, sleep: 1 ZzZzzz, sleep: 1 ZzZzzz, sleep: 1 ZzZzzz, sleep: 1 ZzZzzz, sleep: 2 ZzZzzz, sleep: 2 ZzZzzz, sleep: 2 ZzZzzz, sleep: 2 ### Done at: Thu Sep 1 14:18:02 2016 使用多线程，只用了2秒。 多线程：派生 Thread 子类并创建子类的实例栗子#!/usr/bin/env python3 import threading from random import randint from time import sleep, ctime class MyThread(threading.Thread): def __init__(self, func, args, times): super(MyThread, self).__init__() self.func = func self.args = args self.times = times def run(self): print(\"begin thread......\", self.times) self.res = self.func(*self.args) print(\"end threads......\", self.times) def hi(n): sleep(n) print(\"ZzZzzz, sleep: \", n) def main(): print(\"### Start at: \", ctime()) threads = [] for i in range(10): rands = randint(1,2) t = MyThread(hi, (rands,), i+1) threads.append(t) for i in range(10): threads[i].start() for i in range(10): threads[i].join() print(\"### Done at: \", ctime()) if __name__ == '__main__': main() 执行结果：### Start at: Thu Sep 1 14:47:09 2016 begin thread...... 1 begin thread...... 2 begin thread...... 3 begin thread...... 4 begin thread...... 5 begin thread...... 6 begin thread...... 7 begin thread...... 8 begin thread...... 9 begin thread...... 10 ZzZzzz, sleep: 1 ZzZzzz, sleep: 1 end threads...... 1 end threads...... 4 ZzZzzz, sleep: 1 end threads...... 7 ZzZzzz, sleep: 1 end threads...... 3 ZzZzzz, sleep: 1 end threads...... 9 ZzZzzz, sleep: 2 end threads...... 2 ZzZzzz, sleep: 2 end threads...... 5 ZzZzzz, sleep: 2 ZzZzzz, sleep: 2 end threads...... 10 end threads...... 6 ZzZzzz, sleep: 2 end threads...... 8 ### Done at: Thu Sep 1 14:47:11 2016 这个栗子对 Thread 子类化，而不是对其实例化，使得定制线程对象更具灵活性，同时也简化线程创建的调用过程。 线程锁当多线程争夺锁时，允许第一个获得锁的线程进入临街区，并执行代码。所有之后到达的线程将被阻塞，直到第一个线程执行结束，退出临街区，并释放锁。需要注意，那些阻塞的线程是没有顺序的。 举个栗子#!/usr/bin/env python3 import threading from random import randint from time import sleep, ctime L = threading.Lock() # 引入锁 def hi(n): L.acquire() # 加锁 for i in [1,2]: print(i) sleep(n) print(\"ZzZzzz, sleep: \", n) L.release() # 释放锁 def main(): print(\"### Start at: \", ctime()) threads = [] for i in range(10): rands = randint(1,2) t = threading.Thread(target=hi, args=(rands,)) threads.append(t) for i in range(10): threads[i].start() for i in range(10): threads[i].join() print(\"### Done at: \", ctime()) if __name__ == '__main__': main() 运行上面的代码，再将锁的代码注释掉，对比下输出。","tags":[{"name":"多线程","slug":"多线程","permalink":"http://www.jifu.io/tags/多线程/"},{"name":"Python","slug":"Python","permalink":"http://www.jifu.io/tags/Python/"},{"name":"锁","slug":"锁","permalink":"http://www.jifu.io/tags/锁/"}],"categories":[{"name":"back-end","slug":"back-end","permalink":"http://www.jifu.io/categories/back-end/"},{"name":"Python","slug":"back-end/Python","permalink":"http://www.jifu.io/categories/back-end/Python/"},{"name":"Build-in","slug":"back-end/Python/Build-in","permalink":"http://www.jifu.io/categories/back-end/Python/Build-in/"}]},{"title":"强制退出Mac程序的六种方法","date":"2019-05-07T02:33:09.000Z","path":"posts/1207571108/","text":"摘要用电脑时间长了，难免会遇到程序卡住，风火轮狂转不停，没有任何相应等情况。可能是由于程序冲突、缓存不足或者一些bug等情况导致，这个时候我们就需要强制退出这个程序了，下面有六种在Mac系统中强制退出程序的方法，大家至少应该记住一两个。 使用键盘快捷键强制退出处于活跃状态的Mac程序快捷键：Command+Option+Shift+Esc这样按住一两秒钟，就可以强制退出当前程序了，算是最方便的一种方法。 打开强制退出程序窗口使用快捷键：Command+Option+Esc来打开“强制退出应用程序”的窗口，然后选中你需要退出的程序，再点右下方的“强制退出”即可。 从Dock中强制退出程序按住Option然后右键点击程序在Dock中的图标，可以看到“强制退出”的选项，选择即可。 从左上角苹果菜单中强制退出程序这个有些类似第二条，从左上角的菜单中选择“强制退出”，不过有些时候程序当机，点击菜单会出现没反应的情况。 使用“活动监视器”强制退出程序在 应用程序-实用工具 中找到“活动监视器”，找到程序的名字然后选择左上方红色按钮强制退出程序，这个就有些类似Windows中的任务管理器了。如果上面的方法都不奏效，那么可以尝试这个方法。 使用终端命令强制退出程序这个应该算是重启电脑之前的最后办法了，在终端中输入如下命令 killall [程序名称] 比如说强制退出Safari，就输入killall Safari再回车即可，这样有关Safari的全部进程就都退出了；如果你想分的细一些，可以通过ps或者ps aux命令查找某些单独的进行，然后使用kill -9 [pid]来单独结束某个进程。很多情况下强制退出程序，之前的内容可能就会不在了，需要注意一下。最后说说iOS设备上的强制退出程序方法：按住上方电源键，直到出现提示关机滑动条，这个时候放开电源键再按住Home键，直到程序退出。","tags":[{"name":"Mac OS","slug":"Mac-OS","permalink":"http://www.jifu.io/tags/Mac-OS/"},{"name":"强制退出","slug":"强制退出","permalink":"http://www.jifu.io/tags/强制退出/"}],"categories":[{"name":"OPS","slug":"OPS","permalink":"http://www.jifu.io/categories/OPS/"},{"name":"MacOS","slug":"OPS/MacOS","permalink":"http://www.jifu.io/categories/OPS/MacOS/"}]},{"title":"Mac重置系统管理控制器SMC","date":"2019-05-02T08:00:17.000Z","path":"posts/1208074722/","text":"摘要在某些情况下，您可能需要重置电脑的系统管理控制器（SMC）。了解如何辨识这些情况并重置SMC。 SMC可能发生问题，导致出现通常与下述症状相关的异常系统行为。在某些情况下，重置SMC可能是解决问题的唯一正确方法，不过，应该在执行过所有其他标准故障诊断之后才尝试SMC重置。 重置SMC之前重置SMC之前，请依序尝试以下各个步骤。完成每个故障诊断步骤之后请测试问题，判断问题是否仍会发生。 按Command + Option + Escape来强制结束所有无回应的应用程式。 选择左上角选单列中的Apple（）选单，然后选择“睡眠”，让Mac进入睡眠状态。进入睡眠状态后唤醒电脑。 从左上角选单列选择Apple（）选单，然后选择「重新启动」，借此重新启动Mac。 从左上角选单列选择Apple（）选单，然后选择「关机」，借此关闭Mac。 如果Mac似乎正常执行但却没有回应，请按住电源按钮10秒以强制关机。 您可能会遗失开启中应用程式的所有未储存工作。 若Mac可携式电脑发生MagSafe电源转换器和/或电池相关问题，请尝试： 从Mac和墙壁插座拔下MagSafe电源转换器，然后等候几秒钟。 将Mac关机。实际卸下电池后重新安装（如果可卸除），然后启动Mac。 如果执行上述故障诊断步骤后，还是无法解决问题，可能就需要重置SMC。执行一般故障诊断之后，这些症状表示可能需要重置SMC。 虽然电脑负荷量不大而且通风良好，但风扇还是高速运转。 键盘背光功能似乎异常（在配备此功能的Mac电脑上）。 状态指示灯（SIL）似乎功能异常（在配备SIL的Mac电脑上）。 电池指示灯（如果有）的功能似乎异常（使用不可卸除电池的可携式电脑）。 配备显示器背光灯的Mac电脑无法根据环境光线的变化正确反应。 按下电源按钮时，电脑没有反应。 开阖上盖时，可携式Mac无法适当反应。 电脑意外进入睡眠状态或关机。 电池似乎无法适当充电。 MagSafe电源转换器LED似乎无法指出正确活动。 虽然CPU使用率没有不正常，但电脑执行速度还是异常缓慢。 电脑启动时，应用程式图像可能会在Dock中「弹跳」很长一段时间。 应用程式可能无法正常运作，或在开启时停止回应。 支援目标显示器模式的电脑，无法正常来回切换目标显示器模式。 支援目标显示器模式的电脑，会意外地来回切换目标显示器模式。 重置系统管理控制器（SMC）在可以取出电池的Mac可携式电脑上重置SMC 了解如何拆卸MacBook和MacBook Pro的电池。 将电脑关机。 从电脑拔下连接的MagSafe电源转换器。 取出电池。 按住电源按钮5秒。 放开电源按钮。 重新连接电池和MagSafe电源转换器。 按下电源按钮以启动电脑。 在无法自行取出电池的可携式电脑上重置SMC 配备无法自行取出电池的可携式电脑，包括MacBook Pro（2009年初）和后续机型，MacBook Air的所有机型，以及MacBook（2009年末）。 将电脑关机。 将MagSafe电源转换器插入电源，并连接到Mac上（若尚未连接）。 在内建键盘上同时按下（左侧）Shift-Control-Option键及电源按钮。 同时放开所有按键和电源按钮。 按下电源按钮以启动电脑。附注：重置SMC时，MagSafe电源转换器的LED可能改变状态或暂时熄灭。 在Mac Pro，Intel型iMac，Intel型Mac mini或Intel型Xserve上重置SMC 将电脑关机。 拔除电脑的电源线。 等候15秒。 插上电脑的电源线。 等候5秒，然后按下电源按钮以开启电脑。 对于没有回应的Intel型Xserve电脑，您可以在本机进行关机，或者使用远端命令，又或按住电源按钮5秒。 系统管理控制器（SMC）负责Intel型Mac的许多低阶功能，包括： 回应按下电源按钮 回应可携式Mac显示器上盖的开阖 SMS（瞬间防震感测装置） 环境光线感应 状态指示灯（SIL）管理 电池状态指示灯 为某些iMac显示器选择外部（非内部）视讯来源 重置SMC不会重置或更改PRAM（在Intel型Mac上也称为NVRAM）的内容。","tags":[{"name":"Mac","slug":"Mac","permalink":"http://www.jifu.io/tags/Mac/"},{"name":"重置","slug":"重置","permalink":"http://www.jifu.io/tags/重置/"},{"name":"MSC","slug":"MSC","permalink":"http://www.jifu.io/tags/MSC/"}],"categories":[{"name":"OPS","slug":"OPS","permalink":"http://www.jifu.io/categories/OPS/"},{"name":"MacOS","slug":"OPS/MacOS","permalink":"http://www.jifu.io/categories/OPS/MacOS/"}]},{"title":"如何重置Mac上的NVRAM","date":"2019-04-29T12:15:47.000Z","path":"posts/3920589165/","text":"了解电脑的NVRAM以及重置的时机与方法。 什麼是 NVRAM？电脑有一小部分的记忆体称为「非挥发性随机存取记忆体」或 NVRAM，会将特定设定储存在一个 OS X 可以快速存取的位置。储存在 NVRAM 的设定取决于您所使用的 Mac 以及连接的装置类型。 储存在 NVRAM 的资讯可能包括 扬声器音量 萤幕解析度 选择的启动磁碟 最近的核心异常资讯（如有） 如果您遇到这些功能的相关问题，可能需要重置电脑上的 NVRAM。例如，如果 Mac 启动时不是使用您在「启动磁碟」偏好设定中指定的启动磁碟，或者您的 Mac 在启动时会短暂出现问号图像。 重置 NVRAM 关闭 Mac。 在键盘上找到下列按键：Command（⌘）、Option、P 和 R。 开启 Mac。 在听到开机启动音效之后，立刻按住 Command-Option-P-R 组合键。 按住这些键，直到电脑重新启动且再次听到开机启动音效。 放开这些键。 重置 NVRAM 后，可能必须重新设定扬声器音量、萤幕解析度、选择的启动磁碟和时区资讯。 如果这些功能的相关问题仍存在于桌上型 Mac（如 iMac、Mac mini 或 Mac Pro），则可能需要更换主机板电池。当 Mac 拔掉电源线时，桌上型电脑的主机板电池可协助保存 NVRAM 设定。您可以把 Mac 交给 Apple Store 或 Apple 授权维修中心，以更换主机板电池。 更多内容在旧款 Mac 电脑上，类似的资讯储存在参数记忆体（PRAM）中。使用相同的按键组合重置 Intel 型 Mac 上的 NVRAM，就像是重置 PRAM。 电源相关设定在 Mac 上可透过「系统管理控制器」（SMC）控制。如果您无法开启电脑电源、睡眠、唤醒、为 Mac 笔记型电脑电池充电，或遇到其他电源相关的症状，您可能需要改为重置 SMC。","tags":[{"name":"Mac","slug":"Mac","permalink":"http://www.jifu.io/tags/Mac/"},{"name":"NVRAM","slug":"NVRAM","permalink":"http://www.jifu.io/tags/NVRAM/"}],"categories":[{"name":"OPS","slug":"OPS","permalink":"http://www.jifu.io/categories/OPS/"},{"name":"MacOS","slug":"OPS/MacOS","permalink":"http://www.jifu.io/categories/OPS/MacOS/"}]},{"title":"Git忽略提交规则 - .gitignore配置总结","date":"2019-04-26T10:03:16.000Z","path":"posts/3784546227/","text":"摘要在使用Git的过程中，我们喜欢有的文件比如日志，临时文件，编译的中间文件等不要提交到代码仓库，这时就要设置相应的忽略规则，来忽略这些文件的提交。简单来说一个场景：在你使用git add .的时候，遇到了把你不想提交的文件也添加到了缓存中去的情况，比如项目的本地配置信息，如果你上传到Git中去其他人pull下来的时候就会和他本地的配置有冲突，所以这样的个性化配置文件我们一般不把它推送到git服务器中，但是又为了偷懒每次添加缓存的时候都想用git add .而不是手动一个一个文件添加，该怎么办呢？很简单，git为我们提供了一个.gitignore文件只要在这个文件中申明那些文件你不希望添加到git中去，这样当你使用git add .的时候这些文件就会被自动忽略掉。 有三种方法可以实现忽略Git中不想提交的文件在Git项目中定义.gitignore文件对于经常使用Git的朋友来说，.gitignore配置一定不会陌生。这种方式通过在项目的某个文件夹下定义.gitignore文件，在该文件中定义相应的忽略规则，来管理当前文件夹下的文件的Git提交行为。.gitignore文件是可以提交到公有仓库中，这就为该项目下的所有开发者都共享一套定义好的忽略规则。在.gitingore 文件中，遵循相应的语法，在每一行指定一个忽略规则。如： *.log *.temp /vendor 在Git项目的设置中指定排除文件这种方式只是临时指定该项目的行为，需要编辑当前项目下的.git/info/exclude文件，然后将需要忽略提交的文件写入其中。需要注意的是，这种方式指定的忽略文件的根目录是项目根目录。 定义Git全局的.gitignore文件除了可以在项目中定义.gitignore文件外，还可以设置全局的git .gitignore文件来管理所有Git项目的行为。这种方式在不同的项目开发者之间是不共享的，是属于项目之上Git应用级别的行为。这种方式也需要创建相应的.gitignore文件，可以放在任意位置。然后在使用以下命令配置Git： # git config --global core.excludesfile ~/.gitignore 首先要强调一点，这个文件的完整文件名就是.gitignore，注意最前面有个“.”。一般来说每个Git项目中都需要一个.gitignore文件，这个文件的作用就是告诉Git哪些文件不需要添加到版本管理中。实际项目中，很多文件都是不需要版本管理的，比如Python的.pyc文件和一些包含密码的配置文件等等。这个文件的内容是一些规则，Git会根据这些规则来判断是否将文件添加到版本控制中。 Git忽略文件的原则 忽略操作系统自动生成的文件，比如缩略图等； 忽略编译生成的中间文件、可执行文件等，也就是如果一个文件是通过另一个文件自动生成的，那自动生成的文件就没必要放进版本库，比如Java编译产生的.class文件； 忽略你自己的带有敏感信息的配置文件，比如存放口令的配置文件。 .gitignore文件的使用方法首先，在你的工作区新建一个名称为.gitignore的文件。然后，把要忽略的文件名填进去，Git就会自动忽略这些文件。不需要从头写.gitignore文件，GitHub已经为我们准备了各种配置文件，只需要组合一下就可以使用了。 有时对于git项目下的某些文件，我们不需要纳入版本控制，比如日志文件或者IDE的配置文件，此时可以在项目的根目录下建立一个隐藏文件 .gitignore（linux下以.开头的文件都是隐藏文件），然后在.gitignore中写入需要忽略的文件。 [root@kevin ~]# cat .gitignore *.xml *.log *.apk .gitignore注释用#, *表示匹配0个或多个任意字符，所以上面的模式就是要忽略所有的xml文件,log文件和apk文件。 .gitignore配置文件用于配置不需要加入版本管理的文件，配置好该文件可以为版本管理带来很大的便利。 .gitignore忽略规则的优先级在 .gitingore 文件中，每一行指定一个忽略规则，Git检查忽略规则的时候有多个来源，它的优先级如下（由高到低）： 从命令行中读取可用的忽略规则 当前目录定义的规则 父级目录定义的规则，依次递推 $GIT_DIR/info/exclude 文件中定义的规则 core.excludesfile中定义的全局规则 .gitignore忽略规则的匹配语法在.gitignore文件中，每一行的忽略规则的语法如下： 空格不匹配任意文件，可作为分隔符，可用反斜杠转义 以“＃”开头的行都会被 Git 忽略。即#开头的文件标识注释，可以使用反斜杠进行转义。 可以使用标准的glob模式匹配。所谓的glob模式是指shell所使用的简化了的正则表达式。 以斜杠”/“开头表示目录；”/“结束的模式只匹配文件夹以及在该文件夹路径下的内容，但是不匹配该文件；”/“开始的模式匹配项目跟目录；如果一个模式不包含斜杠，则它匹配相对于当前.gitignore文件路径的内容，如果该模式不在.gitignore文件中，则相对于项目根目录。 以星号”*”通配多个字符，即匹配多个任意字符；使用两个星号”“ 表示匹配任意中间目录，比如`a//z`可以匹配 a/z, a/b/z 或 a/b/c/z等。 以问号”?”通配单个字符，即匹配一个任意字符； 以方括号”[]”包含单个字符的匹配列表，即匹配任何一个列在方括号中的字符。比如[abc]表示要么匹配一个a，要么匹配一个b，要么匹配一个c；如果在方括号中使用短划线分隔两个字符，表示所有在这两个字符范围内的都可以匹配。比如[0-9]表示匹配所有0到9的数字，[a-z]表示匹配任意的小写字母）。 以叹号”!”表示不忽略(跟踪)匹配到的文件或目录，即要忽略指定模式以外的文件或目录，可以在模式前加上惊叹号（!）取反。需要特别注意的是：如果文件的父目录已经被前面的规则排除掉了，那么对这个文件用”!”规则是不起作用的。也就是说”!”开头的模式表示否定，该文件将会再次被包含，如果排除了该文件的父级目录，则使用”!”也不会再次被包含。可以使用反斜杠进行转义。 需要谨记：git对于.ignore配置文件是按行从上到下进行规则匹配的，意味着如果前面的规则匹配的范围更大，则后面的规则将不会生效； .gitignore忽略规则简单说明# 表示此为注释,将被Git忽略 *.a 表示忽略所有 .a 结尾的文件 !lib.a 表示但lib.a除外 /TODO 表示仅仅忽略项目根目录下的 TODO 文件，不包括 subdir/TODO build/ 表示忽略 build/目录下的所有文件，过滤整个build文件夹； doc/*.txt 表示会忽略doc/notes.txt但不包括 doc/server/arch.txt bin/: 表示忽略当前路径下的bin文件夹，该文件夹下的所有内容都会被忽略，不忽略 bin 文件 /bin: 表示忽略根目录下的bin文件 /*.c: 表示忽略cat.c，不忽略 build/cat.c debug/*.obj: 表示忽略debug/io.obj，不忽略 debug/common/io.obj和tools/debug/io.obj **/foo: 表示忽略/foo,a/foo,a/b/foo等 a/**/b: 表示忽略a/b, a/x/b,a/x/y/b等 !/bin/run.sh 表示不忽略bin目录下的run.sh文件 *.log: 表示忽略所有 .log 文件 config.php: 表示忽略当前路径的 config.php 文件 /mtk/ 表示过滤整个文件夹 *.zip 表示过滤所有.zip文件 /mtk/do.c 表示过滤某个具体文件 被过滤掉的文件就不会出现在git仓库中（gitlab或github）了，当然本地库中还有，只是push的时候不会上传。 需要注意的是，gitignore还可以指定要将哪些文件添加到版本管理中，如下： !*.zip !/mtk/one.txt 唯一的区别就是规则开头多了一个感叹号，Git会将满足这类规则的文件添加到版本管理中。为什么要有两种规则呢？想象一个场景：假如我们只需要管理/mtk/目录中的one.txt文件，这个目录中的其他文件都不需要管理，那么.gitignore规则应写为：： /mtk/* !/mtk/one.txt 假设我们只有过滤规则，而没有添加规则，那么我们就需要把/mtk/目录下除了one.txt以外的所有文件都写出来！注意上面的/mtk/*不能写为/mtk/，否则父目录被前面的规则排除掉了，one.txt文件虽然加了!过滤规则，也不会生效！ 其他规则fd1/* 说明：忽略目录 fd1 下的全部内容；注意，不管是根目录下的 /fd1/ 目录，还是某个子目录 /child/fd1/ 目录，都会被忽略； /fd1/* 说明：忽略根目录下的 /fd1/ 目录的全部内容； /* !.gitignore !/fw/ /fw/* !/fw/bin/ !/fw/sf/ 说明：忽略全部内容，但是不忽略.gitignore文件、根目录下的 /fw/bin/ 和 /fw/sf/ 目录；注意要先对bin/的父目录使用!规则，使其不被排除。 温馨提示如果你不慎在创建.gitignore文件之前就push了项目，那么即使你在.gitignore文件中写入新的过滤规则，这些规则也不会起作用，Git仍然会对所有文件进行版本管理。简单来说出现这种问题的原因就是Git已经开始管理这些文件了，所以你无法再通过过滤规则过滤它们。所以大家一定要养成在项目开始就创建.gitignore文件的习惯，否则一单push，处理起来会非常麻烦。 .gitignore忽略规则常用示例示例A比如你的项目是java项目，.java文件编译后会生成.class文件，这些文件多数情况下是不想被传到仓库中的文件。这时候你可以直接适用github的.gitignore文件模板https://github.com/github/gitignore/blob/master/Java.gitignore将这些忽略文件信息复制到你的.gitignore文件中去： # Compiled class file *.class # Log file *.log # BlueJ files *.ctxt # Mobile Tools for Java (J2ME) .mtj.tmp/ # Package Files # *.jar *.war *.nar *.ear *.zip *.tar.gz *.rar # virtual machine crash logs, see http://www.java.com/en/download/help/error_hotspot.xml hs_err_pid* 可以看到github为我们提供了最流行的.gitignore文件配置。保存.ignore文件后我们查看下git status，检查下是否还有我们不需要的文件会被添加到git中去： $ git status On branch master Initial commit Changes to be committed: (use \"git rm --cached &lt;file>...\" to unstage) new file: .gitignore new file: HelloWorld.java Untracked files: (use \"git add &lt;file>...\" to include in what will be committed) Config.ini 比如我的项目目录下有一个Config.ini文件，这个是个本地配置文件我不希望上传到git中去，我们可以在gitignore文件中添加这样的配置： Config.ini 或者你想忽略所有的.ini文件你可以这样写： *.ini 如果有些文件已经被你忽略了，当你使用git add时是无法添加的，比如我忽略了*.class，现在我想把HelloWorld.class添加到git中去： $ git add HelloWorld.class The following paths are ignored by one of your .gitignore files: HelloWorld.class Use -f if you really want to add them. git会提示我们这个文件已经被我们忽略了，需要加上-f参数才能强制添加到git中去： $ git status On branch master Initial commit Changes to be committed: (use \"git rm --cached &lt;file>...\" to unstage) new file: .gitignore new file: HelloWorld.class new file: HelloWorld.java 这样就能强制添加到缓存中去了。如果我们意外的将想要忽略的文件添加到缓存中去了，我们可以使用rm命令将其从中移除： $ git rm HelloWorld.class --cached rm 'HelloWorld.class' 如果你已经把不想上传的文件上传到了git仓库，那么你必须先从远程仓库删了它，我们可以从远程仓库直接删除然后pull代码到本地仓库这些文件就会本删除，或者从本地删除这些文件并且在.gitignore文件中添加这些你想忽略的文件，然后再push到远程仓库。 示例B下面是曾经线上使用过的一个gerrit里项目代码的.gitignore的配置（在项目中添加.gitignore过滤文件，在git push到gerrit里即可） [wangshibo@gerrit-server hq_ios]$ cat .gitignore #Built application files *.apk *.ap_ # Files for the Dalvik VM *.dex # Java class files *.class # Generated files */bin/ */gen/ */out/ # Gradle files .gradle/ build/ */build/ gradlew gradlew.bat # Local configuration file (sdk path, etc) local.properties # Proguard folder generated by Eclipse proguard/ # Log Files *.log # Android Studio Navigation editor temp files .navigation/ # Android Studio captures folder captures/ # Intellij *.iml */*.iml # Keystore files #*.jks #gradle wrapper gradle/ #some local files */.settings/ */.DS_Store .DS_Store */.idea/ .idea/ gradlew gradlew.bat unused.txt 示例C[wangshibo@gerrit-server hq_ios$ cat .gitignore # Lines that start with '#' are comments. # IntelliJ IDEA Project files .idea *.iml *.ipr *.iws out # Eclipse Project files .classpath .project .settings/ bin/ gen/ local.properties .DS_Store Thumbs.db *.bak *.tem *.temp #.swp *.*~ ~*.* .gitignor忽略规则查看如果你发下.gitignore写得有问题，需要找出来到底哪个规则写错了，可以用git check-ignore命令检查： $ git check-ignore -v HelloWorld.class .gitignore:1:*.class HelloWorld.class 可以看到HelloWorld.class匹配到了我们的第一条*.class的忽略规则所以文件被忽略了。 #简单来说，要实现过滤掉Git里不想上传的文件，如上介绍三种方法能达到这种目的，只不过适用情景不一样： 第一种方法针对单一工程排除文件，这种方式会让这个工程的所有修改者在克隆代码的同时，也能克隆到过滤规则，而不用自己再写一份，这就能保证所有修改者应用的都是同一份规则，而不是张三自己有一套过滤规则，李四又使用另一套过滤规则，个人比较喜欢这个。 配置步骤如下：在工程根目录下建立.gitignore文件，将要排除的文件或目录 写到.gitignore这个文件中，其中有两种写入方法： 使用命令行增加排除文件排除以.class结尾的文件echo &quot;*.class&quot; &gt;.gitignore(&gt;&gt; 是在文件尾增加,&gt; 是删除已经存在的内容再增加)，之后会在当前目录下生成一个.gitignore的文件。排除bin目录下的文件echo &quot;bin/&quot; &gt;.gitignore 最方便的办法是，用记事本打开，增加需要排除的文件或目录，一行增加一个，例如： *.class *.apk bin/ gen/ .settings/ proguard/ 第二种方法全局设置排除文件，这会在全局起作用，只要是Git管理的工程，在提交时都会自动排除不在控制范围内的文件或目录。这种方法对开发者来说,比较省事只要一次全局配置，不用每次建立工程都要配置一遍过滤规则。但是这不保证其他的开发者在克隆你的代码后，他们那边的规则跟你的是一样的，这就带来了代码提交过程中的各种冲突问题。配置步骤如下： 像方法（1）一样，也需要建立一个.gitignore文件，把要排除的文件写进去。 但在这里，我们不规定一定要把.gitnore文件放到某个工程下面，而是任何地方，比如我们这里放到了Git默认的Home路径下，比如：/home/wangshibo/hqsb_ios 使用命令方式可以配置全局排除文件: # git config --global core.excludesfile ~/.gitignore 你会发现在~/.gitconfig文件中会出现excludesfile = /home/wangshibo/hqsb_ios/.gitignore说明Git把文件过滤规则应用到了Global的规则中。 第三种方法单个工程设置排除文件，在工程目录下找到.git/info/exclude，把要排除的文件写进去： *.class *.apk bin/ gen/ .settings/ proguard/ 这种方法就不提倡了，只能针对单一工程配置，而且还不能将过滤规则同步到其他开发者，跟方法一和方法二比较起来没有一点优势。 Git忽略规则(.gitignore配置）不生效原因和解决第一种方法.gitignore中已经标明忽略的文件目录下的文件git push的时候还会出现在push的目录中，或者用git status查看状态，想要忽略的文件还是显示被追踪状态。原因是因为在git忽略目录中，新建的文件在git中会有缓存，如果某些文件已经被纳入了版本管理中，就算是在.gitignore中已经声明了忽略路径也是不起作用的，这时候我们就应该先把本地缓存删除，然后再进行git的提交，这样就不会出现忽略的文件了。 解决方法: git清除本地缓存（改变成未track状态），然后再提交[root@kevin ~]# git rm -r --cached . [root@kevin ~]# git add . [root@kevin ~]# git commit -m 'update .gitignore' [root@kevin ~]# git push -u origin master 需要特别注意 .gitignore只能忽略那些原来没有被track的文件，如果某些文件已经被纳入了版本管理中，则修改.gitignore是无效的。 想要.gitignore起作用，必须要在这些文件不在暂存区中才可以.gitignore文件只是忽略没有被staged(cached)文件， 对于已经被staged文件，加入ignore文件时一定要先从staged移除，才可以忽略。 第二种方法:（推荐）在每个clone下来的仓库中手动设置不要检查特定文件的更改情况。 [root@kevin ~]# git update-index --assume-unchanged PATH //在PATH处输入要忽略的文件 在使用.gitignore文件后如何删除远程仓库中以前上传的此类文件而保留本地文件在使用git和github的时候，之前没有写.gitignore文件，就上传了一些没有必要的文件，在添加了.gitignore文件后，就想删除远程仓库中的文件却想保存本地的文件。这时候不可以直接使用git rm directory，这样会删除本地仓库的文件。可以使用git rm -r –cached directory来删除缓冲，然后进行commit和push，这样会发现远程仓库中的不必要文件就被删除了，以后可以直接使用git add -A来添加修改的内容，上传的文件就会受到.gitignore文件的内容约束。 额外说明：git库所在的文件夹中的文件大致有4种状态Untracked未跟踪, 此文件在文件夹中, 但并没有加入到git库, 不参与版本控制. 通过git add状态变为Staged. Unmodify文件已经入库, 未修改, 即版本库中的文件快照内容与文件夹中完全一致. 这种类型的文件有两种去处, 如果它被修改,而变为Modified. 如果使用git rm移出版本库, 则成为Untracked文件 Modified文件已修改, 仅仅是修改, 并没有进行其他的操作. 这个文件也有两个去处, 通过git add可进入暂存staged状态,使用git checkout则丢弃修改过, 返回到unmodify状态, 这个git checkout即从库中取出文件, 覆盖当前修改 Staged暂存状态. 执行git commit则将修改同步到库中, 这时库中的文件和本地文件又变为一致, 文件为Unmodify状态.执行git reset HEAD filename取消暂存, 文件状态为Modified Git状态untracked和not staged的区别 untrack 表示是新文件，没有被add过，是为跟踪的意思。 not staged 表示add过的文件，即跟踪文件，再次修改没有add，就是没有暂存的意思","tags":[{"name":".gitignore","slug":"gitignore","permalink":"http://www.jifu.io/tags/gitignore/"},{"name":"Git","slug":"Git","permalink":"http://www.jifu.io/tags/Git/"},{"name":"忽略规则","slug":"忽略规则","permalink":"http://www.jifu.io/tags/忽略规则/"},{"name":"配置","slug":"配置","permalink":"http://www.jifu.io/tags/配置/"}],"categories":[{"name":"OPS","slug":"OPS","permalink":"http://www.jifu.io/categories/OPS/"},{"name":"Others","slug":"OPS/Others","permalink":"http://www.jifu.io/categories/OPS/Others/"}]},{"title":"Git中.gitignore无效的解决办法","date":"2019-04-23T11:44:16.000Z","path":"posts/3101956195/","text":"git规则.gitignore只能忽略那些原来没有被track的文件，如果某些文件已经被纳入了版本管理中，则修改.gitignore是无效的 解决办法git rm -r --cached . git add . git commit -m 'update .gitignore'","tags":[{"name":"git","slug":"git","permalink":"http://www.jifu.io/tags/git/"},{"name":".gitignore","slug":"gitignore","permalink":"http://www.jifu.io/tags/gitignore/"}],"categories":[{"name":"OPS","slug":"OPS","permalink":"http://www.jifu.io/categories/OPS/"},{"name":"Others","slug":"OPS/Others","permalink":"http://www.jifu.io/categories/OPS/Others/"}]},{"title":"定时任务Crontab命令详解","date":"2019-04-23T10:33:28.000Z","path":"posts/3403344661/","text":"摘要linux 系统则是由 cron (crond) 这个系统服务来控制的。Linux 系统上面原本就有非常多的计划性工作，因此这个系统服务是默认启动的。另 外, 由于使用者自己也可以设置计划任务，所以， Linux 系统也提供了使用者控制计划任务的命令 :crontab 命令。 crond简介crond 是linux下用来周期性的执行某种任务或等待处理某些事件的一个守护进程，与windows下的计划任务类似，当安装完成操作系统后，默认会安装此服务 工具，并且会自动启动crond进程，crond进程每分钟会定期检查是否有要执行的任务，如果有要执行的任务，则自动执行该任务。 Linux下的任务调度分为两类，系统任务调度和用户任务调度。 系统任务调度系统周期性所要执行的工作，比如写缓存数据到硬盘、日志清理等。在/etc目录下有一个crontab文件，这个就是系统任务调度的配置文件。 /etc/crontab文件包括下面几行： cat /etc/crontab SHELL=/bin/bash PATH=/sbin:/bin:/usr/sbin:/usr/bin MAILTO=HOME=/ # run-parts 51 * * * * root run-parts /etc/cron.hourly 24 7 * * * root run-parts /etc/cron.daily 22 4 * * 0 root run-parts /etc/cron.weekly 42 4 1 * * root run-parts /etc/cron.monthly 前四行是用来配置crond任务运行的环境变量，第一行SHELL变量指定了系统要使用哪个shell，这里是bash，第二行PATH变量指定了系统执行 命令的路径，第三行MAILTO变量指定了crond的任务执行信息将通过电子邮件发送给root用户，如果MAILTO变量的值为空，则表示不发送任务 执行信息给用户，第四行的HOME变量指定了在执行命令或者脚本时使用的主目录。第六至九行表示的含义将在下个小节详细讲述。这里不在多说。 用户任务调度用户定期要执行的工作，比如用户数据备份、定时邮件提醒等。用户可以使用 crontab 工具来定制自己的计划任务。所有用户定义的crontab 文件都被保存在/var/spool/cron目录中。其文件名与用户名一致。 使用者权限文件： 文件 说明 /etc/cron.deny 该文件中所列用户不允许使用crontab命令 /etc/cron.allow 该文件中所列用户允许使用crontab命令 /var/spool/cron/ 所有用户crontab文件存放的目录,以用户名命名 crontab文件的含义用户所建立的crontab文件中，每一行都代表一项任务，每行的每个字段代表一项设置，它的格式共分为六个字段，前五段是时间设定段，第六段是要执行的命令段，格式如下： minute hour day month week command 字段 功能 minute 表示分钟，可以是从0到59之间的任何整数。 hour 表示小时，可以是从0到23之间的任何整数。 day 表示日期，可以是从1到31之间的任何整数。 month 表示月份，可以是从1到12之间的任何整数。 week 表示星期几，可以是从0到7之间的任何整数，这里的0或7代表星期日。 command 要执行的命令，可以是系统命令，也可以是自己编写的脚本文件。 在以上各个字段中，还可以使用以下特殊字符： 符号 功能 星号（*） 代表所有可能的值，例如month字段如果是星号，则表示在满足其它字段的制约条件后每月都执行该命令操作。 逗号（,） 可以用逗号隔开的值指定一个列表范围，例如，“1,2,5,7,8,9” 中杠（-） 可以用整数之间的中杠表示一个整数范围，例如“2-6”表示“2,3,4,5,6” 正斜线（/） 可以用正斜线指定时间的间隔频率，例如“0-23/2”表示每两小时执行一次。同时正斜线可以和星号一起使用，例如*/10，如果用在minute字段，表示每十分钟执行一次。 crond服务安装crontabyum install crontabs 服务操作说明启动服务/sbin/service crond start 关闭服务/sbin/service crond stop 重启服务/sbin/service crond restart 重新载入配置/sbin/service crond reload 启动服务/sbin/service crond status crontab服务开机启动检查ntsysv 开机自动启动chkconfig –level 35 crond on crontab命令详解命令格式crontab [-u user] file crontab [-u user] [ -e | -l | -r ] 命令功能通过crontab 命令，我们可以在固定的间隔时间执行指定的系统指令或 shell script脚本。时间间隔的单位可以是分钟、小时、日、月、周及以上的任意组合。这个命令非常设合周期性的日志分析或数据备份等工作。 命令参数 参数 功能 -u user 用来设定某个用户的crontab服务，例如，“-u ixdba”表示设定ixdba用户的crontab服务，此参数一般有root用户来运行。 file file是命令文件的名字,表示将file做为crontab的任务列表文件并载入crontab。如果在命令行中没有指定这个文件，crontab命令将接受标准输入（键盘）上键入的命令，并将它们载入crontab。 -e 编辑某个用户的crontab文件内容。如果不指定用户，则表示编辑当前用户的crontab文件。 -l 显示某个用户的crontab文件内容，如果不指定用户，则表示显示当前用户的crontab文件内容。 -r 从/var/spool/cron目录中删除某个用户的crontab文件，如果不指定用户，则默认删除当前用户的crontab文件。 -i 在删除用户的crontab文件时给确认提示。 常用方法创建一个新的crontab文件在考虑向cron进程提交一个crontab文件之前，首先要做的一件事情就是设置环境变量EDITOR。cron进程根据它来确定使用哪个编辑器编辑 crontab文件。9 9 %的UNIX和LINUX用户都使用vi，如果你也是这样，那么你就编辑$ HOME目录下的. profile文件，在其中加入这样一行： EDITOR=vi; export EDITOR 然后保存并退出。不妨创建一个名为&lt;user&gt;cron的文件，其中&lt;user&gt;是用户名，例如davecron。在该文件中加入如下的内容。 # (put your own initials here)echo the date to the console every # 15minutes between 6pm and 6am 0,15,30,45 18-06 * * * /bin/echo ‘date’ > /dev/console 保存并退出。确信前面5个域用空格分隔。 在上面的例子中，系统将每隔15分钟向控制台输出一次当前时间。如果系统崩溃或挂起，从最后所显示的时间就可以一眼看出系统是什么时间停止工作的。在有些系统中，用tty1来表示控制台，可以根据实际情况对上面的例子进行相应的修改。为了提交你刚刚创建的crontab文件，可以把这个新创建的文件作为cron命令的参数： $crontab davecron 现在该文件已经提交给cron进程，它将每隔15分钟运行一次。 同时，新创建文件的一个副本已经被放在/var/spool/cron目录中，文件名就是用户名(即dave)。 列出crontab文件为了列出crontab文件，可以用： $ crontab -l 0,15,30,45,18-06 * * * /bin/echo `date` > dev/tty1 你将会看到和上面类似的内容。可以使用这种方法在$HOME目录中对crontab文件做一备份： $crontab -l > $HOME/mycron 这样，一旦不小心误删了crontab文件，可以用上一节所讲述的方法迅速恢复。 编辑crontab文件如果希望添加、删除或编辑crontab文件中的条目，而EDITOR环境变量又设置为vi，那么就可以用vi来编辑crontab文件，相应的命令为： $crontab -e 可以像使用vi编辑其他任何文件那样修改crontab文件并退出。如果修改了某些条目或添加了新的条目，那么在保存该文件时， cron会对其进行必要的完整性检查。如果其中的某个域出现了超出允许范围的值，它会提示你。 我们在编辑crontab文件时，没准会加入新的条目。例如加入下面的一条： # DT:delete core files,at 3.30am on 1,7,14,21,26,26 days of each month 30 3 1,7,14,21,26 * * /bin/find -name “core’ -exec rm {} \\; 现在保存并退出。最好在crontab文件的每一个条目之上加入一条注释，这样就可以知道它的功能、运行时间，更为重要的是，知道这是哪位用户的作业。 现在让我们使用前面讲过的crontab -l命令列出它的全部信息： $crontab -l # (crondave installed on Tue May 4 13:07:43 1999) # DT:ech the date to the console every 30 minites 0,15,30,45 18-06 * * * /bin/echo `date` > /dev/tty1 # DT:delete core files,at 3.30am on 1,7,14,21,26,26 days of each month 30 3 1,7,14,21,26 * * /bin/find -name “core’ -exec rm {} \\; 删除crontab文件要删除crontab文件，可以用： $crontab -r 恢复丢失的crontab文件如果不小心误删了crontab文件，假设你在自己的$HOME目录下还有一个备份，那么可以将其拷贝到/var/spool/cron/&lt;username&gt;，其中&lt;username&gt;是用户名。如果由于权限问题无法完成拷贝，可以用： $crontab &lt;filename> 其中，&lt;filename&gt;是你在$HOME目录中副本的文件名。 我建议你在自己的$HOME目录中保存一个该文件的副本。我就有过类似的经历，有数次误删了crontab文件（因为r键紧挨在e键的右边）。这就是为什么有些系统文档建议不要直接编辑crontab文件，而是编辑该文件的一个副本，然后重新提交新的文件。 有些crontab的变体有些怪异，所以在使用crontab命令时要格外小心。如果遗漏了任何选项，crontab可能会打开一个空文件，或者看起来像是个空文件。这时敲delete键退出，不要按&lt;Ctrl-D&gt;，否则你将丢失crontab文件。 使用实例实例1：每1分钟执行一次command * * * * * command 实例2：每小时的第3和第15分钟执行 3,15 * * * * command 实例3：在上午8点到11点的第3和第15分钟执行 3,15 8-11 * * * command 实例4：每隔两天的上午8点到11点的第3和第15分钟执行 3,15 8-11 */2 * * command 实例5：每个星期一的上午8点到11点的第3和第15分钟执行 3,15 8-11 * * 1 command 实例6：每晚的21:30重启smb 30 21 * * * /etc/init.d/smb restart 实例7：每月1、10、22日的4 : 45重启smb 45 4 1,10,22 * * /etc/init.d/smb restart 实例8：每周六、周日的1 : 10重启smb 10 1 * * 6,0 /etc/init.d/smb restart 实例9：每天18 : 00至23 : 00之间每隔30分钟重启smb 0,30 18-23 * * * /etc/init.d/smb restart 实例10：每星期六的晚上11 : 00 pm重启smb 0 23 * * 6 /etc/init.d/smb restart 实例11：每一小时重启smb * */1 * * * /etc/init.d/smb restart 实例12：晚上11点到早上7点之间，每隔一小时重启smb * 23-7/1 * * * /etc/init.d/smb restart 实例13：每月的4号与每周一到周三的11点重启smb 0 11 4 * mon-wed /etc/init.d/smb restart 实例14：一月一号的4点重启smb 0 4 1 jan * /etc/init.d/smb restart 实例15：每小时执行/etc/cron.hourly目录内的脚本 01 * * * * root run-parts /etc/cron.hourly 说明：run-parts这个参数了，如果去掉这个参数的话，后面就可以写要运行的某个脚本名，而不是目录名了 使用注意事项注意环境变量问题有时我们创建了一个crontab，但是这个任务却无法自动执行，而手动执行这个任务却没有问题，这种情况一般是由于在crontab文件中没有配置环境变量引起的。 在crontab文件中定义多个调度任务时，需要特别注意的一个问题就是环境变量的设置，因为我们手动执行某个任务时，是在当前shell环境下进行的，程序当然能找到环境变量，而系统自动执行任务调度时，是不会加载任何环境变量的，因此就需要在crontab文件中指定任务运行所需的所有环境变量，这样，系统执行任务调度时就没有问题了。 不要假定cron知道所需要的特殊环境，它其实并不知道。所以你要保证在shelll脚本中提供所有必要的路径和环境变量，除了一些自动设置的全局变量。所以注意如下3点： 脚本中涉及文件路径时写全局路径； 脚本执行要用到java或其他环境变量时，通过source命令引入环境变量，如： cat start_cbp.sh #!/bin/sh source /etc/profile export RUN_CONF=/home/d139/conf/platform/cbp/cbp_jboss.conf /usr/local/jboss-4.0.5/bin/run.sh -c mev &amp; 当手动执行脚本OK，但是crontab死活不执行时。这时必须大胆怀疑是环境变量惹的祸，并可以尝试在crontab中直接引入环境变量解决问题。 0 * * * * . /etc/profile;/bin/sh /var/www/java/audit_no_count/bin/restart_audit.sh 注意清理系统用户的邮件日志每条任务调度执行完毕，系统都会将任务输出信息通过电子邮件的形式发送给当前系统用户，这样日积月累，日志信息会非常大，可能会影响系统的正常运行，因此，将每条任务进行重定向处理非常重要。 例如，可以在crontab文件中设置如下形式，忽略日志输出： 0 */3 * * * /usr/local/apache2/apachectl restart >/dev/null 2>&amp;1 “/dev/null 2&gt;&amp;1”表示先将标准输出重定向到/dev/null，然后将标准错误重定向到标准输出，由于标准输出已经重定向到了/dev/null，因此标准错误也会重定向到/dev/null，这样日志输出问题就解决了。 系统级任务调度与用户级任务调度系统级任务调度主要完成系统的一些维护操作，用户级任务调度主要完成用户自定义的一些任务，可以将用户级任务调度放到系统级任务调度来完成（不建议这么做），但是反过来却不行，root用户的任务调度操作可以通过“crontab –uroot –e”来设置，也可以将调度任务直接写入/etc/crontab文件，需要注意的是，如果要定义一个定时重启系统的任务，就必须将任务放到/etc/crontab文件，即使在root用户下创建一个定时重启系统的任务也是无效的。 其他注意事项新创建的cron job，不会马上执行，至少要过2分钟才执行。如果重启cron则马上执行。 当crontab突然失效时，可以尝试/etc/init.d/crond restart解决问题。或者查看日志看某个job有没有执行/报错tail -f /var/log/cron 千万别乱运行crontab -r。它从Crontab目录（/var/spool/cron）中删除用户的Crontab文件。删除了该用户的所有crontab都没了。 在crontab中%是有特殊含义的，表示换行的意思。如果要用的话必须进行转义\\%，如经常用的date ‘+%Y%m%d’在crontab里是不会执行的，应该换成date ‘+\\%Y\\%m\\%d’。","tags":[{"name":"Linux","slug":"Linux","permalink":"http://www.jifu.io/tags/Linux/"},{"name":"crontab","slug":"crontab","permalink":"http://www.jifu.io/tags/crontab/"},{"name":"定是任务","slug":"定是任务","permalink":"http://www.jifu.io/tags/定是任务/"}],"categories":[{"name":"OPS","slug":"OPS","permalink":"http://www.jifu.io/categories/OPS/"},{"name":"command","slug":"OPS/command","permalink":"http://www.jifu.io/categories/OPS/command/"}]},{"title":"history命令设置linux查看历史命令显示执行时间","date":"2019-04-21T04:53:02.000Z","path":"posts/2407250830/","text":"修改配置文件[root@iZwz90n2a7lzpav1xsdmiqZ ~]# vim /etc/profile 添加至末尾行export HISTTIMEFORMAT=\"%Y-%m-%d %H:%M:%S \" 重载配置[root@iZwz90n2a7lzpav1xsdmiqZ ~]# source /etc/profile 查看结果[root@iZwz90n2a7lzpav1xsdmiqZ ~]# history 988 2019-04-13 14:04:10 ls 989 2019-04-13 14:04:10 su - shilvfei 990 2019-04-13 14:04:10 ls 991 2019-04-13 14:04:10 cat /etc/group 992 2019-04-13 14:04:10 groupadd dev 993 2019-04-13 14:04:10 usermod -G dev shilvfei 994 2019-04-13 14:04:10 env 995 2019-04-13 14:04:10 su - shilvfei 996 2019-04-13 14:04:10 ls 997 2019-04-13 14:04:10 cat /etc/group 998 2019-04-13 14:04:10 groupadd lamp1 999 2019-04-13 14:04:10 grep \"lamp1\" /etc/passwd 1000 2019-04-13 14:04:10 grep \"shilvfei\" /etc/passwd 1001 2019-04-13 14:04:11 ls 1002 2019-04-13 14:04:16 vim /etc/profile 1003 2019-04-13 14:04:38 source /etc/profile 1004 2019-04-13 14:04:39 ls 1005 2019-04-13 14:04:42 history 1006 2019-04-13 14:06:42 vim /etc/profile 1007 2019-04-13 14:08:47 history","tags":[{"name":"Linux","slug":"Linux","permalink":"http://www.jifu.io/tags/Linux/"},{"name":"history","slug":"history","permalink":"http://www.jifu.io/tags/history/"},{"name":"执行时间","slug":"执行时间","permalink":"http://www.jifu.io/tags/执行时间/"}],"categories":[{"name":"OPS","slug":"OPS","permalink":"http://www.jifu.io/categories/OPS/"},{"name":"command","slug":"OPS/command","permalink":"http://www.jifu.io/categories/OPS/command/"}]},{"title":"DevOps简介","date":"2019-04-20T08:21:47.000Z","path":"posts/404814820/","text":"DevOps 是一个完整的面向IT运维的工作流，以 IT 自动化以及持续集成（CI）、持续部署（CD）为基础，来优化程式开发、测试、系统运维等所有环节。 DevOps的概念DevOps一词的来自于Development和Operations的组合，突出重视软件开发人员和运维人员的沟通合作，通过自动化流程来使得软件构建、测试、发布更加快捷、频繁和可靠。 DevOps是为了填补开发端和运维端之间的信息鸿沟，改善团队之间的协作关系。不过需要澄清的一点是，从开发到运维，中间还有测试环节。DevOps其实包含了三个部分：开发、测试和运维。 换句话说，DevOps希望做到的是软件产品交付过程中IT工具链的打通，使得各个团队减少时间损耗，更加高效地协同工作。专家们总结出了下面这个DevOps能力图，良好的闭环可以大大增加整体的产出。 历史变革由上所述，相信大家对DevOps有了一定的了解。但是除了触及工具链之外，作为文化和技术的方法论，DevOps还需要公司在组织文化上的变革。回顾软件行业的研发模式，可以发现大致有三个阶段：瀑布式开发、敏捷开发、DevOps。 DevOps早在九年前就有人提出来，但是，为什么这两年才开始受到越来越多的企业重视和实践呢？因为DevOps的发展是独木不成林的，现在有越来越多的技术支撑。微服务架构理念、容器技术使得DevOps的实施变得更加容易，计算能力提升和云环境的发展使得快速开发的产品可以立刻获得更广泛的使用。 好处是什么？DevOps的一个巨大好处就是可以高效交付，这也正好是它的初衷。Puppet和DevOps Research and Assessment (DORA) 主办了2016年DevOps调查报告，根据全球4600位各IT公司的技术工作者的提交数据统计，得出高效公司平均每年可以完成1460次部署。 与低效组织相比，高效组织的部署频繁200倍，产品投入使用速度快2555倍，服务恢复速度快24倍。在工作内容的时间分配上，低效者要多花22%的时间用在为规划好或者重复工作上，而高效者却可以多花29%的时间用在新的工作上。所以这里的高效不仅仅指公司产出的效率提高，还指员工的工作质量得到提升。 DevOps另外一个好处就是会改善公司组织文化、提高员工的参与感。员工们变得更高效，也更有满足和成就感；调查显示高效员工的雇员净推荐值（eNPS:employee Net Promoter Score）更高，即对公司更加认同。 快速部署同时提高IT稳定性。这难道不矛盾吗？快速的部署其实可以帮助更快地发现问题，产品被更快地交付到用户手中，团队可以更快地得到用户的反馈，从而进行更快地响应。而且，DevOps小步快跑的形式带来的变化是比较小的，出现问题的偏差每次都不会太大，修复起来也会相对容易一些。 因此，认为速度就意味着危险是一种偏见。此外，滞后软件服务的发布也并不一定会完全地避免问题，在竞争日益激烈的IT行业，这反而可能错失了软件的发布时机 为什么DevOps会兴起？条件成熟：技术配套发展技术的发展使得DevOps有了更多的配合。早期时，大家虽然意识到了这个问题的，但是苦于当时没有完善丰富的技术工具，是一种“理想很丰满，但是现实很骨感”的情况。DevOps的实现可以基于新兴的容器技术；也可以在自动化运维工具Puppet、SaltStack、Ansible之后的延伸；还可以构建在传统的Cloud Foundry、OpenShift等PaaS厂商之上。 来自市场的外部需求：这世界变化太快IT行业已经越来越与市场的经济发展紧密挂钩，专家们认为IT将会有支持中心变成利润驱动中心。事实上，这个变化已经开始了，这不仅体现在Google、苹果这些大企业中，而且也发生在传统行业中，比如出租车业务中的Uber、酒店连锁行业中的Airbnb、图书经销商Amazon等等。能否让公司的IT配套方案及时跟上市场需求的步伐，在今天显得至关重要。 DevOps 2016年度报告给出了一个运维成本的计算公式：停机费用成本 = 部署频率 版本迭代失败概率 平均修复时间 * 断电的金钱损失 来自团队的内在动力：工程师也需要对于工程师而言，他们也是DevOps的受益者。微软资深工程师Scott Hanselman说过“对于开发者而言，最有力的工具就是自动化工具”（The most powerful tool we have as developers is automation）。 工具链的打通使得开发者们在交付软件时可以完成生产环境的构建、测试和运行；正如Amazon的VP兼CTO Werner Vogels那句让人印象深刻的话：“谁开发谁运行”。（You build it, you run it） 实现DevOps需要什么？硬性要求：工具上的准备上文提到了工具链的打通，那么工具自然就需要做好准备。现将工具类型及对应的不完全列举整理如下： 代码管理（SCM）：GitHub、GitLab、BitBucket、SubVersion 构建工具：Ant、Gradle、maven 自动部署：Capistrano、CodeDeploy 持续集成（CI）：Bamboo、Hudson、Jenkins 配置管理：Ansible、Chef、Puppet、SaltStack、ScriptRock GuardRail 容器：Docker、LXC、第三方厂商如AWS 编排：Kubernetes、Core、Apache Mesos、DC/OS 服务注册与发现：Zookeeper、etcd、Consul 脚本语言：python、ruby、shell 日志管理：ELK、Logentries 系统监控：Datadog、Graphite、Icinga、Nagios 性能监控：AppDynamics、New Relic、Splunk 压力测试：JMeter、Blaze Meter、loader.io 预警：PagerDuty、pingdom、厂商自带如AWS SNS HTTP加速器：Varnish 消息总线：ActiveMQ、SQS 应用服务器：Tomcat、JBoss Web服务器：Apache、Nginx、IIS 数据库：MySQL、Oracle、PostgreSQL等关系型数据库；cassandra、mongoDB、redis等NoSQL数据库 项目管理（PM）：Jira、Asana、Taiga、Trello、Basecamp、Pivotal Tracker在工具的选择上，需要结合公司业务需求和技术团队情况而定。（注：更多关于工具的详细介绍可以参见此文：51 Best DevOps Tools for #DevOps Engineers） 软性需求：文化和人DevOps成功与否，公司组织是否利于协作是关键。开发人员和运维人员可以良好沟通互相学习，从而拥有高生产力。并且协作也存在于业务人员与开发人员之间。 出席了2016年伦敦企业级DevOps峰会的ITV公司在2012年就开始落地DevOps，其通用平台主管Clark在接受了InfoQ的采访，在谈及成功时表示，业务人员非常清楚他们希望在最小化可行产品中实现什么，工程师们就按需交付，不做多余工作。 这样，工程师们使用通用的平台（即打通的工具链）得到更好的一致性和更高的质量。此外，DevOps对工程师个人的要求也提高了，很多专家也认为招募到优秀的人才也是一个挑战。 DevOps的采用现状哪些公司在用？DevOps正在增长，尤其是在大企业中：调查发现，DevOps的接受度有了显著提高。74%的受访者已经接受了DevOps，而去年这一比例为66%。目前，在81%的大企业开始接受DevOps，中小企业的接受度仅为70%。 那么具体而言都有些公司在采用DevOps呢？Adobe、Amazon、Apple、Airbnb、Ebay、Etsy、Facebook、LinkedIn、Netflix、NASA、Starbucks、Target（泛欧实时全额自动清算系统）、Walmart、Sony等等。 他们怎么实施的？首先，大企业正在自下而上接受DevOps，其中业务单位或部门（31%）以及项目和团队（29%）已经实施DevOps。不过，只有21%的大企业在整个公司范围内采用了DevOps。 其次，在工具层面上，DevOps工具的用量大幅激增。Chef和Puppet依然是最常用的DevOps工具，使用率均为32%。Docker是年增长率最快的工具，用量增长一倍以上。Ansible的用量也有显著增加，使用率从10%翻倍至20%。","tags":[{"name":"DevOps","slug":"DevOps","permalink":"http://www.jifu.io/tags/DevOps/"},{"name":"介绍","slug":"介绍","permalink":"http://www.jifu.io/tags/介绍/"},{"name":"OPS","slug":"OPS","permalink":"http://www.jifu.io/tags/OPS/"}],"categories":[{"name":"OPS","slug":"OPS","permalink":"http://www.jifu.io/categories/OPS/"}]},{"title":"解决EXCEL按上下左右键不是单元格移动的问题","date":"2019-04-20T08:16:43.000Z","path":"posts/913943227/","text":"常常遇到在Excel里面，按上下左右键，本来想移动单元格，然而不幸的是，整个页面都在一起动！ 百度了好久，终于知道原来是scroll lock键被按下。 如果是笔记本的话，键盘上还没有这个键。 也不知道这个键的快捷键是什么。 不过可以用虚拟键盘。 windows下面，运行（windows徽标键+R），输入osk。 然后就会弹出一个虚拟键盘。 再点一下，把这个ScrLk关掉，就好了。","tags":[{"name":"EXCEL","slug":"EXCEL","permalink":"http://www.jifu.io/tags/EXCEL/"},{"name":"无法移动","slug":"无法移动","permalink":"http://www.jifu.io/tags/无法移动/"},{"name":"锁定","slug":"锁定","permalink":"http://www.jifu.io/tags/锁定/"}],"categories":[{"name":"OPS","slug":"OPS","permalink":"http://www.jifu.io/categories/OPS/"},{"name":"Windows","slug":"OPS/Windows","permalink":"http://www.jifu.io/categories/OPS/Windows/"}]},{"title":"更改pip源至国内镜像 - 显著提升下载速度","date":"2019-04-16T11:01:32.000Z","path":"posts/3568487154/","text":"摘要http://pypi.douban.com/simple/ 虽然用easy_install和pip来安装第三方库很方便它们的原理其实就是从Python的官方源pypi.python.org/pypi 下载到本地，然后解包安装。不过因为某些原因，访问官方的pypi不稳定，很慢甚至有些还时不时的访问不了。 跟ubuntu的apt和centos的yum有各个镜像源一样，pypi也有。 使用镜像源很简单，用-i指定就行了： sudo easy_install -i http://pypi.douban.com/simple/ saltTesting sudo pip install -i http://pypi.douban.com/simple/ saltTesting pip国内的一些镜像阿里云 http://mirrors.aliyun.com/pypi/simple/中国科技大学 https://pypi.mirrors.ustc.edu.cn/simple/豆瓣(douban) http://pypi.douban.com/simple/清华大学 https://pypi.tuna.tsinghua.edu.cn/simple/中国科学技术大学 http://pypi.mirrors.ustc.edu.cn/simple/ 修改源方法临时使用可以在使用pip的时候在后面加上-i参数，指定pip源 pip install scrapy -i https://pypi.tuna.tsinghua.edu.cn/simple 永久修改linux修改 ~/.pip/pip.conf (没有就创建一个)， 内容如下： [global] index-url = https://pypi.tuna.tsinghua.edu.cn/simple windows直接在user目录中创建一个pip目录，如：C:\\Users\\xx\\pip，新建文件pip.ini，内容如下 [global] index-url = https://pypi.tuna.tsinghua.edu.cn/simple","tags":[{"name":"提速","slug":"提速","permalink":"http://www.jifu.io/tags/提速/"},{"name":"PIP","slug":"PIP","permalink":"http://www.jifu.io/tags/PIP/"},{"name":"国内","slug":"国内","permalink":"http://www.jifu.io/tags/国内/"},{"name":"镜像","slug":"镜像","permalink":"http://www.jifu.io/tags/镜像/"}],"categories":[{"name":"back-end","slug":"back-end","permalink":"http://www.jifu.io/categories/back-end/"},{"name":"Python","slug":"back-end/Python","permalink":"http://www.jifu.io/categories/back-end/Python/"},{"name":"Configuration","slug":"back-end/Python/Configuration","permalink":"http://www.jifu.io/categories/back-end/Python/Configuration/"}]},{"title":"软件发布版本区别介绍","date":"2019-04-16T10:41:17.000Z","path":"posts/1755831586/","text":"软件版本阶段说明Alpha版此版本表示该软件在此阶段主要是以实现软件功能为主，通常只在软件开发者内部交流，一般而言，该版本软件的Bug较多，需要继续修改。 Beta版该版本相对于α版已有了很大的改进，消除了严重的错误，但还是存在着一些缺陷，需要经过多次测试来进一步消除，此版本主要的修改对像是软件的UI。 RC版该版本已经相当成熟了，基本上不存在导致错误的BUG，与即将发行的正式版相差无几。 Release版该版本意味“最终版本”，在前面版本的一系列测试版之后，终归会有一个正式版本，是最终交付用户使用的一个版本。该版本有时也称为标准版。一般情况下，Release不会以单词形式出现在软件封面上，取而代之的是符号(R)。 版本命名规范软件版本号由四部分组成 为主版本号 为子版本号 为阶段版本号 日期版本号加希腊字母版本号，希腊字母版本号共有5种，分别为：base、alpha、beta、RC、release。例如：1.1.1.051021_beta。 版本号定修改规则主版本号(1)当功能模块有较大的变动，比如增加多个模块或者整体架构发生变化。此版本号由项目决定 是否修改。 子版本号(1)当功能有一定的增加或变化，比如增加了对权限控制、增加自定义视图等功能。此版本号由项目决定 是否修改。 阶段版本号(1)一般是 Bug 修复或是一些小的变动，要经常发布修订版，时间间隔不限，修复一个严重的bug即可发布一个修订版。此版本号由项目经理决定 是否修改。 日期版本号(051021)用于记录修改项目的当前日期，每天对项目的修改都需要更改日期版本号。此版本号由开发人员决定 是否修改。 希腊字母版本号(beta)此版本号用于标注当前版本的软件处于哪个开发阶段，当软件进入到另一个阶段时需要修改此版本号。此版本号由项目决定 是否修改。 文件命名规范文件名称由四部分组成 项目名称 为文件的描述 为当前软件的版本号 为文件阶段标识加文件后缀 例如：项目外包平台测试报告1.1.1.051021_beta_b.xls，此文件为项目外包平台的测试报告文档，版本号为：1.1.1.051021_beta。 如果是同一版本同一阶段的文件修改过两次以上，则在阶段标识后面加以数字标识，每次修改数字加1，项目外包平台测试报告1.1.1.051021_beta_b1.xls。 当有多人同时提交同一份文件时，可以在阶段标识的后面加入人名或缩写来区别，例如：项目外包平台测试报告 1.1.1.051021_beta_b_LiuQi.xls。当此文件再次提交时也可以在人名或人名缩写的后面加入序号来区别，例如：项目外包平台测试报告1.1.1.051021_beta_b_LiuQi2.xls。 版本号的阶段标识软件的每个版本中包括11个阶段，详细阶段描述如下 阶段名称 阶段标识 需求控制 a 设计阶段 b 编码阶段 c 单元测试 d 单元测试修改 e 集成测试 f 集成测试修改 g 系统测试 h 系统测试修改 i 验收测试 j 验收测试修改 k","tags":[{"name":"软件工程","slug":"软件工程","permalink":"http://www.jifu.io/tags/软件工程/"},{"name":"软件版本","slug":"软件版本","permalink":"http://www.jifu.io/tags/软件版本/"},{"name":"项目","slug":"项目","permalink":"http://www.jifu.io/tags/项目/"}],"categories":[{"name":"Soft engineering","slug":"Soft-engineering","permalink":"http://www.jifu.io/categories/Soft-engineering/"},{"name":"Project","slug":"Soft-engineering/Project","permalink":"http://www.jifu.io/categories/Soft-engineering/Project/"}]},{"title":"如何彻底和CrossOver说GoodBye","date":"2019-04-15T11:47:23.000Z","path":"posts/3807466731/","text":"摘要前阵子安装了一个CrossOver, 据说是一个可以在Mac下跑Win软件的东东,可是安装起来后,体验实在太差, 虽然能跑Win的应用程序,但稳定性和功能上实在不行,所以就Delete掉了. 原来我只是Delete Applications 下的CrossOver.app, 后来发现在Mail中偏好设置的 “默认的电子邮件阅读程序” 里居然出现了IE7( 这个是我在CrossOver下安装的)选项, 看着着实不爽.于是就动手find 所有与CrossOver相关的文件及文件夹并完全Delete掉. 大致需要清除的文件如下/Applications/CrossOver.app (主程序文件) /Users/YourName/Library/Application Support/CrossOver/ (这个乃Mail选项的罪之源,里面有一序列的配置和已安装Windows程序文件的说明和指向) /Users/YourName/Library/Preferences/com.codeweavers.CrossOver.plist (空文件,不知道是干吗的) /Users/YourName/Library/Caches/com.codeweavers.CrossOver/ (一些缓存文件) /Users/YourName/.local/share/mime/ (一些文件contentType关联的配置文件) /Users/YourName/.mime.types (文件) (配置文件)","tags":[{"name":"Mac OS","slug":"Mac-OS","permalink":"http://www.jifu.io/tags/Mac-OS/"},{"name":"CrossOver","slug":"CrossOver","permalink":"http://www.jifu.io/tags/CrossOver/"},{"name":"卸载","slug":"卸载","permalink":"http://www.jifu.io/tags/卸载/"}],"categories":[{"name":"OPS","slug":"OPS","permalink":"http://www.jifu.io/categories/OPS/"},{"name":"MacOS","slug":"OPS/MacOS","permalink":"http://www.jifu.io/categories/OPS/MacOS/"}]},{"title":"Apple Store上iOS App上架流程","date":"2019-04-07T11:18:06.000Z","path":"posts/1054462359/","text":"前言总的来说，App Store 的上架流程，主要分为 7 大步骤: 创建证书请求文件(CSR文件) 制作发布证书 注册要发布的 App ID 制作 App 描述文件 填写 App 相关信息 配置 Xcode 项目信息 Xcode 打包 ipa 上架 为了演示整个流程，预先准备了一个名为Test888的空项目，设置好启动图片和应用程序图标。 创建证书请求文件（即CSR文件）首先，打开应用程序 -&gt; 实用工具 -&gt; 钥匙串访问（KEY CHAIN），如下图所示： 当然，也可以 Launchpad-&gt;其他-&gt;钥匙串访问 在证书助理中，选从证书颁发机构请求证书: 点击从证书颁发机构申请证书，进入如下界面： 注意： 1. 电子邮件地址: 填写你申请开发者账号的电子邮件地址 2. 常用名称: 可以随便写，但是建议起个有意义的名称，方便后期辨认。 3. CA电子邮件地址: 留空即可 4. 请求存储到磁盘(到时可以选择保存到桌面，方便找到使用) 点击继续，来到以下界面 点击存储，将请求文件保存到了桌面上 此时，在桌面上就可以看到一个CertificateSigningRequest.certSigningRequest的证书请求文件（CSR文件）。 注意： CSR文件尽量每个证书都制作一次，将常用名称区分开来，因为该常用名称是证书中的'专用密钥'的名字。 双击CSR文件，安装签名证书 点击继续，选择为您自己创建证书 再点击继续 点击创建，制作自签名根证书 点击继续，证书成功创建 签名算法: 带 RSA加密的 SHA-256 公共密钥信息: RSA 加密，公共密钥256字节 制作发布证书前期准备工作首先，需要具备以下条件 苹果的开发者账号 Mac操作系统 Xcode(这里使用的是Xcode7.3正式版) 如果没有账号，可以打开 http://developer.apple.com/ 注册苹果的开发者帐号。开发者帐号具体申请流程，这里不再细述。如果已经有开发者账号，打开http://developer.apple.com/ 点击 Account，进入到苹果 MemberCenter 的登录界面，如下: 输入自己的开发者账号，登录，进入如下界面： 发布证书的制作 点击Certificates,Identifiers&amp;Profiles，进入如下界面： 点击右上角的加号按钮，然后选择 Production -&gt; App Store and Hoc 注意: 有的时候，我们会发现，不能选中 App Store and Ad Hoc 这是因为一个 Production 中最多只能有两个 iOS Distribution 文件，删掉即可。 点击Continue 由于CSR文件已经创建好，直接点击Continue，然后上传 CSR 文件 点击 Choose File，选中在Mac上配置的请求文件 点击Continue，这个时候，发布证书已经制作完毕 点击Download，这时就有了一个 .cer 证书文件 ios_distribution-8.cer 双击安装证书（如果安装不上，可以直接将证书文件拖拽到钥匙串访问的列表中） 注册要发布的 App ID 选择 App IDs 然后点右上角的加号，创建一个新的 App ID 注意: 这里有两项需要我们自己填： 第一项 ‘Name’，用来描述你的 ‘AppID’，这个随便填，没有什么限制，最好是项目名称，这样方便自己辨识（不允许包含中文）； 第二项 ‘App ID Suffix‘中的’Bundle ID ‘，这是你 ‘App ID’的后缀，这个需要仔细填写。因为这个内容和你的程序直接相关，后面很多地方都要用到，最好是’com.yourcompany.yourappname’的格式，说白了，就是用Xcode中的Bundle ID（这样是最保险的）。 选择你的app中需要的服务 注意： Explict App ID 表示明确的App ID，即 Bundle ID 中必须填写 ‘精确的、完整的’ 产品标识。 Wildcard App ID 表示 通配符 App ID，即 只要 Bundle ID 的前缀满足要求，就可以拿来使用。 ‘如何选择呢？’ 精确式 App ID，可以集成更多的功能； 通配符式 App ID，可以集成的功能较少，比如: 推送、内购等，都不能集成。 如果是公司产品，建议选择 ‘ Explict App ID’ ，以便集成更丰富的功能。 有一个区别，因为PP证书的开发者证书需要真机调试，所以我们需要绑定真机，如果没有的话，需要将真机的udid复制出来在此添加，在发布PP证书中，是没有这一步的。 点击Continue，进入如下界面 注册 App ID信息，如果无误，点击 Register 点击 Done，这时 App ID就注册成功了 制作 App 描述文件(Provisioning Profiles)(简称PP证书)到目前为止，上架所需要的证书还不齐全，想提交AppStore，还需要PP证书。 PP证书分为 开发用的PP证书 和 发布用的PP证书，这里我们制作的是 发布用的PP证书 制作 PP 证书，需要 App ID 和 发布证书(App ID 和 发布证书在上面已经做好了) 点击 Provisioning Profiles，然后点击右上角的加号 点击 Continue，如图，选择我们刚刚注册的 App ID 点击 Continue，选择刚刚创建的发布证书 点击Continue，如图，给PP证书起个名字 点击Continue，如图，PP证书制作完毕 点击Download 将PP证书下载下来，如图 双击PP证书，将其添加到Xcode中 填写 App 相关信息选择 iTunes Connect iTunes Connect.png 进入iTunes Connect网页.png 进入 iTunes Connect 网页 iTunes Connect首页.png 打开我的App，然后点击左上角的加号，新建 App 新建App.png 弹出以下界面，设置 App信息 App信息.png 1&gt; 名称：指的是App上架后，显示在App Store中的名称2&gt; 主要语言: Simplified Chinese(简体中文)3&gt; 套装ID: Test888-com.iOS.www.* 就是之前申请的 App ID4&gt; 套装ID后缀: Test888 后缀就是Xcode中的 Bundle Identifier 最后一个点后面的内容(本例中是 Test888)5&gt; SKU: 可以使用项目中的 Bundle Identifier 点击创建 App信息界面.png 价格与销售范围，根据app不同自己填写 价格与销售范围.png 设置完App信息，点击准备提交，进入如下界面 准备提交界面.png 设置 App预览和屏幕快照 屏幕快照.png 注意:1&gt; 这里需要不同屏幕的截图，可以直接用模拟器运行后截图。待模拟器运行开始的时候，按住cmd+S, 模拟器的屏幕截图就直接保存在桌面上了2&gt; 每种尺寸的屏幕截图必须是在模拟器100%的比例下进行截取。否则会报错。3&gt; 上传的时候会提示“无法载入文件”的问题。原因是：截图保存的文件名有中文，修改下截图名称即可！4&gt; 屏幕尺寸大家都可以查到，为了自己方便，简单备注下： 4.7英寸 -&gt; iPhone6/s 5.5英寸—&gt;iPhone 6/s Plus 4英寸 —&gt;iPhone5S 3.5英寸 —&gt; iPhone 4S 设置 App描述和关键字 App描述和关键字.png 1&gt; 描述: 对App进行简要介绍，让用户快速了解App的基本功能2&gt; 关键字: 用户可以通过这些关键字找到App3&gt; 技术支持网址4&gt; 营销网址 设置 App 综合信息 App综合信息.png 注意:1&gt; 上传App Icon的时候，需要上传1024*1024的，而且不能有圆角效果和透明效果！2&gt; 点击编辑，设置分级，需要根据app的实际情况来设置3&gt; 版权，app的所有者和获利时间 ‘Copyright © 2004 - 2016 xxx.com 版权所有’ App 审核信息 App审核信息.png 注意: 审核信息，必须填写 设置版本发布选项，本例选择的是手动发布 版本发布选项.png 六、配置 Xcode 相关信息1、Account的配置 Xcode -&gt; Preferences -&gt; Account，如图 Account配置界面.png 1&gt; 点击+可以选择Add Apple ID；2&gt; 点击View Details可以查看该Apple Id下的Certificates和Provisioning Profile证书文件，在这里你可以点击下载。 View Details界面.png 2、 项目配置 在项目Targets下的Identity中，Team选择对应的Apple ID 即可 选择对应的Apple ID.png 在Xcode的项目设置里，Provisioning Profile就可以选择对应的证书。 选择对应的PP证书.png 到此为止，前期的准备工作就做完了。 七、Xcode 打包 ipa 上架首先，要将项目改为 Release。然后继续下面的步骤: 在 “真机状态” 下选择 Product-&gt;Archive(如果不是真机状态下，Archive会是灰色不可用的)，成功会弹出如下图： 注意: 这里说的 ‘真机状态’，不是必须插上真机设备，只要选中 ‘Generic iOS Device’ 就可以。 操作步骤.png Archive在线打包成功后返回的界面.png 1&gt; Validate表示验证，Export表示导出2&gt; 建议先点击Validate进行验证，验证的过程有点慢，但是为了审核顺利点，还是验证下为好。3&gt; 验证成功后点击Export导出ipa包，用于上传即可。 导出ipa.png Test888.ipa.png 提交构建版本，打开Xcode，上传应用程序包 上传应用程序包.png 正在上传.png 等上几分钟 上传成功.png 有两种方式:1&gt; Xcode 6或更高版本2&gt; Application Loader 3.0或更高版本提交构建版本 回到 iTunes Connect网页，选择构建版本 选择一个需要上架的构建版本.png 点击提交以供审核 最后的确认信息.png 1&gt; 出口合规信息: 如果使用了加密，选择『是』，否则选『否』2&gt; 内容版权: 包含了第三方的东西，就选『是』，否则选『否』3&gt; 广告标识符（IDFA）: 这个一定要选对，选错了会导致二进制文件永久被拒，需要重新提交二进制文件。 点击提交 等待审核.png 到此，整个 App 上架流程就演示完了！","tags":[{"name":"iOS","slug":"iOS","permalink":"http://www.jifu.io/tags/iOS/"},{"name":"Apple Store","slug":"Apple-Store","permalink":"http://www.jifu.io/tags/Apple-Store/"},{"name":"上架流程","slug":"上架流程","permalink":"http://www.jifu.io/tags/上架流程/"}],"categories":[{"name":"iOS Development","slug":"iOS-Development","permalink":"http://www.jifu.io/categories/iOS-Development/"}]},{"title":"一览Mac OS 图形界面的发展史","date":"2019-04-06T08:45:07.000Z","path":"posts/2768996547/","text":"Mac OS 是运行在苹果电脑上的操作系统，它是第一个在商用领域取得成功的图形用户界面，下面这个轻单带你一览从 System 到 Mac OS 8 再到后续的连续 OS X 图形界面的发展史。 最早期 Mac OSSystem 1-6 1984 年的苹果发布了其第一台 Mac 个人电脑，与其一起发布的操作系统当时被简单的称为 System Software，第一代 System 1 打破了字符终端的模式，最早使用图形界面和用户交互设计：基于窗口操作并使用了图标，鼠标可以在移动，并可以通过拖拽来拷贝文件及文件夹。这让它成为图形界面设计的先驱，但后续直到 System 7 界面始终没有大改变。 System 7 1991 年的 System 7 开始引入彩色，图标也增加了隐约的灰色，蓝色和黄色阴影。但 Mac OS 整体界面却始终没有显著的变化。与此同时微软家的 Windows 从黑屏的 DOS 到全屏幕的Windows 1，再到成熟的 Windows 3，最后演变到奠定当今 Windows 界面基础的炫丽多彩的 Windows 95。用当时的眼光来看，这个变化是相当惊人的。而 Mac OS 因为因循守旧，在界面设计上从领先掉到了最后。 另外从 System 7 的 7.6 版本开始被苹果公司改名为 Mac OS ,这一年是 1997 年。 Mac OS 8 1997年，苹果发布的 Mac OS 8 开始加入更多的颜色，默认支持 256 色的图标，并较早的采用了等距风格图标，也称伪 3D 图标，但整体界面变化依旧不大。 NeXT 附体 已经有十年历史的 Mac OS 已经遇到了瓶颈限制，为了让 Mac OS 现代化内部做了一番尝试和舍弃后，最后决定收购 NeXT，因为不仅可以带来用户界面的变化，还可以使整个系统设计的全盘革新。 买完 NeXT 后，乔布斯回来了，“你们就是一群白痴！”他把所有团队的人叫到一个房间里以乔布斯风格把所有地方都骂了一遍，之后包括拉茨拉夫在内的设计师们的日子遍越来越难熬了。 注：拉茨拉夫，当时 Mac OS 人机界面设计负责人 过渡 OS XRhapsody 1997 年苹果发布了过渡时代的 Rhapsody，整合了Mac OS 8 的外观与 NeXT-based 界面，它是介于 NeXT 以及 Mac OS X 之间的操作系统，也可以理解为是套了壳的 NeXT 操作系统。 而代号 Rhapsody 是依循苹果在 1990 年代以音乐名词作为操作系统代号的模式所命名的，其他代号包括 Harmony (Mac OS 7.6)，Tempo (Mac OS 8)，Allegro (Mac OS 8.5)及 Sonata (Mac OS 9)。 Mac OS 9 1999 年发布，是乔布斯宣布过渡到 Mac OS X 阶段路线上最后一个 Mac OS 系列。 Mac OS X Server 1.0 1999 年 3 月苹果发布 Mac OS X Server 1.0 ，即第一个版本的 Mac OS X 开发者预览版，它是苹果第一个真正基于 NeXT 的操作系统，和 Rhapsody 很像。 早期 Mac OS XOS X 公开测试版 2000 年 9 月发布，在这个版本中全新的用户界面 Aqua 初次亮相。另外它也是所有 Mac OS 中惟一一个将苹果菜单置于屏幕顶部中央的版本，这个修改因饱受用家诟病而在 Mac OS X 10.0 中被恢复。 注：Aqua 是 Mac OS X 的 GUI 商标名称，下面这个视频就是当年乔布斯在 2000 年 MacWorld 上介绍 Aqua 界面部分，强烈推荐观看。youtube OS X 10.0 Cheetah 猎豹 2001 年 3 月，经历了四个开发者预览版和一个公共测试版之后的 Aqua 界面终于跟随 10.0 正式发布，发布后改变了人们对计算机界面的印象，在随后的 10 年里苹果一直沿用这套界面风格。 另外伴随 Aqua 一起来的还有苹果一整堪称经典的套拟物化的图标，也是一直基本持续沿用到现在，以及一个全新的方式组织 Mac OS X 应用程序的用户界面：Dock 栏，以及组成 Aqua 界面的那些细节：菜单、按钮、进度条、滚动条等等，其中一根看似简单得不能再简单的滚动条，就耗费了苹果设计组整整六个月。 这些都影响了整整一代图形界面设计者。 One more thing, 从 Mac OS X 苹果开启了以猫科动物系列为代号的命名史。 OS X 10.1 Puma 美洲狮 OS X 10.0 半年后即 2001 年 9 月，苹果就推出了 OS X 10.1美洲狮，没有新增太多功能，主要聚焦于改善系统表现。 OS X 10.2 Jaguar 美洲豹 2002 年 8月发布，在这一版本中 Aqua 界面的装饰风格达到新高峰：窗口背景底纹，非活动窗口标题栏半透明、滚动条的抽空效果。另外也是从这个版本有了新的起始画面和新的苹果标志，过往 Happy Mac 的标志不再出现，取而代之的是如今那颗被偷咬了一口的苹果。 进化 Mac OS XAqua 的衰退，这种变化事实上从 OS X 10.3 Panther 就开始了 OS X 10.3 Panther 黑豹 2003 年 10 月发布，在这一版本 Aqua 界面引入了新的 Brush 风格，即金属拉丝质感，并在最常用的 Finder 上使用。 OS X 10.4 Tiger 老虎 2005 年 4月发布，顶栏最右侧新增了一个蓝色的 Spotlight 搜索按钮。 OS X 10.5 Leopard 豹 2007 年 10月发布，用户界面上改进幅度比较大的一个版本，虽然基本的界面仍为 Aqua 和其糖果滚动条，但新加入了一些铂灰色和蓝色，另外重新设计的 3D Dock和更多的动画交互使得新界面看上去 3D效果更强，此外还改进了 Finder、半透明菜单条并新增了最初只用于 iTunes 的 Cover Flow 界面。 整体来说这一版本的界面相比之前有了翻天覆地的变化。 OS X 10.6 Snow Leopard 雪豹 2009 年 8 月发布，就像雪豹的名字，只比豹多了个雪字，它是以 OS X 10.5 的版本为基础跟进开发的，不过 OS X 10.6 还跑去向 iOS 偷师，引进了 Mac App Store 即应用商店。 现代 Mac OS XOS X 10.7 Lion 狮子 2011 年 7 月发布，重新设计了 Aqua GUI 元素、按钮、进度条、滚动条（不使用时会自动隐藏）以及“滑动切换”的选项卡，全新设计了拟物化 iCal 界面，新的通信录和邮件应用都使用了类似 iPad 的界面。此外还引进了像 iOS 那样的应用启动器 Lauchpad 界面。 OS X 10.8 Mountain Lion 美洲狮 2012 年 7 月发布，和 Lion 同样的的风格，更多类 iPad 及 iOS 的功能界面被引入（一些内置应用程序甚至被更名以与 iOS 保持一致），整体界面变化不大。 OS X 10.9 Mavericks 2013 年 10 月发布，可以说是近期苹果的突破之作，界面上它看起来则更像是 OS X 10.6 的继承者，OS X 10.7 和 OS X 10.8 里面的拟物化设计在 OS X 10.9 中被移除。 另外从这一版本苹果不再以动物命名 Mac OS X ，取而代之的是加州地名，如 Mavericks 就是加州某个冲浪景点。 OS X 10.10 Yosemite 优胜美地 2014 年 10 月发布，苹果历年来变化最大的操作系统，包括趋于扁平化的界面风格、类似 iOS 7 的图标设计、半透明导航栏及全新字体设计等。","tags":[{"name":"Mac OS","slug":"Mac-OS","permalink":"http://www.jifu.io/tags/Mac-OS/"},{"name":"发展史","slug":"发展史","permalink":"http://www.jifu.io/tags/发展史/"}],"categories":[{"name":"OPS","slug":"OPS","permalink":"http://www.jifu.io/categories/OPS/"},{"name":"MacOS","slug":"OPS/MacOS","permalink":"http://www.jifu.io/categories/OPS/MacOS/"}]},{"title":"发布你自己的轮子 - PyPI打包上传实践","date":"2019-04-05T06:25:44.000Z","path":"posts/55626181/","text":"本文仅讨论上传相关的步骤，关于如何给写一个setup.py 请参阅官方文档： https://docs.python.org/2/dis… 上传前的注意事项假设你的包已经开发完成，并且根目录必须要有一个setup.py。最好有一个README.rst用来描述你的轮子，虽然这不是必须的，但文档就像内裤，你最好还是要有的。如果你需要打包代码文件夹以外的文件，比如版权信息等等，你还需要写一个 MANIFEST.in。 关于setup.py的补充说明 name必须是唯一的，允许使用数字和字母，推荐使用中划线（-）而不是下划线（_），因为pip安装只支持中划线，比如pip install my-pkg，为了不给自己找麻烦请听话。 version推荐遵循语义化版本号规则，简单说就像这样：1.2.0 作者姓名和邮箱地址不一定要和你的PyPI账号一致。 测试本地打包命令如果上面的都没问题，在本地目录执行以下命令应该能成功在dist目录下生成*.tar.gz的包文件。 python setup.py sdist 上传并发布包文件到PyPI创建 PyPI账号非常简单，直接通过官网注册https://pypi.python.org/pypi?…， 但是需要验证邮件并确认激活。 创建用户验证文件 ~/.pypirc在自己的用户目录下新建一个空白文件命名为.pypirc，内容如下： [distutils] index-servers=pypi [pypi] repository = https://upload.pypi.org/legacy/ username = &lt;username> password = &lt;password> 用户名和密码就是上一步骤所创建的，直接明文输入。如果你觉得明文密码不安全也可以留空，在后面的上传过程中会提示你手动输入。 注册你的包你需要到PyPI注册并验证你的包，之后才能开始真正上传，注册的方式有以下几种。 使用命令python setup.py register，最简单但官网不推荐，因为使用的是HTTP未加密，有可能会被攻击人嗅探到你的密码。 通过PyPI网站提交表单完成注册验证。 安装pip install twine然后在通过命令twine register dist/mypkg.whl完成注册。 上传并完成发布你可以任选以下两种方式之一发布你的轮子。 使用命令: python setup.py sdist upload，还是和上面一样，简单但有安全隐患，目前已淘汰。 使用twine: twine upload dist/* 管理你的包如果你的包已经上传成功，那么当你登录PyPI网站后应该能在右侧导航栏看到管理入口。 点击包名进去后你可以对你的包进行管理，当然你也可以从这里删除这个包。 让别人使用你的包包发布完成后，其他人只需要使用pip就可以安装你的包文件。比如： pip install package-name 如果你更新了包，别人可以可以通过--update参数来更新： pip install package-name --update 可能遇到的错误Upload failed (403): Invalid or non-existent authentication information.错误的用户验证信息，你需要创建一个用户验证文件~/.pypirc。请参阅上文。 Upload failed (403): You are not allowed to edit ‘xxx’ package information你需要先注册你的包才可以开始上传，运行注册命令:python setup.py register Server response (401): Incomplete registration; check your email你的PyPI账户还没完成邮箱验证，你需要去注册邮箱找到一封验证邮件完成验证后再重试失败的步骤。 Server response (400): Invalid classifier “Topic :: Software Development :: Utilities”你的setup.py文件中的classifier信息有误，请按官网的正确分类书写classifier. error: No dist file created in earlier command你还没打包就开始了上传命令，建议打包和上传的操作放在一起做，比如： python setup sdist upload error: Upload failed (499): Client Disconnected这应该是网络问题，多重试几次。 Upload failed (400): File already exists文件已经存在了，你每一次上次都应该更新版本号。","tags":[{"name":"Python","slug":"Python","permalink":"http://www.jifu.io/tags/Python/"},{"name":"pypi","slug":"pypi","permalink":"http://www.jifu.io/tags/pypi/"},{"name":"打包","slug":"打包","permalink":"http://www.jifu.io/tags/打包/"}],"categories":[{"name":"back-end","slug":"back-end","permalink":"http://www.jifu.io/categories/back-end/"},{"name":"Python","slug":"back-end/Python","permalink":"http://www.jifu.io/categories/back-end/Python/"},{"name":"Library","slug":"back-end/Python/Library","permalink":"http://www.jifu.io/categories/back-end/Python/Library/"}]},{"title":"HR常用的招聘邮件模板","date":"2019-04-03T21:08:45.000Z","path":"posts/3142539384/","text":"对于HR来说，一些邮件模板是非常有用的，但是应该小心应用，因为不是每一个邮件都适合所有的问题。每个邮件都应该像面对面的对话一样，显示着本公司的风格特征。 在招聘的每个环节，包括第一次和潜在的候选人进行对话到最终招聘到新的雇员，都需要用邮件进行交流，这里提供一些邮件模板和人力资源模板，可以帮助HR和候选人更好的进行对话，也可以帮助节省大量的时间。除此之外，对于招聘指标进行定期的追踪，都可以帮助提高和改善招聘流程。 寻找候选人的邮件如果你想要让候选人更好的考虑这个工作机会，对于潜在候选人的寻找邮件应该是比较开门见山的。想要与这些被动的候选人进行交流，邮件应该包括你如何发现他们的以及想要联系他们的原因。 英文版：My name is [X] and I’m helping the CTO here at [Company] to find someone to join our Back-end developer team. The latest debugging feature you published in Github particularly drew our attention. We are currently working on a similar project for our application and we think your experience would be a strong addition to our team. 中文版：你好，我是xxx，正在帮助公司扩充后端开发团队，最近你在xxx上的简历引起了我们招聘团队的关注，我们公司目前也在进行一项类似的项目，我们认为你的经历对于我们团队将会有很大的帮助，也十分希望您能够加入我们公司。 如果想要提高招聘邮件的回应率，应该使招聘邮件更具个性化。这可能和招聘邮件模板本身有些矛盾冲突，但是应该牢记，模板仅仅提供了一个灵感而已，避免出现电子邮件的常见错误。 如果你和收到邮件的对方在之前就已经有过联系，比如说对方是过去的候选人，可以充分利用这一优势来激起他们对于这份工作的兴趣，不要只希望他们仅仅是对于你感兴趣。 英文版：I am [your name], a recruiter at [Company]. We met around 2 months ago when you applied for the web designer position. I remember you were looking for a new apartment at that time. How did the house hunt go?Although we decided to move on with a more experienced candidate, our team was really impressed with both your design skills and your positive attitude during the interview process. We now have a new opening for a junior web designer, that is closer for for your profile. I’d really like to give you some more details about the role, if you’re interested. 中文版：你好，我是xxx，xx公司的 HR，大约在2个月前，您申请过我们公司的xx职位，我们也见过一面，我记得当时你在找一个新住处，不知最近情况如何呢？虽然当时公司决定雇佣了一位经验更加丰富的候选人，但是对您的印象也十分深刻。公司目前在招聘xx职位，和您的简历也比较吻合，如果你对该岗位感兴趣，我十分乐意给您提供更多相关信息。 英文版：We are currently looking to hire a Marketing specialist and [Employee_name] mentioned that you might be a good fit.From what I have seen in your LinkedIn profile, you have an impressive background in paid campaigns and you’ve done some interesting things organizing promotional events, which is our priority for this new role.Here, at [Company], we’re always looking for more great people like [Employee_name], so we’d like to get to know you. 中文版：目前我们公司正在招聘xxx岗位， xxx提到你可能是一个很不错的候选人，我也在xxx中看到你的简历，您不仅有相关的工作经验，工作也十分突出。公司也在寻找像您这样的人，我们十分希望能和您进行更深入的沟通了解，也十分希望收到您的回复。 员工推荐员工推荐是招聘的重要来源，为了让员工积极推荐一些合适的候选人岗位，可以设计一些合适的内部推荐所适用的邮件模板，内容需要包括：新员工的工作内容是什么，要在哪个部门工作，需要什么样的工作技能和经验。 英文版：We are excited to announce that we are currently looking for a Technical writer to join [Hiring_Manager_name’s] team! If you know someone who understands end-user requirements and has experience in software documentation, feel free to let us know by simply replying to this email. 中文版：HI! 大家好，最近公司的HR 部门正在寻找 xxx 岗位的优秀候选人。该工作岗位需要了解客户的需求，并且有撰写软文的工作技能和经验。如果大家有推荐的候选人可以回复这封邮件~ 邀请候选人邀请候选人参加面试的邮件中应该包括一些具体的信息，包括面试的时间和地点，面试官的名字以及面试需要多久的时间，不同类型的面试邀请也需要一些不一样的内容。 电话面试电话面试邮件通常是候选人在招聘过程中第一次接受的面试邀请邮件，所以要记得感谢候选人的申请，并再次提供招聘职位的基本信息。 英文版：Thank you for applying to [Company].We would like to have a phone discussion about your application for the [Job_title] role. I’d like to tell you more about [Company] and get to know you a bit better. 中文版：非常感谢您对公司 xxx 职位的申请。关于xxx 工作职位，我们想要和您有进一步的沟通，我们想要告诉您一些关于公司的具体的信息，也希望你能够对于这一职位更加了解。 现场面试现场面试的邮件应该包括一些提示性的信息，比如说候选人应该带一些什么东西，公司的具体地址，如果有必要的话，还可以附上公司的具体地图，以及如何到达。 英文版：Your application for the [Job_title] position stood out to us and we would like to invite you for an interview at our office[s] to get to know you a bit better.You will meet with the Marketing department manager, [Manager’ name]. The interview will last about [X] minutes and you’ll have the chance to discuss the [Job_title] position and learn more about our company.Please note that the security guard will ask to see your ID to let you enter the building. 中文版：你好，对于公司某岗位的招聘中，您的简历十分突出，公司想要和您进行下一步的面试。接下来的面试中，您将会见到 xxx，面试时间大约会持续x 时间，我们将会在下一步的面试环节中与您讨论一下该岗位相关的信息。面试时，请携带好您的证件，保安会根据您出示的证件让您进入办公大楼。 第二轮面试如果你打算和候选人进行第二轮的面试，邮件应该说明清楚具体状况。 英文版：Thank you for taking the time to discuss the [Job_title] position with us. We’d like to invite you for a second interview at our office[s]. You will meet with [Manager’s name], head of the IT department, to discuss your written assignment and delve deeper into job duties. 中文版：很高兴您通过了我们的第一轮面试环节，我们想邀请你进行第二次面试。这次您将会见到技术部门的负责人 xxx，我们将深入的与您讨论公司的xxx岗位，也十分期待收到您的回复。 测试邮件为了更好的评估候选人的技能，你可能需要发送含候选人测试的邮件，在邮件中，应该对测试内容和意图进行介绍，并且对候选人进行指导，告诉候选人应该准备的工具和网络环境。 英文版：Thank you for taking the time to speak to us on the phone. We would like to invite you to complete an assignment for the next round of our interview process. Please find the assignment attached. Its objective is to gauge your skills, give us an idea of how you approach tasks relevant to the job and provide us with some talking points. We would appreciate it if you could return your completed assignment to us [by X date/ in Y time frame]. 中文版：十分感谢您能够在百忙中抽出时间与我们进行了电话面试，在下一轮面试之前，我们想邀请您进行网上测试。请点击邮件的链接进入测试环节，该测试时为了测试您的工作技能和工作的处理方法，请在xxx 之前完成测试，十分感谢您的配合！ 拒绝邮件没有人喜欢发送让人不开心的邮件，但是工作中又避免不了发送一些拒绝候选人的邮件。不要让候选人不断的等待和猜测面试结果，要以及极的态度与候选人简单的解释一下面试失败的原因，和候选人建立良好的社交关系。 英文版：Although we are now focusing on hiring more senior [Job_title], we’ll be more than happy to get in touch with you again for a future job opening. 中文版：很抱歉的通知您，虽然您在我们的面试环节中表现也非常有优秀，但是我们有更加合适的候选人选了。我们认为公司未来可能会有更加合适的岗位提供给您，也十分希望能够与您继续保持联系，以便于我们未来的进一步合作。 工作offer工作offer 邮件应该通知到候选人您想录用他们，并且应该包含工作的具体信息，以帮助他们更好的进行决策。 英文版：We have been impressed with your background and would like to formally offer you the position of [Job_title]. This is a [full/part] time position [mention working days and hours] with an annual salary of [X]. You will be reporting to the head of the [Department_name] department. Your expected starting date is [date.] 中文版：你在本公司的面试中表现十分突出，您的工作技能和经验和我们的工作要求也十分的吻合，公司认为您确实是公司 xxx 岗位的合适人选，这份工作的年薪将会是xxx，工作入职时间大约为 xxx，该工作岗位属于 xxx 部门，您将会和xxx 一起共事，十分希望你能够接受我们的工作offer. 入职邮件一旦候选人接受了你的工作offer,下一个环节中就要欢迎新员工入职，准备好一些新员工的注意事项，比如说，期望他们入职的时间，他们将要和哪些员工共事。合适的入职邮件应该体现公司的招聘环节以及你为候选人的入职设计了具体的入职流程。 英文版：We are all really excited to welcome you to our team! As agreed, your start date is [date.] We expect you to be at our office by [time] and our dress code is [casual/ business casual.]We’ve organized your first days to help you settle in properly. You can find more details in the attached agenda. 中文版：十分欢迎加入我们团队！按照我们商量的，入职时间是 xxx，希望您能够按时的到达公司，来的时候最好穿正装/便装。工作的第一天，我们将帮助你完成入职培训，更多相关的信息可以查看附件的入职流程文件。 欢迎新员工邮件在新员工到来之前，HR 应该用电子邮件对于新员工进行介绍，保障他们对于新的员工并不陌生，并且积极的欢迎新员工的到来。 英文版：I am very pleased to announce that [Employee’s name] will be joining us as an Android developer on [Start date.] [Employee’s name] will work with our mobile team to help us elevate our applications. Please make sure you give [him/her] a warm welcome and introduce yourselves! 中文版：大家好，最近xxx将作为xxx岗位的新员工入职我们公司，他将和xxx 团队一起共事，为我们公司贡献一份力量，希望大家能够对这位员工表示热烈的欢迎，并且在入职当天能够积极的介绍自己。","tags":[{"name":"HR","slug":"HR","permalink":"http://www.jifu.io/tags/HR/"},{"name":"模板","slug":"模板","permalink":"http://www.jifu.io/tags/模板/"},{"name":"招聘","slug":"招聘","permalink":"http://www.jifu.io/tags/招聘/"}],"categories":[{"name":"HR","slug":"HR","permalink":"http://www.jifu.io/categories/HR/"}]},{"title":"Docker学习笔记","date":"2019-04-02T03:48:38.000Z","path":"posts/1245529498/","text":"Docker 简介 Docker 两个主要部件： Docker: 开源的容器虚拟化平台 Docker Hub: 用于分享、管理 Docker 容器的 Docker SaaS 平台 – Docker Hub Docker 使用客户端-服务器 (C/S) 架构模式。Docker 客户端会与 Docker 守护进程进行通信。Docker 守护进程会处理复杂繁重的任务，例如建立、运行、发布你的 Docker 容器。Docker 客户端和守护进程可以运行在同一个系统上，当然你也可以使用 Docker 客户端去连接一个远程的 Docker 守护进程。Docker 客户端和守护进程之间通过 socket 或者 RESTful API 进行通信。 Docker 守护进程如上图所示，Docker 守护进程运行在一台主机上。用户并不直接和守护进程进行交互，而是通过 Docker 客户端间接和其通信。 Docker 客户端Docker 客户端，实际上是 docker 的二进制程序，是主要的用户与 Docker 交互方式。它接收用户指令并且与背后的 Docker 守护进程通信，如此来回往复。 Docker 内部要理解 Docker 内部构建，需要理解以下三种部件： Docker 镜像 - Docker images Docker 仓库 - Docker registeries Docker 容器 - Docker containers Docker 镜像Docker 镜像是 Docker 容器运行时的只读模板，每一个镜像由一系列的层 (layers) 组成。Docker 使用 UnionFS 来将这些层联合到单独的镜像中。UnionFS 允许独立文件系统中的文件和文件夹(称之为分支)被透明覆盖，形成一个单独连贯的文件系统。正因为有了这些层的存在，Docker 是如此的轻量。当你改变了一个 Docker 镜像，比如升级到某个程序到新的版本，一个新的层会被创建。因此，不用替换整个原先的镜像或者重新建立(在使用虚拟机的时候你可能会这么做)，只是一个新的层被添加或升级了。现在你不用重新发布整个镜像，只需要升级，层使得分发 Docker 镜像变得简单和快速。 Docker 仓库Docker 仓库用来保存镜像，可以理解为代码控制中的代码仓库。同样的，Docker 仓库也有公有和私有的概念。公有的 Docker 仓库名字是 Docker Hub。Docker Hub 提供了庞大的镜像集合供使用。这些镜像可以是自己创建，或者在别人的镜像基础上创建。Docker 仓库是 Docker 的分发部分。 Docker 容器Docker 容器和文件夹很类似，一个Docker容器包含了所有的某个应用运行所需要的环境。每一个 Docker 容器都是从 Docker 镜像创建的。Docker 容器可以运行、开始、停止、移动和删除。每一个 Docker 容器都是独立和安全的应用平台，Docker 容器是 Docker 的运行部分。 libcontainerDocker 从 0.9 版本开始使用 libcontainer 替代 lxc，libcontainer 和 Linux 系统的交互图如下： 命名空间「Namespaces」pid namespace不同用户的进程就是通过 pid namespace 隔离开的，且不同 namespace 中可以有相同 PID。具有以下特征: 每个 namespace 中的 pid 是有自己的 pid=1 的进程(类似 /sbin/init 进程)每个 namespace 中的进程只能影响自己的同一个 namespace 或子 namespace 中的进程因为 /proc 包含正在运行的进程，因此在 container 中的 pseudo-filesystem 的 /proc 目录只能看到自己 namespace 中的进程因为 namespace 允许嵌套，父 namespace 可以影响子 namespace 的进程，所以子 namespace 的进程可以在父 namespace 中看到，但是具有不同的 pid 参考文档：Introduction to Linux namespaces – Part 3: PID mnt namespace类似 chroot，将一个进程放到一个特定的目录执行。mnt namespace 允许不同 namespace 的进程看到的文件结构不同，这样每个 namespace 中的进程所看到的文件目录就被隔离开了。同 chroot 不同，每个 namespace 中的 container 在 /proc/mounts 的信息只包含所在 namespace 的 mount point。 net namespace网络隔离是通过 net namespace 实现的， 每个 net namespace 有独立的 network devices, IP addresses, IP routing tables, /proc/net 目录。这样每个 container 的网络就能隔离开来。 docker 默认采用 veth 的方式将 container 中的虚拟网卡同 host 上的一个 docker bridge 连接在一起。 参考文档：Introduction to Linux namespaces – Part 5: NET uts namespaceUTS (“UNIX Time-sharing System”) namespace 允许每个 container 拥有独立的 hostname 和 domain name, 使其在网络上可以被视作一个独立的节点而非 Host 上的一个进程。 参考文档：Introduction to Linux namespaces – Part 1: UTS ipc namespacecontainer 中进程交互还是采用 Linux 常见的进程间交互方法 (interprocess communication - IPC), 包括常见的信号量、消息队列和共享内存。然而同 VM 不同，container 的进程间交互实际上还是 host 上具有相同 pid namespace 中的进程间交互，因此需要在 IPC 资源申请时加入 namespace 信息 - 每个 IPC 资源有一个唯一的 32bit ID。 参考文档：Introduction to Linux namespaces – Part 2: IPC user namespace每个 container 可以有不同的 user 和 group id, 也就是说可以以 container 内部的用户在 container 内部执行程序而非 Host 上的用户。 有了以上 6 种 namespace 从进程、网络、IPC、文件系统、UTS 和用户角度的隔离，一个 container 就可以对外展现出一个独立计算机的能力，并且不同 container 从 OS 层面实现了隔离。 然而不同 namespace 之间资源还是相互竞争的，仍然需要类似 ulimit 来管理每个 container 所能使用的资源 - cgroup。 ReferenceDocker Getting Start: Related Knowledge Docker 介绍以及其相关术语、底层原理和技术 资源配额「cgroups」cgroups 实现了对资源的配额和度量。 cgroups 的使用非常简单，提供类似文件的接口，在 /cgroup 目录下新建一个文件夹即可新建一个 group，在此文件夹中新建 task 文件，并将 pid 写入该文件，即可实现对该进程的资源控制。具体的资源配置选项可以在该文件夹中新建子 subsystem ，{子系统前缀}.{资源项} 是典型的配置方法， 如 memory.usage_in_bytes 就定义了该 group 在 subsystem memory 中的一个内存限制选项。 另外，cgroups 中的 subsystem 可以随意组合，一个 subsystem 可以在不同的 group 中，也可以一个 group 包含多个 subsystem - 也就是说一个 subsystem。 memory内存相关的限制 cpu在 cgroup 中，并不能像硬件虚拟化方案一样能够定义 CPU 能力，但是能够定义 CPU 轮转的优先级，因此具有较高 CPU 优先级的进程会更可能得到 CPU 运算。 通过将参数写入 cpu.shares ,即可定义改 cgroup 的 CPU 优先级 - 这里是一个相对权重，而非绝对值 blkioblock IO 相关的统计和限制，byte/operation 统计和限制 (IOPS 等)，读写速度限制等，但是这里主要统计的都是同步 IO devices设备权限限制 参考文档：how to use cgroup Docker 安装docker 的相关安装方法这里不作介绍，具体安装参考官档 获取当前 docker 版本$ sudo docker version Client version: 1.3.2 Client API version: 1.15 Go version (client): go1.3.3 Git commit (client): 39fa2fa/1.3.2 OS/Arch (client): linux/amd64 Server version: 1.3.2 Server API version: 1.15 Go version (server): go1.3.3 Git commit (server): 39fa2fa/1.3.2 Docker 基础用法Docker HUB : Docker镜像首页，包括官方镜像和其它公开镜像 因为国情的原因，国内下载 Docker HUB 官方的相关镜像比较慢，可以使用 Daocloud 镜像加速。 Search images$ sudo docker search ubuntu Pull images$ sudo docker pull ubuntu # 获取 ubuntu 官方镜像 $ sudo docker images # 查看当前镜像列表 Running an interactive shell$ sudo docker run -i -t ubuntu:14.04 /bin/bash docker run - 运行一个容器 -t - 分配一个（伪）tty (link is external) -i - 交互模式 (so we can interact with it) ubuntu:14.04 - 使用 ubuntu 基础镜像 14.04 /bin/bash - 运行命令 bash shell 注: ubuntu 会有多个版本，通过指定 tag 来启动特定的版本 [image]:[tag] $ sudo docker ps # 查看当前运行的容器, ps -a 列出当前系统所有的容器 CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 6c9129e9df10 ubuntu:14.04 /bin/bash 6 minutes ago Up 6 minutes cranky_babbage 相关快捷键 退出：Ctrl-D or exit detach：Ctrl-P + Ctrl-Q attach: docker attach CONTAINER-ID Docker 命令帮助docker helpdocker command$ sudo docker # docker 命令帮助 Commands: attach Attach to a running container # 当前 shell 下 attach 连接指定运行镜像 build Build an image from a Dockerfile # 通过 Dockerfile 定制镜像 commit Create a new image from a container's changes # 提交当前容器为新的镜像 cp Copy files/folders from the containers filesystem to the host path # 从容器中拷贝指定文件或者目录到宿主机中 create Create a new container # 创建一个新的容器，同 run，但不启动容器 diff Inspect changes on a container's filesystem # 查看 docker 容器变化 events Get real time events from the server # 从 docker 服务获取容器实时事件 exec Run a command in an existing container # 在已存在的容器上运行命令 export Stream the contents of a container as a tar archive # 导出容器的内容流作为一个 tar 归档文件[对应 import ] history Show the history of an image # 展示一个镜像形成历史 images List images # 列出系统当前镜像 import Create a new filesystem image from the contents of a tarball # 从tar包中的内容创建一个新的文件系统映像[对应 export] info Display system-wide information # 显示系统相关信息 inspect Return low-level information on a container # 查看容器详细信息 kill Kill a running container # kill 指定 docker 容器 load Load an image from a tar archive # 从一个 tar 包中加载一个镜像[对应 save] login Register or Login to the docker registry server # 注册或者登陆一个 docker 源服务器 logout Log out from a Docker registry server # 从当前 Docker registry 退出 logs Fetch the logs of a container # 输出当前容器日志信息 port Lookup the public-facing port which is NAT-ed to PRIVATE_PORT # 查看映射端口对应的容器内部源端口 pause Pause all processes within a container # 暂停容器 ps List containers # 列出容器列表 pull Pull an image or a repository from the docker registry server # 从docker镜像源服务器拉取指定镜像或者库镜像 push Push an image or a repository to the docker registry server # 推送指定镜像或者库镜像至docker源服务器 restart Restart a running container # 重启运行的容器 rm Remove one or more containers # 移除一个或者多个容器 rmi Remove one or more images # 移除一个或多个镜像[无容器使用该镜像才可删除，否则需删除相关容器才可继续或 -f 强制删除] run Run a command in a new container # 创建一个新的容器并运行一个命令 save Save an image to a tar archive # 保存一个镜像为一个 tar 包[对应 load] search Search for an image on the Docker Hub # 在 docker hub 中搜索镜像 start Start a stopped containers # 启动容器 stop Stop a running containers # 停止容器 tag Tag an image into a repository # 给源中镜像打标签 top Lookup the running processes of a container # 查看容器中运行的进程信息 unpause Unpause a paused container # 取消暂停容器 version Show the docker version information # 查看 docker 版本号 wait Block until a container stops, then print its exit code # 截取容器停止时的退出状态值 Run 'docker COMMAND --help' for more information on a command. docker optionUsage of docker: --api-enable-cors=false Enable CORS headers in the remote API # 远程 API 中开启 CORS 头 -b, --bridge=\"\" Attach containers to a pre-existing network bridge # 桥接网络 use 'none' to disable container networking --bip=\"\" Use this CIDR notation address for the network bridge's IP, not compatible with -b # 和 -b 选项不兼容，具体没有测试过 -d, --daemon=false Enable daemon mode # daemon 模式 -D, --debug=false Enable debug mode # debug 模式 --dns=[] Force docker to use specific DNS servers # 强制 docker 使用指定 dns 服务器 --dns-search=[] Force Docker to use specific DNS search domains # 强制 docker 使用指定 dns 搜索域 -e, --exec-driver=\"native\" Force the docker runtime to use a specific exec driver # 强制 docker 运行时使用指定执行驱动器 --fixed-cidr=\"\" IPv4 subnet for fixed IPs (ex: 10.20.0.0/16) this subnet must be nested in the bridge subnet (which is defined by -b or --bip) -G, --group=\"docker\" Group to assign the unix socket specified by -H when running in daemon mode use '' (the empty string) to disable setting of a group -g, --graph=\"/var/lib/docker\" Path to use as the root of the docker runtime # 容器运行的根目录路径 -H, --host=[] The socket(s) to bind to in daemon mode # daemon 模式下 docker 指定绑定方式[tcp or 本地 socket] specified using one or more tcp://host:port, unix:///path/to/socket, fd://* or fd://socketfd. --icc=true Enable inter-container communication # 跨容器通信 --insecure-registry=[] Enable insecure communication with specified registries (no certificate verification for HTTPS and enable HTTP fallback) (e.g., localhost:5000 or 10.20.0.0/16) --ip=\"0.0.0.0\" Default IP address to use when binding container ports # 指定监听地址，默认所有 ip --ip-forward=true Enable net.ipv4.ip_forward # 开启转发 --ip-masq=true Enable IP masquerading for bridge's IP range --iptables=true Enable Docker's addition of iptables rules # 添加对应 iptables 规则 --mtu=0 Set the containers network MTU # 设置网络 mtu if no value is provided: default to the default route MTU or 1500 if no default route is available -p, --pidfile=\"/var/run/docker.pid\" Path to use for daemon PID file # 指定 pid 文件位置 --registry-mirror=[] Specify a preferred Docker registry mirror -s, --storage-driver=\"\" Force the docker runtime to use a specific storage driver # 强制 docker 运行时使用指定存储驱动 --selinux-enabled=false Enable selinux support # 开启 selinux 支持 --storage-opt=[] Set storage driver options # 设置存储驱动选项 --tls=false Use TLS; implied by tls-verify flags # 开启 tls --tlscacert=\"/root/.docker/ca.pem\" Trust only remotes providing a certificate signed by the CA given here --tlscert=\"/root/.docker/cert.pem\" Path to TLS certificate file # tls 证书文件位置 --tlskey=\"/root/.docker/key.pem\" Path to TLS key file # tls key 文件位置 --tlsverify=false Use TLS and verify the remote (daemon: verify client, client: verify daemon) # 使用 tls 并确认远程控制主机 -v, --version=false Print version information and quit # 输出 docker 版本信息 docker search$ sudo docker search --help Usage: docker search TERM Search the Docker Hub for images # 从 Docker Hub 搜索镜像 --automated=false Only show automated builds --no-trunc=false Don't truncate output -s, --stars=0 Only displays with at least xxx stars 示例： $ sudo docker search -s 100 ubuntu # 查找 star 数至少为 100 的镜像，找出只有官方镜像 start 数超过 100，默认不加 s 选项找出所有相关 ubuntu 镜像 NAME DESCRIPTION STARS OFFICIAL AUTOMATED ubuntu Official Ubuntu base image 425 [OK] docker info$ sudo docker info Containers: 1 # 容器个数 Images: 22 # 镜像个数 Storage Driver: devicemapper # 存储驱动 Pool Name: docker-8:17-3221225728-pool Pool Blocksize: 65.54 kB Data file: /data/docker/devicemapper/devicemapper/data Metadata file: /data/docker/devicemapper/devicemapper/metadata Data Space Used: 1.83 GB Data Space Total: 107.4 GB Metadata Space Used: 2.191 MB Metadata Space Total: 2.147 GB Library Version: 1.02.84-RHEL7 (2014-03-26) Execution Driver: native-0.2 # 存储驱动 Kernel Version: 3.10.0-123.el7.x86_64 Operating System: CentOS Linux 7 (Core) docker pull &amp;&amp; docker push$ sudo docker pull --help # pull 拉取镜像 Usage: docker pull [OPTIONS] NAME[:TAG] Pull an image or a repository from the registry -a, --all-tags=false Download all tagged images in the repository $ sudo docker push # push 推送指定镜像 Usage: docker push NAME[:TAG] Push an image or a repository to the registry 示例： $ sudo docker pull ubuntu # 下载官方 ubuntu docker 镜像，默认下载所有 ubuntu 官方库镜像 $ sudo docker pull ubuntu:14.04 # 下载指定版本 ubuntu 官方镜像 $ sudo docker push 192.168.0.100:5000/ubuntu # 推送镜像库到私有源[可注册 docker 官方账户，推送到官方自有账户] $ sudo docker push 192.168.0.100:5000/ubuntu:14.04 # 推送指定镜像到私有源 docker images列出当前系统镜像$ sudo docker images --help Usage: docker images [OPTIONS] [NAME] List images -a, --all=false Show all images (by default filter out the intermediate image layers) # -a 显示当前系统的所有镜像，包括过渡层镜像，默认 docker images 显示最终镜像，不包括过渡层镜像 -f, --filter=[] Provide filter values (i.e. 'dangling=true') --no-trunc=false Don't truncate output -q, --quiet=false Only show numeric IDs 示例： $ sudo docker images # 显示当前系统镜像，不包括过渡层镜像 $ sudo docker images -a # 显示当前系统所有镜像，包括过渡层镜像 $ sudo docker images ubuntu # 显示当前系统 docker ubuntu 库中的所有镜像 REPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZE ubuntu 12.04 ebe4be4dd427 4 weeks ago 210.6 MB ubuntu 14.04 e54ca5efa2e9 4 weeks ago 276.5 MB ubuntu 14.04-ssh 6334d3ac099a 7 weeks ago 383.2 MB docker rmi删除一个或者多个镜像 $ sudo docker rmi --help Usage: docker rmi IMAGE [IMAGE...] Remove one or more images -f, --force=false Force removal of the image # 强制移除镜像不管是否有容器使用该镜像 --no-prune=false Do not delete untagged parents # 不要删除未标记的父镜像 docker run$ sudo docker run --help Usage: docker run [OPTIONS] IMAGE [COMMAND] [ARG...] Run a command in a new container -a, --attach=[] Attach to stdin, stdout or stderr. -c, --cpu-shares=0 CPU shares (relative weight) # 设置 cpu 使用权重 --cap-add=[] Add Linux capabilities --cap-drop=[] Drop Linux capabilities --cidfile=\"\" Write the container ID to the file # 把容器 id 写入到指定文件 --cpuset=\"\" CPUs in which to allow execution (0-3, 0,1) # cpu 绑定 -d, --detach=false Detached mode: Run container in the background, print new container id # 后台运行容器 --device=[] Add a host device to the container (e.g. --device=/dev/sdc:/dev/xvdc) --dns=[] Set custom dns servers # 设置 dns --dns-search=[] Set custom dns search domains # 设置 dns 域搜索 -e, --env=[] Set environment variables # 定义环境变量 --entrypoint=\"\" Overwrite the default entrypoint of the image # ？ --env-file=[] Read in a line delimited file of ENV variables # 从指定文件读取变量值 --expose=[] Expose a port from the container without publishing it to your host # 指定对外提供服务端口 -h, --hostname=\"\" Container host name # 设置容器主机名 -i, --interactive=false Keep stdin open even if not attached # 保持标准输出开启即使没有 attached --link=[] Add link to another container (name:alias) # 添加链接到另外一个容器 --lxc-conf=[] (lxc exec-driver only) Add custom lxc options --lxc-conf=\"lxc.cgroup.cpuset.cpus = 0,1\" -m, --memory=\"\" Memory limit (format: &lt;number>&lt;optional unit>, where unit = b, k, m or g) # 内存限制 --name=\"\" Assign a name to the container # 设置容器名 --net=\"bridge\" Set the Network mode for the container # 设置容器网络模式 'bridge': creates a new network stack for the container on the docker bridge 'none': no networking for this container 'container:&lt;name|id>': reuses another container network stack 'host': use the host network stack inside the container. Note: the host mode gives the container full access to local system services such as D-bus and is therefore considered insecure. -P, --publish-all=false Publish all exposed ports to the host interfaces # 自动映射容器对外提供服务的端口 -p, --publish=[] Publish a container's port to the host # 指定端口映射 format: ip:hostPort:containerPort | ip::containerPort | hostPort:containerPort (use 'docker port' to see the actual mapping) --privileged=false Give extended privileges to this container # 提供更多的权限给容器 --restart=\"\" Restart policy to apply when a container exits (no, on-failure[:max-retry], always) --rm=false Automatically remove the container when it exits (incompatible with -d) # 如果容器退出自动移除和 -d 选项冲突 --security-opt=[] Security Options --sig-proxy=true Proxify received signals to the process (even in non-tty mode). SIGCHLD is not proxied. -t, --tty=false Allocate a pseudo-tty # 分配伪终端 -u, --user=\"\" Username or UID # 指定运行容器的用户 uid 或者用户名 -v, --volume=[] Bind mount a volume (e.g., from the host: -v /host:/container, from docker: -v /container) # 挂载卷 --volumes-from=[] Mount volumes from the specified container(s) # 从指定容器挂载卷 -w, --workdir=\"\" Working directory inside the container # 指定容器工作目录 示例： $ sudo docker images ubuntu REPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZE ubuntu 14.04 e54ca5efa2e9 4 weeks ago 276.5 MB ... ... $ sudo docker run -t -i -c 100 -m 512MB -h test1 -d --name=\"docker_test1\" ubuntu /bin/bash # 创建一个 cpu 优先级为 100，内存限制 512MB，主机名为 test1，名为 docker_test1 后台运行 bash 的容器 a424ca613c9f2247cd3ede95adfbaf8d28400cbcb1d5f9b69a7b56f97b2b52e5 $ sudo docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES a424ca613c9f ubuntu:14.04 /bin/bash 6 seconds ago Up 5 seconds docker_test1 $ sudo docker attach docker_test1 root@test1:/# pwd / root@test1:/# exit exit 关于cpu优先级 By default all groups have 1024 shares. A group with 100 shares will get a ~10% portion of the CPU time - archlinux cgroups docker start|stop|kill… …docker start CONTAINER [CONTAINER…] # 运行一个或多个停止的容器 docker stop CONTAINER [CONTAINER…] # 停掉一个或多个运行的容器 -t 选项可指定超时时间 docker kill [OPTIONS] CONTAINER [CONTAINER…] # 默认 kill 发送 SIGKILL 信号 -s 可以指定发送 kill 信号类型 docker restart [OPTIONS] CONTAINER [CONTAINER…] # 重启一个或多个运行的容器 -t 选项可指定超时时间 docker pause CONTAINER # 暂停一个容器，方便 commit docker unpause CONTAINER # 继续暂停的容器 docker rm [OPTIONS] CONTAINER [CONTAINER…] # 移除一个或多个容器 -f, –force=false Force removal of running container -l, –link=false Remove the specified link and not the underlying container -v, –volumes=false Remove the volumes associated with the container docker commit [OPTIONS] CONTAINER [REPOSITORY[:TAG]] # 提交指定容器为镜像 -a, –author=”” Author (e.g., “John Hannibal Smith hannibal@a-team.com”) -m, –message=”” Commit message -p, –pause=true Pause container during commit # 默认 commit 是暂停状态 docker inspect CONTAINER|IMAGE [CONTAINER|IMAGE…] # 查看容器或者镜像的详细信息 docker logs CONTAINER # 输出指定容器日志信息 -f, –follow=false Follow log output # 类似 tail -f -t, –timestamps=false Show timestamps –tail=”all” Output the specified number of lines at the end of logs (defaults to all logs) 参考文档：Docker Run Reference Docker 1.3 新增特性和命令Digital Signature VerificationDocker 1.3 版本将使用数字签名自动验证所有官方库的来源和完整性，如果一个官方镜像被篡改或者被破坏，目前 Docker 只会对这种情况发出警告而并不阻止容器的运行。 Inject new processes with docker exec docker exec --help Usage: docker exec [OPTIONS] CONTAINER COMMAND [ARG...] Run a command in an existing container -d, --detach=false Detached mode: run command in the background -i, --interactive=false Keep STDIN open even if not attached -t, --tty=false Allocate a pseudo-TTY 为了简化调试，可以使用 docker exec 命令通过 Docker API 和 CLI 在运行的容器上运行程序。 $ docker exec -it ubuntu_bash bash 上例将在容器 ubuntu_bash 中创建一个新的 Bash 会话。 Tune container lifecycles with docker create 我们可以通过docker run &lt;image name&gt;命令创建一个容器并运行其中的程序，因为有很多用户要求创建容器的时候不启动容器，所以docker create应运而生了。 $ docker create -t -i fedora bash 6d8af538ec541dd581ebc2a24153a28329acb5268abe5ef868c1f1a261221752 上例创建了一个可写的容器层 (并且打印出容器 ID)，但是并不运行它，可以使用以下命令运行该容器： $ docker start -a -i 6d8af538ec5 bash-4.2# Security Options 通过--security-opt选项，运行容器时用户可自定义 SELinux 和 AppArmor 卷标和配置。 $ docker run --security-opt label:type:svirt_apache -i -t centos \\ bash 上例只允许容器监听在 Apache 端口，这个选项的好处是用户不需要运行 docker 的时候指定--privileged选项，降低安全风险。 参考文档：Docker 1.3: signed images, process injection, security options, Mac shared directories Docker 1.5 新特性参考文档：Docker 1.5 新特性 Docker 端口映射# Find IP address of container with ID &lt;container_id> 通过容器 id 获取 ip $ sudo docker inspect &lt;container_id> | grep IPAddress | cut -d ’\"’ -f 4 无论如何，这些 ip 是基于本地系统的并且容器的端口非本地主机是访问不到的。此外，除了端口只能本地访问外，对于容器的另外一个问题是这些 ip 在容器每次启动的时候都会改变。 Docker 解决了容器的这两个问题，并且给容器内部服务的访问提供了一个简单而可靠的方法。Docker 通过端口绑定主机系统的接口，允许非本地客户端访问容器内部运行的服务。为了简便的使得容器间通信，Docker 提供了这种连接机制。 自动映射端口-P使用时需要指定--expose选项，指定需要对外提供服务的端口 $ sudo docker run -t -P --expose 22 --name server ubuntu:14.04 使用docker run -P自动绑定所有对外提供服务的容器端口，映射的端口将会从没有使用的端口池中 (49000..49900) 自动选择，你可以通过docker ps、docker inspect &lt;container_id&gt;或者docker port &lt;container_id&gt; &lt;port&gt;确定具体的绑定信息。 绑定端口到指定接口基本语法$ sudo docker run -p [([&lt;host_interface>:[host_port]])|(&lt;host_port>):]&lt;container_port>[/udp] &lt;image> &lt;cmd> 默认不指定绑定 ip 则监听所有网络接口。 绑定 TCP 端口# Bind TCP port 8080 of the container to TCP port 80 on 127.0.0.1 of the host machine. $ sudo docker run -p 127.0.0.1:80:8080 &lt;image> &lt;cmd> # Bind TCP port 8080 of the container to a dynamically allocated TCP port on 127.0.0.1 of the host machine. $ sudo docker run -p 127.0.0.1::8080 &lt;image> &lt;cmd> # Bind TCP port 8080 of the container to TCP port 80 on all available interfaces of the host machine. $ sudo docker run -p 80:8080 &lt;image> &lt;cmd> # Bind TCP port 8080 of the container to a dynamically allocated TCP port on all available interfaces $ sudo docker run -p 8080 &lt;image> &lt;cmd> 绑定 UDP 端口# Bind UDP port 5353 of the container to UDP port 53 on 127.0.0.1 of the host machine. $ sudo docker run -p 127.0.0.1:53:5353/udp &lt;image> &lt;cmd> Docker 网络配置 Dokcer 通过使用 Linux 桥接提供容器之间的通信，docker0 桥接接口的目的就是方便 Docker 管理。当 Docker daemon 启动时需要做以下操作： creates the docker0 bridge if not present # 如果 docker0 不存在则创建 searches for an IP address range which doesn’t overlap with an existing route # 搜索一个与当前路由不冲突的 ip 段 picks an IP in the selected range # 在确定的范围中选择 ip assigns this IP to the docker0 bridge # 绑定 ip 到 docker0 Docker 四种网络模式四种网络模式摘自Docker 网络详解及 pipework 源码解读与实践 docker run 创建 Docker 容器时，可以用 –net 选项指定容器的网络模式，Docker 有以下 4 种网络模式： host 模式，使用 –net=host 指定。 container 模式，使用 –net=container:NAME_or_ID 指定。 none 模式，使用 –net=none 指定。 bridge 模式，使用 –net=bridge 指定，默认设置。 host 模式 如果启动容器的时候使用 host 模式，那么这个容器将不会获得一个独立的 Network Namespace，而是和宿主机共用一个 Network Namespace。容器将不会虚拟出自己的网卡，配置自己的 IP 等，而是使用宿主机的 IP 和端口。 例如，我们在 10.10.101.105/24 的机器上用 host 模式启动一个含有 web 应用的 Docker 容器，监听 tcp 80 端口。当我们在容器中执行任何类似 ifconfig 命令查看网络环境时，看到的都是宿主机上的信息。而外界访问容器中的应用，则直接使用 10.10.101.105:80 即可，不用任何 NAT 转换，就如直接跑在宿主机中一样。但是，容器的其他方面，如文件系统、进程列表等还是和宿主机隔离的。 container 模式这个模式指定新创建的容器和已经存在的一个容器共享一个 Network Namespace，而不是和宿主机共享。新创建的容器不会创建自己的网卡，配置自己的 IP，而是和一个指定的容器共享 IP、端口范围等。同样，两个容器除了网络方面，其他的如文件系统、进程列表等还是隔离的。两个容器的进程可以通过 lo 网卡设备通信。 none模式这个模式和前两个不同。在这种模式下，Docker 容器拥有自己的 Network Namespace，但是，并不为 Docker容器进行任何网络配置。也就是说，这个 Docker 容器没有网卡、IP、路由等信息。需要我们自己为 Docker 容器添加网卡、配置 IP 等。 bridge模式 bridge 模式是 Docker 默认的网络设置，此模式会为每一个容器分配 Network Namespace、设置 IP 等，并将一个主机上的 Docker 容器连接到一个虚拟网桥上。当 Docker server 启动时，会在主机上创建一个名为 docker0 的虚拟网桥，此主机上启动的 Docker 容器会连接到这个虚拟网桥上。虚拟网桥的工作方式和物理交换机类似，这样主机上的所有容器就通过交换机连在了一个二层网络中。接下来就要为容器分配 IP 了，Docker 会从 RFC1918 所定义的私有 IP 网段中，选择一个和宿主机不同的IP地址和子网分配给 docker0，连接到 docker0 的容器就从这个子网中选择一个未占用的 IP 使用。如一般 Docker 会使用 172.17.0.0/16 这个网段，并将 172.17.42.1/16 分配给 docker0 网桥（在主机上使用 ifconfig 命令是可以看到 docker0 的，可以认为它是网桥的管理接口，在宿主机上作为一块虚拟网卡使用） 列出当前主机网桥$ sudo brctl show # brctl 工具依赖 bridge-utils 软件包 bridge name bridge id STP enabled interfaces docker0 8000.000000000000 no 查看当前 docker0 ip$ sudo ifconfig docker0 docker0 Link encap:Ethernet HWaddr xx:xx:xx:xx:xx:xx inet addr:172.17.42.1 Bcast:0.0.0.0 Mask:255.255.0.0 在容器运行时，每个容器都会分配一个特定的虚拟机口并桥接到 docker0。每个容器都会配置同 docker0 ip 相同网段的专用 ip 地址，docker0 的 IP 地址被用于所有容器的默认网关。 运行一个容器$ sudo docker run -t -i -d ubuntu /bin/bash 52f811c5d3d69edddefc75aff5a4525fc8ba8bcfa1818132f9dc7d4f7c7e78b4 $ sudo brctl show bridge name bridge id STP enabled interfaces docker0 8000.fef213db5a66 no vethQCDY1N 以上, docker0 扮演着 52f811c5d3d6 container 这个容器的虚拟接口 vethQCDY1N interface 桥接的角色。 使用特定范围的 IPDocker 会尝试寻找没有被主机使用的 ip 段，尽管它适用于大多数情况下，但是它不是万能的，有时候我们还是需要对 ip 进一步规划。Docker 允许你管理 docker0 桥接或者通过 -b 选项自定义桥接网卡，需要安装 bridge-utils 软件包。 基本步骤如下： ensure Docker is stopped # 确保 docker 的进程是停止的 create your own bridge (bridge0 for example) # 创建自定义网桥 assign a specific IP to this bridge # 给网桥分配特定的 ip start Docker with the -b=bridge0 parameter # 以 -b 的方式指定网桥 # Stopping Docker and removing docker0 $ sudo service docker stop $ sudo ip link set dev docker0 down $ sudo brctl delbr docker0 # Create our own bridge $ sudo brctl addbr bridge0 $ sudo ip addr add 192.168.5.1/24 dev bridge0 $ sudo ip link set dev bridge0 up # Confirming that our bridge is up and running $ ip addr show bridge0 4: bridge0: &lt;BROADCAST,MULTICAST> mtu 1500 qdisc noop state UP group default link/ether 66:38:d0:0d:76:18 brd ff:ff:ff:ff:ff:ff inet 192.168.5.1/24 scope global bridge0 valid_lft forever preferred_lft forever # Tell Docker about it and restart (on Ubuntu) $ echo 'DOCKER_OPTS=\"-b=bridge0\"' >> /etc/default/docker $ sudo service docker start 参考文档: Network Configuration 不同主机间容器通信不同容器之间的通信可以借助于 pipework 这个工具：$ git clone https://github.com/jpetazzo/pipework.git $ sudo cp -rp pipework/pipework /usr/local/bin/ 安装相应依赖软件$ sudo apt-get install iputils-arping bridge-utils -y 桥接网络桥接网络可以参考日常问题处理 Tips关于桥接的配置说明，这里不再赘述。 # brctl show bridge name bridge id STP enabled interfaces br0 8000.000c291412cd no eth0 docker0 8000.56847afe9799 no vetheb48029 可以删除 docker0，直接把 docker 的桥接指定为 br0。也可以保留使用默认的配置，这样单主机容器之间的通信可以通过 docker0，而跨主机不同容器之间通过 pipework 新建 docker 容器的网卡桥接到 br0，这样跨主机容器之间就可以通信了。 ubuntu $ sudo service docker stop $ sudo ip link set dev docker0 down $ sudo brctl delbr docker0 $ echo 'DOCKER_OPTS=\"-b=br0\"' >> /etc/default/docker $ sudo service docker start CentOS 7/RHEL 7 $ sudo systemctl stop docker $ sudo ip link set dev docker0 down $ sudo brctl delbr docker0 $ cat /etc/sysconfig/docker | grep 'OPTIONS=' OPTIONS=--selinux-enabled -b=br0 -H fd:// $ sudo systemctl start docker pipework 不同容器之间的通信可以借助于 pipework 这个工具给 docker 容器新建虚拟网卡并绑定 IP 桥接到 br0 $ git clone https://github.com/jpetazzo/pipework.git $ sudo cp -rp pipework/pipework /usr/local/bin/ $ pipework Syntax: pipework &lt;hostinterface> [-i containerinterface] &lt;guest> &lt;ipaddr>/&lt;subnet>[@default_gateway] [macaddr][@vlan] pipework &lt;hostinterface> [-i containerinterface] &lt;guest> dhcp [macaddr][@vlan] pipework --wait [-i containerinterface] 如果删除了默认的 docker0 桥接，把 docker 默认桥接指定到了 br0，则最好在创建容器的时候加上 --net=none，防止自动分配的 IP 在局域网中有冲突。 $ sudo docker run --rm -ti --net=none ubuntu:14.04 /bin/bash root@a46657528059:/# $ # Ctrl-P + Ctrl-Q 回到宿主机 shell，容器 detach 状态 $ sudo docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES a46657528059 ubuntu:14.04 \"/bin/bash\" 4 minutes ago Up 4 minutes hungry_lalande $ sudo pipework br0 -i eth0 a46657528059 192.168.115.10/24@192.168.115.2 # 默认不指定网卡设备名，则默认添加为 eth1 # 另外 pipework 不能添加静态路由，如果有需求则可以在 run 的时候加上 --privileged=true 权限在容器中手动添加， # 但这种安全性有缺陷，可以通过 ip netns 操作 $ sudo docker attach a46657528059 root@a46657528059:/# ifconfig eth0 eth0 Link encap:Ethernet HWaddr 86:b6:6b:e8:2e:4d inet addr:192.168.115.10 Bcast:0.0.0.0 Mask:255.255.255.0 inet6 addr: fe80::84b6:6bff:fee8:2e4d/64 Scope:Link UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:8 errors:0 dropped:0 overruns:0 frame:0 TX packets:9 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:648 (648.0 B) TX bytes:690 (690.0 B) root@a46657528059:/# route -n Kernel IP routing table Destination Gateway Genmask Flags Metric Ref Use Iface 0.0.0.0 192.168.115.2 0.0.0.0 UG 0 0 0 eth0 192.168.115.0 0.0.0.0 255.255.255.0 U 0 0 0 eth0 使用ip netns添加静态路由，避免创建容器使用--privileged=true选项造成一些不必要的安全问题： $ docker inspect --format=&quot;{{ .State.Pid }}&quot; a46657528059 # 获取指定容器 pid 6350 $ sudo ln -s /proc/6350/ns/net /var/run/netns/6350 $ sudo ip netns exec 6350 ip route add 192.168.0.0/16 dev eth0 via 192.168.115.2 $ sudo ip netns exec 6350 ip route # 添加成功 192.168.0.0/16 via 192.168.115.2 dev eth0 ... ... 在其它宿主机进行相应的配置，新建容器并使用 pipework 添加虚拟网卡桥接到 br0，测试通信情况即可。 另外，pipework 可以创建容器的 vlan 网络，这里不作过多的介绍了，官方文档已经写的很清楚了，可以查看以下两篇文章： Pipework 官方文档Docker 网络详解及 pipework 源码解读与实践 DockerfileDocker 可以通过 Dockerfile 的内容来自动构建镜像。Dockerfile 是一个包含创建镜像所有命令的文本文件，通过docker build命令可以根据 Dockerfile 的内容构建镜像，在介绍如何构建之前先介绍下 Dockerfile 的基本语法结构。 Dockerfile 有以下指令选项: FROM MAINTAINER RUN CMD EXPOSE ENV ADD COPY ENTRYPOINT VOLUME USER WORKDIR ONBUILD FROM用法: FROM &lt;image> 或者 FROM &lt;image> FROM 指定构建镜像的基础源镜像，如果本地没有指定的镜像，则会自动从 Docker 的公共库 pull 镜像下来。 FROM 必须是 Dockerfile 中非注释行的第一个指令，即一个 Dockerfile 从 FROM 语句开始。 FROM 可以在一个 Dockerfile 中出现多次，如果有需求在一个 Dockerfile 中创建多个镜像。 如果 FROM 语句没有指定镜像标签，则默认使用latest`标签。 MAINTAINER用法: MAINTAINER &lt;name> 指定创建镜像的用户 RUN 有两种使用方式 RUN (the command is run in a shell - /bin/sh -c - shell form) RUN [“executable”, “param1”, “param2”] (exec form) 每条RUN指令将在当前镜像基础上执行指定命令，并提交为新的镜像，后续的RUN都在之前 RUN 提交后的镜像为基础，镜像是分层的，可以通过一个镜像的任何一个历史提交点来创建，类似源码的版本控制。 exec方式会被解析为一个 JSON 数组，所以必须使用双引号而不是单引号。exec 方式不会调用一个命令 shell，所以也就不会继承相应的变量，如： RUN [ \"echo\", \"$HOME\" ] 这种方式是不会达到输出 HOME 变量的，正确的方式应该是这样的 RUN [ \"sh\", \"-c\", \"echo\", \"$HOME\" ] RUN产生的缓存在下一次构建的时候是不会失效的，会被重用，可以使用--no-cache选项，即 docker build --no-cache，如此便不会缓存。 CMDCMD 有三种使用方式: CMD [“executable”,”param1”,”param2”] (exec form, this is the preferred form, 优先选择) CMD [“param1”,”param2”] (as default parameters to ENTRYPOINT) CMD command param1 param2 (shell form) CMD 指定在 Dockerfile 中只能使用一次，如果有多个，则只有最后一个会生效。 CMD 的目的是为了在启动容器时提供一个默认的命令执行选项。如果用户启动容器时指定了运行的命令，则会覆盖掉 CMD 指定的命令。 CMD 会在启动容器的时候执行，build 时不执行，而 RUN 只是在构建镜像的时候执行，后续镜像构建完成之后，启动容器就与 RUN 无关了，这个初学者容易弄混这个概念，这里简单注解一下。 EXPOSEEXPOSE […]告诉 Docker 服务端容器对外映射的本地端口，需要在 docker run 的时候使用 -p 或者 -P 选项生效。 ENVENV &lt;key> &lt;value> # 只能设置一个变量 ENV &lt;key>=&lt;value> ... # 允许一次设置多个变量 指定一个环节变量，会被后续 RUN 指令使用，并在容器运行时保留。 例子: ENV myName=\"John Doe\" myDog=Rex\\ The\\ Dog \\ myCat=fluffy 等同于 ENV myName John Doe ENV myDog Rex The Dog ENV myCat fluffy ADDADD &lt;src>... &lt;dest> ADD复制本地主机文件、目录或者远程文件 URLS 从 并且添加到容器指定路径中 。 支持通过 GO 的正则模糊匹配，具体规则可参见 Go filepath.Match ADD hom* /mydir/ # adds all files starting with \"hom\" ADD hom?.txt /mydir/ # ? is replaced with any single character 路径必须是绝对路径，如果 不存在，会自动创建对应目录 路径必须是 Dockerfile 所在路径的相对路径 如果是一个目录，只会复制目录下的内容，而目录本身则不会被复制 COPYCOPY &lt;src>... &lt;dest> COPY复制新文件或者目录从 添加到容器指定路径中 。用法同ADD，唯一的不同是不能指定远程文件 URLS。 ENTRYPOINT ENTRYPOINT [“executable”, “param1”, “param2”] (the preferred exec form，优先选择) ENTRYPOINT command param1 param2 (shell form) 配置容器启动后执行的命令，并且不可被 docker run 提供的参数覆盖，而CMD是可以被覆盖的。如果需要覆盖，则可以使用docker run --entrypoint选项。 每个 Dockerfile 中只能有一个ENTRYPOINT，当指定多个时，只有最后一个生效。 Exec form ENTRYPOINT 例子 通过ENTRYPOINT使用 exec form 方式设置稳定的默认命令和选项，而使用 CMD 添加默认之外经常被改动的选项。 FROM ubuntu ENTRYPOINT [\"top\", \"-b\"] CMD [\"-c\"] 通过 Dockerfile 使用ENTRYPOINT展示前台运行 Apache 服务 FROM debian:stable RUN apt-get update &amp;&amp; apt-get install -y --force-yes apache2 EXPOSE 80 443 VOLUME [\"/var/www\", \"/var/log/apache2\", \"/etc/apache2\"] ENTRYPOINT [\"/usr/sbin/apache2ctl\", \"-D\", \"FOREGROUND\"] Shell form ENTRYPOINT 例子这种方式会在/bin/sh -c中执行，会忽略任何CMD或者docker run命令行选项，为了确保docker stop能够停止长时间运行ENTRYPOINT的容器，确保执行的时候使用exec选项。 FROM ubuntu ENTRYPOINT exec top -b 如果在ENTRYPOINT忘记使用exec选项，则可以使用CMD补上: FROM ubuntu ENTRYPOINT top -b CMD --ignored-param1 # --ignored-param2 ... --ignored-param3 ... 依此类推 VOLUMEVOLUME [\"/data\"] 创建一个可以从本地主机或其他容器挂载的挂载点，后续具体介绍。 USERUSER daemon 指定运行容器时的用户名或UID，后续的RUN、CMD、ENTRYPOINT也会使用指定用户。 WORKDIRWORKDIR /path/to/workdir 为后续的RUN、CMD、ENTRYPOINT指令配置工作目录。可以使用多个WORKDIR指令，后续命令如果参数是相对路径，则会基于之前命令指定的路径。 WORKDIR /a WORKDIR b WORKDIR c RUN pwd 最终路径是/a/b/c。 WORKDIR指令可以在ENV设置变量之后调用环境变量: ENV DIRPATH /path WORKDIR $DIRPATH/$DIRNAME 最终路径则为 /path/$DIRNAME。 ONBUILDONBUILD [INSTRUCTION] 配置当所创建的镜像作为其它新创建镜像的基础镜像时，所执行的操作指令。 例如，Dockerfile 使用如下的内容创建了镜像 image-A： [...] ONBUILD ADD . /app/src ONBUILD RUN /usr/local/bin/python-build --dir /app/src [...] 如果基于 image-A 创建新的镜像时，新的 Dockerfile 中使用 FROM image-A 指定基础镜像时，会自动执行 ONBUILD 指令内容，等价于在后面添加了两条指令。 # Automatically run the following ADD . /app/src RUN /usr/local/bin/python-build --dir /app/src 使用ONBUILD指令的镜像，推荐在标签中注明，例如 ruby:1.9-onbuild。 Dockerfile Examples# Nginx # # VERSION 0.0.1 FROM ubuntu MAINTAINER Victor Vieux &lt;victor@docker.com> RUN apt-get update &amp;&amp; apt-get install -y inotify-tools nginx apache2 openssh-server # Firefox over VNC # # VERSION 0.3 FROM ubuntu # Install vnc, xvfb in order to create a 'fake' display and firefox RUN apt-get update &amp;&amp; apt-get install -y x11vnc xvfb firefox RUN mkdir ~/.vnc # Setup a password RUN x11vnc -storepasswd 1234 ~/.vnc/passwd # Autostart firefox (might not be the best way, but it does the trick) RUN bash -c 'echo \"firefox\" >> /.bashrc' EXPOSE 5900 CMD [\"x11vnc\", \"-forever\", \"-usepw\", \"-create\"] # Multiple images example # # VERSION 0.1 FROM ubuntu RUN echo foo > bar # Will output something like ===> 907ad6c2736f FROM ubuntu RUN echo moo > oink # Will output something like ===> 695d7793cbe4 # You᾿ll now have two images, 907ad6c2736f with /bar, and 695d7793cbe4 with # /oink. docker build$ docker build --help Usage: docker build [OPTIONS] PATH | URL | - Build a new image from the source code at PATH --force-rm=false Always remove intermediate containers, even after unsuccessful builds # 移除过渡容器，即使构建失败 --no-cache=false Do not use cache when building the image # 不实用 cache -q, --quiet=false Suppress the verbose output generated by the containers --rm=true Remove intermediate containers after a successful build # 构建成功后移除过渡层容器 -t, --tag=\"\" Repository name (and optionally a tag) to be applied to the resulting image in case of success 参考文档:Dockerfile Reference dockerfile 最佳实践使用.dockerignore文件为了在docker build过程中更快上传和更加高效，应该使用一个.dockerignore文件用来排除构建镜像时不需要的文件或目录。例如,除非.git在构建过程中需要用到，否则你应该将它添加到.dockerignore文件中，这样可以节省很多时间。 避免安装不必要的软件包为了降低复杂性、依赖性、文件大小以及构建时间，应该避免安装额外的或不必要的包。例如，不需要在一个数据库镜像中安装一个文本编辑器。 每个容器都跑一个进程在大多数情况下，一个容器应该只单独跑一个程序。解耦应用到多个容器使其更容易横向扩展和重用。如果一个服务依赖另外一个服务，可以参考 Linking Containers Together。 最小化层我们知道每执行一个指令，都会有一次镜像的提交，镜像是分层的结构，对于Dockerfile，应该找到可读性和最小化层之间的平衡。 多行参数排序如果可能，通过字母顺序来排序，这样可以避免安装包的重复并且更容易更新列表，另外可读性也会更强，添加一个空行使用 \\ 换行: RUN apt-get update &amp;&amp; apt-get install -y \\ bzr \\ cvs \\ git \\ mercurial \\ subversion 创建缓存镜像构建过程中会按照Dockerfile的顺序依次执行，每执行一次指令 Docker 会寻找是否有存在的镜像缓存可复用，如果没有则创建新的镜像。如果不想使用缓存，则可以在docker build时添加--no-cache=true选项。 从基础镜像开始就已经在缓存中了，下一个指令会对比所有的子镜像寻找是否执行相同的指令，如果没有则缓存失效。在大多数情况下只对比Dockerfile指令和子镜像就足够了。ADD和COPY指令除外，执行ADD和COPY时存放到镜像的文件也是需要检查的，完成一个文件的校验之后再利用这个校验在缓存中查找，如果检测的文件改变则缓存失效。RUN apt-get -y update命令只检查命令是否匹配，如果匹配就不会再执行更新了。 为了有效地利用缓存，你需要保持你的 Dockerfile 一致，并且尽量在末尾修改。 Dockerfile 指令 FROM: 只要可能就使用官方镜像库作为基础镜像 RUN: 为保持可读性、方便理解、可维护性，把长或者复杂的 RUN 语句使用 \\ 分隔符分成多行 不建议RUN apt-get update独立成行，否则如果后续包有更新，那么也不会再执行更新 避免使用RUN apt-get upgrade或者dist-upgrade，很多必要的包在一个非 privileged 权限的容器里是无法升级的。如果知道某个包更新，使用apt-get install -y xxx 标准写法 RUN apt-get update &amp;&amp; apt-get install -y package-bar package-foo 例子: RUN apt-get update &amp;&amp; apt-get install -y \\ aufs-tools \\ automake \\ btrfs-tools \\ build-essential \\ curl \\ dpkg-sig \\ git \\ iptables \\ libapparmor-dev \\ libcap-dev \\ libsqlite3-dev \\ lxc=1.0* \\ mercurial \\ parallel \\ reprepro \\ ruby1.9.1 \\ ruby1.9.1-dev \\ s3cmd=1.1.0* CMD: 推荐使用CMD [“executable”, “param1”, “param2”…]这种格式，CMD [“param”, “param”]则配合ENTRYPOINT使用EXPOSE: Dockerfile 指定要公开的端口，使用 docker run 时指定映射到宿主机的端口即可ENV: 为了使新的软件更容易运行，可以使用 ENV 更新 PATH 变量。如ENV PATH /usr/local/nginx/bin:$PATH确保CMD [&quot;nginx&quot;]即可运行ENV 也可以这样定义变量： ENV PG_MAJOR 9.3 ENV PG_VERSION 9.3.4 RUN curl -SL http://example.com/postgres-$PG_VERSION.tar.xz | tar -xJC /usr/src/postgress &amp;&amp; … ENV PATH /usr/local/postgres-$PG_MAJOR/bin:$PATH ADD or COPY: ADD比COPY多一些特性「tar 文件自动解包和支持远程 URL」，不推荐添加远程 URL 如不推荐这种方式: ADD http://example.com/big.tar.xz /usr/src/things/ RUN tar -xJf /usr/src/things/big.tar.xz -C /usr/src/things RUN make -C /usr/src/things all 推荐使用 curl 或者 wget 替换，使用如下方式: RUN mkdir -p /usr/src/things \\ &amp;&amp; curl -SL http://example.com/big.tar.gz \\ | tar -xJC /usr/src/things \\ &amp;&amp; make -C /usr/src/things all 如果不需要添加 tar 文件，推荐使用COPY。 参考文档: Best practices for writing Dockerfiles Dockerfile最佳实践（一） Dockerfile最佳实践（二） 容器数据管理docker管理数据的方式有两种： 数据卷 数据卷容器 数据卷数据卷是一个或多个容器专门指定绕过Union File System的目录，为持续性或共享数据提供一些有用的功能： 数据卷可以在容器间共享和重用 数据卷数据改变是直接修改的 数据卷数据改变不会被包括在容器中 数据卷是持续性的，直到没有容器使用它们 添加一个数据卷 你可以使用 -v 选项添加一个数据卷，或者可以使用多次 -v 选项为一个 docker 容器运行挂载多个数据卷。 $ sudo docker run --name data -v /data -t -i ubuntu:14.04 /bin/bash # 创建数据卷绑定到到新建容器，新建容器中会创建 /data 数据卷 bash-4.1# ls -ld /data/ drwxr-xr-x 2 root root 4096 Jul 23 06:59 /data/ bash-4.1# df -Th Filesystem Type Size Used Avail Use% Mounted on ... ... ext4 91G 4.6G 82G 6% /data 创建的数据卷可以通过docker inspect获取宿主机对应路径 $ sudo docker inspect data ... ... \"Volumes\": { \"/data\": \"/var/lib/docker/vfs/dir/151de401d268226f96d824fdf444e77a4500aed74c495de5980c807a2ffb7ea9\" }, # 可以看到创建的数据卷宿主机路径 ... ... 或者直接指定获取 $ sudo docker inspect --format=\"{{ .Volumes }}\" data map[/data: /var/lib/docker/vfs/dir/151de401d268226f96d824fdf444e77a4500aed74c495de5980c807a2ffb7ea9] 挂载宿主机目录为一个数据卷 -v选项除了可以创建卷，也可以挂载当前主机的一个目录到容器中。 $ sudo docker run --name web -v /source/:/web -t -i ubuntu:14.04 /bin/bash bash-4.1# ls -ld /web/ drwxr-xr-x 2 root root 4096 Jul 23 06:59 /web/ bash-4.1# df -Th ... ... ext4 91G 4.6G 82G 6% /web bash-4.1# exit 默认挂载卷是可读写的，可以在挂载时指定只读 $ sudo docker run --rm --name test -v /source/:/test:ro -t -i ubuntu:14.04 /bin/bash 创建和挂载一个数据卷容器如果你有一些持久性的数据并且想在容器间共享，或者想用在非持久性的容器上，最好的方法是创建一个数据卷容器，然后从此容器上挂载数据。 创建数据卷容器 $ sudo docker run -t -i -d -v /test --name test ubuntu:14.04 echo hello 使用--volumes-from选项在另一个容器中挂载 /test 卷。不管 test 容器是否运行，其它容器都可以挂载该容器数据卷，当然如果只是单独的数据卷是没必要运行容器的。 $ sudo docker run -t -i -d --volumes-from test --name test1 ubuntu:14.04 /bin/bash 添加另一个容器 $ sudo docker run -t -i -d --volumes-from test --name test2 ubuntu:14.04 /bin/bash 也可以继承其它挂载有 /test 卷的容器 $ sudo docker run -t -i -d --volumes-from test1 --name test3 ubuntu:14.04 /bin/bash 备份、恢复或迁移数据卷备份$ sudo docker run --rm --volumes-from test -v $(pwd):/backup ubuntu:14.04 tar cvf /backup/test.tar /test tar: Removing leading `/' from member names /test/ /test/b /test/d /test/c /test/a 启动一个新的容器并且从test容器中挂载卷，然后挂载当前目录到容器中为 backup，并备份test卷中所有的数据为test.tar，执行完成之后删除容器--rm，此时备份就在当前的目录下，名为 test.tar。 $ ls # 宿主机当前目录下产生了 test 卷的备份文件 test.tar test.tar 恢复你可以恢复给同一个容器或者另外的容器，新建容器并解压备份文件到新的容器数据卷 $ sudo docker run -t -i -d -v /test --name test4 ubuntu:14.04 /bin/bash $ sudo docker run --rm --volumes-from test4 -v $(pwd):/backup ubuntu:14.04 tar xvf /backup/test.tar -C / # 恢复之前的文件到新建卷中，执行完后自动删除容器 test/ test/b test/d test/c test/a 删除 VolumesVolume 只有在下列情况下才能被删除： docker rm -v删除容器时添加了-v选项 docker run --rm运行容器时添加了--rm选项否则，会在/var/lib/docker/vfs/dir目录中遗留很多不明目录。 参考文档： Managing Data in Containers深入理解Docker Volume（一）深入理解Docker Volume（二） 链接容器docker 允许把多个容器连接在一起，相互交互信息。docker 链接会创建一种容器父子级别的关系，其中父容器可以看到其子容器提供的信息。 容器命名在创建容器时，如果不指定容器的名字，则默认会自动创建一个名字，这里推荐给容器命名： 1、给容器命名方便记忆，如命名运行 web 应用的容器为 web 2、为 docker 容器提供一个参考，允许方便其他容器调用，如把容器 web 链接到容器 db 可以通过--name选项给容器自定义命名： $ sudo docker run -d -t -i --name test ubuntu:14.04 bash $ sudo docker inspect --format=\"{{ .Nmae }}\" test /test 注：容器名称必须唯一，即你只能命名一个叫test的容器。如果你想复用容器名，则必须在创建新的容器前通过docker rm删除旧的容器或者创建容器时添加--rm选项。 链接容器链接允许容器间安全通信，使用 –link 选项创建链接。 $ sudo docker run -d --name db training/postgres 基于 training/postgres 镜像创建一个名为 db 的容器，然后下面创建一个叫做 web 的容器，并且将它与 db 相互连接在一起 $ sudo docker run -d -P --name web --link db:db training/webapp python app.py --link &lt;name or id&gt;:alias选项指定链接到的容器。 查看 web 容器的链接关系: $ sudo docker inspect -f \"{{ .HostConfig.Links }}\" web [/db:/web/db] 可以看到 web 容器被链接到 db 容器为/web/db，这允许 web 容器访问 db 容器的信息。 容器之间的链接实际做了什么？一个链接允许一个源容器提供信息访问给一个接收容器。在本例中，web 容器作为一个接收者，允许访问源容器 db 的相关服务信息。Docker 创建了一个安全隧道而不需要对外公开任何端口给外部容器，因此不需要在创建容器的时候添加-p或-P指定对外公开的端口，这也是链接容器的最大好处，本例为 PostgreSQL 数据库。 Docker 主要通过以下两个方式提供连接信息给接收容器： 环境变量 更新/etc/hosts文件 环境变量当两个容器链接，Docker 会在目标容器上设置一些环境变量，以获取源容器的相关信息。 首先，Docker 会在每个通过--link选项指定别名的目标容器上设置一个&lt;alias&gt;_NAME环境变量。如果一个名为 web 的容器通过--link db:webdb被链接到一个名为 db 的数据库容器，那么 web 容器上会设置一个环境变量为WEBDB_NAME=/web/webdb. 以之前的为例，Docker 还会设置端口变量: $ sudo docker run --rm --name web2 --link db:db training/webapp env . . . DB_NAME=/web2/db DB_PORT=tcp://172.17.0.5:5432 DB_PORT_5432_TCP=tcp://172.17.0.5:5432 # &lt;name>_PORT_&lt;port>_&lt;protocol> 协议可以是 TCP 或 UDP DB_PORT_5432_TCP_PROTO=tcp DB_PORT_5432_TCP_PORT=5432 DB_PORT_5432_TCP_ADDR=172.17.0.5 . . . 注：这些环境变量只设置给容器中的第一个进程，类似一些守护进程 (如 sshd ) 当他们派生 shells 时会清除这些变量 更新/etc/hosts文件 除了环境变量，Docker 会在目标容器上添加相关主机条目到/etc/hosts中，上例中就是 web 容器。 $ sudo docker run -t -i --rm --link db:db training/webapp /bin/bash root@aed84ee21bde:/opt/webapp# cat /etc/hosts 172.17.0.7 aed84ee21bde . . . 172.17.0.5 db /etc/host文件在源容器被重启之后会自动更新 IP 地址，而环境变量中的 IP 地址则不会自动更新的。 构建私有库Docker 官方提供了 docker registry 的构建方法docker-registry 快速构建快速构建 docker registry 通过以下两步: 安装 docker 运行 registry: docker run -p 5000:5000 registry 这种方法通过 Docker hub 使用官方镜像 official image from the Docker hub 不使用容器构建 registry安装必要的软件 $ sudo apt-get install build-essential python-dev libevent-dev python-pip liblzma-dev 配置 docker-registry sudo pip install docker-registry 或者 使用 github clone 手动安装 $ git clone https://github.com/dotcloud/docker-registry.git $ cd docker-registry/ $ cp config/config_sample.yml config/config.yml $ mkdir /data/registry -p $ pip install . 运行 docker-registry 高级启动方式 「不推荐」使用gunicorn控制: gunicorn -c contrib/gunicorn_config.py docker_registry.wsgi:application 或者对外监听开放 gunicorn --access-logfile - --error-logfile - -k gevent -b 0.0.0.0:5000 -w 4 --max-requests 100 docker_registry.wsgi:application 提交指定容器到私有库$ docker tag ubuntu:12.04 私有库IP:5000/ubuntu:12.04 $ docker push 私有库IP:5000/ubuntu 更多的配置选项推荐阅读官方文档: Docker-Registry README Docker-Registry advanced use","tags":[{"name":"Docker","slug":"Docker","permalink":"http://www.jifu.io/tags/Docker/"},{"name":"笔记","slug":"笔记","permalink":"http://www.jifu.io/tags/笔记/"}],"categories":[{"name":"OPS","slug":"OPS","permalink":"http://www.jifu.io/categories/OPS/"},{"name":"Docker","slug":"OPS/Docker","permalink":"http://www.jifu.io/categories/OPS/Docker/"}]},{"title":"Xcode开发中Build与version区别/build自增设置/build随时间变化？","date":"2019-04-01T11:38:28.000Z","path":"posts/1098789015/","text":"摘要xcode开发中，version和build可能总是让大家迷惑。其实version平时大家叫做发布版本号，build叫做编译版本号。 发布相关发布app到AppStore时候version相同时候，build相同提交构建版本失败，version相同时候，build不相同提交构建版本成功 列表 名称 解释 Version 发布版本号 Build 编译版本号 装逼技能：build的自增？跟随时间变化？ 步骤 Xcode ——&gt; target——&gt;general ———&gt; Build Phases——&gt; “+”——&gt;Run scripe——&gt;复制代码 代码跟随时间变化（release和Debug不同情况）#!/bin/bash // 判断是哪个configuration // Release Debug 或者只自定义的配置 if [ \"Release\" != \"${CONFIGURATION}\" ] // 如果是Release做哪些事情 then // 如果不是Release做哪些事情 // exit 0 退出 不执行下面的代码 fi // 获取info.plist信息 CFBundleVersion 可以更改为想获取的信息的名字 buildNumber=$(/usr/libexec/PlistBuddy -c \"Print :CFBundleVersion\" \"${PROJECT_DIR}/${INFOPLIST_FILE}\") shortVersion=$(/usr/libexec/PlistBuddy -c \"Print :CFBundleShortVersionString\" \"${PROJECT_DIR}/${INFOPLIST_FILE}\") buildNumber=`date +\"%m%d\"` buildNumber=\"$shortVersion.$buildNumber\" // 设置info.plist /usr/libexec/PlistBuddy -c \"Set :CFBundleVersion $buildNumber\" \"${PROJECT_DIR}/${INFOPLIST_FILE}\" 跟随时间变化#!/bin/bash buildNumber=$(date +%Y%m%d%H%M%S) /usr/libexec/PlistBuddy -c \"Set :CFBundleVersion $buildNumber\" \"$INFOPLIST_FILE\" 自动加1#!/bin/bash buildNumber=$(/usr/libexec/PlistBuddy -c \"Print CFBundleVersion\" \"$INFOPLIST_FILE\") buildNumber=$(($buildNumber + 1)) /usr/libexec/PlistBuddy -c \"Set :CFBundleVersion $buildNumber\" \"$INFOPLIST_FILE\" 修改项目显示名称为版本号 (适用于不同版本号装到一个机器里面，便于区分是哪个版本） #/bin/bash if [ \"Release\" != \"${CONFIGURATION}\" ]; then DisplayName=$(/usr/libexec/PlistBuddy -c \"Print CFBundleShortVersionString\" \"$INFOPLIST_FILE\") DisplayName=\"ep${DisplayName}-I\" /usr/libexec/PlistBuddy -c \"Set :CFBundleDisplayName $DisplayName\" \"$INFOPLIST_FILE\" else DisplayName=\"真正的项目名称\" /usr/libexec/PlistBuddy -c \"Set :CFBundleDisplayName $DisplayName\" \"$INFOPLIST_FILE\" fi build与version的区别区别1首先，Version是显示对外的版本号，（itunesconect和Appstore用户可以看到），对应O-C中获取version的值：[[[NSBundle mainBundle]infoDictionary]valueForKey:@&quot;CFBundleShortVersionString&quot;]；该版本的版本号是三个分隔的整数组成的字符串。第一个整数代表重大修改的版本，如实现新的功能或重大变化的修订。第二个整数表示的修订，实现较突出的特点。第三个整数代表维护版本例如：1.0.12或者 1.2.3等等 区别2build别人看不到，只有开发者自己才能看到，相当于内部版本号。【更新版本的时候，也要高于之前的build号】 对应获取方式：[[[NSBundle mainBundle]infoDictionary]valueForKey:@&quot;CFBundleVersion&quot;]；标示（发布或者未发布）的内部版本号。这是一个单调增加的字符串，包括一个或者多个分割的整数。 区别3附加解释InfoDictionary version CFBundleInfoDictionaryVersion Info.plist格式的版本信息，一般这个值不改动； 总结VersionBundle versions string, short：用于iTunes上显示的版本号，即对外的版本。（最多是3个部分组成即 x.y.z）。 buildBundle version： 内部项目管理的版本号，不对外。所以,可以定义任意形式一般要检查版本更新，要用到的是Version，而不是用build； 参考资料 -Xcode进行iOS开发中Build与version区别?build自增设置？build随时间变化？","tags":[{"name":"Xcode","slug":"Xcode","permalink":"http://www.jifu.io/tags/Xcode/"},{"name":"版本号","slug":"版本号","permalink":"http://www.jifu.io/tags/版本号/"},{"name":"自增长","slug":"自增长","permalink":"http://www.jifu.io/tags/自增长/"}],"categories":[{"name":"iOS Development","slug":"iOS-Development","permalink":"http://www.jifu.io/categories/iOS-Development/"}]},{"title":"PS快捷键使用指南","date":"2019-04-01T10:57:35.000Z","path":"posts/1907494021/","text":"Ctrl+T：自由变形该快捷键，主要对图层进行旋转、缩放等变形调整，同时可以拖动修改图层在画面中的位置，是极为常用的功能键。 左上为Mac快捷键，右上为PC快捷键 Ctrl+J：复制图层对图层的复制，一般的操作是通过图层菜单栏选择，或者直接在图层面板上右键单击图层的下拉菜单中选择，而“Ctrl+J”的快捷键不仅能复制图层，还能高光层、阴影层，在修图、调色、合成等设计工作中都是很常用的功能。 数字键：图层不透明度变化在图层面板中，选中图层后，直接按数字键即可修改该图层的不透明度，1即10%，以此类推，0是100% 空格键+F：更改工作区颜色工作区即画布所在的地方，就是PS软件中最大的那块区域，通过改快捷键可以更改工作区的颜色，四种不同灰度的颜色，从死黑到浅黑到灰到亮灰，任君选择。 F：更改屏幕显示模式即让PS在标准屏幕模式、带有菜单栏的全屏模式和全屏模式间切换，一般常用于欣赏作品、检查设计效果等工作环境中。 TAB：工作区窗口显示/隐藏主要作用是，让工作区全屏，只保留菜单栏，隐藏工具栏和各种面板窗口，以最大的工作区显示，以便有更大的视域来观察、设计等。 Ctrl+Shift+Alt+E：盖印图层盖印图层，简单说就是将当前所有图层（及效果）合并，且生成一个全新的图层，打个比喻来说，这是一种“无损合成图层”，并不会破坏之前的任何图层，方便我们在设计中“反悔”去修改，而又能满足进一步修饰、设计的目的，实乃PS操练中必备之大法。 Ctrl+Alt+A：选中所有图层顾名思义，按下该快捷键可以让我们迅速选中所有图层，免去键盘（ctrl /shift）+鼠标点击来选中图层的麻烦。需要注意的是，当文档中存在背景图层时，按下此快捷键则不会选中背景图层，只会选中除它之外的所有图层。 Ctrl+G：图层编组从数学中的合并同类项，到文件夹管理中的新建文件夹，来把具有某种联系的内容放到一起，都体现着我们追求整洁、有序的好习惯，那么在PS中，图层面板中的图层多起来的时候，合适的编组将是一个灰常好而且相当必要的习惯，这时候快捷键Ctrl+G就大显神威了，选中要编组的图层，然后按快捷键即可编组。 D：复位颜色PS默认的前景色和背景色为黑色、白色，而当我们做了一段时间的设计后，难免会遇到颜色已经不再是黑白，而又想用到黑白的时候，这个时候，只要按下键盘快捷键D即可恢复默认状态了。PS：所有涉及字母键的快捷键都要在英文输入状态下使用。 X：切换前景色和背景色字母X键的作用，一是前景色和背景色的互换，一是在蒙版状态下，切换黑白画笔。 Ctrl+I：反相选中图片图层的情况下，按下该快捷键的作用是得到该图片的负片效果。 空格键+鼠标左键：移动画布画布，也就是我们在进行设计的图片，有时候1:1比例观看时，很可能大得会超过了工作区，而有些地方看不到，这个时候就需要移动它了，只需按住空格键，然后左键单击移动即可。PS：当我们用选框工具画出一个选区时，按下空格键，移动鼠标则可以移动选区。 Ctrl+D：取消选区一生二，二生三，三生万物，反之亦反，So，有创建选区的，就会有取消选区的需求，只需按下该快捷键，蚂蚁线就消失了，选区不见了。 Shift+Alt+M：切换成“正片叠底”模式当在使用画笔工具或者污点修复画笔工具类时，按此快捷键，可以把当前的绘画模式从默认的“正常”切换到“正片叠底”模式。 Shift+Alt+S：滤色模式还是在使用画笔类工具的时候，按下该快捷键，可以将绘画模式一秒切换到“滤色模式”。 Shift+Alt+O：叠加模式依然是画笔类工具被选择状态下，按下该快捷键可以把绘画模式一秒切换成“叠加模式”。 Shift+Alt+F：柔光模式依然是画笔类工具被选择状态下，按下该快捷键可以把绘画模式一秒切换成“柔光模式”。 Shift+Alt+Y：明度模式依然是画笔类工具被选择状态下，按下该快捷键可以把绘画模式一秒切换成“明度模式”。 Shift+Alt+W：线性减淡（添加）模式依然是画笔类工具被选择状态下，按下该快捷键可以把绘画模式一秒切换成“线性减淡（添加）模式”。 Shift+Alt+C：颜色模式依然是画笔类工具被选择状态下，按下该快捷键可以把绘画模式一秒切换成“颜色模式”。 Alt+，：选中“背景图层”有时候我们的文件中，图层已经相当得多了，想要选中最下面的“背景图层”都要鼠标滚轮滑动好久，很累的嘛，所以快捷键“Alt+，”就非常有用了，瞬间选中“背景图层”。 Ctrl+R：显示标尺所谓“无规矩不成方圆，无准绳难知平直”嘛，在工作时“标尺”的存在还是很实用的，而它显示/隐藏的快捷键则是“Ctrl+R”。 Ctrl+Shift+Alt+N：创建新图层按下该组合快捷键，则会在当前选中图层上方直接创建一个新的透明图层。 Ctrl+删除键：填充背景色厉害这个，直接为选中的图层/对象填充背景色，一秒上色，棒棒哒。 Alt+删除键：填充前景色有填充背景色，自然也要有填充前景色的喽，就是这个，阿随君用这个比上一个还多。 Ctrl+F：重复执行滤镜这个快捷键的作用有点类似于word中的“格式刷”，就是再次执行上一次使用的滤镜，比如对图层1刚刚做了高斯模糊，如果此时选中图层2，按快捷键Ctrl+F，则图层2就同样被高斯模糊了。当然，也可以反复对同一个图层Ctrl+F。 Ctrl+0：缩放至工作区在各种缩放操作中，快捷键Ctrl+0的作用是把当前画布/图片缩放到适配工作区，即图片铺满了整个工作区。 Ctrl+1：缩放至100%即是把画布或是图片按照它的真实尺寸1:1的在PS中显示，如果是很大的图，那么无疑将超过工作区面积，一眼已经无法看全整张图。PS：也可以直接Ctrl++或者Ctrl+-来缩放。 Ctrl+Tab：文档切换这组快捷键是针对多PSD文件同时打开，同时工作的情况时，按下Ctrl+Tab则会在PSD文件之间切换。 Shift+Alt+鼠标左键：设置前景色在画笔或者油漆桶工具被选择的情况下，按此快捷键则会激活一个调色板出现，鼠标的移动则会直接设置好前景色。 Shift+Alt+N：正常模式当画笔工具处在正片叠底的绘画模式时，按下此快捷键则可以一秒让绘画模式回归“正常模式”。 好了，以上是总结的32场演唱会了，啊，不，是32个快捷键。当然啦，好用的快捷键也不止这些了，比如说轻松制作“画中画”德罗斯特效应的“Ctrl+Shift+Alt+T”，比如说按住Alt键同时滚动鼠标滑轮来缩放画布，比如说按住Ctrl键同时滚动鼠标滑轮可以左右移动画布等等，不一而足，而要想快捷键发挥最佳作用，最好的方法莫过于多用多练多总结，正所谓功夫虽好，唯手熟尔。 参考资料 -唯快不破！可能是最全面的PS快捷键使用指南（图文演示）","tags":[{"name":"PS","slug":"PS","permalink":"http://www.jifu.io/tags/PS/"},{"name":"Cheat Sheets","slug":"Cheat-Sheets","permalink":"http://www.jifu.io/tags/Cheat-Sheets/"},{"name":"快捷键","slug":"快捷键","permalink":"http://www.jifu.io/tags/快捷键/"}],"categories":[{"name":"Design","slug":"Design","permalink":"http://www.jifu.io/categories/Design/"}]},{"title":"MacBook十年进化史","date":"2019-04-01T10:41:04.000Z","path":"posts/3904818761/","text":"参考资料 -一图流 | hello again！MacBook 十年进化史","tags":[{"name":"hardware","slug":"hardware","permalink":"http://www.jifu.io/tags/hardware/"},{"name":"Macbook","slug":"Macbook","permalink":"http://www.jifu.io/tags/Macbook/"}],"categories":[{"name":"Hardware","slug":"Hardware","permalink":"http://www.jifu.io/categories/Hardware/"}]},{"title":"Redis Stream应用案例","date":"2019-04-01T03:20:21.000Z","path":"posts/156114019/","text":"摘要Redis最新的大版本5.0已经RC1了，其中最重要的Feature莫过于Redis Stream了，关于Redis Stream的基本使用介绍和设计理念可以看我之前的一篇文章（Redis Stream简介）。 Redis StreamRedis最新的大版本5.0已经RC1了，其中最重要的Feature莫过于Redis Stream了，关于Redis Stream的基本使用介绍和设计理念可以看我之前的一篇文章（Redis Stream简介）。Redis Stream本质上是在Redis内核上（非Redis Module）实现的一个消息发布订阅功能组件。相比于现有的PUB/SUB、BLOCKED LIST，其虽然也可以在简单的场景下作为消息队列来使用，但是Redis Stream无疑要完善很多。Redis Stream提供了消息的持久化和主备复制功能、新的RadixTree数据结构来支持更高效的内存使用和消息读取、甚至是类似于Kafka的Consumer Group功能。今天我们重点关注怎么在实际业务场景下去使用Redis Stream。 Redis Stream实战——IRC系统相信大家对IRC都比较了解了（还记得被和谐掉的xx聊天室吗:-)），很多知名的开源项目（包括Redis）都有自己的IRC频道，方便开发者和使用者实时的进行思想火花的碰撞，我们今天介绍的主角——Redis Stream，本身就是起源于IRC中一个用户的idea。IRC的模型如下， 在某个IRC频道中的用户，既可以向所有的其他用户自由的发送消息，也可以接收其他所有用户发送的消息。如果要基于Redis来构建一个IRC系统，那我们不由自主的会想到使用Redis的PUB/SUB功能， 可以看到，基于PUB/SUB，只需要所有的用户(client)都订阅(subscribe)同一个IRC频道(channel1)，就可以接收所有用户发出的消息了。发出消息时，只需使用发布命令(publish)命令即可。整个业务逻辑非常的清晰简单，这也是Redis强大和流行的重要原因——提供的功能和数据结构能尽可能提升开发者的开发效率。 但是基于PUB/SUB构建的IRC，有一个问题是PUB/SUB的消息模型是Fire and Forgot。也就是说Redis本身并不保存任何历史消息，如果IRC中某个用户的网络连接出现异常，重新加入IRC后，他是看不到断链期间的聊天记录的，新加入的用户同样也看不到最近一段时间的历史记录，这个对用户迅速的理解当前讨论的问题非常不便。此外，如果Redis发生了重启，所有的用户也需要重新订阅频道。 那如果基于Redis Stream来构建IRC呢？ 创建频道# 目前Redis还不支持创建空的stream，所以我们可以添加一个特殊消息, # 来创建一个新的stream(频道) ip:7000> xadd channel1 * create-channel null 1528702126345-0 发送消息# 发送一条消息，只需要使用xadd命令即可，我们可以给每条消息命名，顺便带上消息来源，方便业务逻辑处理。 # 我们也可以一次发送多条消息，可以作为优化网络开销的一种手段。 ip:7000> xadd channel1 * msg1-tony \"Hello everyone.\" 1528702503377-0 ip:7000> xadd channel1 * msg2-tony \"I am a big Redis fan.\" msg3-tony \"Hope we can learn from each other.:-)\" 1528702573546-0 接收消息# 新用户初次加入频道时，指定'$'作为一个特殊起始ID读取消息，表示只接收最新的频道消息 # 之后如果新消息，只需从上一次的返回结果ID继续读取即可 # 当没有新消息时，xread命令返回空集 ip:7000> xread BLOCK 100 STREAMS channel1 $ 1) 1) \"channel1\" 2) 1) 1) 1528703048021-0 2) 1) \"msg1-tony\" 2) \"Hello everyone.\" ip:7000> xread BLOCK 100 STREAMS channel1 1528703048021-0 1) 1) \"channel1\" 2) 1) 1) 1528703061087-0 2) 1) \"msg2-tony\" 2) \"I am a big Redis fan.\" 3) \"msg3-tony\" 4) \"Hope we can learn from each other.:-)\" ip:7000> xread BLOCK 100 STREAMS channel1 1528703061087-0 (nil) 获取历史消息前面我们提到了，Redis Stream和PUB/SUB相比，一个重要的区别是，Redis Stream可以获取历史发送的消息，所以当一个用户断开连接重新加入IRC时，可以通过如下方式获取历史消息： # 1528703061087-0 为用户记录的最后接收的消息的ID ip:7000> xrange channel1 1528703061087-0 + 1) 1) 1528706457462-0 2) 1) \"msg1-andy\" 2) \"Nice to meet you guys.\" 2) 1) 1528706497200-0 2) 1) \"msg4-tony\" 2) \"When will Redis 5.0 GA comes out?\" 3) 1) 1528706601973-0 2) 1) \"msg1-antirez\" 2) \"I think it will arrive in the second half of 2018.\" Redis Stream实战——IoT数据采集Redis除了强大而且丰富的数据结构支持，还有一个很重要的能力是跨平台，甚至是作为一个嵌入式的存储系统跑在基于ARM的平台上，比如作者之前就宣称，Redis成功的跑在了“树莓派”上。 试想一下，在IoT时代，会有无数随时随地可以接入互联网的智能设备，你家里的冰箱会实时的汇报，冰箱里面有哪些食物，数量多少，新鲜程度如何，空调会汇报现在温度多少，空气质量如何，你的车会不断的汇报发动机的各项数据，变速箱的各项数据，车内空气的各项数据。这么多的IoT设备会形成巨大的数据洪流，采集完成后在云端进行分析，产生巨大的用户价值。 这些数据虽然内容各个不同，但是都有一个共同的特点，都是一种时序数据。看到这里，你可能会突然发现，Redis Stream从设计初就是为了支持时间序列数据而生（见第一部分Redis Stream介绍），Redis又成功的跑在了ARM平台，而未来物联网会有万亿级的设备基于ARM平台。所以，我们不由自主的可以猜想，除了现在在各种互联网服务中作为Cache和KV存储广泛应用，Redis下一个大放异彩的领域也许就在物联网。 上面这个图，就是一个典型的物联网设备信息采集，分析，展示的架构。Redis作为一个嵌入式的存储系统跑在各个IoT设备上，各个设备使用Redis Stream暂存产生的时序数据，然后再异步的推送到云端。云上部署的各个业务程序，会读取推送的原始数据，基于一定的规则进行分析，然后将结果写入可靠的数据存储系统。用户读取结果，在APP或者web页面上进行展示，从而整个系统形成一个闭环。 作者简介夏德军，花名夏周，阿里云Redis技术专家，负责阿里云Redis内核开发和维护。活跃于开源社区，Redis Contributor，设计并实现了阿里云Redis开源项目ApsaraCache的部分核心feature，如时间点恢复，binlog同步等。 参考资料 -Redis Stream应用案例","tags":[{"name":"Redis","slug":"Redis","permalink":"http://www.jifu.io/tags/Redis/"},{"name":"Stream","slug":"Stream","permalink":"http://www.jifu.io/tags/Stream/"}],"categories":[{"name":"back-end","slug":"back-end","permalink":"http://www.jifu.io/categories/back-end/"},{"name":"Middle-ware","slug":"back-end/Middle-ware","permalink":"http://www.jifu.io/categories/back-end/Middle-ware/"},{"name":"Redis","slug":"back-end/Middle-ware/Redis","permalink":"http://www.jifu.io/categories/back-end/Middle-ware/Redis/"}]},{"title":"redis.conf参数配置及解释","date":"2019-04-01T02:48:33.000Z","path":"posts/2992538737/","text":"# redis关于内存分配使用的单位，不区分大小写，K、M、G单位进制1000，kb，mb，gb进制1024 ##################################关于include指令 ################################### # 一般的一台服务器上会跑多个Redis实例，而这些实例配置大同小异，因此将共同的部分抽取出来template.conf， #然后在其他配置(Instance.conf)中引入是一种合理的实践方式，Redis配置支持这种实践模式,通过include指令； #除此以外,在Instance.conf 覆盖参数也是合理的需求。 #Redis include处理的逻辑可以这么理解： #Redis 利用Map 存储参数，按照定义的顺序读取及解析文件并肩参数存储到Map中，也就是说同样的配置靠后的才是生效的配置。 #最常用的实践方式为：在instance.conf文件的开头引入template.conf,并在instance.conf重写特定的配置 # include .\\path\\to\\local.conf ################################## 以下为Redis使用的全部参数 ##################################### ################################## 网络参数 ##################################### # bind 参数用于设定监听的本机IP（v4或者v6），可以是一个也可以是多个，如下所示： # bind 192.168.1.100 10.0.0.1 # bind 127.0.0.1 ::1 # 如果bind参数没有定义, redis将会监听服务器的所有的IP（一般服务器有多个网卡）； # 警告：在生产环境中（或者说在公网）监听全部的IP是极度危险的，所以默认的，Redis设定之间听回环IP(127.0.0.1),这样Redis只会处理来自本机的连接。 # 如果 你确认需要监听本机全部的IP，请注释掉bind 配置 # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ bind 127.0.0.1 #protected-mode 用于设定是否开启保护模式，默认开启。 # 当Redis暴露在互联网，没有设定具体的监听IP，也没有开启访问的密码验证： # 如果开启保护模式，那么Redis只会接受来自本机（本机回环地址）以及Unix Domain Socket（也是本机）的连接， #关于 Unix Domain Socket ，请参看https://blog.csdn.net/guxch/article/details/7041052； #基本类似于Socket 但是只用于本机进程间通讯，数据并不经过网络协议栈，没有打包解包流程，同时发送数据时会携带组Id，用户Id，进程Id用于接收方进程验证。 # 请确认好再做修改 protected-mode yes # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ #Redis监听的TCP端口 ，用于客户端连接，必须设定为大于0，且要避开系统端口 port 6379 #tcp-backlog #在高并发的环境下,需要提高tcp-bakclog 的值，用于保证连接较慢的客户端不会失去连接 #tcp backlog参数的作用 参看https://www.cnblogs.com/Orgliny/p/5780796.html #基本上就是用于指定Redis可同时维持的最大的通信进程数，但是这个进程数不能超过Linux系统的默认设定值 #Linux 系统设定文件为/proc/sys/net/core/somaxconn somaxconn &amp;cp_max_syn_backlog #一般不需要设定 tcp-backlog 511 # Unix socket. # 设定本机进程间通讯端口，默认不监听，一般也不用； # unixsocket /tmp/redis.sock # unixsocketperm 700 #设定Redis与客户端断开连接后与Redis关闭这个连接的时间差，0代表No timeout 0 # TCP keepalive.单位second 一般60秒 # 用于设定Redis向客户端发出心跳检测的间隔时间，目的有两个：一个是心跳检测，一个是保证网络畅通（网络中间设备可能会掐断链路 tcp-keepalive 0 ################################# 通用设置 ##################################### # daemonize 设定是否在以守护进程的模式运行，默认No，当开启后会在写一个/var/run/redis.pid 记录pid daemonize no # 如果使用 upstart or systemd 做服务的监控，可以配置这个选项用于发送信号给两者 # 可用选项： # supervised no - no supervision interaction # supervised upstart - signal upstart by putting Redis into SIGSTOP mode # supervised systemd - signal systemd by writing READY=1 to $NOTIFY_SOCKET # supervised auto - detect upstart or systemd method based on # UPSTART_JOB or NOTIFY_SOCKET environment variables # 注意: 不保证有效，仅仅是发送信号给两者. supervised no # pidfile 用于设定Redis run on deamon 时 pid写到哪个文件 pidfile /var/run/redis.pid # 设定Redis 日志的级别 loglevel notice # 设定日输出文件名，不设定日志输出会被重定向到标准输出流 logfile \"\" # 设定 redis 分区数量，一般在多个应用使用一个群组的时候需要为不同应用分配不同空间避免Key冲突 databases 16 ################################ 快照（数据定时写入磁盘）################################ # Save the DB on disk: # 设定写入到磁盘的时机，要同时满足两条件 时间（单位seconds）、key的更改次数 # 如果不需要写到磁盘 用save \"\" 覆写 save 900 1 save 300 10 save 60 10000 # 如果开启了快照而最新的快照又失败的话,Redis将拒绝写入操作,以避免灾难发生,尽管这是很硬核的策略 #如果Redis 后台写快照又正常了，Redis则会自动的允许写入 #如果你设定正确的监控和持久化策略。你可以关闭这个特性(use no),即使硬盘坏了或者写出权限不足 stop-writes-on-bgsave-error yes # 在Redis 把内存中的数据dump到硬盘上的rdb文件时，是否使用LZF算法对string 进行压缩，开启压缩的话，文件会变小，但是CPU小号功率会上升，默认开启。 rdbcompression yes # 从第5个发布的版本开始，Redis增加了在RDB文件的介未增加了CRC64的完整性校验位，防止文件被破坏。但是在存储的时候会降低大约10%的效率。默认yes开启no关闭 rdbchecksum yes #设定mem数据dump到硬盘时的文件名 （Snapshot） dbfilename dump.rdb # 设定文件的存储目录 绝对路径或者相对路径均可以 只可以是文件夹：dafilename文件会存储在这个目录下 dir ./ ################################# 主从复制设定 ################################# # 为了保证应用的的高可用（最高目标就是7*24*100%尽管实际上很难达到)。一般采用的套路有两种 # 一种是单机但是提供一个监控服务在应用服务程序挂掉马上重启（时间有间断用户可感知）； # 一种是跑两个实例一台主机提供服务一台做备机备灾，主机挂掉，备机自动马上开始提供服务（无间断服务用户无法感知）。 # Redis 高可用是同通过双机切换来做的。 #具体的配置主机Mater和备机Slave关系可以使用如下参数（slaveof &lt;masterip> &lt;masterport>） # Redis 主从的数据复制是异步的，Master可以配置备机的最小数量N，当与Master连接备机小于N时，Master将不会接受写入请求{Slave 数据和Master的数据对程序的表现是一致的（实际上并不一致，当Mater上有已过期的未被回收的Key存在时，这些Key不会复制到Slave上去，这个是Redis的一个Feature not Bug）}，一般情况下就是一主一备。 # 也可以i可以设定备机与主机的最长失联时间，在这个时间内连接恢复的话，同步会再次自动的进行不需要人工干预。 # slaveof &lt;masterip> &lt;masterport> # 如果主机开启了password保护（requirepass 配置），需要使用下面的配置主机的访问密码 # masterauth &lt;master-password> #Slave，在失去了Master的链接或者在进行主从复制的时，收到客户端的请求时, # 如果slave-serve-stale-data 配置为yes，Slave会继续响应这个读取请求（但是响应数据有可能为过期数据，或者空数据如果Slave是第一次同步数据） #如果配置为no，Slave会响应给客户端一个ERROR(SYNC with master in progress) slave-serve-stale-data yes #我们可以配置一个Slave是否响应写请求，接受写请求可能对写如一些临时数据时有效果（会在主机数据进行同步时删除掉） #Attention：但是很容易造成数据或者业务的混乱之类的问题， #从Redis 2.6 开始 Slave默认为read-only，而且只读Slave并不适合暴露在互联网上,只读只是一个防止RedisSlave被错误使用的机制。 #除此之外，只读Slave仍旧可以接受一些管理命令比如config，debug等等。 #如果你想提高Slave的安全性，请使用“rename-command”命令对redis命令重命名,屏蔽掉管理\\危险的命令,尽管这很有限。 slave-read-only yes #数据同步的策略，通过硬盘或者socket #Attention:不通过磁盘机型数据同步仅仅是试验中的特性； #新增加的或者断线重连(如果不能继续原先的同步)的Slave会从Master进行全量同步（rdb文件被传输给Slave，Slave解析RDB文件）； #传输的方式分为两种： # 1.Master创建一个新的进程把数据不断写到硬盘上，然后再把文件传输给Slaves； # 2.Master创建一个新的进程通过socket直接把rdb文件写到Slave上，不在经过硬盘； # #使用硬盘进行同步时,rdb文件生成完成后,Master再接受同步请求后就会把rdb文件发送过去； #通过socket同步时,新的同步请求会被阻塞直到当前处理的同步请求完成； #在使用socket同步时,Master可以配置一个等待时间以便于同时处理几个同步请求。 #如果网络带宽够大而且硬盘读写速度较慢时，socket是一个较号的选择。 repl-diskless-sync no # socket同步请求处理延时，单位second repl-diskless-sync-delay 5 #Slave 按照如下配置的时间ping Master，默认10seconds。 # repl-ping-slave-period 10 # 以下配置设定主从复制的相关超时设置：如果超时就会断开连接重连Master并且重新进行同步操作 # IO传输超时，从Slave的角度；（Slave发送SYNC到Mater,Master 需要在60s内把rdb文件内数据发送到Slave） # Master网络超时，从Slave的角度；（Slave ping Master） # Slave网络超时，从Master角度；（Master ping Slave） # 注意这个值需要比repl-ping-slave-period 这个配置要大,不让当传输较慢的时候 总会触发超时。 # repl-timeout 60 # 完成数据同步后，Slave是否禁用TCP-NODELAY？ # 如果yes，Redis Master会将多份数据打包成一个小的数据报后再发送到Slave,会导致数据主从 数据上的延迟约40ms #打包操作由linux内核完成，约延迟40ms，参看https://www.cnblogs.com/wajika/p/6573028.html #if no,数据传输延迟会降低，但是带宽消耗会上升,默认会禁用延时。如果数据量很大或者主备机延时很高的情况设置为yes可能会好点 repl-disable-tcp-nodelay no #设定主从复制的数据缓冲区大小，当Slave再复制期间断线，后又再次重连的话，如果数据缓冲区还未写满，Slave则会继续从缓冲区读入数据，否则会再次发送全量同步的请求。 # 只有存在Slave时，Redis才会申请这块内存 # repl-backlog-size 1mb # 设定Master没有Slave connect多上时间后开始释放 backlog 内存 # repl-backlog-ttl 3600 # Slave的优先级（必须是正整数），决定了成为Master的顺位（当Master挂了的时候）。 #数值越小，优先级越高。但是如果是0的时候，则永远不会成为Master slave-priority 100 #当在线的Slave小于N时，Master将不再接受写入请求。 #当Master收到Slave的最后一次ping 如果持续M秒时还未收到Ping，Master会Mark Slave offline # 这配置并不能保证其他的N-1个Slave会接受写操作，只能保证少于N个Slave时Master不在接受写操作 # 0代表disable，默认的 # min-slaves-to-write 0， min-slaves-max-lag 10 # min-slaves-to-write 3 # min-slaves-max-lag 10 ################################## 安全保证################################### #是否需要开启密码验证（一般情况下，并不需要）,Redis 性能相当高，大约每秒处理大约150k请求，因此密码最好很长，不然直接就暴力破解了 # requirepass foobared # 修改命令的名字为新的字符，比如 rename-command CONFIG b840fc02d524045429941cc15f59e41cb7be6c52 # 这样的话 客户端只能用过 b840fc02d524045429941cc15f59e41cb7be6c52 来达到 config的的效果，当rename-command CONFIG “” 时，CONFIG命令就会失效 # 注意：如果修改的命令会被记录到AOF或者传输到Slave机器会造成很多问题。 # Command renaming. # Please note that changing the name of commands that are logged into the # AOF file or transmitted to slaves may cause problems. ################################### 限制 #################################### #设定Redis同时最大的客户端连接数量，默认情况为10000，如果Redis无法从配置文件进行配置，Redis将会设定为当前文件的限制减去32； # maxclients 10000 # 是否开启持久化机制，如果否，那么一切持久化相关配置都会失效。比如RDB（内存数据快照）&amp;AOF(操作记录AppendOnlyFile) # persistence-available [(yes)|no] #当内存使用量达到设定的上限时，Redis就会开始回收过期的Key. #如果无法删除key,Redis会对使用大量内存的命令（lpush等）返回错误信息，但是GET类命令正常响应。 #除此之外,如果当前Redis有备机存在，那么写到备机时所可使用的最大缓存大小为机器内存减去Redis数据所占内存。 #因此,当数据过多时就会挤压主从缓冲的大小，直至缓冲被挤占完全，当网络有问题时，会造成同步失败 #简单的说，当有备机存在时，maxmemory需要设置的小点给主从复制缓冲留些空间 #注意：这是为0时,代表不限制内存的使用，当内存用尽时会OOM #Redis使用系统内存分页申请堆,其他的内存占用分析工具查看Redis使用的内存大小时并不准确 # maxmemory &lt;bytes> #内存用尽时的Key删除策略，共5种 # volatile-lru -> 删除 Least Recent Use 算法&amp; Has Expried Keys # allkeys-lru ->删除 Least Recent Use 算法 &amp; Any Keys # volatile-random -> 随机删除A Has Expried Key # allkeys-random -> 随机删除A Key # volatile-ttl -> 删除距离过期时间最近的Key # noeviction -> 不做任何处理,当达到maxmemory时,直接return an error to client # maxmemory-policy noeviction # LRU或者TTL并不是精确算法,可以对算法进行调整，默认的，LRU或者TTL 每次会选择5个Key检测,随机的删除满足条件一个。不需要修改，5 is tested for the best performance # maxmemory-samples 5 ##############################只追加模式 ############################### # 默认情况下,Redis dump data to disk 和接受读写的线程是异步的，这种模式在大部分情况下足够用了，但是如果突然停电关机，一般情况下，Mem内的数据 会丢失一部分（不确定的）。 # AOF 模式提供了更可靠的持久化方式，使用fsync 策略时，Redis只会丢失1s的写入数据(取决于appendfsync 配置)。 #AOF 和RDB 可以同时启用，但是会优先使用AOF appendonly no # aof 文件名 appendfilename \"appendonly.aof\" # Redsi调用fsync()时，会告诉系统立刻把数据的从内存写入到 硬盘而不是停留在在输出buffer里面。（但是取决于系统，linux下是如此） # Redis 调用 fsync()模式有如下几种： # no，不调用，让系统决定； # always 每一次写操做都会调用 # everysec每秒调用一次，默认值 # appendfsync always appendfsync everysec # appendfsync no #当AOF fsync 为always 或者 everysec，同时在后台有进程在进行大量的磁盘IO（比如BGSAVE或者AOF重写时）， #在一些Linux配置中Redis会长时间的阻塞在fsync调用上（目前还没有办法解决），甚至至其他线程调用也会阻塞我们对write(2)的调用(因为Redis Main Thread调用write是同步阻塞的） #为了减少这个问题请使用如下的配置，以阻止主线程对fsync的调用（当有BGSAVE或者BGREWRITEAOF执行的时候） # 这样有一个后果，AOF文件从内存写入到硬盘完全由系统控制即appendfsync 为no的效果一样，最坏的情况下，AOF会丢失30s的数据 #如果你对读写效率要求非常高时，请将下面的配置为yes，不然请保持no，这样是数据最安全的 no-appendfsync-on-rewrite no #AOF 持久化是通过保存被执行的写命令来记录数据库状态的，所以AOF文件的大小随着时间的流逝一定会越来越大； #影响包括但不限于：对于Redis服务器，计算机的存储压力；AOF还原出数据库状态的时间增加； # 为了解决AOF文件体积膨胀的问题，Redis提供了AOF重写功能： # Redis服务器可以创建一个新的AOF文件来替代现有的AOF文件，新旧两个文件所保存的数据库状态是相同的， # 但是新的AOF文件不会包含任何浪费空间的冗余命令，通常体积会较旧AOF文件小很多。（主要是合并一些命令） # 这个机制触发机制是：当AOF文件大小的增长到某一个值时； # auto-aof-rewrite-min-size 配置 重写的触发时最小的AOF大小， #auto-aof-rewrite-percentage 配置当AOF文件相比于Redis启动时大小增长的比率，0代表禁用BGAOFREWRITE特性 auto-aof-rewrite-percentage 100 auto-aof-rewrite-min-size 64mb #在Redis启动时，AOF文件被载入内存，有可能持续出现（AOF被截断文件不完整这种情况，一般是系统挂掉造成的尤其是EXT4这种文件系统），Redis根据如下的aof-load-truncated的配置要么直接报错退出，要么尽可能的载入可载入的数据。 #aof-load-truncated yes 时，Redis会正常启动并尽可能的载入数据，并将AOF损坏报告给用户 #aof-load-truncated no时，Redis将会因为报错而退出，需要使用redis-check-aof来修复AOF文件后再次启动。 # 注意，这个选项支队啊、AOF文件结尾损坏有效，如果AOF文件中间损坏了并不会由任何效果Redis人仍旧会退出报错。 aof-load-truncated yes ################################ LUA 脚本 ############################### #配置一个Lua脚本执行时，最大的毫秒数，如果超过这个时间脚本仍在执行，Redis将会记录这个情况,并且会对所有的读取请求回复错误。 #当脚本执行时间超标了，那么只有SCRIPT KILL and SHUTDOWN NOSAVE可以使用； #SCRIPT KILL 只能应用在脚本还未执行写操作时， #SHUTDOWN NOSAVE 适用于脚本有了写操作，而用户又不想等待脚本自然终止的情况下； #设置为0 或者负数时，代表不设置最高时间上限。 lua-time-limit 5000 ################################ REDIS 集群############################### #警告：Redis集群尽管被认为是个稳定的版本，但是仍需要一些吃螃蟹的人在生产环境中大规模使用才能被标记为成熟。 # 一般的正常的Redis时无法成为集群的一部分的，只有以集群节点方式启动的Redis才可以加入集群。 # 将如下配置为yes，Redis启动模式将会改为集群节点模式； # cluster-enabled yes #每个Redis节点都有一个自己的集群配置文件，但是这个文件不适于手动编辑，而是由Redis节点生成修改； #在单机配置 多个节点的时候，请确认每个节点都有自己的配置，不会相互复写； # cluster-config-file nodes-6379.conf #集群超时时间是这个节点不可达的最长毫秒数，不然节点见会被标记为failure，一般是redis内部超时的整数倍 # cluster-node-timeout 15000 #集群主机的备机，将不会自动的切换为主机状态，如果 备机数据too old， #检测备机数据的年龄，Redis依靠如下两个检测结果： # 1）如果存在多个备机可以切换为主机,那么备机将相互交换数据查看谁备份数据最好(接受处理的Master发送的同步数据最多) # 2）每个备机将会计算自己与Master最后一次通信（互ping，接受命令）的时间，或者与Master失联的时间，如果时间太大则根本不会切换为主机， # 判断标准为{(node-timeout * slave-validity-factor) + repl-ping-slave-period}单位秒。 # 当设置slave-validity-factor 为0 时，Slave会忽略数据年龄判断，加入Master选举 # cluster-slave-validity-factor 10 # 集群备机能够迁移成为其他单点主机的备机，这样可以提高集群的稳定性； #但是备机迁移的前提是老的主机备机数量大于老主机指定的最小备机数； #默认情况下，每个主机只需要要有一个备机。 #但是为了节点的稳定性要避免备机迁移，请将数值调很大， #也可以设置为0，但是只是请旨在debug情境下使用，生产环境会很危险 # cluster-migration-barrier 1 #默认情况下，只要有一个slot不可使用，整个集群立刻进入不可用状态（不可写也不可读），当这个slot可用了整个集群又会回复； # 如果你想使仍在工作的部分机器继续接受读取请求，请将下面的配置设为no #备注：slot 是每个Key存储的位置,Redis设计有16384 slot， #对于任何一个的Key的任何操作都需要确定他的在哪个slot（通过CRC64计算Key的hash，然后对16384求余即可得到slot id） # cluster-require-full-coverage yes ################################## SLOW LOG ################################### #SLOW LOG 用于记录执行超时的命令,(执行时间的计算不包括与IO时间仅仅是Redis执行命令的时间，这个时间内Redis仅只执行这一个命令，命令处理是单线程的)， # 可以配置最大执行时间（单位ms）及记录超时命令的队列长度（队列满后老命令会被挤出） slowlog-log-slower-than 10000 slowlog-max-len 128 ################################ LATENCY MONITOR ############################## #LATENCY MONITOR 主要是Redis集群用来收集子节点有哪些命令执行超时（>= latency-monitor-threshold的 值),通过LATENCY命令可以获取可视化的数据及报告 #默认地，这个系统是禁用的（设置为0），如果想在运行时启用可以使用“CONFIG SET latency-monitor-threshold &lt;milliseconds>”命令 latency-monitor-threshold 0 ############################# EVENT NOTIFICATION ############################## #Redis 支持Pub/Sub 模式，Redis可以通知客户端发生了什么 #可以设定Redis需要对哪一类事件进行通知， # K Keyspace events, published with __keyspace@&lt;db>__ prefix. # E Keyevent events, published with __keyevent@&lt;db>__ prefix. # g Generic commands (non-type specific) like DEL, EXPIRE, RENAME, ... # $ String commands # l List commands # s Set commands # h Hash commands # z Sorted set commands # x Expired events (events generated every time a key expires) # e Evicted events (events generated when a key is evicted for maxmemory) # A Alias for g$lshzxe, so that the \"AKE\" string means all the events. #notify-keyspace-events 支持多个类型事件直接拼接即可，默认情况下会禁用 notify-keyspace-events \"\" ############################### ADVANCED CONFIG ############################### #存储的的Value REDIS_LIST,list.size&lt;64 ,最大element长度不超过512 ，那么这个 RedisList 会被重新Hash以节约内存 #否则使用 HashTable来存储 hash-max-ziplist-entries 512 hash-max-ziplist-value 64 #RedisList 数据会被重新编码以节约内存,可以指定每个Node的内存大小或者可以持有的元素数量 #负数标识内存大小 # -5: max size: 64 Kb &lt;-- not recommended for normal workloads # -4: max size: 32 Kb &lt;-- not recommended # -3: max size: 16 Kb &lt;-- probably not recommended # -2: max size: 8 Kb &lt;-- good # -1: max size: 4 Kb &lt;-- good #整数表示可有存储的元素数量 #一般每个node 8kb足够好了 不需要修改 list-max-ziplist-size -2 #Redis List 也可以压缩，可以设定压缩的深度，即前多少个节点可以压缩默认0不要要锁 list-compress-depth 0 #Sets 只有满足如下情况是才会被压缩： # 这个set 完全由64bit所能表示的有符号整数组成时； # 如下条目配置了一个Set最大元素数量 set-max-intset-entries 512 #和Hash和List相似，有序Set也会被重新压缩编码节约内存，当仅当Set内的元素数量小于64.元素bit数小于128时； zset-max-ziplist-entries 128 zset-max-ziplist-value 64 #基数统计分组大小（主要用于统计Keyde数量通过HyperLogLog 算法，别去看：涉及数理统计及数据分布，数据可信度等等内容） hll-sparse-max-bytes 3000 # 激活ReHash Redis Main hash table（存储Top key的那个，指SET a 命令存储 a 的hash table） 大约只占用1%的CPU时间片。 # Redis 对主表的rehash延迟执行，对正在HashTable操作越多，执行rehash的步骤越多,因此处于空闲的Redis，rehash永远无法完成 #默认情况下每秒执行10次rehash操作用于释放内存； # 如果不确定或者对redis读取有很高的速度要求,请将activerehashing 设置为 no， # 如果尽快释放内存，请设置yes activerehashing yes # 客户端输出缓冲区限制可以被用来青珀客户端断开与服务器的链接（如果客户端读取很慢而服务器生成很快情况下） # 可以对三种不同类型的客户端normal、slave、pubsub）进行限制，限制的语法为（注意0为禁用） # client-output-buffer-limit &lt;class> &lt;hard limit> &lt;soft limit> &lt;soft seconds> # 当缓冲区占用了大小达到 hard limit 时，或者 达到 soft limit 达到 soft secnds 后，客户端会马上被强制断开链接 # 默认情况下，normal 不会别限制，因为只有在异步的pubsub模式下才会出现输出缓冲被占满的情况； #其他的情况，有默认的限制 client-output-buffer-limit normal 0 0 0 client-output-buffer-limit slave 256mb 64mb 60 client-output-buffer-limit pubsub 32mb 8mb 60 # Redis 通过调内部函数执行很多后台任务（关闭超时连接,废Key回收等等），尽管这些任务执行的频率并不一样，但是我们可以设定检测需要执行任务的频率（hz 10 范围 1-500，但一般不要超过100除非需要很低的垃圾回收延迟）; #Redis 空闲时会略微提升CPU功率，但是同时会提升垃圾回收的速度， hz 10 #在后台重写AOF的时候，如果开启aof-rewrite-incremental-fsync yes，重写的AOF将会没32MB存到DISK一次，以避免IO速率出现尖峰形态 aof-rewrite-incremental-fsync yes ################################## INCLUDES ################################### # include /path/to/local.conf # include /path/to/other.conf","tags":[{"name":"Redis","slug":"Redis","permalink":"http://www.jifu.io/tags/Redis/"},{"name":"config","slug":"config","permalink":"http://www.jifu.io/tags/config/"},{"name":"参数","slug":"参数","permalink":"http://www.jifu.io/tags/参数/"}],"categories":[{"name":"back-end","slug":"back-end","permalink":"http://www.jifu.io/categories/back-end/"},{"name":"Middle-ware","slug":"back-end/Middle-ware","permalink":"http://www.jifu.io/categories/back-end/Middle-ware/"},{"name":"Redis","slug":"back-end/Middle-ware/Redis","permalink":"http://www.jifu.io/categories/back-end/Middle-ware/Redis/"}]},{"title":"高性能Web服务器 - Nginx配置详解","date":"2019-03-31T22:14:03.000Z","path":"posts/1544228005/","text":"概述Nginx是轻量级的高性能Web服务器，提供了诸如HTTP代理和反向代理、负载均衡、缓存等一系列重要特性，因而在实践之中使用广泛，笔者也在学习和实践之中。 在本文中，我们详解一下Nginx服务器的各种配置指令的作用和用法。 Nginx配置文件的整体结构 从图中可以看出主要包含以下几大部分内容： 全局块该部分配置主要影响Nginx全局，通常包括下面几个部分： 配置运行Nginx服务器用户（组） worker process数 Nginx进程PID存放路径 错误日志的存放路径 配置文件的引入 events块该部分配置主要影响Nginx服务器与用户的网络连接，主要包括： 设置网络连接的序列化 是否允许同时接收多个网络连接 事件驱动模型的选择 最大连接数的配置 HTTP块 定义MIMI-Type 自定义服务日志 允许sendfile方式传输文件 连接超时时间 单连接请求数上限 server块 配置网络监听 基于名称的虚拟主机配置 基于IP的虚拟主机配置 location块 location配置 请求根目录配置 更改location的URI 网站默认首页配置 一份配置清单例析给出了一份简要的清单配置举例： 配置代码如下： user nobody nobody; worker_processes 3; error_log logs/error.log; pid logs/nginx.pid; events { use epoll; worker_connections 1024; } http { include mime.types; default_type application/octet-stream; log_format main '$remote_addr - $remote_user [$time_local] \"$request\" ' '$status $body_bytes_sent \"$http_referer\" ' '\"$http_user_agent\" \"$http_x_forwarded_for\"'; access_log logs/access.log main; sendfile on; keepalive_timeout 65; server { listen 8088; server_name codesheep; access_log /codesheep/webserver/server1/log/access.log; error_page 404 /404.html; location /server1/location1 { root /codesheep/webserver; index index.server2-location1.htm; } location /server1/location2 { root /codesheep/webserver; index index.server2-location2.htm; } } server { listen 8089; server_name 192.168.31.177; access_log /codesheep/webserver/server2/log/access.log; error_page 404 /404.html; location /server2/location1 { root /codesheep/webserver; index index.server2-location1.htm; } location /srv2/loc2 { alias /codesheep/webserver/server2/location2/; index index.server2-location2.htm; } location = /404.html { root /codesheep/webserver/; index 404.html; } } } 配置详细剖析配置运行Nginx服务器用户（组）指令格式：user user [group]; user：指定可以运行Nginx服务器的用户 group：可选项，可以运行Nginx服务器的用户组 如果user指令不配置或者配置为user nobody nobody，则默认所有用户都可以启动Nginx进程 worker process数配置Nginx服务器实现并发处理服务的关键，指令格式：worker_processes number | auto; number：Nginx进程最多可以产生的worker process数 auto：Nginx进程将自动检测 我们给worker_processes配置的数目是：3，启动Nginx服务器后，我们可以后台看一下主机上的Nginx进程情况： ps -aux | grep nginx 很明显，理解 worker_processes 这个指令的含义就很容易了 Nginx进程PID存放路径Nginx进程是作为系统守护进程在运行，需要在某文件中保存当前运行程序的主进程号，Nginx支持该保存文件路径的自定义 指令格式：pid file; file：指定存放路径和文件名称 如果不指定默认置于路径 logs/nginx.pid 错误日志的存放路径指定格式：error_log file | stderr; file：日志输出到某个文件file stderr：日志输出到标准错误输出 配置文件的引入指令格式：include file; 该指令主要用于将其他的Nginx配置或者第三方模块的配置引用到当前的主配置文件中 设置网络连接的序列化指令格式：accept_mutex on | off; 该指令默认为on状态，表示会对多个Nginx进程接收连接进行序列化，防止多个进程对连接的争抢。 说到该指令，首先得阐述一下什么是所谓的 “惊群问题”，可以参考。就Nginx的场景来解释的话大致的意思就是：当一个新网络连接来到时，多个worker进程会被同时唤醒，但仅仅只有一个进程可以真正获得连接并处理之。如果每次唤醒的进程数目过多的话，其实是会影响一部分性能的。 所以在这里，如果accept_mutex on，那么多个worker将是以串行方式来处理，其中有一个worker会被唤醒；反之若accept_mutex off，那么所有的worker都会被唤醒，不过只有一个worker能获取新连接，其它的worker会重新进入休眠状态 这个值的开关与否其实是要和具体场景挂钩的。 是否允许同时接收多个网络连接指令格式：multi_accept on | off; 该指令默认为off状态，意指每个worker process一次只能接收一个新到达的网络连接。若想让每个Nginx的worker process都有能力同时接收多个网络连接，则需要开启此配置 事件驱动模型的选择指令格式：use model; model模型可选择项包括：select、poll、kqueue、epoll、rtsig等…… 最大连接数的配置指令格式：worker_connections number; number默认值为512，表示允许每一个worker process可以同时开启的最大连接数 定义MIME-Type指令格式： include mime.types; default_type mime-type; MIME-Type指的是网络资源的媒体类型，也即前端请求的资源类型 include指令将mime.types文件包含进来 cat mime.types来查看mime.types文件内容，我们发现其就是一个types结构，里面包含了各种浏览器能够识别的MIME类型以及对应类型的文件后缀名字，如下所示： 自定义服务日志指令格式： access_log path [format]; path：自定义服务日志的路径 + 名称 format：可选项，自定义服务日志的字符串格式。其也可以使用 log_format 定义的格式 允许sendfile方式传输文件指令格式： sendfile on | off; sendfile_max_chunk size; 前者用于开启或关闭使用sendfile()传输文件，默认off 后者指令若size&gt;0，则Nginx进程的每个worker process每次调用sendfile()传输的数据了最大不能超出此值；若size=0则表示不限制。默认值为0 连接超时时间配置指令格式：keepalive_timeout timeout [header_timeout]; timeout表示server端对连接的保持时间，默认75秒 header_timeout为可选项，表示在应答报文头部的Keep-Alive域设置超时时间：Keep-Alive : timeout = header_timeout 单连接请求数上限指令格式：keepalive_requests number; 该指令用于限制用户通过某一个连接向Nginx服务器发起请求的次数 配置网络监听指令格式： 第一种：配置监听的IP地址：listen IP[:PORT]; 第二种：配置监听的端口：listen PORT; 实际举例： listen 192.168.31.177:8080; # 监听具体IP和具体端口上的连接 listen 192.168.31.177; # 监听IP上所有端口上的连接 listen 8080; # 监听具体端口上的所有IP的连接 基于名称和IP的虚拟主机配置指令格式：server_name name1 name2 ... name可以有多个并列名称，而且此处的name支持正则表达式书写 实际举例： server_name ~^www\\d+\\.myserver\\.com$ 此时表示该虚拟主机可以接收类似域名www1.myserver.com等的请求而拒绝www.myserver.com的域名请求，所以说用正则表达式可以实现更精准的控制 至于基于IP的虚拟主机配置比较简单，不再太赘述： 指令格式：server_name IP地址 location配置指令格式为：location [ = | ~ | ~* | ^~ ] uri {...} 这里的uri分为标准uri和正则uri，两者的唯一区别是uri中是否包含正则表达式 uri前面的方括号中的内容是可选项，解释如下： “=”：用于标准uri前，要求请求字符串与uri严格匹配，一旦匹配成功则停止 “~”：用于正则uri前，并且区分大小写 “~*”：用于正则uri前，但不区分大小写 “^~”：用于标准uri前，要求Nginx找到标识uri和请求字符串匹配度最高的location后，立即使用此location处理请求，而不再使用location块中的正则uri和请求字符串做匹配 请求根目录配置指令格式：root path; path：Nginx接收到请求以后查找资源的根目录路径 当然，还可以通过alias指令来更改location接收到的URI请求路径，指令为： alias path; # path为修改后的根路径 设置网站的默认首页指令格式：index file ...... file可以包含多个用空格隔开的文件名，首先找到哪个页面，就使用哪个页面响应请求","tags":[{"name":"配置","slug":"配置","permalink":"http://www.jifu.io/tags/配置/"},{"name":"Nginx","slug":"Nginx","permalink":"http://www.jifu.io/tags/Nginx/"}],"categories":[{"name":"back-end","slug":"back-end","permalink":"http://www.jifu.io/categories/back-end/"},{"name":"Middle-ware","slug":"back-end/Middle-ware","permalink":"http://www.jifu.io/categories/back-end/Middle-ware/"},{"name":"Nginx","slug":"back-end/Middle-ware/Nginx","permalink":"http://www.jifu.io/categories/back-end/Middle-ware/Nginx/"}]},{"title":"利用windows内置工具测试硬盘速度 - winsat","date":"2019-03-31T05:57:04.000Z","path":"posts/3426016246/","text":"用上了SSD一段时间，突然想测一下其读写速度。本来想下个第三方的软件什么的，原来发现Windows有内置的工具使用–WinSat，那自然是最好不过。 操作步骤以管理员身份运行命令行程序，win+R–&gt;输入cmd并回车. (否则在win10下面最终测试结果会一闪而过) 输入命令winsat disk并回车，此时为默认扫描系统盘，一般也就是C盘. 输入winsat disk + 参数-drive盘符,就是扫描指定盘了。例如扫描D盘：winsat disk -drive d","tags":[{"name":"windows","slug":"windows","permalink":"http://www.jifu.io/tags/windows/"},{"name":"winsat","slug":"winsat","permalink":"http://www.jifu.io/tags/winsat/"},{"name":"内置","slug":"内置","permalink":"http://www.jifu.io/tags/内置/"},{"name":"硬盘测速","slug":"硬盘测速","permalink":"http://www.jifu.io/tags/硬盘测速/"}],"categories":[{"name":"OPS","slug":"OPS","permalink":"http://www.jifu.io/categories/OPS/"},{"name":"Windows","slug":"OPS/Windows","permalink":"http://www.jifu.io/categories/OPS/Windows/"}]},{"title":"Mac定时任务-利用launchctl定时启动任务","date":"2019-03-12T11:54:00.000Z","path":"posts/2733308530/","text":"介绍LaunchctlLaunchctl控制OS X系统里的启动进程(launch),在Mac里有一个命令行工具叫做：launchctl，可以用来控制服务的自动启动或者关闭。 Plist文件Plist的全称是Property lists，是一种用来存储串行化后的对象的文件。属性列表文件的文件扩展名为.plist，因此通常被称为plist文件。Plist文件通常用于储存用户设置，也可以用于存储捆绑的信息。 Plist组织数据到命名值和列表值，主要通过几个主要的Core Foundation类型：CFString, CFNumber, CFBoolean, CFDate, CFData, CFArray, 和 CFDictionary。 编写APP启动脚本 1.打开launchpad-&gt;脚本编辑器,写入如下代码 set appName to \"XXApp(此处为app名称)\" if application appName is not running then tell application \"Finder\" activate open application file \"XXApp.app\" of folder \"Applications\" of startup disk end tell return \"Running\" else return \"Not running\" end if 保存到合适的路径 创建launch plist启动文件进入~/Library/LaunchAgents文件夹,创建新的plist文件com.autoOpenXXApp &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?> &lt;!DOCTYPE plist PUBLIC \"-//Apple//DTD PLIST 1.0//EN\" \"http://www.apple.com/DTDs/PropertyList-1.0.dtd\"> &lt;plist version=\"1.0\"> &lt;dict> &lt;!-- Label唯一的标识 --> &lt;key>Label&lt;/key> &lt;string>com.demo.plist&lt;/string> &lt;!-- 指定要运行的脚本 --> &lt;key>ProgramArguments&lt;/key> &lt;array> &lt;string>osascript&lt;/string> &lt;string>/Users/mac/Downloads/AutoOpenXXApp.scpt&lt;/string> &lt;/array> &lt;!-- 指定要运行的时间 --> &lt;key>StartInterval&lt;/key> &lt;integer>10&lt;/integer> &lt;!-- 标准输入文件 --> &lt;key>StandardInPath&lt;/key> &lt;string>/Users/mac/Downloads/testScript.log&lt;/string> &lt;!-- 标准输出文件 --> &lt;key>StandardOutPath&lt;/key> &lt;string>/Users/mac/Downloads/testScript.log&lt;/string> &lt;!-- 标准错误输出文件 --> &lt;key>StandardErrorPath&lt;/key> &lt;string>/Users/mac/Downloads/testScript.log&lt;/string> &lt;/dict> &lt;/plist> launchctl命令cd ~/Library/LaunchAgents 挂载任务launchctl load -w com.autoOpenXXApp.plist 开启任务launchctl start com.autoOpenXXApp.plist 停止任务launchctl stop com.autoOpenXXApp.plist 重新挂载任务 - 修改脚本后需要重新挂载卸载任务launchctl unload -w com.autoOpenXXApp.plist 重新挂载任务launchctl load -w com.autoOpenXXApp.plist 参考资料 MAC定时任务:利用launchctl配合AppScript写一个定时启动某APP的任务","tags":[{"name":"MacOS","slug":"MacOS","permalink":"http://www.jifu.io/tags/MacOS/"},{"name":"Mac","slug":"Mac","permalink":"http://www.jifu.io/tags/Mac/"},{"name":"定时任务","slug":"定时任务","permalink":"http://www.jifu.io/tags/定时任务/"},{"name":"launchctl","slug":"launchctl","permalink":"http://www.jifu.io/tags/launchctl/"}],"categories":[{"name":"OPS","slug":"OPS","permalink":"http://www.jifu.io/categories/OPS/"},{"name":"MacOS","slug":"OPS/MacOS","permalink":"http://www.jifu.io/categories/OPS/MacOS/"}]},{"title":"find命令快速技巧：如何定位一个文件","date":"2019-03-09T05:40:58.000Z","path":"posts/3200906184/","text":"我们都会有文件存储在电脑里 —— 目录、相片、源代码等等。它们是如此之多。也无疑超出了我的记忆范围。要是毫无目标，找到正确的那一个可能会很费时间。在这篇文章里我们来看一下如何在命令行里找到需要的文件，特别是快速找到你想要的那一个。 好消息是 Linux 命令行专门设计了很多非常有用的命令行工具在你的电脑上查找文件。下面我们看一下它们其中三个：ls、tree 和 find。 ls如果你知道文件在哪里，你只需要列出它们或者查看有关它们的信息，ls 就是为此而生的。 只需运行 ls 就可以列出当下目录中所有可见的文件和目录： $ ls Documents Music Pictures Videos notes.txt 添加 -l 选项可以查看文件的相关信息。同时再加上 -h 选项，就可以用一种人们易读的格式查看文件的大小： $ ls -lh total 60K drwxr-xr-x 2 adam adam 4.0K Nov 2 13:07 Documents drwxr-xr-x 2 adam adam 4.0K Nov 2 13:07 Music drwxr-xr-x 2 adam adam 4.0K Nov 2 13:13 Pictures drwxr-xr-x 2 adam adam 4.0K Nov 2 13:07 Videos -rw-r--r-- 1 adam adam 43K Nov 2 13:12 notes.txt ls 也可以搜索一个指定位置： $ ls Pictures/ trees.png wallpaper.png 或者一个指定文件 —— 即便只跟着名字的一部分： $ ls *.txt notes.txt 少了点什么？想要查看一个隐藏文件？没问题，使用 -a 选项： $ ls -a . .bash_logout .bashrc Documents Pictures notes.txt .. .bash_profile .vimrc Music Videos ls 还有很多其他有用的选项，你可以把它们组合在一起获得你想要的效果。可以使用以下命令了解更多： $ man ls tree如果你想查看你的文件的树状结构，tree 是一个不错的选择。可能你的系统上没有默认安装它，你可以使用包管理 DNF 手动安装： $ sudo dnf install tree 如果不带任何选项或者参数地运行 tree，将会以当前目录开始，显示出包含其下所有目录和文件的一个树状图。提醒一下，这个输出可能会非常大，因为它包含了这个目录下的所有目录和文件： $ tree . |-- Documents | |-- notes.txt | |-- secret | | `-- christmas-presents.txt | `-- work | |-- project-abc | | |-- README.md | | |-- do-things.sh | | `-- project-notes.txt | `-- status-reports.txt |-- Music |-- Pictures | |-- trees.png | `-- wallpaper.png |-- Videos `-- notes.txt 如果列出的太多了，使用 -L 选项，并在其后加上你想查看的层级数，可以限制列出文件的层级： $ tree -L 2 . |-- Documents | |-- notes.txt | |-- secret | `-- work |-- Music |-- Pictures | |-- trees.png | `-- wallpaper.png |-- Videos `-- notes.txt 你也可以显示一个指定目录的树状图： $ tree Documents/work/ Documents/work/ |-- project-abc | |-- README.md | |-- do-things.sh | `-- project-notes.txt `-- status-reports.txt 如果使用 tree 列出的是一个很大的树状图，你可以把它跟 less 组合使用： $ tree | less 再一次，tree 有很多其他的选项可以使用，你可以把他们组合在一起发挥更强大的作用。man 手册页有所有这些选项： $ man tree find那么如果不知道文件在哪里呢？就让我们来找到它们吧！ 要是你的系统中没有 find，你可以使用 DNF 安装它： $ sudo dnf install findutils 运行 find 时如果没有添加任何选项或者参数，它将会递归列出当前目录下的所有文件和目录。 $ find . ./Documents ./Documents/secret ./Documents/secret/christmas-presents.txt ./Documents/notes.txt ./Documents/work ./Documents/work/status-reports.txt ./Documents/work/project-abc ./Documents/work/project-abc/README.md ./Documents/work/project-abc/do-things.sh ./Documents/work/project-abc/project-notes.txt ./.bash_logout ./.bashrc ./Videos ./.bash_profile ./.vimrc ./Pictures ./Pictures/trees.png ./Pictures/wallpaper.png ./notes.txt ./Music 但是 find 真正强大的是你可以使用文件名进行搜索： $ find -name do-things.sh ./Documents/work/project-abc/do-things.sh 或者仅仅是名字的一部分 —— 像是文件后缀。我们来找一下所有的 .txt 文件： $ find -name \"*.txt\" ./Documents/secret/christmas-presents.txt ./Documents/notes.txt ./Documents/work/status-reports.txt ./Documents/work/project-abc/project-notes.txt ./notes.txt 你也可以根据大小寻找文件。如果你的空间不足的时候，这种方法也许特别有用。现在来列出所有大于 1 MB 的文件： $ find -size +1M ./Pictures/trees.png ./Pictures/wallpaper.png 当然也可以搜索一个具体的目录。假如我想在我的 Documents 文件夹下找一个文件，而且我知道它的名字里有 “project” 这个词： $ find Documents -name \"*project*\" Documents/work/project-abc Documents/work/project-abc/project-notes.txt 除了文件它还显示目录。你可以限制仅搜索查询文件： $ find Documents -name \"*project*\" -type f Documents/work/project-abc/project-notes.txt 最后再一次，find 还有很多供你使用的选项，要是你想使用它们，man 手册页绝对可以帮到你： $ man find 参考资料 -命令行快速技巧：如何定位一个文件","tags":[{"name":"技巧","slug":"技巧","permalink":"http://www.jifu.io/tags/技巧/"},{"name":"find","slug":"find","permalink":"http://www.jifu.io/tags/find/"},{"name":"定位","slug":"定位","permalink":"http://www.jifu.io/tags/定位/"},{"name":"命令","slug":"命令","permalink":"http://www.jifu.io/tags/命令/"}],"categories":[{"name":"OPS","slug":"OPS","permalink":"http://www.jifu.io/categories/OPS/"},{"name":"command","slug":"OPS/command","permalink":"http://www.jifu.io/categories/OPS/command/"}]},{"title":"yum提示Error: rpmdb open failed的解决方案","date":"2019-02-19T04:57:25.000Z","path":"posts/4057676473/","text":"出错信息rpmdb: /var/lib/rpm/__db.003: No such file or directory error: db3 error(2) from dbenv->open: No such file or directory Segmentation fault 出错原因 这多半是因为rpm数据库出现损坏所致，此错误可能导致多数(甚至是所有的)rpm软件的升级、安装甚至是删除都会出现问题。 解决方案方案1 - 重建rpm数据库[root@www rpm]# rm -f __db.* # 清除原rpmdb文件 [root@www rpm]# rpm --rebuilddb # 重建rpm数据库 [root@www rpm]# yum clean all # 清除所有yum的缓存 方案2 - 手动清理数据库[root@www~]# cd /var/lib/rpm # rpmdb所在目录 [root@www rpm]# ls | grep ‘db.‘ # 列出相关rpmdb文件 __db.001 __db.002 __db.003 __db.004 [root@www rpm]# for i in $(ls | grep ‘db.‘);do mv $i $i.bak;done # 将原rpmdb文件都更名为结尾带.bak的文件或者 参考资料 -使用yum提示Error: rpmdb open failed的解决方案","tags":[{"name":"error","slug":"error","permalink":"http://www.jifu.io/tags/error/"},{"name":"CentOS","slug":"CentOS","permalink":"http://www.jifu.io/tags/CentOS/"},{"name":"yum","slug":"yum","permalink":"http://www.jifu.io/tags/yum/"},{"name":"rpmdb","slug":"rpmdb","permalink":"http://www.jifu.io/tags/rpmdb/"},{"name":"open failed","slug":"open-failed","permalink":"http://www.jifu.io/tags/open-failed/"}],"categories":[{"name":"OPS","slug":"OPS","permalink":"http://www.jifu.io/categories/OPS/"},{"name":"Linux","slug":"OPS/Linux","permalink":"http://www.jifu.io/categories/OPS/Linux/"},{"name":"CentOS","slug":"OPS/Linux/CentOS","permalink":"http://www.jifu.io/categories/OPS/Linux/CentOS/"}]},{"title":"如何查看 macOS 系统日志，辅助排除应用程序和系统故障","date":"2019-02-18T09:35:23.000Z","path":"posts/646546052/","text":"macOS 保留的「系统日志」可以帮助用户诊断和解决 macOS 系统本身和所安装应用程序的各种问题。「系统日志」以纯文本文件的形式存储在 Mac 系统驱动器当中，而且系统还附带了「控制台」应用辅助用户对系统日志进行查看和分析。 在「控制台」应用中查看 macOS 系统日志要查看 macOS 系统日志需要用到系统自带的「控制台」应用程序，您可以通过 ⌘Command + 空格 快捷键——使用 Spotlight 搜索「控制台」之后回车打开它。也可以在「访达」——「应用程序」——「实用工具」当找到并打开「控制台」应用程序。 其实 macOS 中的「控制台」应用就相当于 Windows 系统中的「eventvwr.msc，事件查看器」 默认情况下，您可以在「控制台」中查看到不断刷新的设备消息列表（全部信息），也可以在「工具栏」的「操作」菜单中选择仅查看「错误和故障」（⌘ 2 快键）信息。如果有明确的导向，在「搜索框」中直接搜索需要的信息则更为方便快捷。 「控制台」左侧的「报告」条目下分类了更多日志，如果要查看应用程序崩溃和冻结日志，可以直接点击「系统报告」，或用户应用程序的「用户报告」。在此您将看到各种带有 .crash、.diag 或 .spin 等扩展名的日志文件，单击它们就可以在「信息空格」中查看详细信息。 例如，需要了解有关应用程序在 macOS 系统中崩溃原因的更多信息，就可以在此处找到相关原因，开发人员也可以借助这些信息来修复应用程序问题。 如果要查看系统日志文件，可以点击左侧 system.log；如果要浏览特定应用程序日志，也可以选择「报告」条目下的其它日志分类文件夹。其中 ~Library/Logs 是您当前 Mac 用户账户的应用程序日志文件夹、/Library/Logs 是系统范围的应用程序日志文件夹，而 /var/log 文件夹主要用于存储低层级系统服务的相关日志信息。 如果您需要将日志导出给专业人员进行排错，可以将系统日志复制到文本文件。先全选需要复制的日志内容——点击「工具栏」中的「编辑」菜单——选择「拷贝 ⌘ C」，就可以将日志内容复制到剪贴板。 在磁盘上查找 macOS 日志文件当然，您也可以使用最直接的方式，在磁盘中查找 macOS 日志的纯文本文件，在其它文本编辑器中进行查看。macOS 系统的主要日志文件都存储于如下位置： 系统日志文件夹 /var/log 系统日志文件 /var/log/system.log Mac 分析数据 /var/log/DiagnosticMessages 系统应用程序日志 /Library/Logs 系统报告 /Library/Logs/DiagnosticReports 用户应用程序日志 ~/Library/Logs 用户报告 ~/Library/Logs/DiagnosticReports 为了方便访问这些系统日志，您还可以在「控制台」应用程序左侧通过按住 ⌃Control 键单击或者右击任意日志分类，选择「在访达中显示」就可以直达日志文件目录。 参考资料 -如何查看 macOS 系统日志，辅助排除应用程序和系统故障","tags":[{"name":"MacOS","slug":"MacOS","permalink":"http://www.jifu.io/tags/MacOS/"},{"name":"日志","slug":"日志","permalink":"http://www.jifu.io/tags/日志/"},{"name":"排查","slug":"排查","permalink":"http://www.jifu.io/tags/排查/"}],"categories":[{"name":"OPS","slug":"OPS","permalink":"http://www.jifu.io/categories/OPS/"},{"name":"MacOS","slug":"OPS/MacOS","permalink":"http://www.jifu.io/categories/OPS/MacOS/"}]},{"title":"MACOS BOOT CAMP – THE STARTUP DISK DOES NOT HAVE ENOUGH SPACE TO BE PARTITIONED","date":"2019-01-11T14:35:46.000Z","path":"posts/662287335/","text":"When using Boot Camp in macOS, you may get a “The startup disk does not have enough space to be partitioned” The error additionally displays “You must have at least 40 GB of free space available.” below that. ENOUGH FREE SPACEIt would make sense if there wasn’t enough free space on the startup disk but in my case for example, I have more than enough space: The startup disk does not have enough space to be partitioned HOW TO FIX “THE STARTUP DISK DOES NOT HAVE ENOUGH SPACE TO BE PARTITIONED”The culprit is the macOS Time Machine software causing the error message. Resolving the problem is quick and easy, follow these steps: TURN OFF TIME MACHINEFirst go to System Preferences &gt; Time Machine. Turn off “Back Up Automatically” and also remove the backup disk from Time Machine. Your Time Machine should look like this: The startup disk does not have enough space to be partitioned THIN LOCAL SNAPSHOTSIn addition to turning off Time Machine, you also need to thin your local snapshots. Open your Terminal and type or paste the following command: sudo tmutil thinlocalsnapshots / 999999999999 Type in your administrator password when prompted and hit Enter/Return to continue. When it finished running, you can reopen Boot Camp Assistant and try again, it should work fine now. 参考资料 -MACOS BOOT CAMP – THE STARTUP DISK DOES NOT HAVE ENOUGH SPACE TO BE PARTITIONED","tags":[{"name":"MacOS","slug":"MacOS","permalink":"http://www.jifu.io/tags/MacOS/"},{"name":"BootCamp","slug":"BootCamp","permalink":"http://www.jifu.io/tags/BootCamp/"},{"name":"双系统","slug":"双系统","permalink":"http://www.jifu.io/tags/双系统/"},{"name":"Error","slug":"Error","permalink":"http://www.jifu.io/tags/Error/"}],"categories":[{"name":"OPS","slug":"OPS","permalink":"http://www.jifu.io/categories/OPS/"},{"name":"MacOS","slug":"OPS/MacOS","permalink":"http://www.jifu.io/categories/OPS/MacOS/"}]},{"title":"利用Jenkins持续集成iOS项目","date":"2019-01-05T02:50:39.000Z","path":"posts/388825549/","text":"前言众所周知，现在App的竞争已经到了用户体验为王，质量为上的白热化阶段。用户们都是很挑剔的。如果一个公司的推广团队好不容易砸了重金推广了一个APP，好不容易有了一些用户，由于一次线上的bug导致一批的用户在使用中纷纷出现闪退bug，轻则，很可能前期推广砸的钱都白费了，重则，口碑不好，未来也提升不起用户量来了。静下心来分析一下问题的原因，无外乎就是质量没有过关就上线了。除去主观的一些因素，很大部分的客观因素我觉得可以被我们防范的。根据大神们提出的一套开发规范建议，CI + FDD，就可以帮助我们极大程度的解决客观因素。本文接下来主要讨论 Continuous Integration 持续集成（简称CI） 目录1.为什么我们需要持续集成2.持续化集成工具——Jenkins3.iOS自动化打包命令——xcodebuild + xcrun 和 fastlane - gym 命令4.打包完成自动化上传 fir / 蒲公英 第三方平台5.完整的持续集成流程6.Jenkins + Docker 为什么我们需要持续集成谈到为什么需要的问题，我们就需要从什么是来说起。那什么是持续集成呢。 持续集成是一种软件开发实践：许多团队频繁地集成他们的工作，每位成员通常进行日常集成，进而每天会有多种集成。每个集成会由自动的构建（包括测试）来尽可能快地检测错误。许多团队发现这种方法可以显著的减少集成问题并且可以使团队开发更加快捷。 CI是一种开发实践。实践应该包含3个基本模块，一个可以自动构建的过程，自动编译代码，可以自动分发，部署和测试。一个代码仓库，SVN或者Git。最后一个是一个持续集成的服务器。通过持续集成，可以让我们通过自动化等手段高频率地去获取产品反馈并响应反馈的过程。 那么持续集成能给我们带来些什么好处呢？这里推荐一篇文章，文章中把Continuous integration (CI) and test-driven development (TDD)分成了12个步骤。然而带来的好处成倍增加，有24点好处。 我来说说用了CI以后带来的一些深有体会的优点1. 缩减开发周期，快速迭代版本每个版本开始都会估算好开发周期，但是总会因为各种事情而延期。这其中包括了一些客观因素。由于产品线增多，迭代速度越来越快，给测试带来的压力也越来越大。如果测试都在开发完全开发完成之后再来测试，那就会影响很长一段时间。这时候由于集成晚就会严重拖慢项目节奏。如果能尽早的持续集成，尽快进入上图的12步骤的迭代环中，就可以尽早的暴露出问题，提早解决，尽量在规定时间内完成任务。 2. 自动化流水线操作带来的高效其实打包对于开发人员来说是一件很耗时，而且没有很大技术含量的工作。如果开发人员一多，相互改的代码冲突的几率就越大，加上没有产线管理机制，代码仓库的代码质量很难保证。团队里面会花一些时间来解决冲突，解决完了冲突还需要自己手动打包。这个时候如果证书又不对，又要耽误好长时间。这些时间其实可以用持续集成来节约起来的。一天两天看着不多，但是按照年的单位来计算，可以节约很多时间！ 3. 随时可部署有了持续集成以后，我们可以以天为单位来打包，这种高频率的集成带来的最大的优点就是可以随时部署上线。这样就不会导致快要上线，到处是漏洞，到处是bug，手忙脚乱弄完以后还不能部署，严重影响上线时间。 4. 极大程度避免低级错误我们可以犯错误，但是犯低级错误就很不应该。这里指的低级错误包括以下几点：编译错误，安装问题，接口问题，性能问题。以天为单位的持续集成，可以很快发现编译问题，自动打包直接无法通过。打完包以后，测试扫码无法安装，这种问题也会立即被暴露出来。接口问题和性能问题就有自动化测试脚本来发现。这些低级问题由持续集成来暴露展现出来，提醒我们避免低级错误。 持续化集成工具——JenkinsJenkins 是一个开源项目，提供了一种易于使用的持续集成系统，使开发者从繁杂的集成中解脱出来，专注于更为重要的业务逻辑实现上。同时 Jenkins 能实施监控集成中存在的错误，提供详细的日志文件和提醒功能，还能用图表的形式形象地展示项目构建的趋势和稳定性。 根据官方定义，Jenkins有以下的用途： 1.构建项目2.跑测试用例检测bug3.静态代码检测4.部署 关于这4点，实际使用中还是比较方便的： 1.构建项目自动化打包可以省去开发人员好多时间，重要的是，Jenkins为我们维护了一套高质量可用的代码，而且保证了一个纯净的环境。我们经常会出现由于本地配置出错而导致打包失败的情况。现在Jenkins就是一个公平的评判者，它无法正确的编译出ipa，那就是有编译错误或者配置问题。开发人员没必要去争论本地是可以运行的，拉取了谁谁谁的代码以后就不能运行了。共同维护Jenkins的正常编译，因为Jenkins的编译环境比我们本地简单的多，它是最纯净无污染的编译环境。开发者就只用专注于编码。这是给开发者带来的便利。 2.这个可以用来自动化测试。在本地生成大批的测试用例。每天利用服务器不断的跑这些用例。每天每个接口都跑一遍。看上去没必要，但是实际上今天运行正常的系统，很可能由于今天的代码改动，明天就出现问题了。有了Jenkins可以以天为单位的进行回归测试，代码只要有改动，Jenkins就把所有的回归测试的用例全部都跑一遍。在项目工期紧张的情况下，很多情况测试都不是很重视回归测试，毕竟很可能测一遍之后是徒劳的“无用功”。然而由于回归测试不及时，就导致到最后发版的时候系统不可用了，这时候回头查找原因是比较耗时的，查看提交记录，看到上百条提交记录，排查起来也是头疼的事情。以天为单位的回归测试能立即发现问题。测试人员每天可以专注按单元测试，一周手动一次回归测试。这是给测试者带来的便利。 3.这个是静态代码分析，可以检测出很多代码的问题，比如潜在的内存泄露的问题。由于Jenkins所在环境的纯净，还是可以发现一些我们本地复杂环境无法发现的问题，进一步的提高代码质量。这是给质检带来的便利。 4.随时部署。Jenkins在打包完成之后可以设定之后的操作，这个时候往往就是提交app到跑测试用例的系统，或者部署到内测平台生成二维码。部署中不能安装等一些低级问题随之立即暴露。测试人员也只需要扫一下二维码即可安装，很方便。这也算是给测试带来的便利。 以下的例子以2016-07-24 22:35的Weekly Release 2.15的版本为例。我们来开始安装Jenkins。从官网https://jenkins.io/上下载最新的pkg安装包。 也可以下载jenkins.war, 然后运行Java -jar jenkins.war，进行安装。安装完成之后，Safari可能会自动打开，如果没有自动打开，打开浏览器，输入http://localhost:8080 这个时候可能会报一个错误。如果出现了这面的问题。出现这个问题的原因就是Java环境有问题，重新Java环境即可。这个时候如果你重启电脑会发现Jenkins给你新增了一个用户，名字就叫Jenkins，不过这个时候你不知道密码。你可能会去试密码，肯定是是不对的，因为初始密码很复杂。这个时候正确做法是打开http://localhost:8080会出现下图的重设初始密码的界面。 按照提示，找到/Users/Shared/Jenkins/Home/这个目录下，这个目录虽然是共享目录，但是有权限的，非Jenkins用户/secrets/目录是没有读写权限的。 打开initialAdminPassword文件，复制出密码，就可以填到网页上去重置密码了。如下图 一路安装过来，输入用户名，密码，邮件这些，就算安装完成了。还是继续登录localhost:8080，选择“系统管理”——“管理插件”，我们要先安装一些辅助插件。 安装GitLab插件因为我们用的是GitLab来管理源代码，Jenkins本身并没有自带GitLab插件，所以我们需要依次选择 系统管理-&gt;管理插件，在“可选插件”中选中“GitLab Plugin”和“Gitlab Hook Plugin”这两项，然后安装。 安装Xcode插件同安装GitLab插件的步骤一样，我们依次选择系统管理-&gt;管理插件，在“可选插件”中选中“Xcode integration”安装。 安装完了这个，我们就可以配置一个构建项目了。 点击新建好的项目，进来配置一下General参数。 这里可以设置包的保留天数还有天数。 接着设置源码管理由于现在我用到的是GitLab，先配置SSH Key，在Jenkins的证书管理中添加SSH。在Jenkins管理页面，选择“Credentials”，然后选择“Global credentials (unrestricted)”，点击“Add Credentials”，如下图所示，我们填写自己的SSH信息，然后点击“Save”，这样就把SSH添加到Jenkins的全局域中去了。 如果正常的配置正确的话，是不会出现下图中的那段红色的警告。如果有下图的提示，就说明Jenkins还没有连通GitLab或者SVN，那就请再检查SSH Key是否配置正确。 构建触发器设置这里是设置自动化测试的地方。这里涉及的内容很多，暂时我也没有深入研究，这里暂时先不设置。有自动化测试需求的可以好好研究研究这里的设置。不过这里有两个配置还是需要是配置的Poll SCM (poll source code management) 轮询源码管理需要设置源码的路径才能起到轮询的效果。一般设置为类似结果： 0/5 * * * * 每5分钟轮询一次Build periodically (定时build)一般设置为类似： 00 20 * * * 每天 20点执行定时build 。当然两者的设置都是一样可以通用的。格式是这样的分钟(0-59) 小时(0-23) 日期(1-31) 月(1-12) 周几(0-7,0和7都是周日) 更加详细的设置看这里 构建环境设置iOS打包需要签名文件和证书，所以这部分我们勾选“Keychains and Code Signing Identities”和“Mobile Provisioning Profiles”。这里我们又需要用到Jenkins的插件，在系统管理页面，选择“Keychains and Provisioning Profiles Management”。 进入Keychains and Provisioning Profiles Management页面，点击“浏览”按钮，分别上传自己的keychain和证书。上传成功后，我们再为keychain指明签名文件的名称。点击“Add Code Signing Identity”，最后添加成功后如下图所示： 注意：我第一次导入证书和Provisioning Profiles文件，就遇到了一点小“坑”，我当时以为是需要证书，但是这里需要的Keychain，并不是cer证书文件。这个Keychain其实在/Users/管理员用户名/Library/keychains/login.keychain,当把这个Keychain设置好了之后，Jenkins会把这个Keychain拷贝到/Users/Shared/Jenkins/Library/keychains这里，(Library是隐藏文件)。Provisioning Profiles文件也直接拷贝到/Users/Shared/Jenkins/Library/MobileDevice文件目录下。 这样Adhoc证书和签名文件就在Jenkins中配置好了，接下来我们只需要在item设置中指定相关文件即可。回到我们新建的item，找到构建环境，按下图选好自己的相关证书和签名文件。 接下来在进行构建的设置 我们这里选择执行一段打包脚本。脚本在下一章节详细的讲解。 构建后操作这里我们选择Execute a set of scripts，这里也是一个脚本，这个脚本用来上传自动打包好的ipa文件。脚本在第四章节有详细的讲解。至此，我们的Jenkins设置就全部完成了。点击构建，就会开始构建项目了。构建一次，各个颜色代表的意义如下： 天气的晴雨表代表了项目的质量，这也是Jenkins的一个特色。 如果构建失败了，可以去查看Console Output可以查看log日志。 iOS自动化打包命令——xcodebuild + xcrun 和 fastlane - gym 命令在日常开发中，打包是最后上线不可缺少的环节，如果需要把工程打包成 ipa 文件，通常的做法就是在 Xcode 里点击 「Product -&gt; Archive」，当整个工程 archive 后，然后在自动弹出的 「Organizer」 中进行选择，根据需要导出 ad hoc，enterprise 类型的 ipa 包。虽然Xcode已经可以很完美的做到打包的事情，但是还是需要我们手动点击5，6下。加上我们现在需要持续集成，用打包命令自动化执行就顺其自然的需要了。 1. xcodebuild + xcrun命令Xcode为我们开发者提供了一套构建打包的命令，就是xcodebuild和xcrun命令。xcodebuild把我们指定的项目打包成.app文件，xcrun将指定的.app文件转换为对应的.ipa文件。具体的文档如下， xcodebuild官方文档、xcrun官方文档 NAME xcodebuild – build Xcode projects and workspaces SYNOPSIS 1. xcodebuild [-project name.xcodeproj] [[-target targetname] … | -alltargets] [-configuration configurationname] [-sdk [sdkfullpath | sdkname]] [action …] [buildsetting=value …] [-userdefault=value …] 2. xcodebuild [-project name.xcodeproj] -scheme schemename [[-destination destinationspecifier] …] [-destination-timeout value] [-configuration configurationname] [-sdk [sdkfullpath | sdkname]] [action …] [buildsetting=value …] [-userdefault=value …] 3. xcodebuild -workspace name.xcworkspace -scheme schemename [[-destination destinationspecifier] …] [-destination-timeout value] [-configuration configurationname] [-sdk [sdkfullpath | sdkname]] [action …] [buildsetting=value …] [-userdefault=value …] 4. xcodebuild -version [-sdk [sdkfullpath | sdkname]] [infoitem] 5. xcodebuild -showsdks 6. xcodebuild -showBuildSettings [-project name.xcodeproj | [-workspace name.xcworkspace -scheme schemename]] 7. xcodebuild -list [-project name.xcodeproj | -workspace name.xcworkspace] 8. xcodebuild -exportArchive -archivePath xcarchivepath -exportPath destinationpath -exportOptionsPlist path 9. xcodebuild -exportLocalizations -project name.xcodeproj -localizationPath path [[-exportLanguage language] …] 10. xcodebuild -importLocalizations -project name.xcodeproj -localizationPath path 上面10个命令最主要的还是前3个。接下来来说明一下参数：-project -workspace：这两个对应的就是项目的名字。如果有多个工程，这里又没有指定，则默认为第一个工程。-target：打包对应的targets，如果没有指定这默认第一个。-configuration：如果没有修改这个配置，默认就是Debug和Release这两个版本，没有指定默认为Release版本。-buildsetting=value ...：使用此命令去修改工程的配置。-scheme：指定打包的scheme。 上面这些是最最基本的命令。 上面10个命令的第一个和第二个里面的参数，其中 -target和 -configuration 参数可以使用 xcodebuild -list获得，-sdk 参数可由 xcodebuild -showsdks获得，[buildsetting=value …] 用来覆盖工程中已有的配置。可覆盖的参数参考官方文档Xcode Build Setting Reference。 build Build the target in the build root (SYMROOT). This is the default action, and is used if no action is given. analyze Build and analyze a target or scheme from the build root (SYMROOT). This requires specifying a scheme. archive Archive a scheme from the build root (SYMROOT). This requires specifying a scheme. test Test a scheme from the build root (SYMROOT). This requires specifying a scheme and optionally a destination. installsrc Copy the source of the project to the source root (SRCROOT). install Build the target and install it into the target’s installation directory in the distribution root (DSTROOT). clean Remove build products and intermediate files from the build root (SYMROOT). 上面第3个命令就是专门用来打带有Cocopods的项目，因为这个时候项目工程文件不再是xcodeproj了，而是变成了xcworkspace了。 再来说说xcrun命令。 Usage: PackageApplication [-s signature] application [-o output_directory] [-verbose] [-plugin plugin] || -man || -help Options: [-s signature]: certificate name to resign application before packaging [-o output_directory]: specify output filename [-plugin plugin]: specify an optional plugin -help: brief help message -man: full documentation -v[erbose]: provide details during operation 参数不多，使用方法也很简单，xcrun -sdk iphoneos -v PackageApplication + 上述一些参数。 参数都了解之后，我们就来看看该如何用了。下面这个是使用了xcodebuild + xcrun命令写的自动化打包脚本 # 工程名 APP_NAME=\"YourProjectName\" # 证书 CODE_SIGN_DISTRIBUTION=\"iPhone Distribution: Shanghai ******* Co., Ltd.\" # info.plist路径 project_infoplist_path=\"./${APP_NAME}/Info.plist\" #取版本号 bundleShortVersion=$(/usr/libexec/PlistBuddy -c \"print CFBundleShortVersionString\" \"${project_infoplist_path}\") #取build值 bundleVersion=$(/usr/libexec/PlistBuddy -c \"print CFBundleVersion\" \"${project_infoplist_path}\") DATE=\"$(date +%Y%m%d)\" IPANAME=\"${APP_NAME}_V${bundleShortVersion}_${DATE}.ipa\" #要上传的ipa文件路径 IPA_PATH=\"$HOME/${IPANAME}\" echo ${IPA_PATH} echo \"${IPA_PATH}\">> text.txt //下面2行是没有Cocopods的用法 echo \"=================clean=================\" xcodebuild -target \"${APP_NAME}\" -configuration 'Release' clean echo \"+++++++++++++++++build+++++++++++++++++\" xcodebuild -target \"${APP_NAME}\" -sdk iphoneos -configuration 'Release' CODE_SIGN_IDENTITY=\"${CODE_SIGN_DISTRIBUTION}\" SYMROOT='$(PWD)' //下面2行是集成有Cocopods的用法 echo \"=================clean=================\" xcodebuild -workspace \"${APP_NAME}.xcworkspace\" -scheme \"${APP_NAME}\" -configuration 'Release' clean echo \"+++++++++++++++++build+++++++++++++++++\" xcodebuild -workspace \"${APP_NAME}.xcworkspace\" -scheme \"${APP_NAME}\" -sdk iphoneos -configuration 'Release' CODE_SIGN_IDENTITY=\"${CODE_SIGN_DISTRIBUTION}\" SYMROOT='$(PWD)' xcrun -sdk iphoneos PackageApplication \"./Release-iphoneos/${APP_NAME}.app\" -o ~/\"${IPANAME}\" 2. gym 命令说到gym，就要先说一下fastlane。fastlane是一套自动化打包的工具集，用 Ruby 写的，用于 iOS 和 Android 的自动化打包和发布等工作。gym是其中的打包命令。 fastlane 的官网看这里, fastlane 的 github 看这里 要想使用gym，先要安装fastlane。sudo gem install fastlane --verbose fastlane包含了我们日常编码之后要上线时候进行操作的所有命令。 deliver：上传屏幕截图、二进制程序数据和应用程序到AppStore snapshot：自动截取你的程序在每个设备上的图片 frameit：应用截屏外添加设备框架 pem：可以自动化地生成和更新应用推送通知描述文件 sigh：生成下载开发商店的配置文件 produce：利用命令行在iTunes Connect创建一个新的iOS app cert：自动创建iOS证书 pilot：最好的在终端管理测试和建立的文件 boarding：很容易的方式邀请beta测试 gym：建立新的发布的版本，打包 match：使用git同步你成员间的开发者证书和文件配置 scan：在iOS和Mac app上执行测试用例 整个发布过程可以用fastlane描述成下面这样 lane :appstore do increment_build_number cocoapods xctool snapshot sigh deliver frameit sh \"./customScript.sh\" slack end Ps：这里可能大家还会听过一个命令叫 xctoolxctool是官方xcodebuild命令的一个增强实现，输出的内容比xcodebuild直观可读得多。通过brew即可安装。 brew install xctool 使用gym自动化打包，脚本如下 #计时 SECONDS=0 #假设脚本放置在与项目相同的路径下 project_path=$(pwd) #取当前时间字符串添加到文件结尾 now=$(date +\"%Y_%m_%d_%H_%M_%S\") #指定项目的scheme名称 scheme=\"DemoScheme\" #指定要打包的配置名 configuration=\"Adhoc\" #指定打包所使用的输出方式，目前支持app-store, package, ad-hoc, enterprise, development, 和developer-id，即xcodebuild的method参数 export_method='ad-hoc' #指定项目地址 workspace_path=\"$project_path/Demo.xcworkspace\" #指定输出路径 output_path=\"/Users/your_username/Documents/\" #指定输出归档文件地址 archive_path=\"$output_path/Demo_${now}.xcarchive\" #指定输出ipa地址 ipa_path=\"$output_path/Demo_${now}.ipa\" #指定输出ipa名称 ipa_name=\"Demo_${now}.ipa\" #获取执行命令时的commit message commit_msg=\"$1\" #输出设定的变量值 echo \"===workspace path: ${workspace_path}===\" echo \"===archive path: ${archive_path}===\" echo \"===ipa path: ${ipa_path}===\" echo \"===export method: ${export_method}===\" echo \"===commit msg: $1===\" #先清空前一次build gym --workspace ${workspace_path} --scheme ${scheme} --clean --configuration ${configuration} --archive_path ${archive_path} --export_method ${export_method} --output_directory ${output_path} --output_name ${ipa_name} #输出总用时 echo \"===Finished. Total time: ${SECONDS}s===\" 打包完成自动化上传 fir / 蒲公英 第三方平台要上传到 fir / 蒲公英 第三方平台，都需要注册一个账号，获得token，之后才能进行脚本化操作。 自动化上传fir安装fir-clifir的命令行工具需要先装好ruby再执行gem install fir-cli 上传到firfir publish ${ipa_path} -T fir_token -c &quot;${commit_msg}&quot; 自动化上传蒲公英#蒲公英上的User Key uKey=\"7381f97070*****c01fae439fb8b24e\" #蒲公英上的API Key apiKey=\"0b27b5c145*****718508f2ad0409ef4\" #要上传的ipa文件路径 IPA_PATH=$(cat text.txt) rm -rf text.txt #执行上传至蒲公英的命令 echo \"++++++++++++++upload+++++++++++++\" curl -F \"file=@${IPA_PATH}\" -F \"uKey=${uKey}\" -F \"_api_key=${apiKey}\" http://www.pgyer.com/apiv1/app/upload 完整的持续集成流程经过上面的持续化集成，现在我们就拥有了如下完整持续集成的流程 Jenkins + Docker关于Jenkins的部署，其实是分以下两种： 单节点（Master）部署这种部署适用于大多数项目，其构建任务较轻，数量较少，单个节点就足以满足日常开发所需。 多节点(Master-Slave)部署通常规模较大，代码提交频繁（意味着构建频繁），自动化测试压力较大的项目都会采取这种部署结构。在这种部署结构下，Master通常只充当管理者的角色，负责任务的调度，slave节点的管理，任务状态的收集等工作，而具体的构建任务则会分配给slave节点。一个Master节点理论上可以管理的slave节点数是没有上限的，但通常随着数量的增加，其性能以及稳定性就会有不同程度的下降，具体的影响则因Master硬件性能的高低而不同。但是多节点部署又会有一些缺陷，当测试用例变得海量以后，会造成一些问题，于是有人设计出了下面这种部署结构，Jenkins + Docker 由于笔者现在的项目还处于单节点（Master）部署，关于多节点(Master-Slave)部署也没有实践经验，改进版本的Docker更是没有接触过，但是如果有这种海量测试用例，高压力的大量复杂的回归测试的需求的，那推荐大家看这篇文章。 参考资料 -手把手教你利用Jenkins持续集成iOS项目","tags":[{"name":"iOS","slug":"iOS","permalink":"http://www.jifu.io/tags/iOS/"},{"name":"Jenkins","slug":"Jenkins","permalink":"http://www.jifu.io/tags/Jenkins/"},{"name":"持久集成","slug":"持久集成","permalink":"http://www.jifu.io/tags/持久集成/"}],"categories":[{"name":"back-end","slug":"back-end","permalink":"http://www.jifu.io/categories/back-end/"},{"name":"Middle-ware","slug":"back-end/Middle-ware","permalink":"http://www.jifu.io/categories/back-end/Middle-ware/"},{"name":"Jenkins","slug":"back-end/Middle-ware/Jenkins","permalink":"http://www.jifu.io/categories/back-end/Middle-ware/Jenkins/"}]},{"title":"Charles从入门到精通","date":"2019-01-04T11:03:23.000Z","path":"posts/3746871293/","text":"Charles简介Charles 是在 Mac 下常用的网络封包截取工具，在做移动开发时，我们为了调试与服务器端的网络通讯协议，常常需要截取网络封包来分析。 Charles 通过将自己设置成系统的网络访问代理服务器，使得所有的网络访问请求都通过它来完成，从而实现了网络封包的截取和分析. 除了在做移动开发中调试端口外，Charles 也可以用于分析第三方应用的通讯协议。配合 Charles 的 SSL 功能，Charles 还可以分析 Https 协议。 Charles 是收费软件，可以免费试用 30 天。试用期过后，未付费的用户仍然可以继续使用，但是每次使用时间不能超过 30 分钟，并且启动时将会有 10 秒种的延时。因此，该付费方案对广大用户还是相当友好的，即使你长期不付费，也能使用完整的软件功能。只是当你需要长时间进行封包调试时，会因为 Charles 强制关闭而遇到影响。 Charles 主要的功能包括:1.截取 Http 和 Https 网络封包。2.支持重发网络请求，方便后端调试。3.支持修改网络请求参数。4.支持网络请求的截获并动态修改。5.支持模拟慢速网络。 Charles 4 新增的主要功能包括：1.支持 Http 2。2.支持 IPv6。 安装 Charles去Charles官方网站下载最新版的 Charles 安装包，是一个 dmg 后缀的文件。打开后将 Charles 拖到 Application 目录下即完成安装。 将 Charles 设置成系统代理之前提到，Charles 是通过将自己设置成代理服务器来完成封包截取的，所以使用 Charles 的第一步是将其设置成系统的代理服务器。 启动 Charles 后，第一次 Charles 会请求你给它设置系统代理的权限。你可以输入登录密码授予 Charles 该权限。你也可以忽略该请求，然后在需要将 Charles 设置成系统代理时，选择菜单中的 “Proxy” -&gt; “Mac OS X Proxy” 来将 Charles 设置成系统代理。如下所示： 之后，你就可以看到源源不断的网络请求出现在 Charles 的界面中。 需要注意的是，Chrome 和 Firefox 浏览器默认并不使用系统的代理服务器设置，而 Charles 是通过将自己设置成代理服务器来完成封包截取的，所以在默认情况下无法截取 Chrome 和 Firefox 浏览器的网络通讯内容。如果你需要截取的话，在 Chrome 中设置成使用系统的代理服务器设置即可，或者直接将代理服务器设置成 127.0.0.1:8888 也可达到相同效果。 Charles 主界面介绍 Charles 主要提供两种查看封包的视图，分别名为 “Structure” 和 “Sequence”。 1.Structure 视图将网络请求按访问的域名分类。2.Sequence 视图将网络请求按访问的时间排序。 大家可以根据具体的需要在这两种视图之前来回切换。请求多了有些时候会看不过来，Charles 提供了一个简单的 Filter 功能，可以输入关键字来快速筛选出 URL 中带指定关键字的网络请求。 对于某一个具体的网络请求，你可以查看其详细的请求内容和响应内容。如果请求内容是 POST 的表单，Charles 会自动帮你将表单进行分项显示。如果响应内容是 JSON 格式的，那么 Charles 可以自动帮你将 JSON 内容格式化，方便你查看。如果响应内容是图片，那么 Charles 可以显示出图片的预览。 过滤网络请求通常情况下，我们需要对网络请求进行过滤，只监控向指定目录服务器上发送的请求。对于这种需求，以下几种办法：方法一：在主界面的中部的 Filter 栏中填入需要过滤出来的关键字。例如我们的服务器的地址是：http://yuantiku.com, 那么只需要在 Filter 栏中填入 yuantiku 即可。 方法二：在 Charles 的菜单栏选择 “Proxy”-&gt;”Recording Settings”，然后选择 Include 栏，选择添加一个项目，然后填入需要监控的协议，主机地址，端口号。这样就可以只截取目标网站的封包了。如下图所示： 通常情况下，我们使用方法一做一些临时性的封包过滤，使用方法二做一些经常性的封包过滤。 方法三：在想过滤的网络请求上右击，选择 “Focus”，之后在 Filter 一栏勾选上 Focussed 一项，如下图所示： 这种方式可以临时性的，快速地过滤出一些没有通过关键字的一类网络请求。 截取 iPhone 上的网络封包Charles 通常用来截取本地上的网络封包，但是当我们需要时，我们也可以用来截取其它设备上的网络请求。下面我就以 iPhone 为例，讲解如何进行相应操作。 Charles 上的设置要截取 iPhone 上的网络请求，我们首先需要将 Charles 的代理功能打开。在 Charles 的菜单栏上选择 “Proxy”-&gt;”Proxy Settings”，填入代理端口 8888，并且勾上 “Enable transparent HTTP proxying” 就完成了在 Charles 上的设置。如下图所示: iPhone 上的设置首先我们需要获取 Charles 运行所在电脑的 IP 地址，Charles 的顶部菜单的 “Help”-&gt;”Local IP Address”，即可在弹出的对话框中看到 IP 地址，如下图所示： 在 iPhone 的 “ 设置 “-&gt;” 无线局域网 “ 中，可以看到当前连接的 wifi 名，通过点击右边的详情键，可以看到当前连接上的 wifi 的详细信息，包括 IP 地址，子网掩码等信息。在其最底部有「HTTP 代理」一项，我们将其切换成手动，然后填上 Charles 运行所在的电脑的 IP，以及端口号 8888，如下图所示： 设置好之后，我们打开 iPhone 上的任意需要网络通讯的程序，就可以看到 Charles 弹出 iPhone 请求连接的确认菜单（如下图所示），点击 “Allow” 即可完成设置。 截取 Https 通讯信息安装证书如果你需要截取分析 Https 协议相关的内容。那么需要安装 Charles 的 CA 证书。具体步骤如下。 首先我们需要在 Mac 电脑上安装证书。点击 Charles 的顶部菜单，选择 “Help” -&gt; “SSL Proxying” -&gt; “Install Charles Root Certificate”，然后输入系统的帐号密码，即可在 KeyChain 看到添加好的证书。如下图所示： 需要注意的是，即使是安装完证书之后，Charles 默认也并不截取 Https 网络通讯的信息，如果你想对截取某个网站上的所有 Https 网络请求，可以在该请求上右击，选择 SSL proxy，如下图所示： 这样，对于该 Host 的所有 SSL 请求可以被截取到了。 截取移动设备中的 Https 通讯信息如果我们需要在 iOS 或 Android 机器上截取 Https 协议的通讯内容，还需要在手机上安装相应的证书。点击 Charles 的顶部菜单，选择 “Help” -&gt; “SSL Proxying” -&gt; “Install Charles Root Certificate on a Mobile Device or Remote Browser”，然后就可以看到 Charles 弹出的简单的安装教程。如下图所示： 按照我们之前说的教程，在设备上设置好 Charles 为代理后，在手机浏览器中访问地址：http://charlesproxy.com/getssl，即可打开证书安装的界面，安装完证书后，就可以截取手机上的 Https 通讯内容了。不过同样需要注意，默认情况下 Charles 并不做截取，你还需要在要截取的网络请求上右击，选择 SSL proxy 菜单项。 模拟慢速网络在做移动开发的时候，我们常常需要模拟慢速网络或者高延迟的网络，以测试在移动网络下，应用的表现是否正常。Charles 对此需求提供了很好的支持。 在 Charles 的菜单上，选择 “Proxy”-&gt;”Throttle Setting” 项，在之后弹出的对话框中，我们可以勾选上 “Enable Throttling”，并且可以设置 Throttle Preset 的类型。如下图所示： 如果我们只想模拟指定网站的慢速网络，可以再勾选上图中的 “Only for selected hosts” 项，然后在对话框的下半部分设置中增加指定的 hosts 项即可。 修改网络请求内容有些时候为了调试服务器的接口，我们需要反复尝试不同参数的网络请求。Charles 可以方便地提供网络请求的修改和重发功能。只需要在以往的网络请求上点击右键，选择 “Edit”，即可创建一个可编辑的网络请求。如下所示： 我们可以修改该请求的任何信息，包括 URL 地址、端口、参数等，之后点击 “Execute” 即可发送该修改后的网络请求（如下图所示）。Charles 支持我们多次修改和发送该请求，这对于我们和服务器端调试接口非常方便，如下图所示： 给服务器做压力测试我们可以使用 Charles 的 Repeat 功能来简单地测试服务器的并发处理能力，方法如下。 我们在想打压的网络请求上（POST 或 GET 请求均可）右击，然后选择 「Repeat Advanced」菜单项，如下所示： 接着我们就可以在弹出的对话框中，选择打压的并发线程数以及打压次数，确定之后，即可开始打压。 悄悄说一句，一些写得很弱的投票网站，也可以用这个办法来快速投票。当然，我也拿 Charles 的 Repeat 功能给一些诈骗的钓鱼网站喂了不少垃圾数据，上次不小心还把一个钓鱼网站的数据库打挂了，嗯，请叫我雷锋。 修改服务器返回内容有些时候我们想让服务器返回一些指定的内容，方便我们调试一些特殊情况。例如列表页面为空的情况，数据异常的情况，部分耗时的网络请求超时的情况等。如果没有 Charles，要服务器配合构造相应的数据显得会比较麻烦。这个时候，使用 Charles 相关的功能就可以满足我们的需求。 根据具体的需求，Charles 提供了 Map 功能、 Rewrite 功能以及 Breakpoints 功能，都可以达到修改服务器返回内容的目的。这三者在功能上的差异是： 1.Map 功能适合长期地将某一些请求重定向到另一个网络地址或本地文件。2.Rewrite 功能适合对网络请求进行一些正则替换。3.Breakpoints 功能适合做一些临时性的修改。 Map 功能Charles 的 Map 功能分 Map Remote 和 Map Local 两种，顾名思义，Map Remote 是将指定的网络请求重定向到另一个网址请求地址，Map Local 是将指定的网络请求重定向到本地文件。 在 Charles 的菜单中，选择 “Tools”-&gt;”Map Remote” 或 “Map Local” 即可进入到相应功能的设置页面。 对于 Map Remote 功能，我们需要分别填写网络重定向的源地址和目的地址，对于不需要限制的条件，可以留空。下图是一个示例，我将所有 ytk1.yuanku.ws（测试服务器）的请求重定向到了 www.yuantiku.com（线上服务器）。 对于 Map Local 功能，我们需要填写的重定向的源地址和本地的目标文件。对于有一些复杂的网络请求结果，我们可以先使用 Charles 提供的 “Save Response…” 功能，将请求结果保存到本地（如下图所示），然后稍加修改，成为我们的目标映射文件。 下图是一个示例，我将一个指定的网络请求通过 Map Local 功能映射到了本地的一个经过修改的文件中。 Map Local 在使用的时候，有一个潜在的问题，就是其返回的 Http Response Header 与正常的请求并不一样。这个时候如果客户端校验了 Http Response Header 中的部分内容，就会使得该功能失效。解决办法是同时使用 Map Local 以下面提到的 Rewrite 功能，将相关的 Http 头 Rewrite 成我们希望的内容。 Rewrite 功能Rewrite 功能功能适合对某一类网络请求进行一些正则替换，以达到修改结果的目的。 例如，我们的客户端有一个 API 请求是获得用户昵称，而我当前的昵称是 “tangqiaoboy”，如下所示： 我们想试着直接修改网络返回值，将 tangqiaoboy 换成成 iosboy。于是我们启用 Rewrite 功能，然后设置如下的规则： 完成设置之后，我们就可以从 Charles 中看到，之后的 API 获得的昵称被自动 Rewrite 成了 iosboy，如下图所示： Breakpoints 功能上面提供的 Rewrite 功能最适合做批量和长期的替换，但是很多时候，我们只是想临时修改一次网络请求结果，这个时候，使用 Rewrite 功能虽然也可以达到目的，但是过于麻烦，对于临时性的修改，我们最好使用 Breakpoints 功能。 Breakpoints 功能类似我们在 Xcode 中设置的断点一样，当指定的网络请求发生时，Charles 会截获该请求，这个时候，我们可以在 Charles 中临时修改网络请求的返回内容。 下图是我们临时修改获取用户信息的 API，将用户的昵称进行了更改，修改完成后点击 “Execute” 则可以让网络请求继续进行。 需要注意的是，使用 Breakpoints 功能将网络请求截获并修改过程中，整个网络请求的计时并不会暂停，所以长时间的暂停可能导致客户端的请求超时。 反向代理Charles 的反向代理功能允许我们将本地的端口映射到远程的另一个端口上。例如，在下图中，我将本机的 61234 端口映射到了远程（www.yuantiku.com）的80端口上了。这样，当我访问本地的 61234 端口时，实际返回的内容会由 www.yuantiku.com 的 80 端口提供。 设置外部代理，解决与翻墙软件的冲突Charles 的原理是把自己设置成系统的代理服务器，但是在中国，由于工作需要，我们常常需要使用 Google 搜索，所以大部分程序员都有自己的翻墙软件，而这些软件的基本原理，也是把自己设置成系统的代理服务器，来做到透明的翻墙。 为了使得两者能够和平共处，我们可以在 Charles 的 External Proxy Settings 中，设置翻墙的代理端口以及相关信息。同时，我们也要关闭相关翻墙软件的自动设置，使其不主动修改系统代理，避免 Charles 失效。 总结通过 Charles 软件，我们可以很方便地在日常开发中，截取和调试网络请求内容，分析封包协议以及模拟慢速网络。用好 Charles 可以极大的方便我们对于带有网络请求的 App 的开发和调试。 愿本文帮助大家成为 Charles 的专家，祝大家玩得开心～ 参考资料 -Charles 从入门到精通","tags":[{"name":"iOS","slug":"iOS","permalink":"http://www.jifu.io/tags/iOS/"},{"name":"Charles","slug":"Charles","permalink":"http://www.jifu.io/tags/Charles/"},{"name":"MacOS","slug":"MacOS","permalink":"http://www.jifu.io/tags/MacOS/"},{"name":"抓包","slug":"抓包","permalink":"http://www.jifu.io/tags/抓包/"},{"name":"Proxy","slug":"Proxy","permalink":"http://www.jifu.io/tags/Proxy/"}],"categories":[{"name":"OPS","slug":"OPS","permalink":"http://www.jifu.io/categories/OPS/"},{"name":"MacOS","slug":"OPS/MacOS","permalink":"http://www.jifu.io/categories/OPS/MacOS/"}]},{"title":"日志搜集处理框架Logstash-安装配置","date":"2019-01-04T10:43:23.000Z","path":"posts/2615120416/","text":"介绍Logstash是一款轻量级的日志搜集处理框架，可以方便的把分散的、多样化的日志搜集起来，并进行自定义的处理，然后传输到指定的位置，比如某个服务器或者文件。http://kibana.logstash.es/content/logstash/ 下载和安装下载地址https://www.elastic.co/downloads/logstash 1.方式一：TAR wget https://download.elastic.co/logstash/logstash/logstash-2.4.0.tar.gztar -zxvf logstash-2.4.0.tar.gz 2.方式二：deb curl -L -O https://download.elastic.co/logstash/logstash/packages/debian/logstash-2.4.0_all.debsudo dpkg -i logstash-2.4.0_all.deb 3.方式三：rpm curl -L -O https://download.elastic.co/logstash/logstash/packages/centos/logstash-2.4.0.noarch.rpmsudo rpm -vi logstash-2.4.0.noarch.rpm 配置创建配置目录先进入 Logstash 根目录mkdir -p etcvim etc/www.lanmps.com.conf etc/test.conf 文件内容 input { file { type => \"nginx-access\" path => [\"/www/wwwLogs/www.lanmps.com/*.log\"] start_position => \"beginning\" } } filter { grok { \"message\"=>\"%{IPORHOST:client_ip} %{USER:ident} %{USER:auth} \\[%{HTTPDATE:timestamp}\\] \\\"(?:%{WORD:verb} %{NOTSPACE:request}(?: HTTP/%{NUMBER:http_version})?|-)\\\" (%{HOSTNAME:domain}|-) %{NUMBER:response} (?:%{NUMBER:bytes}|-) (%{QS:referrer}) %{QS:agent} \\\"(%{WORD:x_forword}|-)\\\" (%{URIHOST:upstream_host}|-) (%{NUMBER:upstream_response}|-) (%{WORD:upstream_cache_status}|-) %{QS:upstream_content_type} (%{USERNAME:upstream_response_time}) > (%{USERNAME:response_time})\" #匹配模式 message是每段读进来的日志，IP、HTTPDATE、WORD、NOTSPACE、NUMBER都是patterns/grok-patterns中定义好的正则格式名称，对照上面的日志进行编写,冒号，(?:%{USER:ident}|-)这种形式是条件判断，相当于程序里面的二目运算。如果有双引号\"\"或者[]号，需要在前面加\\进行转义。 } kv { source => \"request\" field_split => \"&amp;?\" value_split => \"=\" } #再单独将取得的URL、request字段取出来进行key-value值匹配，需要kv插件。提供字段分隔符\"&amp;?\"，值键分隔符\"=\"，则会自动将字段和值采集出来。 urldecode { all_fields => true } #把所有字段进行urldecode（显示中文） } output { elasticsearch { hosts => [\"10.1.5.66:9200\"] index => \"logstash-%{type}-%{+YYYY.MM.dd}\" document_type => \"%{type}\" } } 配置说明 http://kibana.logstash.es/content/logstash/plugins/input/file.html Nginx 日志格式定义 log_format access '$remote_addr - $remote_user [$time_local] \"$request\" $http_host $status $body_bytes_sent \"$http_referer\" \"$http_user_agent\" \"$http_x_forwarded_for\" $upstream_addr $upstream_status $upstream_cache_status \"$upstream_http_content_type\" $upstream_response_time > $request_time'; Logstash启动和停止测试命令测试logstashbin/logstash -e &#39;input { stdin { } } output { stdout {codec=&gt;rubydebug} }&#39; 然后你会发现终端在等待你的输入。没问题，敲入 Hello World，回车，然后看看会返回什么结果！ 测试配置文件是否 正确bin/logstash -t -f etc/ 启动加载*.conf加载etc文件夹下所有 *.conf 的文本文件，然后在自己内存里拼接成一个完整的大配置文件 bin/logstash -f etc/ 后台运行nohup bin/logstash -f etc/ &amp; 停止查找进程 IDps -ef |grep logstashkill -9 id 高级配置http://kibana.logstash.es/content/logstash/get_start/full_config.htmlhttp://kibana.logstash.es/content/logstash/plugins/output/elasticsearch.html 插件安装http://www.jianshu.com/p/4fe495639a9a 插件grok,useragent,urldecode和kv插件功能./bin/logstash-plugin install kv ./bin/logstash-plugin install urldecode ./bin/logstash-plugin install grok ./bin/logstash-plugin install useragent 使用方式input { file { path => \"/home/vovo/access.log\" #指定日志目录或文件，也可以使用通配符*.log输入目录中的log文件。 start_position => \"beginning\" } } filter { grok { match => { \"message\"=>\"%{IPORHOST:client_ip} %{USER:ident} %{USER:auth} \\[%{HTTPDATE:timestamp}\\] \\\"(?:%{WORD:verb} %{NOTSPACE:request}(?: HTTP/%{NUMBER:http_version})?|-)\\\" (%{HOSTNAME:domain}|-) %{NUMBER:response} (?:%{NUMBER:bytes}|-) (%{QS:referrer}) %{QS:agent} \\\"(%{WORD:x_forword}|-)\\\" (%{URIHOST:upstream_host}|-) (%{NUMBER:upstream_response}|-) (%{WORD:upstream_cache_status}|-) %{QS:upstream_content_type} (%{USERNAME:upstream_response_time}) > (%{USERNAME:response_time})\" } } kv { source => \"request\" field_split => \"&amp;?\" value_split => \"=\" } #再单独将取得的URL、request字段取出来进行key-value值匹配，需要kv插件。提供字段分隔符\"&amp;?\"，值键分隔符\"=\"，则会自动将字段和值采集出来。 urldecode { all_fields => true } #把所有字段进行urldecode（显示中文） } 参考资料 -Logstash 日志搜集处理框架 安装配置","tags":[{"name":"logstash","slug":"logstash","permalink":"http://www.jifu.io/tags/logstash/"},{"name":"日志收集","slug":"日志收集","permalink":"http://www.jifu.io/tags/日志收集/"}],"categories":[{"name":"back-end","slug":"back-end","permalink":"http://www.jifu.io/categories/back-end/"},{"name":"Middle-ware","slug":"back-end/Middle-ware","permalink":"http://www.jifu.io/categories/back-end/Middle-ware/"},{"name":"Logstash","slug":"back-end/Middle-ware/Logstash","permalink":"http://www.jifu.io/categories/back-end/Middle-ware/Logstash/"}]},{"title":"Vim快捷键使用总结","date":"2019-01-04T10:35:49.000Z","path":"posts/3374749959/","text":"移动光标1.左移h、右移l、下移j、上移k2.向下翻页ctrl + f，向上翻页ctrl + b3.向下翻半页ctrl + d，向上翻半页ctrl + u4.移动到行尾$，移动到行首0（数字），移动到行首第一个字符处^5.移动光标到下一个句子 ），移动光标到上一个句子（6.移动到段首{，移动到段尾}7.移动到下一个词w，移动到上一个词b8.移动到文档开始gg，移动到文档结束G9.移动到匹配的{}.().[]处%10.跳到第n行 ngg 或 nG 或 :n11.移动光标到屏幕顶端H，移动到屏幕中间M，移动到底部L12.读取当前字符，并移动到本屏幕内下一次出现的地方 *13.读取当前字符，并移动到本屏幕内上一次出现的地方 # 查找替换1.光标向后查找关键字 #或者g#2.光标向前查找关键字 或者g3.当前行查找字符 fx, Fx, tx, Tx4.基本替换 :s/s1/s2 （将下一个s1替换为s2）5.全部替换 :%s/s1/s26.只替换当前行 :s/s1/s2/g7.替换某些行 :n1,n2 s/s1/s2/g8.搜索模式为 /string，搜索下一处为n，搜索上一处为N9.制定书签 mx, 但是看不到书签标记，而且只能用小写字母10.移动到某标签处 x，1旁边的键 11.移动到上次编辑文件的位置. 参考资料 -","tags":[{"name":"Linux","slug":"Linux","permalink":"http://www.jifu.io/tags/Linux/"},{"name":"Vim","slug":"Vim","permalink":"http://www.jifu.io/tags/Vim/"}],"categories":[{"name":"OPS","slug":"OPS","permalink":"http://www.jifu.io/categories/OPS/"},{"name":"Vim","slug":"OPS/Vim","permalink":"http://www.jifu.io/categories/OPS/Vim/"}]},{"title":"Mac OS系统加速：干掉那些「炫酷」的动画","date":"2019-01-04T09:54:13.000Z","path":"posts/1883980072/","text":"Mac OS 一直以其 UI 界面精美、交互动画炫酷著称，令人印象深刻。但随着使用的深入和操作的娴熟，我们慢慢会发现，有些动画效果略显冗长，反而增加了操作的响应时间，影响了流畅度方面的感受。针对这个问题，可以通过禁用一些动画效果来实现加速，下面列举一些常用的操作技巧： 关闭 Dock 程序聚焦闪烁动画这是一个很常见的操作，例如：移动一张图片到 Evernote 或者 移动一个文件到文件夹中。当文件聚焦在 App Icon 上时，App 的图标会快速闪烁两次，然后再打开窗口并置顶。Burst Link ~ 加速一下通过「空格 Space」键我们可以轻松加速这个过程：按住文件，拖动至 Dock 上的 App 或 文件夹上 快速敲击「空格键」可跳过动画触发，直接弹出对应程序界面 注：这是一个超高频操作，掌握之后，经常会用到。 关闭 文件快速预览动画还是「空格键」的事儿，在 打造高效的 Finder 「基础篇」一文中介绍了快速预览的用法：选中文件，同时敲击「空格键」，会触发一个扩大或缩放（关闭窗口时）的动画效果。Burst Link ~ 加速一下打开系统自带的终端程序（Terminal.app），复制并运行以下指令即可禁用动画效果：执行指令：defaults write com.apple.finder QLPanelAnimationDuration -int 0; killall Finder 还原指令：defaults delete com.apple.finder QLPanelAnimationDuration; killall Finder 关闭 Dock 新开程序图标跳动动画当我们首次点击 Dock 上某程序图标时，这个图标会跳动一下然后打开，略显调皮，如果你不喜欢，也可以如下操作禁用。Burst Link ~ 加速一下执行指令：defaults write com.apple.dock launchanim -boolean false; killall Dock 还原指令：defaults write com.apple.dock launchanim -boolean true; killall Dock 关闭 Dock 自动隐藏动画Dock 栏可以开启自动隐藏功能，然后通过鼠标指针撞击边缘的方式唤出，出现和隐藏都会有对应的动画，可以禁用之。Burst Link ~ 加速一下执行指令：defaults write com.apple.dock autohide-time-modifier -float 0; killall Dock 还原指令：defaults write com.apple.dock autohide-time-modifier -float 0.7; killall Dock 关闭鼠标唤起延迟另外，鼠标唤起的触发有一个延迟时间设置，当然也可以通过指令禁用，达到实时弹出的效果。关闭指令：（无延迟感）defaults write com.apple.Dock autohide-delay -float 0; killall Dock 还原指令：defaults delete com.apple.Dock autohide-delay; killall Dock 关闭 Mission Control 动画如之前在「你无法拒绝的 Mac 触发角」一文中介绍过鼠标指针撞击屏幕四角来触发 Mission Control 的方法，这个过程会有平滑的动画交互，同样也可以禁用来加速。 注：可以通过键盘上的 F3 键或者 四指上扫的手势 快速触发 Mission Control Burst Link ~ 加速一下执行指令：defaults write com.apple.dock expose-animation-duration -int 0; killall Dock 还原指令：defaults delete com.apple.dock expose-animation-duration; killall Dock 小结这里列出了几条最常用的优化脚本，可谓一劳永逸。经过以上的加速优化，Mac OS 在细节上的交互体验会变得更快捷、更流畅。当然，如果对于 Mac OS 的默认的交互动画持保留态度，那只要记住「敲空格键」可以加速动画执行 这一条就已经相当实用了。 参考资料 -Mac 加速：干掉那些「炫酷」的动画","tags":[{"name":"MacOS","slug":"MacOS","permalink":"http://www.jifu.io/tags/MacOS/"},{"name":"运维","slug":"运维","permalink":"http://www.jifu.io/tags/运维/"},{"name":"加速","slug":"加速","permalink":"http://www.jifu.io/tags/加速/"},{"name":"关闭动画","slug":"关闭动画","permalink":"http://www.jifu.io/tags/关闭动画/"}],"categories":[{"name":"OPS","slug":"OPS","permalink":"http://www.jifu.io/categories/OPS/"},{"name":"MacOS","slug":"OPS/MacOS","permalink":"http://www.jifu.io/categories/OPS/MacOS/"}]},{"title":"MySQL延迟复制","date":"2018-12-25T03:51:03.000Z","path":"posts/2625460784/","text":"什么是延迟复制延迟复制就是将 Slaves 节点与 Master 节点保持指定时间的复制间隔。所谓的延迟 ，只是对 SQL_Thread 的线程的延迟。IO_Thread 主库发生的任何操作的日志都会同步到 slave，也就是说 IO_Thread 线程和主库是没有延迟的。只是 SQL_Thread 与主库有延迟。只是执行时间延迟，而不是读取 binlog 时间延迟。 延迟复制使用场景 利用延迟复制做误操作恢复 提供 Master 节点意外错误的快速恢复机制，若 Master 节点出现误改、误删等操作，造成数据丢失的情况，由于 Slave 节点有延迟因素的存在，那么我们 DBA 可以通过 Slave 节点仍然保存的数据，快速地将之恢复回去。不过通常延迟时间不会太长，如果出现误操作，而且 Slave 节点恰好还没有应用这些事件，那就必须争分夺秒进行恢复才可以。 测试复制环境出现延迟时，评估对系统应用可能造成的影响。 启用延迟复制启用延迟复制非常简单，只需要指定 Slave 节点中 MASTER_DELAY 的选项值即可，语句如下： stop slave sql_thread; change master to master_delay=N; #N 单位秒 start slave; 设置完成之后，START SLAVE 就可以使之生效，无需重新启动 MySQL 服务。这样设置了之后，Slaves 节点接收到 Master 节点生成的二进制日志，不会马上应用，而是等待，直到时间符合设定的延迟条件后才开始应用。 延迟复制状态查看Slave 开通延迟复制后，Slave 节点应用状态如何，我们可以通过 SHOW SLAVE STATUS\\G 查看以下 3 个状态值即可。 SQL_Delay：显示当前设定的延迟时间，以秒为单位。SQL_Remaining_Delay: 当 Slave_SQL_Running_State 列的状态是“Waiting until MASTER_DELAY seconds after master executed event’’时，本列显示的值就是距离延迟阈值的时间，也就是说还有多长时间才能开始应用，否则本列值应该是 NULL。复制完成后没有可复制的 events 时这个值就是 NULL。Slave_SQL_Running_State: 该值显示的是当前 SQL_THREAD 的状态；该值一般会有两种情况：当 SQL_THREAD 没有处于延迟等待阶段时显示：Slave has read all relay log; waiting for more updates当 SQL_THREAD 处于延迟等待阶段，SHOW SLAVE STATUS\\G 或者 SHOW PROCESSLIST 显示该进程的状态将会是：Waiting until MASTER_DELAY seconds after master executed event 查看 slave 状态master状态mysql> show slave status\\G ......... SQL_Delay: 300 SQL_Remaining_Delay: 54 Slave_SQL_Running_State: Waiting until MASTER_DELAY seconds after master executed event .......... 说明一下：我设置的是 300 秒延迟复制，master_delay=30。所以上面显示 SQL_Delay：300 SQL_Remaining_Delay: 54 表示还有 54 秒后才可以应用 master 上执行的语句。 slave 状态:mysql> show slave status\\G SQL_Delay: 300 SQL_Remaining_Delay: NULL Slave_SQL_Running_State: Slave has read all relay log; waiting for more updates 怎么从延迟复制变为不延迟复制只需要把 master_delay 的值改为 0 即可。 mysql> stop slave sql_thread; mysql> change master to master_delay=0; mysql> start slave; 延迟复制恢复数据方法和步骤 库出现误操作后，首先我们把 sql_thread 线程停止执行，并把延迟复制 master_delay 这个值改为 0，表示取消延迟复制； mysql> stop slave sql_thread; mysql> change master to master_delay=0; 让 sql_thread 执行到出现问题之前停止； start slave sql_thread until master_log_file=&#39;xxxx&#39;,master_log_pos=&#39;xxxxx&#39;; 然后把 slave 库上恢复的数据使用 mysqldump 备份出来； 把 mysqldump 备份的数据导入到 master 库上； 到此数据恢复成功； 如果数据太大，例如 1TB 数据，我们应该怎么传输这些数据。我们可以使用 rsync 传输数据。 参考资料 -MySQL 延迟复制","tags":[{"name":"运维","slug":"运维","permalink":"http://www.jifu.io/tags/运维/"},{"name":"MySQL","slug":"MySQL","permalink":"http://www.jifu.io/tags/MySQL/"},{"name":"延迟复制","slug":"延迟复制","permalink":"http://www.jifu.io/tags/延迟复制/"}],"categories":[{"name":"back-end","slug":"back-end","permalink":"http://www.jifu.io/categories/back-end/"},{"name":"Middle-ware","slug":"back-end/Middle-ware","permalink":"http://www.jifu.io/categories/back-end/Middle-ware/"},{"name":"MySQL","slug":"back-end/Middle-ware/MySQL","permalink":"http://www.jifu.io/categories/back-end/Middle-ware/MySQL/"}]},{"title":"RabbitMQ入门","date":"2018-12-25T03:25:44.000Z","path":"posts/3135873234/","text":"前言刚开始接触RabbitMQ的时候，有些概念那理解起来简直是像风像雨又像雾，晦涩难懂。 这篇文章用尽可能浅显的语言来解释RabbitMQ的入门知识。毕竟是入门课程，并没有对很多概念进行深入说明，如果你想更深入的了解RabbitMQ，可以继续关注本头条号后续发布的文章或者自己从网上搜寻了资料，自己探索研究。 RabbitMQ是什么官方定义：RabbitMQ是一种消息中间件，用于处理来自客户端的异步消息。服务端将要发送的消息放入到队列池中。接收端可以根据RabbitMQ配置的转发机制接收服务端发来的消息。RabbitMQ依据指定的转发规则进行消息的转发、缓冲和持久化操作，主要用在多服务器间或单服务器的子系统间进行通信，是分布式系统标准的配置。 趣味定义：兔子行动非常迅速而且繁殖起来也非常疯狂，用Rabbit来命名这个分布式软件，呼应了RabbitMQ的主要任务是处理海量的信息 安装安装erlang下载地址：http://erlang.org/download/otp_win64_21.0.1.exe 安装rabbitmq下载地址：https://dl.bintray.com/rabbitmq/all/rabbitmq-server/3.7.7/rabbitmq-server-3.7.7.exe如果你要安装其它版本，注意版本对应：https://www.rabbitmq.com/which-erlang.html 开启web访问Windows下：打开CMD 进入rabbitmq的安装目录 执行rabbitmq-plugins enable rabbitmq_management命令.该命令，仅在首次运行RMQ时使用！！！目的就是加载Web插件！！！ 访问测试测试地址 http://localhost:15672/ 默认用户名：guest 默认密码：guest 核心概念&gt; https://content.pivotal.io/rabbitmq/understanding-when-to-use-rabbitmq-or-apache-kafka RabbitMQ broker: 原话是RabbitMQ isn’t a food truck, it’s a delivery service，其实说白了，就是一种传输服务。Exchange: 接受生产者发送的消息，并根据Binding规则将消息路由给服务器中的队列。ExchangeType决定了Exchange路由消息的行为。在RabbitMQ中，ExchangeType常用的有direct、Fanout和Topic三种，在第三部分会详细介绍。Message Queue: 消息队列。我们发送给RabbitMQ的消息最后都会到达各种queue，并且存储在其中(如果路由找不到相应的queue则数据会丢失)，等待消费者来取。Binding Key：它表示的是Exchange与Message Queue是通过binding key进行联系的，这个关系是固定的，初始化的时候，我们就会建立该队列。Routing Key：生产者在将消息发送给Exchange的时候，一般会指定一个routing key，来指定这个消息的路由规则。这个routing key需要与Exchange Type及binding key联合使用才能生，我们的生产者只需要通过指定routing key来决定消息流向哪里。 我的注释：初始化的时候，exchange与各个队列的绑定关系是通过binding key进行绑定的；发送消息的时候，使用的routing key就是binding key的某一个（实质，两者是一个含义，角度不同，名称含义不同） 对于消费端来说，只用知道MQ的virtual host 和queue的名称就可以了。而对于发送端，则需要知道exchange和routing key的名称，相对而言queue的名称就不那么重要了（不过也要依Exchange Type而定）。以下是RabbitMQ最简单的流程图，相信看到这里的你，对MQ的运作流程应该会有个基本的了解了： 三种ExchangeType&gt; http://www.rabbitmq.com/tutorials/amqp-concepts.html &gt; 这里介绍三种最主要的类型的exchange：direct、fanout和topic。 direct交换器 Direct交换器很简单，如果是Direct类型，就会将消息中的RoutingKey与该Exchange关联的所有Binding中的BindingKey进行比较，如果相等，则发送到该Binding对应的Queue中。有一个需要注意的地方：如果找不到指定的exchange，就会报错。但routing key找不到的话，不会报错，这条消息会直接丢失，所以此处要小心。 fanout交换器 Fanout 扇出，顾名思义，就是像风扇吹面粉一样，吹得到处都是。如果使用fanout类型的exchange，那么routing key就不重要了。因为凡是绑定到这个exchange的queue，都会受到消息。 topic交换器 direct是将消息放到exchange绑定的一个queue里（一对一）； fanout是将消息放到exchange绑定的所有queue里（一对所有） 那可不可以把消息放到exchange绑定的一部分queue里，或者多个routing key可以路由到一个queue里呢？ topic类型的exchange就可以实现（一对部分）。 topic应用场景：打印不同级别的错误日志 例如，我们的系统出错后会根据不同的错误级别生成error_levelX.log日志，我们在后台首先要把所有的error保存在一个总的queue（绑定了一个*.error的路由键）里，然后再按level分别存放在不同的queue。 routing key绑定 参考资料 -RabbitMQ 入门秘籍，三分钟带你快速了解RabbitMQ","tags":[{"name":"中间件","slug":"中间件","permalink":"http://www.jifu.io/tags/中间件/"},{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://www.jifu.io/tags/RabbitMQ/"}],"categories":[{"name":"back-end","slug":"back-end","permalink":"http://www.jifu.io/categories/back-end/"},{"name":"Middle-ware","slug":"back-end/Middle-ware","permalink":"http://www.jifu.io/categories/back-end/Middle-ware/"},{"name":"RabbitMQ","slug":"back-end/Middle-ware/RabbitMQ","permalink":"http://www.jifu.io/categories/back-end/Middle-ware/RabbitMQ/"}]},{"title":"Linux系统目录结构及详细说明","date":"2018-12-25T03:12:08.000Z","path":"posts/4070386720/","text":"比较重要的目录在 Linux 系统中，有几个目录是特别需要注意的，以下提供几个需要注意的目录，以及预设相关的用途`: /etc:这个目录相当重要，如前所述，你的开机与系统数据文件均在这个目录之下，因此当这个目录被破坏，那你的系统大概也就差不多该死掉了！而在往后的文件中，你会发现我们常常使用这个目录下的 /etc/rc.d/init.d 这个子目录，因为这个 init.d 子目录是开启一些 Linux 系统服务的 scripts （可以想成是批次檔 ）的地方。而在 /etc/rc.d/rc.local 这个文件是开机的执行档。 /bin, /sbin, /usr/bin, /usr/sbin:这是系统预设的执行文件的放置目录，例如 root 常常使用的 userconf, netconf, perl, gcc, c++ 等等的数据都放在这几个目录中，所以如果你在提示字符下找不到某个执行档时，可以在这四个目录中查一查！其中， /bin, /usr/bin 是给系统使用者使用的指令，而 /sbin, /usr/sbin 则是给系统管理员使用的指令！ /usr/local:这是系统预设的让你安装你后来升级的套件的目录。例如，当你发现有更新的 Web 套件（如 Apache ）可以安装，而你又不想以 rpm 的方式升级你的套件，则你可以将 apache 这个套件安装在 /usr/local 底下。安装在这里有个好处，因为目前大家的系统都是差不多的，所以如果你的系统要让别人接管的话，也比较容易上手呀！也比较容易找的到数据喔！因此，如果你有需要的话，通常我都会将 /usr/local/bin 这个路径加到我的 path 中。 /home:这个是系统将有账号的人口的家目录设置的地方。 /var:这个路径就重要了！不论是登入、各类服务的问题发生时的记录、以及常态性的服务记录等等的记录目录，所以当你的系统有问题时，就需要来这个目录记录的文件数据中察看问题的所在啰！而 mail 的预设放置也是在这里，所以他是很重要的 。 /usr/share/man, /usr/local/man: 这两个目录为放置各类套件说明档的地方，例如你如果执行 man man，则系统会自动去找这两个目录下的所有说明文件。 文件种类文件属性中最前面的标志 ( d 或 - ) 可以代表目录或文件，那就是不同的文件种类，Linux 的文件种类主要有底下这几种`: 正规文件( regular file ): 就是一般类型的文件，在由 ls –al 所显示出来的属性方面，第一个属性为 [ - ]。 另外，依照文件的内容，又大略可以分为两种文件种类`: 纯文字文件(ascii):这是 Unix 系统中最多的一种啰，几乎只要我们可以用来做为设定的文件都属于这一种； 二进制文件(binary):通常执行档除了 scripts （文字型批次文件）之外，就是这一种文件格式； 目录 (directory):就是目录！第一个属性为 [ d ]； 连结档 (link):就是类似 Windows 底下的快捷方式啦！第一个属性为 [ l ]； 设备档 (device):与系统周边相关的一些文件，通常都集中在 /dev 这个目录之下！通常又分为两种`: 区块 (block) 设备档:就是一些储存数据，以提供系统存取的接口设备，简单的说就是硬盘啦！例如你的一号硬盘的代码是 /dev/hda1 等等的文件啦！第一个属性为 [ b ]； 字符 (character) 设备档:亦即是一些串行端口的接口设备，例如键盘、鼠标等等！第一个属性为 [ c ]。 Linux 的文件系统( inode ): 在 Linux 系统当中，每个文件不止有文件的内容数据，还包括文件的种种属性，例如`:所属群组、所属使用者、能否执行、文件建立时间、文件特殊属性等等。我们将每个文件的内容分为两个部分来储存，一个是文件的属性，另一个则是文件的内容。 / 根目录下/:根目录，位于Linux文件系统目录结构的顶层，一般根目录下只存放目录，不要存放文件，/etc、/bin、/dev、/lib、/sbin应该和根目录放置在一个分区中。/bin，/usr/bin:该目录为命令文件目录，也称为二进制目录。包含了供系统管理员及普通用户使用的重要的linux命令和二进制（可执行）文件，包含shell解释器等。/boot: 该目录中存放系统的内核文件和引导装载程序文件，/boot/vmlinuz为linux的内核文件，以及/boot/gurb。建议单独分区，分区大小100M即可。/dev: 设备（device）文件目录，存放linux系统下的设备文件，访问该目录下某个文件，相当于访问某个设备，存放连接到计算机上的设备（终端、磁盘驱动器、光驱及网卡等）的对应文件，包括字符设备和块设备等，常用的是挂载光驱mount /dev/cdrom/mnt。/etc: 系统配置文件存放的目录，该目录存放系统的大部分配置文件和子目录，不建议在此目录下存放可执行文件，重要的配置文件有/etc/inittab、/etc/fstab、/etc/init.d、/etc/X11（X Window系统有关）、/etc/sysconfig（与网络有关）、/etc/xinetd.d修改配置文件之前记得备份。该目录下的文件由系统管理员来使用，普通用户对大部分文件有只读权限。/home: 系统默认的用户宿主目录，新增用户账号时，用户的宿主目录都存放在此目录下，~表示当前用户的宿主目录，~test表示用户test的宿主目录。建议单独分区，并设置较大的磁盘空间，方便用户存放数据。/lib，/usr/lib，/usr/local/lib:系统使用的函数库的目录，程序在执行过程中，需要调用一些额外的参数时需要函数库的协助，该目录下存放了各种编程语言库。典型的linux系统包含了C、C++和FORTRAN语言的库文件。/lib目录下的库映像文件可以用来启动系统并执行一些命令，目录/lib/modules包含了可加载的内核模块，/lib目录存放了所有重要的库文件，其他的库文件则大部分存放在/usr/lib目录下。/lost+fount: 在EXT2或EXT3文件系统中，当系统意外崩溃或机器意外关机，产生的一些文件碎片放在这里。在系统启动的过程中fsck工具会检查这里，并修复已经损坏的文件系统。有时系统发生问题，有很多的文件被移到这个目录中，可能会用手工的方法来修复，或者移动文件到运来的位置上/mnt，/media: mnt目录主要用来临时挂载文件系统，为某些设备提供默认挂载点，如floppy，cdrom。这样当挂载了一个设备如光驱时，就可以通过访问目录/mnt/cdrom下的文件来访问相应的光驱上的文件了。/opt: 给主机额外安装软件所摆放的目录。如:FC4使用的Fedora 社群开发软件，如果想要自行安装新的KDE 桌面软件，可以将该软件安装在该目录下。以前的 Linux 系统中，习惯放置在 /usr/local 目录下。/proc: 此目录的数据都在内存中，如系统核心，外部设备，网络状态，由于数据都存放于内存中，所以不占用磁盘空间，比较重要的目录有/proc/cpuinfo、/proc/interrupts、/proc/dma、/proc/ioports、/proc/net/*等。/root:系统管理员root的宿主目录，系统第一个启动的分区为/，所以最好将/root和/放置在一个分区下。/sbin，/usr/sbin，/usr/local/sbin:放置系统管理员使用的可执行命令，如fdisk、shutdown、mount等。与/bin不同的是，这几个目录是给系统管理员root使用的命令，一般用户只能”查看”而不能设置和使用。/tmp: 一般用户或正在执行的程序临时存放文件的目录,任何人都可以访问,重要数据不可放置在此目录下。/srv: 服务启动之后需要访问的数据目录，如www服务需要访问的网页数据存放在/srv/www内。/usr: 应用程序存放目录，/var: 放置系统执行过程中经常变化的文件，如随时更改的日志文件 /var/log。/tmp:存放临时文件目录，一些命令和应用程序会用的到这个目录。该目录下的所有文件会被定时删除，以避免临时文件占满整个磁盘。 /usr目录下/usr/bin: 存放应用程序，/usr/share: 存放共享数据，/usr/lib: 存放不能直接运行的，却是许多程序运行所必需的一些函数库文件，/usr/local: 存放软件升级包，/usr/share/doc: 系统说明文件存放目录。/usr/share/man: 程序说明文件存放目录，使用 man ls时会查询/usr/share/man/man1/ls.1.gz的内容建议单独分区，设置较大的磁盘空间。 /var目录下/var/log/message: 所有的登录文件存放目录。/var/spool/mail: 邮件存放的目录。/var/run: 程序或服务启动后。建议单独分区，设置较大的磁盘空间。 /dev目录下dev是设备(device)的英文缩写。/dev这个目录对所有的用户都十分重要。因为在这个目录中包含了所有Linux系统中使用的外部设备。但是这里并不是放的外部设备的驱动程序，这一点和windows,dos操作系统不一样。它实际上是一个访问这些外部设备的端口。我们可以非常方便地去访问这些外部设备，和访问一个文件，一个目录没有任何区别。 Linux沿袭Unix的风格，将所有设备认成是一个文件。 设备文件分为两种: 块设备文件(b) 字符设备文件(c) 设备文件一般存放在/dev目录下，对常见设备文件作如下说明`: /dev/hd[a-t]:IDE设备/dev/sd[a-z]:SCSI设备/dev/fd[0-7]:标准软驱/dev/md[0-31]:软raid设备/dev/loop[0-7]:本地回环设备/dev/ram[0-15]:内存/dev/null:无限数据接收设备,相当于黑洞/dev/zero:无限零资源/dev/tty[0-63]:虚拟终端/dev/ttyS[0-3]:串口/dev/lp[0-3]:并口/dev/console:控制台/dev/fb[0-31]:framebuffer/dev/random:随机数设备/dev/urandom:随机数设备 /etc目录下/etc/rc，/etc/rc.d，/etc/rc*.d 启动、或改变运行级时运行的scripts或scripts的目录。/etc/passwd 用户数据库，其中的域给出了用户名、真实姓名、家目录、加密的口令和用户的其他信息。/etc/fstab 启动时mount -a命令(在/etc/rc 或等效的启动文件中)自动mount的文件系统列表。Linux下，也包括用swapon -a启用的swap区的信息。/etc/group 类似/etc/passwd ，但说明的不是用户而是用户组。/etc/inittab init 的配置文件，设定系统启动时init进程将把系统设置成什么样的runlevel 。/etc/issue getty 在登录提示符前的输出信息.通常包括系统的一段短说明或欢迎信息内容由系统管理员确定。/etc/motd Message Of The Day，成功登录后自动输出内容由系统管理员确定，经常用于通告信息，如计划关机时间的警告。/etc/mtab 当前安装的文件系统列表.由scripts初始化，并由mount 命令自动更新，需要一个当前安装的文件系统的列表时使用，例如df 命令。/etc/shadow 在安装了影子口令软件的系统上的影子口令文件.影子口令文件将/etc/passwd 文件中的加密口令移动到/etc/shadow 中，而后者只对root可读这使破译口令更困难./etc/login.defs login 命令的配置文件。/etc/printcap 类似/etc/termcap ，但针对打印机语法不同。/etc/profile , /etc/csh.login , /etc/csh.cshrc 登录或启动时Bourne或C shells执行的文件，这允许系统管理员为所有用户建立全局缺省环境。/etc/securetty 确认安全终端，即哪个终端允许root登录.一般只列出虚拟控制台，这样就不可能(至少很困难)通过modem或网络闯入系统并得到超级用户特权。/etc/shells 列出可信任的shell.chsh 命令允许用户在本文件指定范围内改变登录shell.提供一台机器FTP服务的服务进程ftpd 检查用户shell是否列在 /etc/shells 文件中，如果不是将不允许该用户登录./etc/sysconfig 网络配置相关目录/etc/DIR_COLORS 设定颜色/etc/HOSTNAME 设定用户的节点名/etc/NETWORKING 只有YES标明网络存在/etc/host.conf 文件说明用户的系统如何查询节点名/etc/hosts 设定用户自已的IP与名字的对应表/etc/hosts.allow 设置允许使用inetd的机器使用/etc/hosts.deny 设置不允许使用inetd的机器使用/etc/hosts.equiv 设置远端机不用密码/etc/inetd.conf 设定系统网络守护进程inetd的配置/etc/inetd.pid inetd这个进程的进程id/etc/hosts.lpd 设定远端有哪些节点可以使用本机的打印机/etc/gateways 设定路由器/etc/protocols 设定系统支持的协议/etc/named.boot 设定本机为名字服务器的配置文件/etc/named.pid 本机上运行的名字服务器的进程id/etc/networks 设定网络的配置文件/etc/resolv.conf 设定系统的名字服务器/etc/services 设定系统的端品与协议类型和提供的服务/etc/exports 设定NFS系统用的/etc/NNTP_INEWS_DOMAIN 设置新闻服务器的配置文件/etc/nntpserver 设置用户使用的新闻服务器的地址/etc/XF86Config X Window的配置文件/etc/hostid 系统独有的一个硬件id/etc/at.deny 设置哪些用户不能使用at命令/etc/bootptab 给MAKEDEV程序设定各种不同的设备驱动文件的格式/etc/makedev.cfg 同DEVINFO一样给MAKEDEV使用的设置文件/etc/diphosts 设置拔号服务器的用户名和口令/etc/slip.hosts,/etc/slip.login 设定SLIP的配置文件/etc/fastboot 使用shutdown -f产生的，重启系统要查这个文件/etc/fstab 记录开机要mount的文件系统/etc/ftpaccess FTP服务器的一些配置/etc/ftpconversions 设定在FTP时使用的过滤器的位置/etc/ftpusers 设定不能使用FTP服务的用户/etc/ld.so.cache 查找系统动态链接库的缓存/etc/ld.so.conf 系统动态链接库的路径/etc/lilo.conf lilo的配置文件/etc/magic 给file命令使用的/etc/aliases 给sendmail使用的设置别名的文件/etc/mail.rc,/etc/mailcap,/etc/sendmail.cf,/etc/sendmail.st 设置sendmail的/etc/motd 超级用户发布通知的地方/etc/organization 存放用户的名字和组织/etc/pnpdevices 列出支持的Plug&amp;Play设备/etc/snooptad 监控用户的屏幕，监听的终端列表/etc/sudoers 可以sudo命令的配置文件/etc/syslog.conf 系统记录程序syslogd的配置文件/etc/utmp 目前在用系统的用户信息/etc/wtmp 同utmp差不多，只是它累加/etc/nologin 系统在shutdown时不希望用户登录就产生这个文件/etc/termcap 设置系统终端信息的/etc/ttys 设定系统的终端类型/etc/gettydefs getty_ps的定义文件/etc/yp.conf NIS的配置文件/etc/mtools.conf 设定mtools程序的参数/etc/fdprm 设定格式化软盘的参数/etc/login.access 控制用户登录权限的文件 /proc目录下/proc/cmdline 加载 kernel 时所下达的相关参数，查阅此文件，可了解系统是如何启动。/proc/cpuinfo 本机的 CPU 的相关资讯，包含时脉、类型与运算功能等/proc/devices 这个文件记录了系统各个主要装置的主要装置代号，与 mknod 有关。/proc/filesystems 目前系统已经加载的文件系统。/proc/interrupts 目前系统上面的 IRQ 分配状态。/proc/ioports 目前系统上面各个装置所配置的 I/O 位址。/proc/kcore 这个就是内存的大小，但是不要读他。/proc/loadavg 还记得 top 以及 uptime 吧？没错，上头的三个平均数值就是记录在此。/proc/meminfo 使用 free 列出的内存资讯，在这里也能够查阅到。/proc/modules 目前我们的 Linux 已经加载的模块列表，也可以想成是驱动程序。/proc/mounts 系统已经挂载的数据，就是用 mount 这个命令呼叫出来的数据。/proc/swaps 到底系统挂加载的内存在哪里？使用掉的 partition 就记录在此啦。/proc/partitions 使用 fdisk -l 会出现目前所有的 partition 吧？在这个文件当中也有纪录。/proc/pci 在 PCI 汇流排上面，每个装置的详细情况，可用 lspci 来查阅。/proc/uptime 就是用 uptime 的时候，会出现的资讯。/proc/version 核心的版本，就是用 uname -a 显示的内容。/proc/bus/* 一些汇流排的装置，还有 U盘 的装置也记录在此。 /usr目录下/usr 最庞大的目录，因为所有应用程序几乎都安装在这里， 本地安装的程序和其他东西在/usr/local 下。/usr/etc 存放配置文件。/usr/games 存放游戏和教学文件。/usr/include 开发和编译应用程序所需要的头文件。/usr/share 存放结构独立的数据。/usr/bin 几乎所有用户命令.有些命令在/bin 或/usr/local/bin 中。/usr/sbin 根文件系统不必要的系统管理命令，例如多数服务程序。/usr/share/man , /usr/share/info , /usr/share/doc 手册页、GNU信息文档和各种其他文档文件。/usr/lib 程序或子系统的不变的数据文件，包括一些site-wide配置文件，名字lib来源于库(library)， 编程的原始库存在/usr/lib 里。/usr/local 本地安装的软件和其他文件放在这里，/usr/local/bin存放本地增加的命令，/usr/local/include存放本地增加的库文件。/usr/src 存放程序的源代码，linux内核的源代码存放在/usr/src/kernels。 /var目录下/var 包括系统一般运行时要改变的数据.每个系统是特定的，即不通过网络与其他计算机共享。/var/catman 当要求格式化时的man页的cache.man页的源文件一般存在/usr/man/man 中；有些man页可能有预格式化的版本，存在/usr/man/cat 中.而其他的man页在第一次看时需要格式化，格式化完的版本存在/var/man 中，这样其他人再看相同的页时就无须等待格式化了. (/var/catman 经常被清除，就象清除临时目录一样.)/var/lib 系统正常运行时要改变的文件。/var/local，/usr/local 中安装的程序的可变数据(即系统管理员安装的程序).注意，如果必要，即使本地安装的程序也会使用其他/var 目录，例如/var/lock 。/var/lock 锁定文件.许多程序遵循在/var/lock 中产生一个锁定文件的约定，以支持他们正在使用某个特定的设备或文件.其他程序注意到这个锁定文件，将不试图使用这个设备或文件。/var/log 各种程序的Log文件，特别是login (/var/log/wtmp log所有到系统的登录和注销) 和syslog (/var/log/messages 里存储所有核心和系统程序信息. /var/log 里的文件经常不确定地增长，应该定期清除。/var/run 保存到下次引导前有效的关于系统的信息文件.例如， /var/run/utmp 包含当前登录的用户的信息。/var/spool，/var/mail, /var/news 打印队列和其他队列工作的目录.每个不同的spool在/var/spool 下有自己的子目录，例如，用户的邮箱在/var/spool/mail 中。/var/tmp 比/tmp 允许的大或需要存在较长时间的临时文件。 (虽然系统管理员可能不允许/var/tmp 有很旧的文件.)","tags":[{"name":"linux","slug":"linux","permalink":"http://www.jifu.io/tags/linux/"},{"name":"目录结构","slug":"目录结构","permalink":"http://www.jifu.io/tags/目录结构/"}],"categories":[{"name":"OPS","slug":"OPS","permalink":"http://www.jifu.io/categories/OPS/"},{"name":"Linux","slug":"OPS/Linux","permalink":"http://www.jifu.io/categories/OPS/Linux/"}]},{"title":"使用 systemctl 添加自定义服务","date":"2018-12-04T03:49:12.000Z","path":"posts/709002730/","text":"简介Centos7.4开机第一个程序从init完全换成了systemd这种启动方式，同centos 5 6已经是实质差别。systemd是靠管理unit的方式来控制开机服务，开机级别等功能。 在/usr/lib/systemd/system目录下包含了各种unit文件，有service后缀的服务unit，有target后缀的开机级别unit等，这里介绍关于service后缀的文件。因为systemd在开机要想执行自启动，都是通过这些*.service 的unit控制的，服务又分为系统服务（system）和用户服务（user）。 系统服务：开机不登陆就能运行的程序（常用于开机自启）。 用户服务：需要登陆以后才能运行的程序。 配置文件[UNIT] #服务描述 Description=Media wanager Service #指定了在systemd在执行完那些target之后再启动该服务 After=network.target [Service] #定义Service的运行类型，一般是forking(后台运行) Type=forking #定义systemctl start|stop|reload *.service 的执行方法（具体命令需要写绝对路径） #注：ExecStartPre为启动前执行的命令 ExecStart=/opt/nginx/sbin/nginx ExecReload=/opt/nginx/sbin/nginx -s reload ExecStop=/opt/nginx/sbin/nginx -s stop #创建私有的内存临时空间 PrivateTmp=True [Install] #多用户 WantedBy=multi-user.target 配置文件说明[UNIT]区块启动顺序与依赖关系 字段 功能 Description 给出当前服务的简单描述 Documentation 给出文档位置 After 如果network.target或sshd-keygen.service需要启动，那么sshd.service应该在它们之后启动 Before 定义sshd.service应该在哪些服务之前启动 注：After和Before字段只涉及启动顺序，不涉及依赖关系。 [Service]区块启动行为 启动命令Type=forking是后台运行的形式 字段 功能 ExecStart 定义启动进程时执行的命令 ExecReload 重启服务时执行的命令 ExecStop 停止服务时执行的命令 ExecStartPre 启动服务之前执行的命令 ExecStartPost 启动服务之后执行的命令 ExecStopPost 停止服务之后执行的命令 注：所有的启动设置之前，都可以加上一个连词号（-），表示”抑制错误”，即发生错误的时候，不影响其他命令的执行。比如EnvironmentFile=-/etc/sysconfig/sshd（注意等号后面的那个连词号），就表示即使/etc/sysconfig/sshd文件不存在，也不会抛出错误。注意：[Service]中的启动、重启、停止命令全部要求使用绝对路径！ 启动类型Type字段定义启动类型。它可以设置的值如下： 字段 功能 simple（默认值） ExecStart字段启动的进程为主进程 forking ExecStart字段将以fork()方式启动，此时父进程将会退出，子进程将成为主进程（后台运行） oneshot 类似于simple，但只执行一次，Systemd 会等它执行完，才启动其他服务 dbus 类似于simple，但会等待 D-Bus 信号后启动 notify 类似于simple，启动结束后会发出通知信号，然后 Systemd 再启动其他服务 idle 类似于simple，但是要等到其他任务都执行完，才会启动该服务。一种使用场合是为让该服务的输出，不与其他服务的输出相混合 PrivateTmp=True表示给服务分配独立的临时空间 [Install]区块服务安装的相关设置，可设置为多用户, 定义如何安装这个配置文件，即怎样做到开机启动。 WantedBy字段：表示该服务所在的 Target。Target的含义是服务组，表示一组服务。WantedBy=multi-user.target指的是：sshd 所在的 Target 是multi-user.target。 这个设置非常重要，因为执行systemctl enable sshd.service命令时，sshd.service的一个符号链接，就会放在/etc/systemd/system目录下面的multi-user.target.wants子目录之中。Systemd 有默认的启动 Target。 systemctl服务基本指令重载系统服务：systemctl daemon-reload设置开机启动：systemctl enable *.service启动服务：systemctl start *.service停止服务：systemctl stop *.service重启服务：systemctl reload *.service 参考资料 -CentOS7.4 使用 systemctl 添加自定义服务","tags":[{"name":"CentOS","slug":"CentOS","permalink":"http://www.jifu.io/tags/CentOS/"},{"name":"systemctl","slug":"systemctl","permalink":"http://www.jifu.io/tags/systemctl/"},{"name":"系统服务","slug":"系统服务","permalink":"http://www.jifu.io/tags/系统服务/"}],"categories":[{"name":"OPS","slug":"OPS","permalink":"http://www.jifu.io/categories/OPS/"},{"name":"Linux","slug":"OPS/Linux","permalink":"http://www.jifu.io/categories/OPS/Linux/"},{"name":"System Service","slug":"OPS/Linux/System-Service","permalink":"http://www.jifu.io/categories/OPS/Linux/System-Service/"}]},{"title":"Gogs数据备份、恢复","date":"2018-12-04T03:38:26.000Z","path":"posts/4076369309/","text":"Other than pack up gogs-repositories, custom and database separately, Gogs provides two commands for unified process of backup, restore and even migrate to another database engine. BackupGo to the directory where your Gogs binary is located, and execute following command: ./gogs backup Without any flags, backup command will pack up all gogs-repositories, custom and database into a single zip archive (e.g. gogs-backup-xxx.zip) under current directory. It could be a bad idea if your gogs-repositories contains GB of raw data, in that case, you can apply –exclude-repos flag: ./gogs backup --exclude-reposIf your custom/conf/app.ini is somewhere unusual, make sure you specify it via –config flag like always: ./gogs backup --config=my/custom/conf/app.ini DatabaseIf you’re only interested in backup database, or want to migrate from one database engine (e.g. SQLite3) to another engine (e.g. MySQL), –database-only is your friend: ./gogs backup --database-only The backup format of database are portable JSON files, each file corresponds to a database table, you can do whatever you want with those files. RestoreThe restore command also has flags to indicate only restore database or everything in backup archive: ./gogs restore --database-only --from=&quot;gogs-backup-xxx.zip&quot; If a table that is not presented in backup archive, whatever in current database table will remain unchanged. Custom config fileThere are 3 steps to determine which custom/conf/app.ini command uses: Use the one you specified vis flag --config.Use the one stored in backup archive.Use the one in $(pwd)/custom/conf/app.ini.If all 3 steps failed, sorry, impossible to perform restore process. 参考资料 -How to backup, restore and migrate","tags":[{"name":"backup","slug":"backup","permalink":"http://www.jifu.io/tags/backup/"},{"name":"gogs","slug":"gogs","permalink":"http://www.jifu.io/tags/gogs/"},{"name":"restore","slug":"restore","permalink":"http://www.jifu.io/tags/restore/"},{"name":"migrate","slug":"migrate","permalink":"http://www.jifu.io/tags/migrate/"}],"categories":[{"name":"back-end","slug":"back-end","permalink":"http://www.jifu.io/categories/back-end/"},{"name":"Middle-ware","slug":"back-end/Middle-ware","permalink":"http://www.jifu.io/categories/back-end/Middle-ware/"},{"name":"Gogs","slug":"back-end/Middle-ware/Gogs","permalink":"http://www.jifu.io/categories/back-end/Middle-ware/Gogs/"}]},{"title":"VIM下使用Vundle搭建python开发环境","date":"2018-11-14T03:46:20.000Z","path":"posts/258379777/","text":"Set up Vundlesh -c &quot;$(curl -fsSL https://raw.githubusercontent.com/ets-labs/python-vimrc/master/setup.sh)&quot; 安装系统依赖ctagsFor Ubuntusudo apt-get install exuberant-ctags With yumsudo yum install ctags-etags cmakewith yumyum install cmake Autocompletionfor linuxbash ~/.vim/bundle/YouCompleteMe/install.sh for mac~/.vim/bundle/YouCompleteMe/install.py --clang-completer 参考资料 -ets-labs/python-vimrc","tags":[{"name":"vim","slug":"vim","permalink":"http://www.jifu.io/tags/vim/"},{"name":"python","slug":"python","permalink":"http://www.jifu.io/tags/python/"},{"name":"开发环境","slug":"开发环境","permalink":"http://www.jifu.io/tags/开发环境/"},{"name":"vundle","slug":"vundle","permalink":"http://www.jifu.io/tags/vundle/"}],"categories":[{"name":"OPS","slug":"OPS","permalink":"http://www.jifu.io/categories/OPS/"},{"name":"Vim","slug":"OPS/Vim","permalink":"http://www.jifu.io/categories/OPS/Vim/"}]},{"title":"CentOS7编译安装VIM8","date":"2018-11-14T03:10:50.000Z","path":"posts/1867760035/","text":"yum安装centos下安装软件最简单的方法了，还能解决依赖问题，首推该方法，缺点是源里面有一些软件并不是其官网上最新的 sudo yum install -y vim 源码编译安装通过git下载vim最新版git clone https://github.com/vim/vim.git 解决vim的依赖问题sudo yum install -y ncurses-devel gcc gcc-c++ 编译安装(选项请参考手册）编译增加参数 --enable-pythoninterp=yes cd vim/src ./configure --prefix=/usr/bin/local/ --enable-pythoninterp=yes make sudo make install ./configure 后面的配置选项bash –with-features=huge：支持最大特性 –enable-rubyinterp：打开对ruby编写的插件的支持 –enable-pythoninterp：打开对python编写的插件的支持 –enable-python3interp：打开对python3编写的插件的支持 –enable-luainterp：打开对lua编写的插件的支持 –enable-perlinterp：打开对perl编写的插件的支持 –enable-multibyte：打开多字节支持，可以在Vim中输入中文 –enable-cscope：打开对cscope的支持 –with-python-config-dir=/usr/lib/python2.7/config-x86_64-linux-gnu/ 指定python 路径 –with-python-config-dir=/usr/lib/python3.5/config-3.5m-x86_64-linux-gnu/ 指定python3路径 –prefix=/usr/local/vim：指定将要安装到的路径(自行创建)bash 参考资料 -Centos7下vim最新版本安装-Centos7安装vim8.0 + YouCompleteMe","tags":[{"name":"vim","slug":"vim","permalink":"http://www.jifu.io/tags/vim/"},{"name":"编译","slug":"编译","permalink":"http://www.jifu.io/tags/编译/"},{"name":"升级","slug":"升级","permalink":"http://www.jifu.io/tags/升级/"},{"name":"CentOS7","slug":"CentOS7","permalink":"http://www.jifu.io/tags/CentOS7/"}],"categories":[{"name":"OPS","slug":"OPS","permalink":"http://www.jifu.io/categories/OPS/"},{"name":"Linux","slug":"OPS/Linux","permalink":"http://www.jifu.io/categories/OPS/Linux/"},{"name":"CentOS","slug":"OPS/Linux/CentOS","permalink":"http://www.jifu.io/categories/OPS/Linux/CentOS/"}]},{"title":"SafariBookmarksSyncAgent意外退出解决方法","date":"2018-10-29T11:19:25.000Z","path":"posts/1070186292/","text":"csrutil是什么？Apple在10.11中全面启用了名为System Integrity Protection (SIP)的系统完整性保护技术. csutil相关命令csrutil命令使用参数时候的格式： csrutil enable [--without kext | fs | debug | dtrace | nvram] [--no-internal] 禁用的时候就相当于所有参数开关全部关闭：csrutil disable（等同于csrutil enable –without kext –without fs –without debug –without dtrace –without nvram） 关闭csrutil 启动系统, 按住⌘-R不松手 在实用工具(Utilities)下打开终端,输入csrutil disable, 然后回车; 你就看到提示系统完整性保护(SIP: System Integrity Protection)已禁用 输入reboot回车重启电脑 删除崩溃文件进到/System/Library/CoreServices/SafariSupport.bundle/Contents/MacOS/目录,删除SafariBookmarkSyncAgent; 重启csrutil如果你想启用SIP, 那么重启启动系统,按住⌘-R不松手; 输入csrutil enable回车.开启SIP 参考资料 -关于csrutil命令参数的介绍-OSX | SafariBookmarksSyncAgent意外退出解决方法","tags":[{"name":"MacOS","slug":"MacOS","permalink":"http://www.jifu.io/tags/MacOS/"},{"name":"Safari","slug":"Safari","permalink":"http://www.jifu.io/tags/Safari/"},{"name":"crash","slug":"crash","permalink":"http://www.jifu.io/tags/crash/"},{"name":"SafariBooksSyncAgent","slug":"SafariBooksSyncAgent","permalink":"http://www.jifu.io/tags/SafariBooksSyncAgent/"}],"categories":[{"name":"OPS","slug":"OPS","permalink":"http://www.jifu.io/categories/OPS/"},{"name":"MacOS","slug":"OPS/MacOS","permalink":"http://www.jifu.io/categories/OPS/MacOS/"}]},{"title":"centos7修改启动内核，删除无用内核","date":"2018-10-18T06:16:24.000Z","path":"posts/1153610031/","text":"查看系统可用内核cat /boot/grub2/grub.cfg |grep menuentry if [ x\"${feature_menuentry_id}\" = xy ]; then menuentry_id_option=\"--id\" menuentry_id_option=\"\" export menuentry_id_option menuentry 'CentOS Linux (3.10.0-514.16.1.el7.x86_64) 7 (Core)' --class centos --class gnu-linux --class gnu --class os --unrestricted $menuentry_id_option 'gnulinux-3.10.0-327.el7.x86_64-advanced-6f5840d0-55ac-4d3b-899b-61c0297c5347' { menuentry 'CentOS Linux (3.10.0-327.el7.x86_64) 7 (Core)' --class centos --class gnu-linux --class gnu --class os --unrestricted $menuentry_id_option 'gnulinux-3.10.0-327.el7.x86_64-advanced-6f5840d0-55ac-4d3b-899b-61c0297c5347' { menuentry 'CentOS Linux (0-rescue-d57307c454c0437d91c309347178cdf5) 7 (Core)' --class centos --class gnu-linux --class gnu --class os --unrestricted $menuentry_id_option 'gnulinux-0-rescue-d57307c454c0437d91c309347178cdf5-advanced-6f5840d0-55ac-4d3b-899b-61c0297c5347' { 查看当前内核uname -r 3.10.0-514.16.1.el7.x86_64 修改开机时默认使用的内核grub2-set-default &#39;CentOS Linux (3.10.0-327.el7.x86_64) 7 (Core)&#39; 查看内核修改结果grub2-editenv list saved_entry=CentOS Linux (3.10.0-327.el7.x86_64) 7 (Core) 查看当前系统已安装的内核rpm -qa |grep kernel kernel-3.10.0-327.el7.x86_64 kernel-headers-3.10.0-514.6.1.el7.x86_64 kernel-tools-libs-3.10.0-327.el7.x86_64 kernel-3.10.0-514.16.1.el7.x86_64 kernel-tools-3.10.0-327.el7.x86_64 删除无用内核yum remove kernel-3.10.0-327.el7.x86_64 参考资料 -centos7 选定默认启动内核，及删除无用内核","tags":[{"name":"CentOS7","slug":"CentOS7","permalink":"http://www.jifu.io/tags/CentOS7/"},{"name":"kernel","slug":"kernel","permalink":"http://www.jifu.io/tags/kernel/"},{"name":"启动","slug":"启动","permalink":"http://www.jifu.io/tags/启动/"}],"categories":[{"name":"OPS","slug":"OPS","permalink":"http://www.jifu.io/categories/OPS/"},{"name":"Linux","slug":"OPS/Linux","permalink":"http://www.jifu.io/categories/OPS/Linux/"},{"name":"CentOS","slug":"OPS/Linux/CentOS","permalink":"http://www.jifu.io/categories/OPS/Linux/CentOS/"}]},{"title":"Nginx正向代理与Client设置代理上网","date":"2018-10-09T09:51:44.000Z","path":"posts/524919010/","text":"介绍Nginx介绍Nginx是一个http服务器。是一个使用c语言开发的高性能的http服务器及反向代理服务器。Nginx是一款高性能的http 服务器/反向代理服务器及电子邮件（IMAP/POP3）代理服务器。由俄罗斯的程序设计师Igor Sysoev所开发，官方测试nginx能够支支撑5万并发链接，并且cpu、内存等资源消耗却非常低，运行非常稳定。 Nginx的应用场景 http服务器。Nginx是一个http服务可以独立提供http服务。可以做网页静态服务器。 虚拟主机。可以实现在一台服务器虚拟出多个网站。例如个人网站使用的虚拟主机。 反向代理，负载均衡。当网站的访问量达到一定程度后，单台服务器不能满足用户的请求时，需要用多台服务器集群可以使用nginx做反向代理。并且多台服务器可以平均分担负载，不会因为某台服务器负载高宕机而某台服务器闲置的情况。 什么是代理nginx的正向代理，只能代理http、tcp等，不能代理https请求。有很多人不是很理解具体什么是nginx的正向代理、什么是反向代理。下面结合自己的使用做的一个简介： 正向代理所谓正向代理就是内网服务器主动要去请求外网的地址或服务，所进行的一种行为。内网服务---访问---&gt;外网 反向代理所谓反向代理就是外网要访问内网服务而进行的一种行为。 外网----请求---&gt;内网服务 安装nginhxyum方式yum安装，需安装第三方yum源，因为nginx默认不在centos的yum源中所以需更新 yum install wget #安装下载工具 wget http://www.atomicorp.com/installers/atomic #下载 sh ./atomic #安装 yum check-update #更新yum源 有的需要更新几次 才有nginx最新版本 否则是老版本nginx yum remove httpd* php* #删除系统自带的软件包 也可加mysql*前提备份数据库 yum install nginx #安装nginx根据提示输入y进行安装 chkconfig nginx on #设置nginx开机启动 #检查服务配置文件 sudo nginx -t #nginx: configuration file /etc/nginx/nginx.conf test is successful 表示配置文件符合标准配置，解析成功 #sudo service nginx {start|stop|status|restart|reload|configtest|} #启动服务 sudo service nginx start #停止服务 sudo service nginx stop 编译安装wget http://nginx.org/download/nginx-1.7.8.tar.gz tar -zxvf nginx-1.7.8.tar.gz cd nginx-1.7.8 ./configure make &amp;&amp; make install nginx负载均衡由于整片篇幅，此处只介绍nginx的负载均衡简单的配置。nginx 的 upstream默认是以轮询的方式实现负载均衡，这种方式中，每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。 另外一种方式是ip_hash：每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题 修改 /etc/nginx/nginx.conf #负载均衡配置 upstream backend { #ip_hash; server 192.168.20.193; // server 1 server 192.168.20.194; // server 2 } Server端 - 配置正向代理配置serverserver { # 配置DNS解析IP地址，比如 Google Public DNS，以及超时时间（5秒） resolver 8.8.8.8; # 必需 resolver_timeout 5s; # 监听端口 listen 8080; access_log /home/reistlin/logs/proxy.access.log; error_log /home/reistlin/logs/proxy.error.log; location / { # 配置正向代理参数 proxy_pass $scheme://$host$request_uri; # 解决如果URL中带\".\"后Nginx 503错误 proxy_set_header Host $http_host; # 配置缓存大小 proxy_buffers 256 4k; # 关闭磁盘缓存读写减少I/O proxy_max_temp_file_size 0; # 代理连接超时时间 proxy_connect_timeout 30; # 配置代理服务器HTTP状态缓存时间 proxy_cache_valid 200 302 10m; proxy_cache_valid 301 1h; proxy_cache_valid any 1m; } } Client端 - 配置代理上网设置http代理修改配置修改/etc/profile，增加以下内容： http_proxy=http://[代理地址]:[代理地址的端口]/ https_proxy=http://[代理地址]:[代理地址的端口]/ export http_proxy https_proxy 永久生效代理vim .bashrc export http_proxy=http://192.168.1.9：8080 source .bashrc 马上生效source /etc/profile 取消代理unset http_proxy 设置https代理默认的情况下，使用nginx做正向代理可以解析http请求， 对于诸如baidu.com这样的https请求，nginx默认并不支持，不过我们可以借助第三方模块来实现。 安装nginx第三方模块这里我们需要借助大神开发的【ngx_http_proxy_connect_module】 首先要确保你安装了patch，gcc、gcc++、pcre、zlib，这些都是我们用到的依赖软件或静态库 yum group install -y \"Development Tools\" yum install -y patch pcre-devel pcre zlib-devel zlib 然后去github下载下来这个模块，就是直接去官网把整个目录下下来，解压放到你centos的某个目录下。再下载nginx、按照官网说明执行以下命令 $ wget http://nginx.org/download/nginx-1.9.2.tar.gz $ tar -xzvf nginx-1.9.2.tar.gz $ cd nginx-1.9.2/ $ patch -p1 &lt; /path/to/ngx_http_proxy_connect_module/proxy_connect.patch $ ./configure --add-module=/path/to/ngx_http_proxy_connect_module $ make &amp;&amp; make install 注意其中的【/path/to/ngx_http_proxy_connect_module】，指的就是你从github上，下载的这个模块的存放路径。 完成后，/usr/local/nginx就是编译后的nginx的路径。 配置config/usr/local/nginx/conf/nginx.conf server { resolver 192.168.31.1; resolver_timeout 5s; listen 8889; proxy_connect; proxy_connect_allow 443 563; proxy_connect_connect_timeout 10s; proxy_connect_read_timeout 10s; proxy_connect_send_timeout 10s; location / { #proxy_pass $scheme://$host$request_uri; #proxy_set_header Host $http_host; proxy_pass http://$host; proxy_set_header Host $host; proxy_buffers 256 4k; proxy_max_temp_file_size 0; proxy_connect_timeout 30; proxy_cache_valid 200 302 10m; proxy_cache_valid 301 1h; proxy_cache_valid any 1m; } error_page 500 502 503 504 /50x.html; location = /50x.html { root html; } } 测试配置正确性nginx -t 重启nginx并生效配置nginx -s reload 参考资料 -centos使用nginx反向代理实现负载均衡-CentOS7 通过代理上网-nginx做正向代理（Centos7，支持http和https）","tags":[{"name":"linux","slug":"linux","permalink":"http://www.jifu.io/tags/linux/"},{"name":"中间件","slug":"中间件","permalink":"http://www.jifu.io/tags/中间件/"},{"name":"Nginx","slug":"Nginx","permalink":"http://www.jifu.io/tags/Nginx/"},{"name":"代理","slug":"代理","permalink":"http://www.jifu.io/tags/代理/"},{"name":"正向代理","slug":"正向代理","permalink":"http://www.jifu.io/tags/正向代理/"}],"categories":[{"name":"back-end","slug":"back-end","permalink":"http://www.jifu.io/categories/back-end/"},{"name":"Middle-ware","slug":"back-end/Middle-ware","permalink":"http://www.jifu.io/categories/back-end/Middle-ware/"},{"name":"Nginx","slug":"back-end/Middle-ware/Nginx","permalink":"http://www.jifu.io/categories/back-end/Middle-ware/Nginx/"}]},{"title":"Vultr快速搭建SS科学上网","date":"2018-10-02T06:38:13.000Z","path":"posts/3154796955/","text":"Vultr介绍 众所周知，我国因为某些原因查阅浏览不到一些国外的资料及内容，这给我们的学习工作带来了很大的不便。所以怎样才能跨越这个障碍呢？这就需要VPS（Virtual Private Server 虚拟专用服务器）的帮助了。 今天给大家推荐的是vultr的VPS，Vultr是一家提供日本、美国、欧洲等多个国家和地区机房的VPS主机商，硬盘都是采用SSD，VPS主机都是KVM架构，VPS配置最少的内存512MB、硬盘为20GB的VPS只要3.5美元/月，vultr是根据时长来扣费的，使用多长时间就算多长时间，扣对应的款。Vultr是KVM系统，开通了15个位置机房，相比较搬瓦工VPS各方面都要强，当然费用上vultr也稍高。 账号注册链接地址是：Vultr官网优惠链接 打开官网地址，进入如下界面输入邮箱地址和密码，点击Create Account创建一个新账户。 输入自己邮箱及密码(注意： vultr passwd 账户密码必须至少10个字符，并包含至少1个小写字母，1个大写字母和1个数字。)，点击注册即可创建一个新账户。 特别提醒 有部分朋友出现购买vultr的VPS在使用几天甚至付款验证后账户就被关闭，主要原因vultr 是禁止用户重复注册账号的，即如果你使用的paypal或者信用卡已经绑定了Vultr其他账号，那么你新注册的账户会被后台关闭的。简单的说就是一个账户的支付信息比如paypal 账号是对应唯一的一个的，如果你再次使用这个paypal支付另外一个新注册的账号的话，那么账户就会被关闭。所以，重复的注册账号是不可取的，试用到期效果好续费即可。 注册完毕，vultr会给我们发送一封验证邮件。我们需要打开注册的邮箱地址完成邮箱验证才能继续使用。 选择信用卡支付填写信用卡信息，这个会预扣信用卡款$2.5美元，后面会返还到信用卡中。另外在Enter Code 处使用优惠码 ：VULTRMATCH 可以获得vultr冲 多少送多少最高送100美元。 这里一个很好的建议是你充值$10美元，防止你被误判恶意使用，如果你使用优惠码VULTRMATCH，则额外送10 美元。这样你就可以优惠使用VPS期限8个月了。 Paypal支付Vultr (仅限paypal 支付查看，信用卡支付请忽略)如果说你没有信用卡，但是你有Paypal 账号，那么你需要在Enter Code 处使用优惠码：VULTRMATCH 获得冲多少送多少活动，最高赠送100美元。 服务器创建账单信息确认完成，我们就可以点击右侧的技术分享 Deploy New Server 建立VPS了。 硬盘默认服务器选择日本 东京 操作系统默认服务器配置：默认即可。 其他信息默认即可。 点击 place order ,生成一个新VPS。 进入 Servers ，稍等片刻服务器信息就生成了。 点击 Cloud Instance 进行管理。 Vultr 的这个控制面板还是比较清新的，VPS的所有功能都在一个页面集中，服务器停止，重新启动，重装系统，删除服务器等指示清晰，非常容易管理。 按照上面的配置信息我们登录putty，注意vultr 端口号是22. 初次登录密码就是 Password 里面的信息(上图中SSH管理密码)，登录后就是我们常规的操作了。 远程登录工具Putty简单简介下putty的使用 首先按照vultr 给我们的信息填写，IP选择控制面板的IP,端口22，选择SSH模式 点击open，会有一个窗口，选择是。 login as填写root.密码填写vultr提供的密码。 putty的密码输入进去是不显示的，所以这里的正确操作步骤是：先复制vultr给的密码，注意复制的密码前后不能有空格（如上图正确密码cteyjukrieh!5），然后先鼠标左键点击下putty软件，再在绿色光标那里鼠标右键一下，然后回车键（Enter建）。这里最关键，好多朋友密码总是输入不对，要么是密码复制错误多了空格，要么就是因为没有看到密码显示就多鼠标右键，多复制了几次密码。正确复制密码回车后的界面是这个样子。 putty的基础使用可以参考： putty及winscp初级使用方法 vultr相关性能测试1、这是测试Vultr日本VPS的IO读写速度，表现可以。 2、因为Vultr日本VPS用的是SSD硬盘，针对SSD硬盘的读写速度测试结果是300MB/s左右。 3、这是用UnixBench测试Vultr日本VPS性能综合跑分结果，内存为1GB的VPS测试超过了1000分。（点击放大） vultr机房选择哪个位置更好这里给出的建议：如果你是联通网络，选择东京机房；如果你是电信用户可以选择东京或者洛杉矶。因为各地网络数据可能不一样，建议大家都创建不同机房测试下。网络流畅需要我们配合安装下锐速或者谷歌BBR拥塞算法。 SSR一键安装附：Vultr一键安装SSR命令： wget http://soft.paozailushang.com/vps/SSR.sh &amp;&amp; chmod +x SSR.sh &amp;&amp; ./SSR.sh 2&gt;&amp;1 | tee ssr.log vultr的网络加速目前有锐速，BBR及hybla。 Tcp连接加速 - 锐速vultr日本东京服务器安装锐速 安装锐速wget --no-check-certificate -O appex.sh https://raw.githubusercontent.com/0oVicero0/serverSpeeder_Install/master/appex.sh &amp;&amp; chmod +x appex.sh &amp;&amp; bash appex.sh install 卸载锐速wget --no-check-certificate -O appex.sh https://raw.githubusercontent.com/0oVicero0/serverSpeeder_Install/master/appex.sh &amp;&amp; chmod +x appex.sh &amp;&amp; bash appex.sh uninstall 根据屏幕提示输入 serverSpeederInstaller 其他信息默认，遇到Y或者N的地方，全部选Y. 然后我们按照图片的数据指示，一路回车就可以了。 现在打开你的浏览器试试速度吧，有图为证 如果你安装没有效果，编辑一下命令 如果你安装没有效果，编辑以下命令，新手可以使用winscp编辑：putty及winscp初级使用方法 vi /appex/etc/config 然后rsc和maxmode设置参数修改为1 /appex/bin/serverSpeeder.sh reload /appex/bin/serverSpeeder.sh restart 常用命令启动锐速/appex/bin/serverSpeeder.sh start 停止锐速/appex/bin/serverSpeeder.sh stop 查看锐速是否正常运行/appex/bin/serverSpeeder.sh status 检查是否有appex0模块：lsmodlsmod 参考资料 -利用vultr搭建自己的服务器，附带ss搭建哦！！！","tags":[{"name":"中间件","slug":"中间件","permalink":"http://www.jifu.io/tags/中间件/"},{"name":"vultr","slug":"vultr","permalink":"http://www.jifu.io/tags/vultr/"},{"name":"vps","slug":"vps","permalink":"http://www.jifu.io/tags/vps/"},{"name":"ss","slug":"ss","permalink":"http://www.jifu.io/tags/ss/"},{"name":"ssr","slug":"ssr","permalink":"http://www.jifu.io/tags/ssr/"},{"name":"科学上网","slug":"科学上网","permalink":"http://www.jifu.io/tags/科学上网/"},{"name":"翻墙","slug":"翻墙","permalink":"http://www.jifu.io/tags/翻墙/"}],"categories":[{"name":"back-end","slug":"back-end","permalink":"http://www.jifu.io/categories/back-end/"},{"name":"Middle-ware","slug":"back-end/Middle-ware","permalink":"http://www.jifu.io/categories/back-end/Middle-ware/"},{"name":"Shadowsocks","slug":"back-end/Middle-ware/Shadowsocks","permalink":"http://www.jifu.io/categories/back-end/Middle-ware/Shadowsocks/"}]},{"title":"Python Library - Flask SQLAlchemy","date":"2018-07-12T12:13:15.000Z","path":"posts/383305840/","text":"What is Flask-SQLAlchemyFlask-SQLAlchemy is a Flask microframework extension which adds support for the SQLAlchemy SQL toolkit/ORM. Example from flask import Flask from flask_sqlalchemy import SQLAlchemy app = Flask(__name__) app.config['SECRET_KEY'] = 'Fianna' app.config['SQLALCHEMY_DATABASE_URI'] = 'mysql://user:password@host:port/dbname' app.config['SQLALCHEMY_TRACK_MODIFICATIONS'] = True db = SQLAlchemy(app) class Role(db.Model): __tablename__ = 'roles' id = db.Column(db.Integer, nullable=False, primary_key=True, autoincrement=True) name = db.Column(db.String(16), nullable=False, server_default='', unique=True) def __repr__(self): return '&lt;Role %r>' % self.name class User(db.Model): __tablename__ = 'users' id = db.Column(db.Integer, nullable=False, primary_key=True, autoincrement=True) username = db.Column(db.String(32), nullable=False, unique=True, server_default='', index=True) role_id = db.Column(db.Integer, nullable=False, server_default='0') def __repr__(self): return '&lt;User %r,Role id %r>' %(self.username,self.role_id) pip依赖包安装pip install mysql-pythonpip install flask-sqlalchemy 数据库URL 数据库引擎 URL MySQL mysql://username:password@hostname/database Postgres postgresql://username:password@hostname/database SQLite(Unix) sqlite:////absolute/path/database SQLite(Windows) sqlite:///c:/absolute/path/database 在这些URL中，hostname表示MySQL服务器所在的主机，可以是本地主机（localhost），也可以是远程服务器。数据服务器上可以托管多个数据库，因此database表示要是使用的数据库名。如果数据库需要进行认证，username和password表示数据库用户和密码。 程序中使用的数据库URL必须保存到Flask配置对象config.py的SQLALCHEMY_DATABASE_URI键中。另外一个很有用的选项，即SQLALCHEMY_COMMIT_ON_TEARDOWN键，将其设置为True时，每次请求结束后都会自动提交数据库中的变动。 创建迁移仓库定义好数据模型之后，就应该设计数据库了，不管你用mysql还是sqlite，flask-SQLAlchemy和flask-Migrate会根据数据模型自动创建数据库。 为了导出数据库迁移命令，flask-Migrate提供了一个MigrateCommand类，可附加在flask-script的manage对象上。设置manage.py。 ... from flask.ext.migrate import Migrate, MigrateCommand ... migrate = Migrate(app=app, db=db) manager.add_command('db', MigrateCommand) 使用一下命令创建数据库及迁移仓库(flask)$ python manage.py db init (flask)$ python manage.py db migrate -m \"initial migration\" (flask)$ python manage.py db upgrade 注意事项，虽然flask-migrate提供了downgrade()函数，可以将改动删除。但是建议大家不要随便使用。如果你觉得数据库设计得有问题，建议你删除相关数据库设计，重新再来。 定义数据模型和所有的应用一样，我们先设计简单的用户和权限模型。模型这个术语表示程序中使用的持久化实体。在 ORM 中,模型一般是一个 Python 类,类中的属性对应数据库表中的列。 示例 2-1 app/models.py: 定义 Role 和 User 模型 class Role(db.Model): __tablename__ = 'roles' id = db.Column(db.Integer, primary_key=True) name = db.Column(db.String(64), unique=True) def __repr__(self): return '&lt;Role %r>' % self.name class User(db.Model): __tablename__ = 'users' id = db.Column(db.Integer, primary_key=True) username = db.Column(db.String(64), unique=True, index=True) def __repr__(self): return '&lt;User %r>' % self.username 类变量tablename定义在数据库中使用的表名。其余的类变量都是该模型的属性，被定义为db.Column类的示例。 db.Column类构造函数的第一个参数是数据库列和模型属性的类型。下表列出了一些最常用的列类型以及在模型中使用的Python类型。 AQLAlchemy列类型 类型名 Python类型 说明 Integer int 普通整数，一般是32位 SmallInteger int 取值范围小的整数，一般是16位 BigInteger int或long 不限制精度的整数 Float float 浮点数 Numeric decimal.Decimal 定点数 String str 变长字符串 Text str 变长字符串，对较长或不限长度的字符串做了优化 Unicode unicode 变长Unicode字符串 UnicodeText unicode 变长Unicode字符串,对较长或不限长度的字符床做了优化 Boolean bool 布尔值 Date datetime.date 日期 Time datetime.time 时间 DateTime datetime.datetime 日期和时间 Interval datetime.timedeta 时间间隔 Enum str 一组字符串 PickleType 任何Python对象 自动化使用Pickle序列化 LargeBinary str 二进制文件 SQLAlchemy列选项 选项名 说明 primary_key 如果设为True，这列就是表的主键 unique 如果设为True，这列不允许出现重复 index 如果设为True，为这列创建索引，提升查询效率 nullable 如果设为True，这列允许使用空值；如果设为False，这列不允许使用空值 default 为这列定义默认值 关系app/models.py 一对多关系模型 class Role(db.Model): # ... users = db.relationship('User', backref='role', lazy='dynamic') class User(UserMixin, db.Model): # ... role_id = db.Column(db.Integer, db.ForeignKey('roles.id')) SQLAlchemy关系选项 选项名 说明 backref 在关系的另一个模型中添加反向引用 primaryjoin 明确指定两个模型之间使用的联结条件。只在模棱两可的关系中需要指定 lazy 指定如何加载相关记录。可选值有select（首次访问时按需加载）、immediate（源对象加载后加载）、joined（加载记录，但使用联结）、subquery（立即加载，但使用子查询），noload（永不加载）和dynamic（不加载记录，但提供加载记录的查询） uselist 如果设为False，不使用列表，而使用标量值 order_by 指定关系中记录的排序方式 secondary 指定多对多关系表的名字 secondaryjoin SQLAlchemy无法自行决定时，指定多对多关系中的二级联结条件 除 一对多 关系之外，还有几种其它的关系类型。一对一 关系可以用前面介绍的 一对多 关系表示，但调用db.relationship()时要把uselist设为False，把“多”变成“一”。 多对一 关系也可使用 一对多 表示，对调两个表即可，或者把外键和db.relationship()都放在“多”这一侧。最复杂的关系是 多对多 ，需要用到第三张表，这个表称为 关系表。 SQLAlchemy查询过滤器 过滤器 说明 filter() 把过滤器添加到原查询上，返回一个新查询 filter_by() 把等值过滤器添加到原查询上，返回一个新查询 limit() 使用指定的值限制原查询返回的结果数量，返回一个新查询 offset() 偏移原查询返回的结果，返回一个新查询 order_by() 根据指定条件对原查询结果进行排序，返回一个新查询 group_by() 根据指定条件对原查询进行分组，返回一个新查询 在查询上应用指定的过滤器后，通过调用all()执行查询，以列表形式返回结果。除了all()，还有其它方法能触发查询执行。 SQLAlchemy查询执行函数 方法 说明 all() 以列表形式返回查询的所有结果 first() 返回查询的第一个结果，如果没有结果，返回None first_or_404() 返回查询的第一个结果，如果没有结果，则终止请求，返回404错误响应 get() 返回指定主键对应的行，如果没有对应的行，返回None get_or_404() 返回指定主键对应的行，如果没有对应的行，则终止请求，返回404错误响应 count() 返回查询结果的数量 paginate() 返回一个Paginate对象，它包含指定范围内的结果。 操作实例连接数据库app.config[&#39;SQLALCHEMY_DATABASE_URI&#39;] = &#39;mysql://user:password@host:port/dbname&#39; 创建所有表>>> from hello import db,Role,User >>> db.create_all() 删除所有表>>> from hello import db,Role,User >>> db.drop_all() 插入行插入单行>>> from hello import db,Role,User >>> db.session.add(Role(name='Admin')) >>> db.session.commit() >>> db.session.add(Role(name='Moderator')) >>> db.session.add(Role(name='User')) >>> db.session.commit() 插入多行>>> from hello import db,Role,User >>> db.session.add_all([User(username='john',role_id=1),User(username='susan',role_id=3),User(username='david',role_id=3)]) >>> db.session.commit() 更新行>>> from hello import db,Role,User >>> admin = Role.query.filter_by(name='Admin').first() >>> admin.name='Administrator' >>> db.session.commit() 删除行`python hello.py shell from hello import db,Role,Usermod = Role.query.filter_by(name=’Moderator’).first()db.session.delete(mod)db.session.commit()` 查询表查询表中全部数据# 注意，此处的查询结果完全取决于代码示例中的 # def __repr__(self) >>> from hello import db,Role,User >>> Role.query.all() [&lt;Role u'Administrator'>, &lt;Role u'User'>] >>> User.query.all() [&lt;User u'john',Role id 1L>, &lt;User u'susan',Role id 3L>, &lt;User u'david',Role id 3L>] 按照一个条件过滤数据记录(where)>>> from hello import db,Role,User >>> Role.query.filter_by(name='Administrator').first() &lt;Role u'Administrator'> >>> User.query.filter_by(role_id=3).all() [&lt;User u'susan',Role id 3L>, &lt;User u'david',Role id 3L>] >>> User.query.filter_by(role_id=3).first() &lt;User u'susan',Role id 3L> 按照两个条件过滤数据记录(where and)>>> from hello import db,Role,User >>> User.query.filter_by(role_id=3,username='susan').first() &lt;User u'susan',Role id 3L> >>> User.query.filter_by(role_id=3,username='susan').all() [&lt;User u'susan',Role id 3L>] 聚合(count)python hello.py shell >>> from hello import db,Role,User >>> User.query.filter_by(role_id=3,username='susan').count() 1L >>> User.query.filter_by(role_id=3).count() 2L >>> User.query.count() 3L 求和(sum)python hello.py shell >>> from hello import db,Role,User >>> from sqlalchemy.sql import func >>> User.query.with_entities(func.sum(User.id)).all() [(Decimal('6'),)] >>> User.query.with_entities(func.sum(User.role_id)).all() [(Decimal('7'),)] 平均数(avg)python >>> from hello import db,Role,User >>> from sqlalchemy.sql import func >>> User.query.with_entities(func.avg(User.role_id)).all() [(Decimal('2.3333'),)] >>> User.query.with_entities(func.avg(User.id)).all() [(Decimal('2.0000'),)] 排序(order by)python >>> from hello import db,Role,User # 升序(asc) >>> User.query.order_by(User.role_id).all() [&lt;User u'john',Role id 1L>, &lt;User u'susan',Role id 3L>, &lt;User u'david',Role id 3L>] # 降序(desc) >>> User.query.order_by(User.role_id.desc()).all() [&lt;User u'susan',Role id 3L>, &lt;User u'david',Role id 3L>, &lt;User u'john',Role id 1L>] 分组(group by)python hello.py shell >>> from hello import db,Role,User >>> User.query.group_by(User.role_id).all() [&lt;User u'john',Role id 1L>, &lt;User u'susan',Role id 3L>] 限制(limit)python >>> from hello import db,Role,User >>> User.query.all() [&lt;User u'john',Role id 1L>, &lt;User u'susan',Role id 3L>, &lt;User u'david',Role id 3L>] # limit 1 >>> User.query.limit(1).all() [&lt;User u'john',Role id 1L>] # limit 2,1 >>> User.query.limit(1).offset(2).all() [&lt;User u'david',Role id 3L>] >>> User.query.filter_by(role_id=3).all() [&lt;User u'susan',Role id 3L>, &lt;User u'david',Role id 3L>] # limit 1 >>> User.query.filter_by(role_id=3).limit(1).all() [&lt;User u'susan',Role id 3L>] # limit 1,1 >>> User.query.filter_by(role_id=3).limit(1).offset(1).all() [&lt;User u'david',Role id 3L>] 将Flask-SQLAlchemy的查询语句转换为SQLpython >>> from hello import db,Role,User >>> User.query.all() [&lt;User u'john',Role id 1L>, &lt;User u'susan',Role id 3L>, &lt;User u'david',Role id 3L>] >>> str(User.query) 'SELECT users.id AS users_id, users.username AS users_username, users.role_id AS users_role_id \\nFROM users' >>> User.query.limit(1).all() [&lt;User u'john',Role id 1L>] >>> str(User.query.limit(1)) 'SELECT users.id AS users_id, users.username AS users_username, users.role_id AS users_role_id \\nFROM users \\n LIMIT %s' >>> User.query.limit(1).offset(2).all() [&lt;User u'david',Role id 3L>] >>> str(User.query.limit(1).offset(2)) 'SELECT users.id AS users_id, users.username AS users_username, users.role_id AS users_role_id \\nFROM users \\n LIMIT %s, %s' 参考资料 -第七章 使用 Flask 扩展管理数据库-使用flask-sqlalchemy玩转MySQL","tags":[{"name":"Python","slug":"Python","permalink":"http://www.jifu.io/tags/Python/"},{"name":"Library","slug":"Library","permalink":"http://www.jifu.io/tags/Library/"}],"categories":[{"name":"back-end","slug":"back-end","permalink":"http://www.jifu.io/categories/back-end/"},{"name":"Python","slug":"back-end/Python","permalink":"http://www.jifu.io/categories/back-end/Python/"},{"name":"Library","slug":"back-end/Python/Library","permalink":"http://www.jifu.io/categories/back-end/Python/Library/"}]},{"title":"Python Library - SQLAlchemy","date":"2018-05-14T07:13:30.000Z","path":"posts/4096440342/","text":"Pip安装pip install MySQL-python pip install SQLAlchemy Engine 数据库引擎想要连接使用SQLAlchemy连接数据库，必须先创建一个引擎来连接，下面是创建引擎的相关代码： # -*- coding: utf-8 -*- from sqlalchemy import * __engine = create_engine('mysql://root:@192.168.150.3/test',convert_unicode=True, echo=True) #conn 是DB-API连接对象 conn = __engine.connect() #result是数据库游标 result = conn.execute('select * from tf_user') for row in result: print row conn.close() create_engine 类接受的参数如下： 1、connect_args 数据库链接参数，一般使用中文需要传递{‘charset’:’utf8’} 2、convert_unicode 将保存的unicode字符串数据转为2进制存入数据库，取出时也将2进制取出专程unicode，主要用于数据库不支持Unicode编码使用，默认 False 3、creator 一个可以被调用的对象（带有call的对象），返回DB-API的链接对象，默认None 4、echo 是否输出SQLAlchemy日志，包括拼接的sql语句，默认None 5、echo_pool 是否输出连接池日志，从连接池取出或放入，默认None 6、encoding 设置传输数据的编码，默认是False 7、module 设置使用这个数据库哪一个连接模块，比如某些数据库安装了几个连接模块，默认False 8、pool 如果设定，则使用一个已经存在的连接池，不设定表示重新创建一个，默认None 9、 poolclass 表示这个引擎是否自己实现连接池类，否则会使用 sqlalchemy.pool.QueuePool ，而SQLite会使用 sqlalchemy.pool.SingletonThreadPool， 默认 None 10、 max_overflow 表示连接池允许超出的连接数，默认是10 11、pool_size 表示连接池数量，默认是5 12、pool_recycle 单位秒，表示将闲置的连接释放掉，对于mysql数据库会自动释放闲置连接，有必要对这个值进行设置 13、pool_timeout 从连接池中获取连接的超时时间，单位秒，默认是30 14、strategy 为这个连接引擎选择一个别用的策略，当前备用策略包括threadlocal和plain 15、threadlocal 在一个线程中重用一个连接，执行多条语句 16、plain （默认） 对每一条语句使用一个连接 17、 threaded 仅在Oracle数据库使用，默认False 18、 use_ansi 仅在Oracle数据库使用 19、 use_oids 仅在PostgreSQL数据库使用 此句返回的result是一个ResultProxy的实例 result = conn.execute(&#39;select * from tf_user&#39;) 具有如下的属性和方法： 1、__iter__() 可迭代 2、fetchone() 获取第一行数据，返回类型 RowProxy 3、fetchall() 获取所有的数据，返回类型 RowProxy 数组 4、scalar() ，获取第一列名的第一条数据，然后关闭游标 5、keys 属性，返回列明的数组 6、rowcount 属性，返回记录数 7、close() 关闭连接，将连接返回连接池 8、fetchmany(size=None)，根据数量返回RowProxy类型数组 此句迭代的row是RowProxy实例，具有如下属性和方法： for row in result: print row RowProxy 类型 1、__getattr__() 可以通过 object.column_name 获取值 2、__getitem__() 可以通过 object[column_name] 或者 object[column_position] 获取值 3、keys() 提供所有 column_name 的数组 4、values() 提供所有 value 值的数组 5、items() 提供一个 元组(column_name,value)的数组 MetaData 类MetaData主要用于保存表结构，连接字符串等数据，是一个多表共享的对象 metadata = MetaData() #生成一个未绑定数据源的metadata bound_meta = MetaData('sqlite:///test2.db') #绑定了数据源的metadata 我们可以利用meatadata.bind来绑定上面生成的数据源引擎 metadata = MetaData() __engine = create_engine('mysql://root:@192.168.150.3/test', connect_args={'charset': 'UTF8'}, echo=True, encoding='UTF-8') metadata.bind = __engine #将metadata绑定数据源 执行create_all方法来创建表，这个操作是安全的操作，会先判断表是否存在 metadata.create_all() Table类构造函数： Table.__init__(self, name, metadata,*args, **kwargs) 1、name 表名 2、metadata 共享的元数据 3、*args Column 是列定义，详见下一节 下面是可变参数 **kwargs 定义 4、schema 此表的结构名称，默认None 5、autoload 自动从现有表中读入表结构，默认False 6、autoload_with 从其他engine读取结构，默认None，例： db = create_engine(&#39;sqlite:///devdata.sqlite&#39;) brand_table = Table(&#39;brand&#39;, metadata, autoload=True, autoload_with=db) 7、include_columns 如果autoload设置为True，则此项数组中的列明将被引用，没有写的列明将被忽略，None表示所有都列明都引用，默认None 8、mustexist 如果为True，表示这个表必须在其他的python应用中定义，必须是metadata的一部分，默认False 9、useexisting 如果为True，表示这个表必须被其他应用定义过，将忽略结构定义，默认False 10、owner 表所有者，用于Orcal，默认None 11、quote 设置为True，如果表明是SQL关键字，将强制转义，默认False 12、quote_schema 设置为True，如果列明是SQL关键字，将强制转义，默认False 13、mysql_engine mysql专用，可以设置&#39;InnoDB&#39;或&#39;MyISAM&#39; Column类构造函数： Column.__init__(self, name, type_, *args, **kwargs) 1、name 列名 2、type_ 类型，更多类型 sqlalchemy.types 3、*args Constraint（约束）, ForeignKey（外键）, ColumnDefault（默认）, Sequenceobjects（序列）定义 4、key 列明的别名，默认None 下面是可变参数 **kwargs 5、primary_key 如果为True，则是主键 6、nullable 是否可为Null，默认是True 7、default 默认值，默认是None 8、index 是否是索引，默认是True 9、unique 是否唯一键，默认是False 10、onupdate 指定一个更新时候的值，这个操作是定义在SQLAlchemy中，不是在数据库里的，当更新一条数据时设置，大部分用于updateTime这类字段 11、autoincrement 设置为整型自动增长，只有没有默认值，并且是Integer类型，默认是True 12、quote 如果列明是关键字，则强制转义，默认False 一个简单的表定义代码： user_table = Table( 'tf_user2', metadata, Column('id', Integer, primary_key=True), Column('user_name', Unicode(16, collation='utf8_bin'), unique=True, nullable=False), Column('email_address', Unicode(255, collation='utf8_bin'), unique=True, nullable=False), Column('password', Unicode(40, collation='utf8_bin'), nullable=False), Column('first_name', Unicode(255, collation='utf8_bin'), default=u'发'), Column('last_name', Unicode(255, collation='utf8_bin'), default=u'发'), Column('created', DateTime, default=datetime.now) ) 约束定义可以同时在列或者表中进行定义，相关代码如下： product_table = Table( 'product', metadata, Column('brand_id', Integer, ForeignKey('brand.id'),primary_key=True), Column('sku', Unicode(80), primary_key=True)) # 或者 product_table = Table( 'product', metadata, Column('brand_id', Integer, ForeignKey('brand.id')), Column('sku', Unicode(80)), PrimaryKeyConstraint('brand_id', 'sku', name='prikey')) 外键的定义ForeignKey类构造函数如下： ForeignKey.__init__( self, column, constraint=None, use_alter=False, name=None, onupdate=None, ondelete=None) 唯一定义Unique类，相关代码如下，当然也可以在列中定义，下面这种是复合唯一约束 product_table = Table( 'product', metadata, Column('id', Integer, primary_key=True), Column('brand_id', Integer, ForeignKey('brand.id')), Column('sku', Unicode(80)), UniqueConstraint('brand_id', 'sku')) 检查约束payment_table = Table( 'payment', metadata, Column('amount', Numeric(10,2), CheckConstraint('amount > 0'))) Column('original', Numeric(10,2), CheckConstraint('original> 0')), Column('discounted', Numeric(10,2), CheckConstraint('discounted > 0')), CheckConstraint('discounted &lt; original', name='check_constraint_1')) index索引对象可以在列中定义，一般用到索引对象有下面几种情况： 1、定义多列复合索引 2、对索引命名 3、独立的对表创建索引，一般用于已经存在的表，增加索引 使用例子 i = Index('idx_name', user_table.c.first_name, user_table.c.last_name, unique=True) i.create(bind=e) 参考资料 -SQLAlchemy 学习（一)","tags":[{"name":"Python","slug":"Python","permalink":"http://www.jifu.io/tags/Python/"},{"name":"Library","slug":"Library","permalink":"http://www.jifu.io/tags/Library/"}],"categories":[{"name":"back-end","slug":"back-end","permalink":"http://www.jifu.io/categories/back-end/"},{"name":"Python","slug":"back-end/Python","permalink":"http://www.jifu.io/categories/back-end/Python/"},{"name":"Library","slug":"back-end/Python/Library","permalink":"http://www.jifu.io/categories/back-end/Python/Library/"}]},{"title":"Redis Manual","date":"2018-05-08T03:27:04.000Z","path":"posts/3909951181/","text":"Redis是什么redis（REmote DIctionary Server）是一个开源的、使用C语言编写的、支持网络交互的、基于内存也可持久化的高性能Key-Value数据库。 redis的官网地址，非常好记，是redis.io。（特意查了一下，域名后缀io属于国家域名，是british Indian Ocean territory，即英属印度洋领地） 目前，Vmware在资助着redis项目的开发和维护。 Redis 优势性能极高 – Redis非常快，每秒可执行大约110000次的设置(SET)操作，每秒大约可执行81000次的读取/获取(GET)操作。 支持丰富的数据类型 - Redis支持开发人员常用的大多数数据类型，例如列表，集合，排序集和散列等等。这使得Redis很容易被用来解决各种问题，因为我们知道哪些问题可以更好使用地哪些数据类型来处理解决。 操作具有原子性 - 所有Redis操作都是原子操作，这确保如果两个客户端并发访问，Redis服务器能接收更新的值。 多实用工具 - Redis是一个多实用工具，可用于多种用例，如：缓存，消息队列(Redis本地支持发布/订阅)，应用程序中的任何短期数据，例如，web应用程序中的会话，网页命中计数等。 支持数据的持久化 - 可以将内存中的数据保存在磁盘中，重启的时候可以再次加载进行使用。 注意：一个键最大能存储512MB。 Redis如何安装从redis.io下载最新版redis-X.Y.Z.tar.gz后解压，然后进入redis-X.Y.Z文件夹后直接make即可，安装非常简单。 make成功后会在src文件夹下产生一些二进制可执行文件，包括redis-server、redis-cli等等： $ find . -type f -executable ./redis-benchmark //用于进行redis性能测试的工具 ./redis-check-dump //用于修复出问题的dump.rdb文件 ./redis-cli //redis的客户端 ./redis-server //redis的服务端 ./redis-check-aof //用于修复出问题的AOF文件 ./redis-sentinel //用于集群管理 如何启动Redis服务启动redis非常简单，直接./redis-server就可以启动服务端了，还可以用下面的方法指定要加载的配置文件： ./redis-server ../redis.conf 默认情况下，redis-server会以非daemon的方式来运行，且默认服务端口为6379。 如何使用redis-cli客户端连接redis服务//这样来启动redis客户端了 $ ./redis-cli //用set指令来设置key、value 127.0.0.1:6379> set name \"roc\" OK //来获取name的值 127.0.0.1:6379> get name \"roc\" //通过客户端来关闭redis服务端 127.0.0.1:6379> shutdown 127.0.0.1:6379> redis-cli -服务端相关命令 command description time 返回当前服务器时间 client list 返回所有连接到服务器的客户端信息和统计数据 client kill ip:port 关闭地址为 ip:port 的客户端 save 将数据同步保存到磁盘 bgsave 将数据异步保存到磁盘 lastsave 返回上次成功将数据保存至磁盘的Unix时戳 shundown 将数据同步保存到磁盘，然后关闭服务 info 提供服务器的信息和统计 config resetstat 重置info命令中的某些统计数据 config get 获取配置文件信息 config set 动态地调整 Redis 服务器的配置而无须重启，可以修改的配置参数可以使用命令 CONFIG GET * 来列 config rewrite Redis 启动时的 redis.conf 改写 monitor 实时转储收到的请求 slaveof 改变复制策略设置 redis-cli - 发布订阅相关命令 command description psubscribe 订阅一个或多个符合给定模式的频道 例如psubscribe news. tweet. publish 将信息 message 发送到指定的频道 channel 例如publish msg “good morning” pubsub channels 列出当前的活跃频道 例如PUBSUB CHANNELS news.i* pubsub numsub 返回给定频道的订阅者数量 例如PUBSUB NUMSUB news.it news.internet news.sport news.music pubsub numpat 返回客户端订阅的所有模式的数量总和 punsubscribe 指示客户端退订所有给定模式。 subscribe 订阅给定的一个或多个频道的信息。例如 subscribe msg chat_room unsubscribe 指示客户端退订给定的频道。 redis-cli - KEY操作的命令 command description exists(key) 确认一个key是否存在 el(key) 删除一个key type(key) 返回值的类型 keys(pattern) 返回满足给定pattern的所有key randomkey 随机返回key空间的一个 keyrename(oldname, newname) 重命名key dbsize 返回当前数据库中key的数目 expire 设定一个key的活动时间（s） ttl 获得一个key的活动时间 move(key, dbindex) 移动当前数据库中的key到dbindex数据库 flushdb 删除当前选择数据库中的所有key flushall 删除所有数据库中的所有key redis-cli - String操作的命令 command description set(key, value) 给数据库中名称为key的string赋予值value get(key) 返回数据库中名称为key的string的value getset(key, value) 给名称为key的string赋予上一次的value mget(key1, key2,…, key N) 返回库中多个string的value setnx(key, value) 添加string，名称为key，值为value setex(key, time, value) 向库中添加string，设定过期时间time mset(key N, value N) 批量设置多个string的值 msetnx(key N, value N) 如果所有名称为key i的string都不存在 incr(key) 名称为key的string增1操作 incrby(key, integer) 名称为key的string增加integer decr(key) 名称为key的string减1操作 decrby(key, integer) 名称为key的string减少integer append(key, value) 名称为key的string的值附加value substr(key, start, end) 返回名称为key的string的value的子串 redis-cli - List操作的命令 command description rpush(key, value) 在名称为key的list尾添加一个值为value的元素 lpush(key, value) 在名称为key的list头添加一个值为value的 元素 llen(key) 返回名称为key的list的长度 lrange(key, start, end) 返回名称为key的list中start至end之间的元素 ltrim(key, start, end) 截取名称为key的list lindex(key, index) 返回名称为key的list中index位置的元素 lset(key, index, value) 给名称为key的list中index位置的元素赋值 lrem(key, count, value) 删除count个key的list中值为value的元素 lpop(key) 返回并删除名称为key的list中的首元素 rpop(key) 返回并删除名称为key的list中的尾元素 blpop(key1, key2,… key N, timeout) lpop命令的block版本。 brpop(key1, key2,… key N, timeout) rpop的block版本。 rpoplpush(srckey, dstkey) 返回并删除名称为srckey的list的尾元素，并将该元素添加到名称为dstkey的list的头部 redis-cli - Set操作的命令 command description sadd(key, member) 向名称为key的set中添加元素member srem(key, member) 删除名称为key的set中的元素member spop(key) 随机返回并删除名称为key的set中一个元素 smove(srckey, dstkey, member) 移到集合元素 scard(key) 返回名称为key的set的基数 sismember(key, member) member是否是名称为key的set的元素 sinter(key1, key2,…key N) 求交集 sinterstore(dstkey, (keys)) 求交集并将交集保存到dstkey的集合 sunion(key1, (keys)) 求并集 sunionstore(dstkey, (keys)) 求并集并将并集保存到dstkey的集合 sdiff(key1, (keys)) 求差集 sdiffstore(dstkey, (keys)) 求差集并将差集保存到dstkey的集合 smembers(key) 返回名称为key的set的所有元素 srandmember(key) 随机返回名称为key的set的一个元素 redis-cli - Hash操作的命令 command description hset(key, field, value) 向名称为key的hash中添加元素field hget(key, field) 返回名称为key的hash中field对应的value hmget(key, (fields)) 返回名称为key的hash中field i对应的value hmset(key, (fields)) 向名称为key的hash中添加元素field hincrby(key, field, integer) 将名称为key的hash中field的value增加integer hexists(key, field) 名称为key的hash中是否存在键为field的域 hdel(key, field) 删除名称为key的hash中键为field的域 hlen(key) 返回名称为key的hash中元素个数 hkeys(key) 返回名称为key的hash中所有键 hvals(key) 返回名称为key的hash中所有键对应的value hgetall(key) 返回名称为key的hash中所有的键（field）及其对应的value redis支持数据结构有哪些redis是一种高级的key:value存储系统，其中value支持五种数据类型： 1.字符串（strings）2.字符串列表（lists）3.字符串集合（sets）4.有序字符串集合（sorted sets）5.哈希（hashes） 而关于key，有几个点要提醒大家： 1.key不要太长，尽量不要超过1024字节，这不仅消耗内存，而且会降低查找的效率；2.key也不要太短，太短的话，key的可读性会降低；3.在一个项目中，key最好使用统一的命名模式，例如user:10000:passwd。 数据结构 - String有人说，如果只使用redis中的字符串类型，且不使用redis的持久化功能，那么，redis就和memcache非常非常的像了。这说明strings类型是一个很基础的数据类型，也是任何存储系统都必备的数据类型。 我们来看一个最简单的例子： set mystr \"hello world!\" //设置字符串类型 get mystr //读取字符串类型 字符串类型的用法就是这么简单，因为是二进制安全的，所以你完全可以把一个图片文件的内容作为字符串来存储。 另外，我们还可以通过字符串类型进行数值操作： 127.0.0.1:6379> set mynum \"2\" OK 127.0.0.1:6379> get mynum \"2\" 127.0.0.1:6379> incr mynum (integer) 3 127.0.0.1:6379> get mynum \"3\" 看，在遇到数值操作时，redis会将字符串类型转换成数值。 由于INCR等指令本身就具有原子操作的特性，所以我们完全可以利用redis的INCR、INCRBY、DECR、DECRBY等指令来实现原子计数的效果，假如，在某种场景下有3个客户端同时读取了mynum的值（值为2），然后对其同时进行了加1的操作，那么，最后mynum的值一定是5。不少网站都利用redis的这个特性来实现业务上的统计计数需求。 数据结构 – listsredis的另一个重要的数据结构叫做lists，翻译成中文叫做“列表”。 首先要明确一点，redis中的lists在底层实现上并不是数组，而是链表，也就是说对于一个具有上百万个元素的lists来说，在头部和尾部插入一个新元素，其时间复杂度是常数级别的，比如用LPUSH在10个元素的lists头部插入新元素，和在上千万元素的lists头部插入新元素的速度应该是相同的。 虽然lists有这样的优势，但同样有其弊端，那就是，链表型lists的元素定位会比较慢，而数组型lists的元素定位就会快得多。 lists的常用操作包括LPUSH、RPUSH、LRANGE等。我们可以用LPUSH在lists的左侧插入一个新元素，用RPUSH在lists的右侧插入一个新元素，用LRANGE命令从lists中指定一个范围来提取元素。 //新建一个list叫做mylist，并在列表头部插入元素\"1\" 127.0.0.1:6379> lpush mylist \"1\" //返回当前mylist中的元素个数 (integer) 1 //在mylist右侧插入元素\"2\" 127.0.0.1:6379> rpush mylist \"2\" (integer) 2 //在mylist左侧插入元素\"0\" 127.0.0.1:6379> lpush mylist \"0\" (integer) 3 //列出mylist中从编号0到编号1的元素 127.0.0.1:6379> lrange mylist 0 1 1) \"0\" 2) \"1\" //列出mylist中从编号0到倒数第一个元素 127.0.0.1:6379> lrange mylist 0 -1 1) \"0\" 2) \"1\" 3) \"2\" lists的应用相当广泛，随便举几个例子： 1.我们可以利用lists来实现一个消息队列，而且可以确保先后顺序，不必像MySQL那样还需要通过ORDER BY来进行排序。2.利用LRANGE还可以很方便的实现分页的功能。3.在博客系统中，每片博文的评论也可以存入一个单独的list中。 数据结构 – setredis的集合，是一种无序的集合，集合中的元素没有先后顺序。 集合相关的操作也很丰富，如添加新元素、删除已有元素、取交集、取并集、取差集等。 //向集合myset中加入一个新元素\"one\" 127.0.0.1:6379> sadd myset \"one\" (integer) 1 127.0.0.1:6379> sadd myset \"two\" (integer) 1 //列出集合myset中的所有元素 127.0.0.1:6379> smembers myset 1) \"one\" 2) \"two\" //判断元素1是否在集合myset中，返回1表示存在 127.0.0.1:6379> sismember myset \"one\" (integer) 1 //判断元素3是否在集合myset中，返回0表示不存在 127.0.0.1:6379> sismember myset \"three\" (integer) 0 //新建一个新的集合yourset 127.0.0.1:6379> sadd yourset \"1\" (integer) 1 127.0.0.1:6379> sadd yourset \"2\" (integer) 1 127.0.0.1:6379> smembers yourset 1) \"1\" 2) \"2\" //对两个集合求并集 127.0.0.1:6379> sunion myset yourset 1) \"1\" 2) \"one\" 3) \"2\" 4) \"two\" 数据结构 – sorted setsredis不但提供了无需集合（sets），还很体贴的提供了有序集合（sorted sets）。有序集合中的每个元素都关联一个序号（score），这便是排序的依据。 很多时候，我们都将redis中的有序集合叫做zsets，这是因为在redis中，有序集合相关的操作指令都是以z开头的，比如zrange、zadd、zrevrange、zrangebyscore等等 //新增一个有序集合myzset，并加入一个元素baidu.com，给它赋予的序号是1： 127.0.0.1:6379> zadd myzset 1 baidu.com (integer) 1 //向myzset中新增一个元素360.com，赋予它的序号是3 127.0.0.1:6379> zadd myzset 3 360.com (integer) 1 //向myzset中新增一个元素google.com，赋予它的序号是2 127.0.0.1:6379> zadd myzset 2 google.com (integer) 1 //列出myzset的所有元素，同时列出其序号，可以看出myzset已经是有序的了。 127.0.0.1:6379> zrange myzset 0 -1 with scores 1) \"baidu.com\" 2) \"1\" 3) \"google.com\" 4) \"2\" 5) \"360.com\" 6) \"3\" //只列出myzset的元素 127.0.0.1:6379> zrange myzset 0 -1 1) \"baidu.com\" 2) \"google.com\" 3) \"360.com\" 数据结构 – hash最后要给大家介绍的是hashes，即哈希。哈希是从redis-2.0.0版本之后才有的数据结构。 hashes存的是字符串和字符串值之间的映射，比如一个用户要存储其全名、姓氏、年龄等等，就很适合使用哈希。 //建立哈希，并赋值 127.0.0.1:6379> HMSET user:001 username antirez password P1pp0 age 34 OK //列出哈希的内容 127.0.0.1:6379> HGETALL user:001 1) \"username\" 2) \"antirez\" 3) \"password\" 4) \"P1pp0\" 5) \"age\" 6) \"34\" //更改哈希中的某一个值 127.0.0.1:6379> HSET user:001 password 12345 (integer) 0 //再次列出哈希的内容 127.0.0.1:6379> HGETALL user:001 1) \"username\" 2) \"antirez\" 3) \"password\" 4) \"12345\" 5) \"age\" 6) \"34\" redis持久化 – 介绍redis提供了两种持久化的方式，分别是RDB（Redis DataBase）和AOF（Append Only File）。 RDB (RDB默认开启)，简而言之，就是在不同的时间点，将redis存储的数据生成快照并存储到磁盘等介质上； AOF，则是换了一个角度来实现持久化，那就是将redis执行过的所有写指令记录下来，在下次redis重新启动时，只要把这些写指令从前到后再重复执行一遍，就可以实现数据恢复了。 其实RDB和AOF两种方式也可以同时使用，在这种情况下，如果redis重启的话，则会优先采用AOF方式来进行数据恢复，这是因为AOF方式的数据恢复完整度更高。 如果你没有数据持久化的需求，也完全可以关闭RDB和AOF方式，这样的话，redis将变成一个纯内存数据库，就像memcache一样。 redis持久化 – RDBRDB(Snapshot)方式，是将redis某一时刻的数据持久化到磁盘中，是一种快照式的持久化方法。 优点：使用单独子进程来进行持久化，主进程不会进行任何IO操作，保证了redis的高性能 缺点：RDB是间隔一段时间进行持久化，如果持久化之间redis发生故障，会发生数据丢失。所以这种方式更适合数据要求不严谨的时候 redis在进行数据持久化的过程中，会先将数据写入到一个临时文件中，待持久化过程都结束了，才会用这个临时文件替换上次持久化好的文件。正是这种特性，让我们可以随时来进行备份，因为快照文件总是完整可用的。 对于RDB方式，redis会单独创建（fork）一个子进程来进行持久化，而主进程是不会进行任何IO操作的，这样就确保了redis极高的性能。 如果需要进行大规模数据的恢复，且对于数据恢复的完整性不是非常敏感，那RDB方式要比AOF方式更加的高效。 虽然RDB有不少优点，但它的缺点也是不容忽视的。如果你对数据的完整性非常敏感，那么RDB方式就不太适合你，因为即使你每5分钟都持久化一次，当redis故障时，仍然会有近5分钟的数据丢失。所以，redis还提供了另一种持久化方式，那就是AOF。 redis持久化 – AOFAOF，英文是Append Only File，即只允许追加不允许改写的文件。 优点：可以保持更高的数据完整性，如果设置追加file的时间是1s，如果redis发生故障，最多会丢失1s的数据；且如果日志写入不完整支持redis-check-aof来进行日志修复；AOF文件没被rewrite之前（文件过大时会对命令进行合并重写），可以删除其中的某些命令（比如误操作的flushall）。 缺点：AOF文件比RDB文件大，且恢复速度慢。 如前面介绍的，AOF方式是将执行过的写指令记录下来，在数据恢复时按照从前到后的顺序再将指令都执行一遍，就这么简单。 我们通过配置redis.conf中的appendonly yes就可以打开AOF功能。如果有写操作（如SET等），redis就会被追加到AOF文件的末尾。 默认的AOF持久化策略是每秒钟fsync一次（fsync是指把缓存中的写指令记录到磁盘中），因为在这种情况下，redis仍然可以保持很好的处理性能，即使redis故障，也只会丢失最近1秒钟的数据。 如果在追加日志时，恰好遇到磁盘空间满、inode满或断电等情况导致日志写入不完整，也没有关系，redis提供了redis-check-aof工具，可以用来进行日志修复。 因为采用了追加方式，如果不做任何处理的话，AOF文件会变得越来越大，为此，redis提供了AOF文件重写（rewrite）机制，即当AOF文件的大小超过所设定的阈值时，redis就会启动AOF文件的内容压缩，只保留可以恢复数据的最小指令集。举个例子或许更形象，假如我们调用了100次INCR指令，在AOF文件中就要存储100条指令，但这明显是很低效的，完全可以把这100条指令合并成一条SET指令，这就是重写机制的原理。 在进行AOF重写时，仍然是采用先写临时文件，全部完成后再替换的流程，所以断电、磁盘满等问题都不会影响AOF文件的可用性，这点大家可以放心。 AOF方式的另一个好处，我们通过一个“场景再现”来说明。某同学在操作redis时，不小心执行了FLUSHALL，导致redis内存中的数据全部被清空了，这是很悲剧的事情。不过这也不是世界末日，只要redis配置了AOF持久化方式，且AOF文件还没有被重写（rewrite），我们就可以用最快的速度暂停redis并编辑AOF文件，将最后一行的FLUSHALL命令删除，然后重启redis，就可以恢复redis的所有数据到FLUSHALL之前的状态了。是不是很神奇，这就是AOF持久化方式的好处之一。但是如果AOF文件已经被重写了，那就无法通过这种方法来恢复数据了。 虽然优点多多，但AOF方式也同样存在缺陷，比如在同样数据规模的情况下，AOF文件要比RDB文件的体积大。而且，AOF方式的恢复速度也要慢于RDB方式。 如果你直接执行BGREWRITEAOF命令，那么redis会生成一个全新的AOF文件，其中便包括了可以恢复现有数据的最少的命令集。 如果运气比较差，AOF文件出现了被写坏的情况，也不必过分担忧，redis并不会贸然加载这个有问题的AOF文件，而是报错退出。这时可以通过以下步骤来修复出错的文件： 1.备份被写坏的AOF文件2.运行redis-check-aof –fix进行修复3.用diff -u来看下两个文件的差异，确认问题点4.重启redis，加载修复后的AOF文件 redis持久化 – AOF重写AOF重写的内部运行原理，我们有必要了解一下。 在重写即将开始之际，redis会创建（fork）一个“重写子进程”，这个子进程会首先读取现有的AOF文件，并将其包含的指令进行分析压缩并写入到一个临时文件中。 与此同时，主工作进程会将新接收到的写指令一边累积到内存缓冲区中，一边继续写入到原有的AOF文件中，这样做是保证原有的AOF文件的可用性，避免在重写过程中出现意外。 当“重写子进程”完成重写工作后，它会给父进程发一个信号，父进程收到信号后就会将内存中缓存的写指令追加到新AOF文件中。 当追加结束后，redis就会用新AOF文件来代替旧AOF文件，之后再有新的写指令，就都会追加到新的AOF文件中了。 redis持久化 – 如何选择RDB和AOF对于我们应该选择RDB还是AOF，官方的建议是两个同时使用。这样可以提供更可靠的持久化方案。 redis主从 – 介绍像MySQL一样，redis是支持主从同步的，而且也支持一主多从以及多级从结构。 主从结构，一是为了纯粹的冗余备份，二是为了提升读性能，比如很消耗性能的SORT就可以由从服务器来承担。 redis的主从同步是异步进行的，这意味着主从同步不会影响主逻辑，也不会降低redis的处理性能。 主从架构中，可以考虑关闭主服务器的数据持久化功能，只让从服务器进行持久化，这样可以提高主服务器的处理性能。 在主从架构中，从服务器通常被设置为只读模式，这样可以避免从服务器的数据被误修改。但是从服务器仍然可以接受CONFIG等指令，所以还是不应该将从服务器直接暴露到不安全的网络环境中。如果必须如此，那可以考虑给重要指令进行重命名，来避免命令被外人误执行。 redis主从 – 同步原理从服务器会向主服务器发出SYNC指令，当主服务器接到此命令后，就会调用BGSAVE指令来创建一个子进程专门进行数据持久化工作，也就是将主服务器的数据写入RDB文件中。在数据持久化期间，主服务器将执行的写指令都缓存在内存中。 在BGSAVE指令执行完成后，主服务器会将持久化好的RDB文件发送给从服务器，从服务器接到此文件后会将其存储到磁盘上，然后再将其读取到内存中。这个动作完成后，主服务器会将这段时间缓存的写指令再以redis协议的格式发送给从服务器。 另外，要说的一点是，即使有多个从服务器同时发来SYNC指令，主服务器也只会执行一次BGSAVE，然后把持久化好的RDB文件发给多个下游。在redis2.8版本之前，如果从服务器与主服务器因某些原因断开连接的话，都会进行一次主从之间的全量的数据同步；而在2.8版本之后，redis支持了效率更高的增量同步策略，这大大降低了连接断开的恢复成本。 主服务器会在内存中维护一个缓冲区，缓冲区中存储着将要发给从服务器的内容。从服务器在与主服务器出现网络瞬断之后，从服务器会尝试再次与主服务器连接，一旦连接成功，从服务器就会把“希望同步的主服务器ID”和“希望请求的数据的偏移位置（replication offset）”发送出去。主服务器接收到这样的同步请求后，首先会验证主服务器ID是否和自己的ID匹配，其次会检查“请求的偏移位置”是否存在于自己的缓冲区中，如果两者都满足的话，主服务器就会向从服务器发送增量内容。 增量同步功能，需要服务器端支持全新的PSYNC指令。这个指令，只有在redis-2.8之后才具有。 redis事务众所周知，事务是指“一个完整的动作，要么全部执行，要么什么也没有做”。 在聊redis事务处理之前，要先和大家介绍四个redis指令，即MULTI、EXEC、DISCARD、WATCH。这四个指令构成了redis事务处理的基础。 1.MULTI用来组装一个事务；2.EXEC用来执行一个事务；3.DISCARD用来取消一个事务；4.WATCH用来监视一些key，一旦这些key在事务执行之前被改变，则取消事务的执行。 纸上得来终觉浅，我们来看一个MULTI和EXEC的例子： redis> MULTI //标记事务开始 OK redis> INCR user_id //多条命令按顺序入队 QUEUED redis> INCR user_id QUEUED redis> INCR user_id QUEUED redis> PING QUEUED redis> EXEC //执行 1) (integer) 1 2) (integer) 2 3) (integer) 3 4) PONG 在上面的例子中，我们看到了QUEUED的字样，这表示我们在用MULTI组装事务时，每一个命令都会进入到内存队列中缓存起来，如果出现QUEUED则表示我们这个命令成功插入了缓存队列，在将来执行EXEC时，这些被QUEUED的命令都会被组装成一个事务来执行。 对于事务的执行来说，如果redis开启了AOF持久化的话，那么一旦事务被成功执行，事务中的命令就会通过write命令一次性写到磁盘中去，如果在向磁盘中写的过程中恰好出现断电、硬件故障等问题，那么就可能出现只有部分命令进行了AOF持久化，这时AOF文件就会出现不完整的情况，这时，我们可以使用redis-check-aof工具来修复这一问题，这个工具会将AOF文件中不完整的信息移除，确保AOF文件完整可用。 有关事务，大家经常会遇到的是两类错误： 1.调用EXEC之前的错误2.调用EXEC之后的错误 “调用EXEC之前的错误”，有可能是由于语法有误导致的，也可能时由于内存不足导致的。只要出现某个命令无法成功写入缓冲队列的情况，redis都会进行记录，在客户端调用EXEC时，redis会拒绝执行这一事务。（这时2.6.5版本之后的策略。在2.6.5之前的版本中，redis会忽略那些入队失败的命令，只执行那些入队成功的命令）。我们来看一个这样的例子： 127.0.0.1:6379> multi OK 127.0.0.1:6379> haha //一个明显错误的指令 (error) ERR unknown command 'haha' 127.0.0.1:6379> ping QUEUED 127.0.0.1:6379> exec //redis无情的拒绝了事务的执行，原因是“之前出现了错误” (error) EXECABORT Transaction discarded because of previous errors. 而对于“调用EXEC之后的错误”，redis则采取了完全不同的策略，即redis不会理睬这些错误，而是继续向下执行事务中的其他命令。这是因为，对于应用层面的错误，并不是redis自身需要考虑和处理的问题，所以一个事务中如果某一条命令执行失败，并不会影响接下来的其他命令的执行。我们也来看一个例子： 127.0.0.1:6379> multi OK 127.0.0.1:6379> set age 23 QUEUED //age不是集合，所以如下是一条明显错误的指令 127.0.0.1:6379> sadd age 15 QUEUED 127.0.0.1:6379> set age 29 QUEUED 127.0.0.1:6379> exec //执行事务时，redis不会理睬第2条指令执行错误 1) OK 2) (error) WRONGTYPE Operation against a key holding the wrong kind of value 3) OK 127.0.0.1:6379> get age \"29\" //可以看出第3条指令被成功执行了 好了，我们来说说最后一个指令“WATCH”，这是一个很好用的指令，它可以帮我们实现类似于“乐观锁”的效果，即CAS（check and set）。 WATCH本身的作用是“监视key是否被改动过”，而且支持同时监视多个key，只要还没真正触发事务，WATCH都会尽职尽责的监视，一旦发现某个key被修改了，在执行EXEC时就会返回nil，表示事务无法触发。 127.0.0.1:6379> set age 23 OK 127.0.0.1:6379> watch age //开始监视age OK 127.0.0.1:6379> set age 24 //在EXEC之前，age的值被修改了 OK 127.0.0.1:6379> multi OK 127.0.0.1:6379> set age 25 QUEUED 127.0.0.1:6379> get age QUEUED 127.0.0.1:6379> exec //触发EXEC (nil) //事务无法被执行 redis配置 – 简介我们可以在启动redis-server时指定应该加载的配置文件，方法如下： /redis-server /path/to/redis.conf 接下来，我们就来讲解下redis配置文件的各个配置项的含义，注意，本文是基于redis-2.8.4版本进行讲解的。 redis官方提供的redis.conf文件，足有700+行，其中100多行为有效配置行，另外的600多行为注释说明。 在配置文件的开头部分，首先明确了一些度量单位： # 1k => 1000 bytes # 1kb => 1024 bytes # 1m => 1000000 bytes # 1mb => 1024*1024 bytes # 1g => 1000000000 bytes # 1gb => 1024*1024*1024 bytes 可以看出，redis配置中对单位的大小写不敏感，1GB、1Gb和1gB都是相同的。由此也说明，redis只支持bytes，不支持bit单位。 redis支持“主配置文件中引入外部配置文件”，很像C/C++中的include指令，比如： include /path/to/other.conf 如果你看过redis的配置文件，会发现还是很有条理的。redis配置文件被分成了几大块区域，它们分别是： 1.通用（general）2.快照（snapshotting）3.复制（replication）4.安全（security）5.限制（limits)6.追加模式（append only mode)7.LUA脚本（lua scripting)8.慢日志（slow log)9.事件通知（event notification） redis配置 – 通用默认情况下，redis并不是以daemon形式来运行的。通过daemonize配置项可以控制redis的运行形式，如果改为yes，那么redis就会以daemon形式运行： daemonize no 当以daemon形式运行时，redis会生成一个pid文件，默认会生成在/var/run/redis.pid。当然，你可以通过pidfile来指定pid文件生成的位置，比如： pidfile /path/to/redis.pid 默认情况下，redis会响应本机所有可用网卡的连接请求。当然，redis允许你通过bind配置项来指定要绑定的IP，比如： bind 192.168.1.2 10.8.4.2 redis的默认服务端口是6379，你可以通过port配置项来修改。如果端口设置为0的话，redis便不会监听端口了。 port 6379 有些同学会问“如果redis不监听端口，还怎么与外界通信呢”，其实redis还支持通过unix socket方式来接收请求。可以通过unixsocket配置项来指定unix socket文件的路径，并通过unixsocketperm来指定文件的权限。 unixsocket /tmp/redis.sock unixsocketperm 755 当一个redis-client一直没有请求发向server端，那么server端有权主动关闭这个连接，可以通过timeout来设置“空闲超时时限”，0表示永不关闭。 timeout 0 TCP连接保活策略，可以通过tcp-keepalive配置项来进行设置，单位为秒，假如设置为60秒，则server端会每60秒向连接空闲的客户端发起一次ACK请求，以检查客户端是否已经挂掉，对于无响应的客户端则会关闭其连接。所以关闭一个连接最长需要120秒的时间。如果设置为0，则不会进行保活检测。 tcp-keepalive 0 redis支持通过loglevel配置项设置日志等级，共分四级，即debug、verbose、notice、warning。 loglevel notice redis也支持通过logfile配置项来设置日志文件的生成位置。如果设置为空字符串，则redis会将日志输出到标准输出。假如你在daemon情况下将日志设置为输出到标准输出，则日志会被写到/dev/null中。 logfile &quot;&quot; 如果希望日志打印到syslog中，也很容易，通过syslog-enabled来控制。另外，syslog-ident还可以让你指定syslog里的日志标志，比如： syslog-ident redis 而且还支持指定syslog设备，值可以是USER或LOCAL0-LOCAL7。具体可以参考syslog服务本身的用法。 syslog-facility local0 对于redis来说，可以设置其数据库的总数量，假如你希望一个redis包含16个数据库，那么设置如下： databases 16 这16个数据库的编号将是0到15。默认的数据库是编号为0的数据库。用户可以使用select来选择相应的数据库。 redis配置 - 快照快照，主要涉及的是redis的RDB持久化相关的配置，我们来一起看一看。 我们可以用如下的指令来让数据保存到磁盘上，即控制RDB快照功能： save &lt;seconds&gt; &lt;changes&gt; save 900 1 //表示每15分钟且至少有1个key改变，就触发一次持久化 save 300 10 //表示每5分钟且至少有10个key改变，就触发一次持久化 save 60 10000 //表示每60秒至少有10000个key改变，就触发一次持久化 如果你想禁用RDB持久化的策略，只要不设置任何save指令就可以，或者给save传入一个空字符串参数也可以达到相同效果，就像这样： save &quot;&quot; 如果用户开启了RDB快照功能，那么在redis持久化数据到磁盘时如果出现失败，默认情况下，redis会停止接受所有的写请求。这样做的好处在于可以让用户很明确的知道内存中的数据和磁盘上的数据已经存在不一致了。如果redis不顾这种不一致，一意孤行的继续接收写请求，就可能会引起一些灾难性的后果。 如果下一次RDB持久化成功，redis会自动恢复接受写请求。 当然，如果你不在乎这种数据不一致或者有其他的手段发现和控制这种不一致的话，你完全可以关闭这个功能，以便在快照写入失败时，也能确保redis继续接受新的写请求。配置项如下： stop-writes-on-bgsave-error yes 对于存储到磁盘中的快照，可以设置是否进行压缩存储。如果是的话，redis会采用LZF算法进行压缩。如果你不想消耗CPU来进行压缩的话，可以设置为关闭此功能，但是存储在磁盘上的快照会比较大。 rdbcompression yes 在存储快照后，我们还可以让redis使用CRC64算法来进行数据校验，但是这样做会增加大约10%的性能消耗，如果你希望获取到最大的性能提升，可以关闭此功能。 rdbchecksum yes 我们还可以设置快照文件的名称，默认是这样配置的： dbfilename dump.rdb 最后，你还可以设置这个快照文件存放的路径。比如默认设置就是当前文件夹： dir ./ redis配置 – 复制redis提供了主从同步功能。 通过slaveof配置项可以控制某一个redis作为另一个redis的从服务器，通过指定IP和端口来定位到主redis的位置。一般情况下，我们会建议用户为从redis设置一个不同频率的快照持久化的周期，或者为从redis配置一个不同的服务端口等等。 slaveof &lt;masterip&gt; &lt;masterport&gt; 如果主redis设置了验证密码的话（使用requirepass来设置），则在从redis的配置中要使用masterauth来设置校验密码，否则的话，主redis会拒绝从redis的访问请求。 masterauth &lt;master-password&gt; 当从redis失去了与主redis的连接，或者主从同步正在进行中时，redis该如何处理外部发来的访问请求呢这里，从redis可以有两种选择： 第一种选择：如果slave-serve-stale-data设置为yes（默认），则从redis仍会继续响应客户端的读写请求。 第二种选择：如果slave-serve-stale-data设置为no，则从redis会对客户端的请求返回“SYNC with master in progress”，当然也有例外，当客户端发来INFO请求和SLAVEOF请求，从redis还是会进行处理。 你可以控制一个从redis是否可以接受写请求。将数据直接写入从redis，一般只适用于那些生命周期非常短的数据，因为在主从同步时，这些临时数据就会被清理掉。自从redis2.6版本之后，默认从redis为只读。 slave-read-only yes 只读的从redis并不适合直接暴露给不可信的客户端。为了尽量降低风险，可以使用rename-command指令来将一些可能有破坏力的命令重命名，避免外部直接调用。比如： rename-command CONFIG b840fc02d524045429941cc15f59e41cb7be6c52 从redis会周期性的向主redis发出PING包。你可以通过repl_ping_slave_period指令来控制其周期。默认是10秒。 repl-ping-slave-period 10 在主从同步时，可能在这些情况下会有超时发生： 1.以从redis的角度来看，当有大规模IO传输时。2.以从redis的角度来看，当数据传输或PING时，主redis超时3.以主redis的角度来看，在回复从redis的PING时，从redis超时 用户可以设置上述超时的时限，不过要确保这个时限比repl-ping-slave-period的值要大，否则每次主redis都会认为从redis超时。 repl-timeout 60 我们可以控制在主从同步时是否禁用TCP_NODELAY。如果开启TCP_NODELAY，那么主redis会使用更少的TCP包和更少的带宽来向从redis传输数据。但是这可能会增加一些同步的延迟，大概会达到40毫秒左右。如果你关闭了TCP_NODELAY，那么数据同步的延迟时间会降低，但是会消耗更多的带宽。（如果你不了解TCP_NODELAY，可以到这里来科普一下）。 repl-disable-tcp-nodelay no 我们还可以设置同步队列长度。队列长度（backlog)是主redis中的一个缓冲区，在与从redis断开连接期间，主redis会用这个缓冲区来缓存应该发给从redis的数据。这样的话，当从redis重新连接上之后，就不必重新全量同步数据，只需要同步这部分增量数据即可。 repl-backlog-size 1mb 如果主redis等了一段时间之后，还是无法连接到从redis，那么缓冲队列中的数据将被清理掉。我们可以设置主redis要等待的时间长度。如果设置为0，则表示永远不清理。默认是1个小时。 repl-backlog-ttl 3600 我们可以给众多的从redis设置优先级，在主redis持续工作不正常的情况，优先级高的从redis将会升级为主redis。而编号越小，优先级越高。比如一个主redis有三个从redis，优先级编号分别为10、100、25，那么编号为10的从redis将会被首先选中升级为主redis。当优先级被设置为0时，这个从redis将永远也不会被选中。默认的优先级为100。 slave-priority 100 假如主redis发现有超过M个从redis的连接延时大于N秒，那么主redis就停止接受外来的写请求。这是因为从redis一般会每秒钟都向主redis发出PING，而主redis会记录每一个从redis最近一次发来PING的时间点，所以主redis能够了解每一个从redis的运行情况。 min-slaves-to-write 3min-slaves-max-lag 10 上面这个例子表示，假如有大于等于3个从redis的连接延迟大于10秒，那么主redis就不再接受外部的写请求。上述两个配置中有一个被置为0，则这个特性将被关闭。默认情况下min-slaves-to-write为0，而min-slaves-max-lag为10。 redis配置 - 安全我们可以要求redis客户端在向redis-server发送请求之前，先进行密码验证。当你的redis-server处于一个不太可信的网络环境中时，相信你会用上这个功能。由于redis性能非常高，所以每秒钟可以完成多达15万次的密码尝试，所以你最好设置一个足够复杂的密码，否则很容易被黑客破解。 requirepass zhimakaimen 这里我们通过requirepass将密码设置成“芝麻开门”。 redis允许我们对redis指令进行更名，比如将一些比较危险的命令改个名字，避免被误执行。比如可以把CONFIG命令改成一个很复杂的名字，这样可以避免外部的调用，同时还可以满足内部调用的需要： rename-command CONFIG b840fc02d524045429941cc15f59e41cb7be6c89 我们甚至可以禁用掉CONFIG命令，那就是把CONFIG的名字改成一个空字符串： rename-command CONFIG &quot;&quot; 但需要注意的是，如果你使用AOF方式进行数据持久化，或者需要与从redis进行通信，那么更改指令的名字可能会引起一些问题。 redis配置 - 限制我们可以设置redis同时可以与多少个客户端进行连接。默认情况下为10000个客户端。当你无法设置进程文件句柄限制时，redis会设置为当前的文件句柄限制值减去32，因为redis会为自身内部处理逻辑留一些句柄出来。 如果达到了此限制，redis则会拒绝新的连接请求，并且向这些连接请求方发出“max number of clients reached”以作回应。 maxclients 10000 我们甚至可以设置redis可以使用的内存量。一旦到达内存使用上限，redis将会试图移除内部数据，移除规则可以通过maxmemory-policy来指定。 如果redis无法根据移除规则来移除内存中的数据，或者我们设置了“不允许移除”，那么redis则会针对那些需要申请内存的指令返回错误信息，比如SET、LPUSH等。但是对于无内存申请的指令，仍然会正常响应，比如GET等。 maxmemory &lt;bytes&gt; 需要注意的一点是，如果你的redis是主redis（说明你的redis有从redis），那么在设置内存使用上限时，需要在系统中留出一些内存空间给同步队列缓存，只有在你设置的是“不移除”的情况下，才不用考虑这个因素。 对于内存移除规则来说，redis提供了多达6种的移除规则。他们是： 1.volatile-lru：使用LRU算法移除过期集合中的key2.allkeys-lru：使用LRU算法移除key3.volatile-random：在过期集合中移除随机的key4.allkeys-random：移除随机的key5.volatile-ttl：移除那些TTL值最小的key，即那些最近才过期的key。6.noeviction：不进行移除。针对写操作，只是返回错误信息。 无论使用上述哪一种移除规则，如果没有合适的key可以移除的话，redis都会针对写请求返回错误信息。 maxmemory-policy volatile-lru LRU算法和最小TTL算法都并非是精确的算法，而是估算值。所以你可以设置样本的大小。假如redis默认会检查三个key并选择其中LRU的那个，那么你可以改变这个key样本的数量。 maxmemory-samples 3 最后，我们补充一个信息，那就是到目前版本（2.8.4）为止，redis支持的写指令包括了如下这些： set setnx setex append incr decr rpush lpush rpushx lpushx linsert lset rpoplpush sadd sinter sinterstore sunion sunionstore sdiff sdiffstore zadd zincrby zunionstore zinterstore hset hsetnx hmset hincrby incrby decrby getset mset msetnx exec sort redis配置 - 追加模式默认情况下，redis会异步的将数据持久化到磁盘。这种模式在大部分应用程序中已被验证是很有效的，但是在一些问题发生时，比如断电，则这种机制可能会导致数分钟的写请求丢失。 如博文上半部分中介绍的，追加文件（Append Only File）是一种更好的保持数据一致性的方式。即使当服务器断电时，也仅会有1秒钟的写请求丢失，当redis进程出现问题且操作系统运行正常时，甚至只会丢失一条写请求。 我们建议大家，AOF机制和RDB机制可以同时使用，不会有任何冲突。对于如何保持数据一致性的讨论，请参见本文。 appendonly no 我们还可以设置aof文件的名称： appendfilename &quot;appendonly.aof&quot; fsync()调用，用来告诉操作系统立即将缓存的指令写入磁盘。一些操作系统会“立即”进行，而另外一些操作系统则会“尽快”进行。 redis支持三种不同的模式： 1.no：不调用fsync()。而是让操作系统自行决定sync的时间。这种模式下，redis的性能会最快。2.always：在每次写请求后都调用fsync()。这种模式下，redis会相对较慢，但数据最安全。3.everysec：每秒钟调用一次fsync()。这是性能和安全的折衷。 默认情况下为everysec。有关数据一致性的揭秘，可以参考本文。 appendfsync everysec 当fsync方式设置为always或everysec时，如果后台持久化进程需要执行一个很大的磁盘IO操作，那么redis可能会在fsync()调用时卡住。目前尚未修复这个问题，这是因为即使我们在另一个新的线程中去执行fsync()，也会阻塞住同步写调用。 为了缓解这个问题，我们可以使用下面的配置项，这样的话，当BGSAVE或BGWRITEAOF运行时，fsync()在主进程中的调用会被阻止。这意味着当另一路进程正在对AOF文件进行重构时，redis的持久化功能就失效了，就好像我们设置了“appendsync none”一样。如果你的redis有时延问题，那么请将下面的选项设置为yes。否则请保持no，因为这是保证数据完整性的最安全的选择。 no-appendfsync-on-rewrite no 我们允许redis自动重写aof。当aof增长到一定规模时，redis会隐式调用BGREWRITEAOF来重写log文件，以缩减文件体积。 redis是这样工作的：redis会记录上次重写时的aof大小。假如redis自启动至今还没有进行过重写，那么启动时aof文件的大小会被作为基准值。这个基准值会和当前的aof大小进行比较。如果当前aof大小超出所设置的增长比例，则会触发重写。另外，你还需要设置一个最小大小，是为了防止在aof很小时就触发重写。 auto-aof-rewrite-percentage 100auto-aof-rewrite-min-size 64mb 如果设置auto-aof-rewrite-percentage为0，则会关闭此重写功能。 redis配置 – LUA脚本lua脚本的最大运行时间是需要被严格限制的，要注意单位是毫秒： lua-time-limit 5000 如果此值设置为0或负数，则既不会有报错也不会有时间限制。 redis配置 – 慢日志redis慢日志是指一个系统进行日志查询超过了指定的时长。这个时长不包括IO操作，比如与客户端的交互、发送响应内容等，而仅包括实际执行查询命令的时间。 针对慢日志，你可以设置两个参数，一个是执行时长，单位是微秒，另一个是慢日志的长度。当一个新的命令被写入日志时，最老的一条会从命令日志队列中被移除。 单位是微秒，即1000000表示一秒。负数则会禁用慢日志功能，而0则表示强制记录每一个命令。 slowlog-log-slower-than 10000 慢日志最大长度，可以随便填写数值，没有上限，但要注意它会消耗内存。你可以使用SLOWLOG RESET来重设这个值。 slowlog-max-len 128 redis配置 – 事件通知redis可以向客户端通知某些事件的发生。这个特性的具体解释可以参见本文。 redis配置 – 高级配置有关哈希数据结构的一些配置项： hash-max-ziplist-entries 512hash-max-ziplist-value 64 有关列表数据结构的一些配置项： list-max-ziplist-entries 512list-max-ziplist-value 64 有关集合数据结构的配置项： set-max-intset-entries 512 有关有序集合数据结构的配置项： zset-max-ziplist-entries 128zset-max-ziplist-value 64 关于是否需要再哈希的配置项： activerehashing yes 关于客户端输出缓冲的控制项： client-output-buffer-limit normal 0 0 0 client-output-buffer-limit slave 256mb 64mb 60 client-output-buffer-limit pubsub 32mb 8mb 60 有关频率的配置项： hz 10 有关重写aof的配置项 aof-rewrite-incremental-fsync yes redis哨兵机制 - SentinelSentinel的作用A、Master 状态监测 B、如果Master 异常，则会进行Master-slave 转换，将其中数据最新的一个Slave作为Master，将之前的Master作为Slave C、Master-Slave切换后，master_redis.conf、slave_redis.conf和sentinel.conf的内容都会发生改变，即master_redis.conf中会多一行slaveof的配置，sentinel.conf的监控目标会随之调换 Sentinel的工作方式1)：每个Sentinel以每秒钟一次的频率向它所知的Master，Slave以及其他 Sentinel 实例发送一个 PING 命令 2)：如果一个实例（instance）距离最后一次有效回复 PING 命令的时间超过 down-after-milliseconds 选项所指定的值， 则这个实例会被 Sentinel 标记为主观下线。 3)：如果一个Master被标记为主观下线，则正在监视这个Master的所有 Sentinel 要以每秒一次的频率确认Master的确进入了主观下线状态。 4)：当有足够数量的 Sentinel（大于等于配置文件指定的值）在指定的时间范围内确认Master的确进入了主观下线状态， 则Master会被标记为客观下线 5)：在一般情况下， 每个 Sentinel 会以每 10 秒一次的频率向它已知的所有Master，Slave发送 INFO 命令 6)：当Master被 Sentinel 标记为客观下线时，Sentinel 向下线的 Master 的所有 Slave 发送 INFO 命令的频率会从 10 秒一次改为每秒一次 7)：若没有足够数量的 Sentinel 同意 Master 已经下线， Master 的客观下线状态就会被移除。 若 Master 重新向 Sentinel 的 PING 命令返回有效回复， Master 的主观下线状态就会被移除。 Sentinel简要搭建方法环境概要模拟搭建一主两从的sentinel服务集群，准备好三台虚拟机，每台机器部署一个redis实例服务和一个sentinel哨兵服务，其中选定10.7.3.88机器上的redis服务为Master，其他两台机器的redis服务为Slave。具体如下： 机器IP redis实例 角色 sentinel服务 10.7.3.88 实例1（6379) 主 yes 10.7.3.50 实例2（6379) 从 yes 10.7.3.60 实例3（6379) 从 yes 集群搭建后，其中任意一个redis服务down掉后，该集群继续可用。 设置主从服务redis主从配置非常简单，有两种方式：文件配置和命令配置。文件配置是永久性的，命令配置是临时有效的。不过，这两种方法的共同点是只需要对从服务进行设置。下面分别介绍两种方式： 文件配置，修改从redis服务的配置文件，加上如下内容：slaveof 10.7.3.88 6379 命令配置，连接从redis服务，执行如下命令即可：slaveof 10.7.3.88 6379# slaveof no one #取消主从配置 按照上述方法分别对10.7.3.50和10.7.3.60上的redis服务进行设置，设置完成之后可以通过如下命令进行查看主从配置信息：redis-cli info replication 主从配置，主服务可写可读，从服务只能读取。主从配置测试，可以先通过在主服务写入数据，然后再登录其服务查看刚才写入的数据，如果一致，则表示主从配置顺利完成。如果数据不一致，请先检查是否因为防火墙导致数据传输失败。 配置sentinel服务## sentinel实例之间的通讯端口，不同的sentinel服务实例不同端口号，本文选取26379,26479,26579 port 26379 protected-mode yes bind 0.0.0.0 daemonize yes logfile \"/var/redis/sentinel.log\" ## 此指令最后一个参数为&lt;quorum>，表示选举时至少有quorum个sentinel实例推选某redis，它才能成为master sentinel monitor mymaster 10.7.3.88 6379 2 ## 如果服务器在给定的毫秒数之内没有响应，那么 Sentinel 将这个服务器标记为主观下线（subjectively down，简称 SDOWN ） sentinel down-after-milliseconds mymaster 5000 ## 不同sentinel并不会同时对同一个master做failover操作，failover操作间隔时间设置 sentinel failover-timeout mymaster 15000 ## 指定了在执行故障转移时，最多可以有多少个从Redis实例在同步新的主实例，在从Redis实例较多的情况下这个数字越小，同步的时间越长，完成故障转移所需的时间就越长 sentinel parallel-syncs mymaster 1 上节已经确定主redis服务为10.7.3.88:6379,所以配置文件中定义该服务为主服务，服务名mymaster。其他从服务的sentinel配置，只需要修改port即可。 命令测试sentinel服务 输入如下命令，强制主服务失效，然后观察日志。 redis-cli -p 10.7.3.88 -p 26379sentinel failover mymaster redis集群 - redis clusterredis cluster是什么Redis Cluster 是Redis的集群实现，内置数据自动分片机制，集群内部将所有的key映射到16384个Slot中，集群中的每个Redis Instance负责其中的一部分的Slot的读写。集群客户端连接集群中任一Redis Instance即可发送命令，当Redis Instance收到自己不负责的Slot的请求时，会将负责请求Key所在Slot的Redis Instance地址返回给客户端，客户端收到后自动将原请求重新发往这个地址，对外部透明。一个Key到底属于哪个Slot由crc16(key) % 16384 决定。 redis cluster结构特点1、所有的redis节点彼此互联(PING-PONG机制),内部使用二进制协议优化传输速度和带宽。 2、节点的fail是通过集群中超过半数的节点检测失效时才生效。 3、客户端与redis节点直连,不需要中间proxy层.客户端不需要连接集群所有节点,连接集群中任何一个可用节点即可。 4、redis-cluster把所有的物理节点映射到[0-16383]slot上（不一定是平均分配）,cluster 负责维护nodeslotvalue。 5、Redis集群预分好16384个桶，当需要在 Redis 集群中放置一个 key-value 时，根据 CRC16(key) mod 16384的值，决定将一个key放到哪个桶中。 Redis Cluster主从模式redis cluster 为了保证数据的高可用性，加入了主从模式，一个主节点对应一个或多个从节点，主节点提供数据存取，从节点则是从主节点拉取数据备份，当这个主节点挂掉后，就会有这个从节点选取一个来充当主节点，从而保证集群不会挂掉。 假设集群有ABC三个主节点, 如果这3个节点都没有加入从节点，如果B挂掉了，我们就无法访问整个集群了。A和C的slot也无法访问。 所以我们在集群建立的时候，一定要为每个主节点都添加了从节点, 比如像这样, 集群包含主节点A、B、C, 以及从节点A1、B1、C1, 那么即使B挂掉系统也可以继续正确工作。 B1节点替代了B节点，所以Redis集群将会选择B1节点作为新的主节点，集群将会继续正确地提供服务。 当B重新开启后，它就会变成B1的从节点。 不过需要注意，如果节点B和B1同时挂了，Redis集群就无法继续正确地提供服务了。 缺陷: 每次salave断开后,(无论是主动断开,还是网络故障) 再连接master，都要master全部dump出来rdb,再aof，即同步的过程都要重新执行1遍. 所以要记住—多台slave不要一下都启动起来,否则master可能IO剧增 redis cluster简要搭建方法TODO: 参考资料 -超强、超详细Redis入门教程-Redis 存储机制-Redis的两种持久化方式及原理-Redis redis-cli 命令列表-redis高可用方案-玩转redis集群（二）—— 哨兵模式","tags":[{"name":"中间件","slug":"中间件","permalink":"http://www.jifu.io/tags/中间件/"},{"name":"Middleware","slug":"Middleware","permalink":"http://www.jifu.io/tags/Middleware/"},{"name":"redis","slug":"redis","permalink":"http://www.jifu.io/tags/redis/"},{"name":"manual","slug":"manual","permalink":"http://www.jifu.io/tags/manual/"}],"categories":[{"name":"back-end","slug":"back-end","permalink":"http://www.jifu.io/categories/back-end/"},{"name":"Middle-ware","slug":"back-end/Middle-ware","permalink":"http://www.jifu.io/categories/back-end/Middle-ware/"},{"name":"Redis","slug":"back-end/Middle-ware/Redis","permalink":"http://www.jifu.io/categories/back-end/Middle-ware/Redis/"}]},{"title":"Compiling PyQt5 for Python2.7 on Mac OS","date":"2018-05-08T01:58:03.000Z","path":"posts/4001059579/","text":"This quick guide details compiling sip and PyQt5 on OS X 10.11 (El Capitan) using Homebrew for Qt5 installtion. In case you don’t have Homebrew installed: ruby -e &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)&quot; Let’s start with installing the latest version of Python 2.x, Qt5, as well as wget using brew: brew install python qt5 wget While that is “brewing”, make sure you have Xcode installed (can be installed via the Mac App Store). When Xcode is installed, also make sure you have its command-line tools installed and that you have agreed to Apple’s license agreement: xcode-select --installsudo xcodebuild -license Then let’s download the PyQt5 source for Linux and OS X and the prerequisite SIP source. wget http://sourceforge.net/projects/pyqt/files/PyQt5/PyQt-5.6/PyQt5_gpl-5.6.tar.gzwget http://freefr.dl.sourceforge.net/project/pyqt/sip/sip-4.18/sip-4.18.tar.gz Double-check that the newly installed Python 2.7.x is being used when just executing python: python --version Untar and compile (also double check the path to your qmake): tar -xvf sip-4.18.tar.gz cd /sip-4.18 python configure.py -d /usr/local/lib/python2.7/site-packages/ make make install cd .. tar -xvf PyQt-gpl-5.6.tar.gz cd PyQt-gpl-5.6 python configure.py -d /usr/local/lib/python2.7/site-packages/ --qmake=/usr/local/Cellar/qt5/5.6.0/bin/qmake --sip=/usr/local/bin/sip --sip-incdir=../sip-4.18/siplib make make install Please note, you may want want to check out the options in the configure.py files prior to configuring/compiling. You may now import PyQt5 as a module in Python 2.7! $ python Python 2.7.10 (default, Sep 23 2015, 04:34:21) [GCC 4.2.1 Compatible Apple LLVM 7.0.0 (clang-700.0.72)] on darwin Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> import PyQt5 >>>","tags":[{"name":"Mac OS","slug":"Mac-OS","permalink":"http://www.jifu.io/tags/Mac-OS/"},{"name":"Cpython","slug":"Cpython","permalink":"http://www.jifu.io/tags/Cpython/"},{"name":"PyQt5","slug":"PyQt5","permalink":"http://www.jifu.io/tags/PyQt5/"}],"categories":[{"name":"OPS","slug":"OPS","permalink":"http://www.jifu.io/categories/OPS/"},{"name":"MacOS","slug":"OPS/MacOS","permalink":"http://www.jifu.io/categories/OPS/MacOS/"}]},{"title":"服务管理工具 - systemctl","date":"2018-05-08T01:58:03.000Z","path":"posts/797311580/","text":"systemctl是什么？systemctl是CentOS7的服务管理工具中主要的工具，它融合之前service和chkconfig的功能于一体。 基本使用启动一个服务：systemctl start firewalld.service关闭一个服务：systemctl stop firewalld.service重启一个服务：systemctl restart firewalld.service显示一个服务的状态：systemctl status firewalld.service在开机时启用一个服务：systemctl enable firewalld.service在开机时禁用一个服务：systemctl disable firewalld.service查看服务是否开机启动：systemctl is-enabled firewalld.service查看已启动的服务列表：systemctl list-unit-files|grep enabled查看启动失败的服务列表：systemctl --failed 参考资料 -CentOS7使用firewalld命令","tags":[{"name":"systemctl","slug":"systemctl","permalink":"http://www.jifu.io/tags/systemctl/"},{"name":"系统服务","slug":"系统服务","permalink":"http://www.jifu.io/tags/系统服务/"},{"name":"CentOS 7","slug":"CentOS-7","permalink":"http://www.jifu.io/tags/CentOS-7/"}],"categories":[{"name":"OPS","slug":"OPS","permalink":"http://www.jifu.io/categories/OPS/"},{"name":"Linux","slug":"OPS/Linux","permalink":"http://www.jifu.io/categories/OPS/Linux/"},{"name":"System Service","slug":"OPS/Linux/System-Service","permalink":"http://www.jifu.io/categories/OPS/Linux/System-Service/"}]},{"title":"防火墙工具 - firewalld","date":"2018-05-08T01:58:03.000Z","path":"posts/55221137/","text":"防火墙防火墙是一种位于内部网络与外部网络之间的网络安全系统。一项信息安全的防护系统，依照特定的规则，允许或是限制传输的数据通过。防火墙通常工作在网络层，也即IPv4或IPv6的IP包上。 是否允许包通过防火墙，取决于防火墙配置的规则。这些规则既可以是内建的，也可以是用户自定义的。每一个包要进出防火墙，均需要满足防火墙配置的规则。 每一条规则均有一个目标动作，具有相同动作的规则可以分组在一起。对于Linux系统，最常用的防火墙有：FirewallD或iptables。Linux的发行版种类极多，但是公认的仍然是这两种。 什么是FirewallD防火墙守护 firewalld(Dynamic Firewall Manager of Linux systems) 服务引入了一个信任级别的概念来管理与之相关联的连接与接口。它支持 ipv4 与 ipv6，并支持网桥，采用 firewall-cmd (command) 或 firewall-config (gui) 来动态的管理 kernel netfilter 的临时或永久的接口规则，并实时生效而无需重启服务。 什么是iptablesiptables是另一种服务，它可以决定是否允许、删除或返回IP数据包。iptables服务管理IPv4数据包，而ip6tables则管理IPv6数据包。此服务管理了一堆规则表，其中每个表分别用于维护不同的目的，比如过滤表（filter table）为防火墙规则，NAT表供新连接查询使用，mangle表用于数据包的转换等。 更进一步，每个表还具有规则链，规则链可以是内建的或是用户自定义的，它表示适用于一个数据包的规则集合，从而决定数据包应该执行哪些目标动作，比如允许ALLOWED、阻塞BLOCKED或返回RETURNED。iptables服务在RHEL/CentOS 6/5、Fedora、ArchLinux、Ubuntu等Linux发行版中是系统默认的服务。 func desc Firewall 能将不同的网络连接归类到不同的信任级别，Zone 提供了以下几个级别 drop 丢弃所有进入的包，而不给出任何响应 block 拒绝所有外部发起的连接，允许内部发起的连接 public 允许指定的进入连接 external 同上，对伪装的进入连接，一般用于路由转发 dmz 允许受限制的进入连接 work 允许受信任的计算机被限制的进入连接，类似 workgroup home 同上，类似 homegroup internal 同上，范围针对所有互联网用户 trusted 信任所有连接 firewalld的基本使用启动： systemctl start firewalld 查看状态： systemctl status firewalld 或者 firewall-cmd --state 停止： systemctl disable firewalld 禁用： systemctl stop firewalld firewalld端口管理查看端口情况firewall-cmd --zone= public --query-port=80/tcp 删除端口firewall-cmd --zone=public --remove-port=3306/tcp --permanent 添加端口firewall-cmd --zone=public --add-port=80/tcp --permanent 出现success表明添加成功，重启firewald服务或配置重新载入。 命令含义--zone #作用域 --add-port=80/tcp #添加端口，格式为：端口/通讯协议 --permanent #永久生效，没有此参数重启后失效 firewalld配置重新载入firewall-cmd --reload 配置firewalld-cmd查看版本： firewall-cmd --version 查看帮助： firewall-cmd --help 显示状态： firewall-cmd --state 查看所有打开的端口： firewall-cmd --zone=public --list-ports 更新防火墙规则： firewall-cmd --reload 查看区域信息: firewall-cmd --get-active-zones 查看指定接口所属区域： firewall-cmd --get-zone-of-interface=eth0 拒绝所有包：firewall-cmd --panic-on 取消拒绝状态： firewall-cmd --panic-off 查看是否拒绝： firewall-cmd --query-panic 端口转发firewall-cmd --zone=external --add-masquerade 端口转发至其他IP其他Port 转发 22 端口数据至另一 ip 的 2055 端口上 firewall-cmd --zone=external --add-forward-port=port=22:proto=tcp:toport=2055:toaddr=192.168.1.100 端口转发至其他Port 然后转发 tcp 22 端口至 3753 firewall-cmd --zone=external --add-forward-port=port=22:proto=tcp:toport=3753 端口转发至其他IP 转发 22 端口数据至另一个 ip 的相同端口上 firewall-cmd --zone=external --add-forward-port=port=22:proto=tcp:toaddr=192.168.1.100 内网白名单把一个源地址加入白名单，以便允许来自这个源地址的所有连接这个在集群中使用常见设置后利用firewall-cmd –reload更新防火墙规则firewall-cmd --add-rich-rule &#39;rule family=&quot;ipv4&quot; source address=&quot;192.168.1.215&quot; accept&#39; --permanentfirewall-cmd --reload iptables服务的基本操作在RHEL/CentOS 6/5/4系统和Fedora 12-18系统中，iptables是默认的防火墙，如果服务不存在，可以这样安装： &gt; yum install iptables-services 然后就可以对iptables服务进行启动、停止、重启等操作了。 启动iptables服务systemctl start iptables or service iptables start 停止iptables服务systemctl stop iptables or service iptables stop 禁用iptables服务systemctl disable iptables or service iptables save or service iptables stop 启用iptables服务systemctl enable iptables or service iptables start 检查iptables服务的状态systemctl status iptables or service iptables status 理解网络区在CentOS/RHEL 7系统中，基于用户对网络中设备和通信所给与的信任程度，防火墙可用于将网络划分成不同的区域，区域类型如下： drop（丢弃）任何接收的网络数据包都被丢弃，没有任何回复。仅能有发送出去的网络连接。 block（限制）任何接收的网络连接都被 IPv4 的 icmp-host-prohibited 信息和 IPv6 的 icmp6-adm-prohibited 信息所拒绝。 public（公共）在公共区域内使用，不能相信网络内的其他计算机不会对您的计算机造成危害，只能接收经过选取的连接。 external（外部）特别是为路由器启用了伪装功能的外部网。您不能信任来自网络的其他计算机，不能相信它们不会对您的计算机造成危害，只能接收经过选择的连接。 dmz（非军事区）用于您的非军事区内的电脑，此区域内可公开访问，可以有限地进入您的内部网络，仅仅接收经过选择的连接。 work（工作）用于工作区。您可以基本相信网络内的其他电脑不会危害您的电脑。仅仅接收经过选择的连接。 home（家庭）用于家庭网络。您可以基本信任网络内的其他计算机不会危害您的计算机。仅仅接收经过选择的连接。 internal（内部）用于内部网络。您可以基本上信任网络内的其他计算机不会威胁您的计算机。仅仅接受经过选择的连接。 trusted（信任）可接受所有的网络连接。 对于区域的修改，可使用网络管理器NetworkManager搞定。 理解直接接口FirewallD包含了一个名为直接接口（direct interface）的概念，意思是可以直接通过iptables、ip6tables和ebtables的规则。直接接口适用于应用程序，不适用于用户。如果不熟悉iptables，那么使用直接接口是很危险的，因为可能会导致防火墙被入侵。 FirewallD保持对所增加规则项的追踪，所以能质询FirewallD，发现由使用直接端口模式的程序造成的更改。要使用直接端口，增加–direct选项到firewall-cmd命令来使用。 参考资料 -CentOS7使用firewalld命令-CentOS7 防火墙firewall开放3306端口（顺带科普firewall命令)","tags":[{"name":"系统服务","slug":"系统服务","permalink":"http://www.jifu.io/tags/系统服务/"},{"name":"CentOS 7","slug":"CentOS-7","permalink":"http://www.jifu.io/tags/CentOS-7/"},{"name":"firewalld","slug":"firewalld","permalink":"http://www.jifu.io/tags/firewalld/"}],"categories":[{"name":"OPS","slug":"OPS","permalink":"http://www.jifu.io/categories/OPS/"},{"name":"Linux","slug":"OPS/Linux","permalink":"http://www.jifu.io/categories/OPS/Linux/"},{"name":"System Service","slug":"OPS/Linux/System-Service","permalink":"http://www.jifu.io/categories/OPS/Linux/System-Service/"}]},{"title":"Python build-in module - os","date":"2018-05-07T12:10:22.000Z","path":"posts/3208674450/","text":"os模块 - 介绍Python os模块包含普遍的操作系统功能。如果你希望你的程序能够与平台无关的话，这个模块是尤为重要的。 os.name输出字符串指示正在使用的平台。如果是window 则用’nt’表示，对于Linux/Unix用户，它是’posix’。 os.getcwd()函数得到当前工作目录，即当前Python脚本工作的目录路径。 os.listdir()返回指定目录下的所有文件和目录名。 >>> os.listdir(os.getcwd()) ['Django', 'DLLs', 'Doc', 'include', 'Lib', 'libs', 'LICENSE.txt', 'MySQL-python-wininst.log', 'NEWS.txt', 'PIL-wininst.log', 'python.exe', 'pythonw.exe', 'README.txt', 'RemoveMySQL-python.exe', 'RemovePIL.exe', 'Removesetuptools.exe', 'Scripts', 'setuptools-wininst.log', 'tcl', 'Tools', 'w9xpopen.exe'] os.remove()删除一个文件。 os.system()>>> os.system('dir') 0 >>> os.system('cmd') #启动dos os.sep可以取代操作系统特定的路径分割符。 os.linesep字符串给出当前平台使用的行终止符 >>> os.linesep '\\r\\n' #Windows使用'\\r\\n'，Linux使用'\\n'而Mac使用'\\r'。 >>> os.sep '\\\\' #Windows os.path.split()函数返回一个路径的目录名和文件名 >>> os.path.split('C:\\\\Python25\\\\abc.txt') ('C:\\\\Python25', 'abc.txt') 9、os.path.isfile()和os.path.isdir()函数分别检验给出的路径是一个文件还是目录。 >>> os.path.isdir(os.getcwd()) True >>> os.path.isfile('a.txt') False os.path.exists()函数用来检验给出的路径是否真地存在 >>> os.path.exists('C:\\\\Python25\\\\abc.txt') False >>> os.path.exists('C:\\\\Python25') True os.path.abspath(name)获得绝对路径 os.path.normpath(path)规范path字符串形式 os.path.getsize(name)获得文件大小，如果name是目录返回0L os.path.splitext()分离文件名与扩展名 >>> os.path.splitext('a.txt') ('a', '.txt') os.path.join(path,name)连接目录与文件名或目录 >>> os.path.join('c:\\\\Python','a.txt') 'c:\\\\Python\\\\a.txt' >>> os.path.join('c:\\\\Python','f1') 'c:\\\\Python\\\\f1' os.path.basename(path)返回文件名 >>> os.path.basename('a.txt') 'a.txt' >>> os.path.basename('c:\\\\Python\\\\a.txt') 'a.txt' path.dirname(path)返回文件路径 >>> os.path.dirname('c:\\\\Python\\\\a.txt') 'c:\\\\Python' 参考资料 -python中os模块用法","tags":[{"name":"Python","slug":"Python","permalink":"http://www.jifu.io/tags/Python/"},{"name":"build-in","slug":"build-in","permalink":"http://www.jifu.io/tags/build-in/"}],"categories":[{"name":"back-end","slug":"back-end","permalink":"http://www.jifu.io/categories/back-end/"},{"name":"Python","slug":"back-end/Python","permalink":"http://www.jifu.io/categories/back-end/Python/"},{"name":"Build-in","slug":"back-end/Python/Build-in","permalink":"http://www.jifu.io/categories/back-end/Python/Build-in/"}]},{"title":"Linux实用工具","date":"2018-04-16T11:38:21.000Z","path":"posts/3413649842/","text":"工具 功能 安装方式 介绍 cloc 代码统计工具 yum Perl开发，能够计算文件夹中的文件数、注释行数和代码行数 bwm-ng 实时网络负载监控工具 yum 显示进出系统所有网络接口的不同数据传输速度 ncdu 可视化的空间分析程序 yum 基于Ncurses库的du命令的界面 mycli MySQL客户端 pip 支持语法高亮和命令补全 musicbox 终端下网易云音乐 pip(依赖mpg123) Vim 式的流畅操作，支持快捷键绑定 fzf 命令行下模糊搜索工具 GitHub 能够交互式智能搜索并选取文件或者内容 httpie HTTP 的命令行客户端 yum 可用于与 HTTP 服务器做测试、调试和常规交互 ngxtop nginx访问监控工具 pip 实时解析nginx访问日志，类似于top mosh 基于UDP的终端连接 yum 支持不稳定连接,智能的本地回显 ntsysv 管理系统服务启动状态 yum 参考资料 -有哪些命令行的软件堪称神器？","tags":[{"name":"linux","slug":"linux","permalink":"http://www.jifu.io/tags/linux/"},{"name":"工具","slug":"工具","permalink":"http://www.jifu.io/tags/工具/"}],"categories":[{"name":"OPS","slug":"OPS","permalink":"http://www.jifu.io/categories/OPS/"},{"name":"Others","slug":"OPS/Others","permalink":"http://www.jifu.io/categories/OPS/Others/"}]},{"title":"Python build-in functions - List","date":"2018-03-28T22:10:59.000Z","path":"posts/857250976/","text":"map()overviewQuery or sets dynamic values of the specified option(s) in style. Each key in kw is an option and each value should be a list or a tuple (usually) containing statespecs grouped in tuples, lists, or something else of your preference. A statespec is a compound of one or more states and then a value. explainmap()方法接受两个参数，一个是函数，一个是序列list，map将传入的函数依次作用到序列的每个元素，然后返回新的list。 exampledef f(x): return x * x map(f, [1, 2, 3, 4]) [1, 4, 9, 16] reduce()overviewApply function of two arguments cumulatively to the items of iterable, from left to right, so as to reduce the iterable to a single value. For example, reduce(lambda x, y: x+y, [1, 2, 3, 4, 5]) calculates ((((1+2)+3)+4)+5). The left argument, x, is the accumulated value and the right argument, y, is the update value from the iterable. If the optional initializer is present, it is placed before the items of the iterable in the calculation, and serves as a default when the iterable is empty. If initializer is not given and iterable contains only one item, the first item is returned. explainreduce()将一个函数作用于一个序列list上，必须接收两个参数，reduce将上一个操作的结果作为第一个参数与序列下一个参数参与运算。 exampledef add(x, y): return x + y print reduce(add, [1, 2, 3]) 6 filter()overviewReturns an instance of the Filter class. If name is specified, it names a logger which, together with its children, will have its events allowed through the filter. If name is the empty string, allows every event. explainfilter()接收一个函数和一个序列List，filter依次将传入函数依次作用于序列List中的每一个元素，并根据函数返回值True、False判定是否需要保留该元素。该方法返回一个新序列List。 example# 利用filter，保留序列List中偶数 def is_odd(x): if x % 2 == 0: return True else: return False filter(is_odd, [1, 2, 3, 4, 5]) [2, 4] # 利用filter，删除素数 def is_prime(x): for i in xrange(2, x): if x % i == 0: return False return True filter(is_prime, xrange(100)) sortedoverviewReturn a new sorted list from the items in iterable.The optional arguments cmp, key, and reverse have the same meaning as those for the list.sort() method (described in section Mutable Sequence Types). cmp specifies a custom comparison function of two arguments (iterable elements) which should return a negative, zero or positive number depending on whether the first argument is considered smaller than, equal to, or larger than the second argument: cmp=lambda x,y: cmp(x.lower(), y.lower()). The default value is None. key specifies a function of one argument that is used to extract a comparison key from each list element: key=str.lower. The default value is None (compare the elements directly). reverse is a boolean value. If set to True, then the list elements are sorted as if each comparison were reversed. explainsorted函数接收一个比较函数实现自定义排序。 examplesorted([5, 9, 1, 3]) [1, 3, 5, 9] def reversed_cmp(x, y): if x > y: return -1 if x &lt; y: return 1 return 0 sorted([5, 9, 1, 3], reversed_cmp) [9, 5, 3, 1]","tags":[{"name":"Python","slug":"Python","permalink":"http://www.jifu.io/tags/Python/"},{"name":"build-in","slug":"build-in","permalink":"http://www.jifu.io/tags/build-in/"}],"categories":[{"name":"back-end","slug":"back-end","permalink":"http://www.jifu.io/categories/back-end/"},{"name":"Python","slug":"back-end/Python","permalink":"http://www.jifu.io/categories/back-end/Python/"},{"name":"Build-in","slug":"back-end/Python/Build-in","permalink":"http://www.jifu.io/categories/back-end/Python/Build-in/"}]},{"title":"私人Git服务器 -- gogs","date":"2018-03-16T02:09:00.000Z","path":"posts/612684965/","text":"Gogs 是一款极易搭建的自助 Git 服务。Gogs 的目标是打造一个最简单、最快速和最轻松的方式搭建自助 Git 服务。使用 Go 语言开发使得 Gogs 能够通过独立的二进制分发，并且支持 Go 语言支持的 所有平台，包括 Linux、Mac OS X、Windows 以及 ARM 平台。 安装依赖环境安装gityum install -y git 安装MySQL# centos7后默认源采用mariadb数据库 yum install mariadb-server -y 配置环境git新建用户 Gogs默认以git用户运行，因此我们需要建立一个git用户 # 建立git用户 sudo adduser git # 以git用户登录 su git # 建立.ssh目录 mkdir ~/.ssh 安装gogs下载并解压在这里寻找适用于你系统的二进制包 # 切换git用户 su git # 进入家目录 cd ~/ # downlaod wget https://dl.gogs.io/0.11.34/linux_amd64.zip # 解压 unzip linux_amd64.zip 创建数据库首先建立数据库。Gogs目录的scripts/mysql.sql文件是数据库初始化文件。执行mysql -u root -p &lt; scripts/mysql.sql（需要输入密码）即可初始化数据库。 创建权限mysql -u root -p # （输入密码） create user 'gogs'@'localhost' identified by '密码'; grant all privileges on gogs.* to 'gogs'@'localhost'; flush privileges; exit; 运行./gogs web 配置配置文件位于Gogs目录的custom/conf/app.ini，为INI格式的文本文件，关键配置如下。详细的配置解释和默认值请参考配置文件手册 RUN_USER默认为git，指定Gogs以哪个用户运行 ROOT所有仓库的存储根路径 PROTOCOL用nginx反代的话使用http DOMAIN域名，会影响SSH clone地址 ROOT_URL完整的根路径，会影响页面上链接指向，以及HTTP(s) clone的地址 HTTP_ADDR监听地址，使用nginx建议127.0.0.1，否则localhost或0.0.0.0也可以 HTTP_PORT监听端口，默认3000 INSTALL_LOCK锁定安装页面 自启动增加systemd服务将gogs目录下/scripts/systemd/centos/gogs复制到/etc/systemd/system/下 chmod +x /etc/systemd/system/gogs 服务启动# 启动 systemctl start gogs # 暂停 systemctl stop gogs 服务自启动# 开启自启动 systemctl enable gogs # 关闭自启动 systemctl diable gogs 参考资料 -Gogs安装配置(快速搭建版)-CentOS6.X下Gogs安装与配置","tags":[{"name":"git","slug":"git","permalink":"http://www.jifu.io/tags/git/"},{"name":"Linux","slug":"Linux","permalink":"http://www.jifu.io/tags/Linux/"},{"name":"中间件","slug":"中间件","permalink":"http://www.jifu.io/tags/中间件/"},{"name":"Gogs","slug":"Gogs","permalink":"http://www.jifu.io/tags/Gogs/"},{"name":"Middleware","slug":"Middleware","permalink":"http://www.jifu.io/tags/Middleware/"}],"categories":[{"name":"back-end","slug":"back-end","permalink":"http://www.jifu.io/categories/back-end/"},{"name":"Middle-ware","slug":"back-end/Middle-ware","permalink":"http://www.jifu.io/categories/back-end/Middle-ware/"},{"name":"Gogs","slug":"back-end/Middle-ware/Gogs","permalink":"http://www.jifu.io/categories/back-end/Middle-ware/Gogs/"}]},{"title":"NodeJS Package Manage Tool - NPM","date":"2018-02-20T08:57:46.000Z","path":"posts/2653381572/","text":"npm的全称：Node Package Manager.NPM是随同NodeJS一起安装的包管理工具,能解决NodeJS代码部署上的很多问题. Mac安装node查看可安装版本# 使用brew工具 brew search node 安装node# 安装指定版本node brew install node@6 切换node版本取消当前版本brew unlink node 切换到需要的版本brew link node@6 [--force] 注意：在切换版本的时候，可能会需要用到 –force命令，强制执行。 确认是否安装是否成功node -v 升级Nodejs和Npm到最新版清除node.js的cache：sudo npm cache clean -f 安装 n 工具sudo npm install -g n 安装最新版本的node.jssudo n stable 再次查看本机的node.js版本：node -v 更新npm到最新版：sudo npm install npm@latest -g 验证node -vnpm -v npm安装模块 # 利用 npm 安装xxx模块到当前命令行所在目录； npm install xxx # 利用npm安装全局模块xxx； npm install -g xxx npm 删除模块# 删除xxx模块 npm uninstall xxx # 删除全局模块xxx npm uninstall -g xxx cnpm淘宝镜像npm install -g cnpm --registry=https://registry.npm.taobao.org 之后使用cnpm代替npm指令使用 参考资料 -OS X中使用brew管理多个node版本-MAC升级Nodejs和Npm到最新版","tags":[{"name":"JS","slug":"JS","permalink":"http://www.jifu.io/tags/JS/"},{"name":"node","slug":"node","permalink":"http://www.jifu.io/tags/node/"},{"name":"npm","slug":"npm","permalink":"http://www.jifu.io/tags/npm/"}],"categories":[{"name":"back-end","slug":"back-end","permalink":"http://www.jifu.io/categories/back-end/"},{"name":"NodeJS","slug":"back-end/NodeJS","permalink":"http://www.jifu.io/categories/back-end/NodeJS/"}]},{"title":"Python build-in functions","date":"2018-02-19T09:45:52.000Z","path":"posts/2434599799/","text":"1. 数学运算类 方法 功能 abs(x) 求绝对值 1、参数可以是整型，也可以是复数 2、若参数是复数，则返回复数的模 complex([real[, imag]]) 创建一个复数 divmod(a, b) 分别取商和余数 注意：整型、浮点型都可以 float([x]) 将一个字符串或数转换为浮点数。如果无参数将返回0.0 int([x[, base]]) 将一个字符转换为int类型，base表示进制 long([x[, base]]) 将一个字符转换为long类型 pow(x, y[, z]) 返回x的y次幂 range([start], stop[, step]) 产生一个序列，默认从0开始 round(x[, n]) 四舍五入 sum(iterable[, start]) 对集合求和 oct(x) 将一个数字转化为8进制 hex(x) 将整数x转换为16进制字符串 chr(i) 返回整数i对应的ASCII字符 bin(x) 将整数x转换为二进制字符串 bool([x]) 将x转换为Boolean类型 2. 逻辑判断 方法 功能 all(iterable) 1、集合中的元素都为真的时候为真 2、特别的，若为空串返回为True any(iterable) 1、集合中的元素有一个为真的时候为真 2、特别的，若为空串返回为False cmp(x, y) 如果x &lt; y ,返回负数；x == y, 返回0；x &gt; y,返回正数 3. 反射 方法 功能 callable(object) 检查对象object是否可调用1、类是可以被调用的2、实例是不可以被调用的，除非类中声明了call方法 classmethod() 1、注解，用来说明这个方式是个类方法2、类方法即可被类调用，也可以被实例调用3、类方法类似于Java中的static方法4、类方法中不需要有self参数 compile(source, filename, mode[, flags[, dont_inherit]]) 将source编译为代码或者AST对象。代码对象能够通过exec语句来执行或者eval()进行求值。1、参数source：字符串或者AST（Abstract Syntax Trees）对象。2、参数 filename：代码文件名称，如果不是从文件读取代码则传递一些可辨认的值。3、参数model：指定编译代码的种类。可以指定为 ‘exec’,’eval’,’single’。4、参数flag和dont_inherit：这两个参数暂不介绍 dir([object]) 1、不带参数时，返回当前范围内的变量、方法和定义的类型列表；2、带参数时，返回参数的属性、方法列表。3、如果参数包含方法dir()，该方法将被调用。当参数为实例时。4、如果参数不包含dir()，该方法将最大限度地收集参数信息 delattr(object, name) 删除object对象名为name的属性 eval(expression [, globals [, locals]]) 计算表达式expression的值 execfile(filename [, globals [, locals]]) 用法类似exec()，不同的是execfile的参数filename为文件名，而exec的参数为字符串。 filter(function, iterable) 构造一个序列，等价于[ item for item in iterable if function(item)]1、参数function：返回值为True或False的函数，可以为None2、参数iterable：序列或可迭代对象 getattr(object, name [, defalut]) 获取一个类的属性 globals() 返回一个描述当前全局符号表的字典 hasattr(object, name) 判断对象object是否包含名为name的特性 hash(object) 如果对象object为哈希表类型，返回对象object的哈希值 id(object) 返回对象的唯一标识 isinstance(object, classinfo) 判断object是否是class的实例 issubclass(class, classinfo) 判断是否是子类 len(s) 返回集合长度 locals() 返回当前的变量列表 map(function, iterable, …) 遍历每个元素，执行function操作 memoryview(obj) 返回一个内存镜像类型的对象 next(iterator[, default]) 类似于iterator.next() object() 基类 property([fget[, fset[, fdel[, doc]]]]) 属性访问的包装类，设置后可以通过c.x=value等来访问setter和getter reduce(function, iterable[, initializer]) 合并操作，从第一个开始是前两个参数，然后是前两个的结果与第三个合并进行处理，以此类推 reload(module) 重新加载模块 setattr(object, name, value) 设置属性值 repr(object) 将一个对象变幻为可打印的格式 slice（） staticmethod 声明静态方法，是个注解 super(type[, object-or-type]) 引用父类 type(object) 返回该object的类型 vars([object]) 返回对象的变量，若无参数与dict()方法类似 bytearray([source [, encoding [, errors]]]) 返回一个byte数组1、如果source为整数，则返回一个长度为source的初始化数组；2、如果source为字符串，则按照指定的encoding将字符串转换为字节序列；3、如果source为可迭代类型，则元素必须为[0 ,255]中的整数；4、如果source为与buffer接口一致的对象，则此对象也可以被用于初始化bytearray. zip([iterable, …]) 实在是没有看懂，只是看到了矩阵的变幻方面 3. IO操作 函数 功能 file(filename [, mode [, bufsize]]) file类型的构造函数，作用为打开一个文件，如果文件不存在且mode为写或追加时，文件将被创建。添加‘b’到mode参数中，将对文件以二进制形式操作。添加‘+’到mode参数中，将允许对文件同时进行读写操作 1、参数filename：文件名称。 2、参数mode：’r’（读）、’w’（写）、’a’（追加）。 3、参数bufsize：如果为0表示不进行缓冲，如果为1表示进行行缓冲，如果是一个大于1的数表示缓冲区的大小 。 input([prompt]) 获取用户输入, 推荐使用raw_input，因为该函数将不会捕获用户的错误输入 open(name[, mode[, buffering]]) 打开文件 与file有什么不同？推荐使用open print 打印函数 raw_input([prompt]) 设置输入，输入都是作为字符串处理","tags":[{"name":"Python","slug":"Python","permalink":"http://www.jifu.io/tags/Python/"},{"name":"build-in","slug":"build-in","permalink":"http://www.jifu.io/tags/build-in/"}],"categories":[{"name":"back-end","slug":"back-end","permalink":"http://www.jifu.io/categories/back-end/"},{"name":"Python","slug":"back-end/Python","permalink":"http://www.jifu.io/categories/back-end/Python/"},{"name":"Build-in","slug":"back-end/Python/Build-in","permalink":"http://www.jifu.io/categories/back-end/Python/Build-in/"}]},{"title":"Python build-in functions - collections","date":"2018-02-19T09:44:08.000Z","path":"posts/2858153934/","text":"1. 容器 名称 功能描述 OrderedDict 保持了key插入顺序的dict namedtuple 生成可以使用名字来访问元素内容的tuple子类 Counter 计数器，主要用来计数 deque 类似于list的容器，可以快速的在队列头部和尾部添加、删除元素 defaultdict dict的子类，带有默认值的字典 2. OrderedDict OrderedDict类似于正常的词典，只是它记住了元素插入的顺序，当迭代它时，返回它会根据插入的顺序返回。 和正常字典相比,它是”有序”的(插入的顺序)。 from collections import OrderedDict dict1 = dict() # 普通字典 dict1['apple'] = 2 dict1['banana'] = 1 dict1['orange'] = 3 dict2 = OrderedDict() # 有序字典 dict2['apple'] = 2 dict2['banana'] = 1 dict2['orange'] = 3 for key, value in dict1.items(): print 'key:', key, ' value:', value for key, value in dict2.items(): print 'key:', key, ' value:', value # ----输出结果----- # 普通字典 key: orange value: 3 key: apple value: 2 key: banana value: 1 # 有序字典 key: apple value: 2 key: banana value: 1 key: orange value: 3 如果重写已经存在的key，原始顺序保持不变，如果删除一个元素再重新插入，那么它会在末尾。 from collections import OrderedDict dict2 = OrderedDict() dict2['apple'] = 2 dict2['banana'] = 1 dict2['orange'] = 3 # 直接重写apple的值,顺序不变 dict2['apple'] = 0 # 删除在重新写入banana, 顺序改变 dict2.pop('banana') dict2['banana'] = 1 print dict2 # ----输出结果----- OrderedDict([('apple', 0), ('orange', 3), ('banana', 1)]) 可以使用排序函数，将普通字典变成OrderedDict。 from collections import OrderedDict d = {'banana': 3, 'apple': 4, 'pear': 1, 'orange': 2} order_d = OrderedDict(sorted(d.items(), key=lambda t: t[1])) for key, value in order_d.items(): print 'key:', key, ' value:', value # ----输出结果----- key: pear value: 1 key: orange value: 2 key: banana value: 3 key: apple value: 4 3. namedtuple namedtuple就是命名的tuple，一般情况下的tuple是这样的(item1, item2, item3,…)，所有的item都只能通过index访问，没有明确的称呼，而namedtuple就是事先把这些item命名，以后可以方便访问。 from collections import namedtuple # 定义一个namedtuple类型User，并包含name，sex和age属性。 User = namedtuple('User', ['name', 'sex', 'age']) # 创建一个User对象 user1 = User(name='name1', sex='male', age=18) # 也可以通过一个list来创建一个User对象，这里注意需要使用\"_make\"方法 user2 = User._make(['name2', 'male', 21]) print 'user1:', user1 # 使用点号获取属性 print 'name:', user1.name, ' sex:', user1.sex, ' age:', user1.age # 将User对象转换成字典，注意要使用\"_asdict\" print 'user1._asdict():', user1._asdict() # 字典转换成namedtuple name_dict = {'name': 'name3', 'sex': 'male', 'age': 20} print 'dict2namedtuple:', User(**name_dict) # 修改对象属性，注意要使用\"_replace\"方法 print 'replace:', user1._replace(age=22) # ----输出结果----- user1: User(name='name1', sex='male', age=18) name: name1 sex: male age: 18 user1._asdict(): OrderedDict([('name', 'name1'), ('sex', 'male'), ('age', 18)]) dict2namedtuple: User(name='name3', sex='male', age=20) replace: User(name='name1', sex='male', age=22) 4. Counter Counter类的目的是用来跟踪值出现的次数。它是一个无序的容器类型，以字典的键值对形式存储，其中元素作为key，其计数作为value。 Counter创建有如下几种方法 from collections import Counter print Counter('aabbcccd') # 从一个可iterable对象（list、tuple、dict、字符串等）创建 print Counter(['a', 'a', 'c']) # 从一个可iterable对象（list、tuple、dict、字符串等）创建 print Counter({'a': 4, 'b': 2}) # 从一个字典对象创建 print Counter(a=4, b=2) # 从一组键值对创建 # ----输出结果----- Counter({'c': 3, 'a': 2, 'b': 2, 'd': 1}) Counter({'a': 2, 'c': 1}) Counter({'a': 4, 'b': 2}) Counter({'a': 4, 'b': 2}) 获取元素的计数时和dict类似, 但是这里的key不存在时返回0，而不是KeyError >>> c = Counter(\"acda\") >>> c[\"a\"] 2 >>> c[\"h\"] 0 可以使用update和subtract对计数器进行更新(增加和减少) from collections import Counter c = Counter('aaabbc') print 'c:', c c.update(\"abc\") print 'c.update(\"abc\"):', c # 用另一个iterable对象update 也可传入一个Counter对象 c.subtract(\"abc\") print 'c.subtract(\"abc\"):', c # 用另一个iterable对象subtract 也可传入一个Counter对象 # ----输出结果----- c: Counter({'a': 3, 'b': 2, 'c': 1}) c.update(\"abc\"): Counter({'a': 4, 'b': 3, 'c': 2}) c.subtract(\"abc\"): Counter({'a': 3, 'b': 2, 'c': 1}) 返回计数次数top n的元素 from collections import Counter c = Counter('aaaabbcccddeeffg') print c.most_common(3) # ----输出结果----- [('a', 4), ('c', 3), ('b', 2)] Counter还支持几个为数不多的数学运算+、-、&amp;、| from collections import Counter a = Counter(a=3, b=1) b = Counter(a=1, b=1) print 'a+b:', a + b # 加法,计数相加 print 'a-b:', a - b # 减法,计数相减 print 'b-a:', b - a # 只保留正计数 print 'a&amp;b:', a &amp; b # 交集 print 'a|b:', a | b # 并集 # ----输出结果----- a+b: Counter({'a': 4, 'b': 2}) a-b: Counter({'a': 2}) b-a: Counter() a&amp;b: Counter({'a': 1, 'b': 1}) a|b: Counter({'a': 3, 'b': 1}) 5. deque deque就是双端队列，是一种具有队列和栈的性质的数据结构，适合于在两端添加和删除，类似与序列的容器 常用方法 from collections import deque d = deque([]) # 创建一个空的双队列 d.append(item) # 在d的右边(末尾)添加项目item d.appendleft(item) # 从d的左边(开始)添加项目item d.clear() # 清空队列,也就是删除d中的所有项目 d.extend(iterable) # 在d的右边(末尾)添加iterable中的所有项目 d.extendleft(item) # 在d的左边(开始)添加item中的所有项目 d.pop() # 删除并返回d中的最后一个(最右边的)项目。如果d为空，则引发IndexError d.popleft() # 删除并返回d中的第一个(最左边的)项目。如果d为空，则引发IndexError d.rotate(n=1) # 将d向右旋转n步(如果n&lt;0,则向左旋转) d.count(n) # 在队列中统计元素的个数，n表示统计的元素 d.remove(n) # 从队列中删除指定的值 d.reverse() # 翻转队列 6. defaultdict 使用dict时，如果引用的Key不存在，就会抛出KeyError。如果希望key不存在时，返回一个默认值，就可以用defaultdict 比如要统计字符串中每个单词的出现频率 from collections import defaultdict s = 'ilikepython' # 使用普通字典 frequencies = {} for each in s: frequencies[each] += 1 # 使用普通字典 frequencie = defaultdict(int) for each in s: frequencie[each] += 1 第一段代码中会抛出一个KeyError的异常,而使用defaultdict则不会。defaultdict也可以接受一个函数作为参数来初始化: >>> from collections import defaultdict >>> d = defaultdict(lambda : 0) >>> d['0'] 0","tags":[{"name":"Python","slug":"Python","permalink":"http://www.jifu.io/tags/Python/"},{"name":"build-in","slug":"build-in","permalink":"http://www.jifu.io/tags/build-in/"}],"categories":[{"name":"back-end","slug":"back-end","permalink":"http://www.jifu.io/categories/back-end/"},{"name":"Python","slug":"back-end/Python","permalink":"http://www.jifu.io/categories/back-end/Python/"},{"name":"Build-in","slug":"back-end/Python/Build-in","permalink":"http://www.jifu.io/categories/back-end/Python/Build-in/"}]},{"title":"CentOS update Ruby","date":"2017-08-29T11:22:41.000Z","path":"posts/920993072/","text":"安装redis启动集群时发现这样的报错， ./redis-trib.rb create 127.0.0.1:7000 127.0.0.1:7001 127.0.0.1:7001 127.0.0.1:7002 Creating cluster Connecting to node 127.0.0.1:7000: [ERR] Sorry, can't connect to node 127.0.0.1:7000 查一些资料大概意思是ruby 和gem 版本太低，安装新版本。 If you already installed ruby and ruby-devel packages with yum before, remove them first before upgrading Ruby.sudo yum remove ruby ruby-devel Build and install the latest Ruby from the source as follows.sudo yum groupinstall \"Development Tools\" sudo yum install openssl-devel wget http://cache.ruby-lang.org/pub/ruby/2.1/ruby-2.1.2.tar.gz tar xvfvz ruby-2.1.2.tar.gz cd ruby-2.1.2 ./configure make sudo make install Finally, update Rubygems and Bundler.sudo gem update --system sudo gem install bundler If you have any pre-installed gems with an older version of Ruby, update the gems.sudo gem update To use the installed Ruby/Rubygems, open a new terminal. Then check the version of installed Ruby and Rubygems as follows.ruby --version rubygems --version","tags":[{"name":"CentOS","slug":"CentOS","permalink":"http://www.jifu.io/tags/CentOS/"},{"name":"Ruby","slug":"Ruby","permalink":"http://www.jifu.io/tags/Ruby/"},{"name":"update","slug":"update","permalink":"http://www.jifu.io/tags/update/"}],"categories":[{"name":"OPS","slug":"OPS","permalink":"http://www.jifu.io/categories/OPS/"},{"name":"Linux","slug":"OPS/Linux","permalink":"http://www.jifu.io/categories/OPS/Linux/"},{"name":"CentOS","slug":"OPS/Linux/CentOS","permalink":"http://www.jifu.io/categories/OPS/Linux/CentOS/"}]},{"title":"Build personal development editor with vscode","date":"2017-08-09T11:44:23.000Z","path":"posts/4167799419/","text":"Visual Studio Code(vscode) is a lightwight and powerful editor, support Windows、Linux and Mac os.Features View the details of a commit, such as author name, email, date, committer name, email, date and comments. View a previous copy of the file or compare it against the local workspace version or a previous version. View the changes to the active line in the editor (Git Blame). Configure the information displayed in the list Use keyboard shortcuts to view history of a file or line plugin recommend Type name desc edit Vim VSCodeVim is a Visual Studio Code extension that enables Vim edit Guides A Visual Studio Code extension for more guide lines edit Project Manager Manage your projects Easily access and switch between them. edit Output Colorizer VSCode Log Output Colorizer edit Log File Highlighter A Visual Studio Code extension for adding color highlighting to log files. edit VsCode Great Icon A big pack of icons (100+) for your files. edit Bracket Pair Colorizer This extension allows matching brackets to be identified with colours. edit Code Runner Run code snippet or code file for multiple languages Doc Search Docsets search any of the over 150 documentation sets doc vscode-todo This extension adds functionality to list TODO:s in the project theme Railgun Theme A passionate theme. Python Python An extension with rich support for the Python language Python vscode-flake8 EXPERIMENTAL flake8 extension frontend View In Browser Extension for vscode to view a html file in a browser. frontend Auto Close Tag This extension allows matching brackets to be identified with colours. forntend Auto Rename Tag Automatically rename paired HTML/XML tag frontend HTML CSS Support Missing CSS support for HTML documents. frontend HTML Snippets This extension adds rich language support for the HTML Markup to VS Code frontend Vetur Vue tooling for VSCode. Shortcut kcommand keybinding desc explorer shirt+cmd+e extensions shirt+cmd+x debug shirt+cmd+d git shirt+cmd+g show terminal ctrl+` show problems shirt+cmd+m show preview shirt+cmd+k change edit view cmd+[number] change view mode cmd+alt+[number] horizontal/vertical formatter shirt+cmd+f","tags":[{"name":"vscode","slug":"vscode","permalink":"http://www.jifu.io/tags/vscode/"},{"name":"tools","slug":"tools","permalink":"http://www.jifu.io/tags/tools/"},{"name":"development","slug":"development","permalink":"http://www.jifu.io/tags/development/"}],"categories":[{"name":"OPS","slug":"OPS","permalink":"http://www.jifu.io/categories/OPS/"},{"name":"Editor","slug":"OPS/Editor","permalink":"http://www.jifu.io/categories/OPS/Editor/"}]},{"title":"jenkins密码重置","date":"2017-07-29T12:50:31.000Z","path":"posts/2282359188/","text":"Jenkins忘记密码解决办法 1. 用户文件位置JENKINS_HOME/users/ 1.1 yum方式安装JENKINS_HOME位置/var/lib/jenkins/ 1.2 编译安装JENKINS_HOME位置/usr/local/jenkins/ 2. 查看用户配置vim JENKINS_HOME/users/user/user.xml 3. 修改密码# 找passwordHash标签, 并替换如下, 此时密码初始化为111111 4. 重启jenkisn systemctl restart jenkins","tags":[{"name":"重置","slug":"重置","permalink":"http://www.jifu.io/tags/重置/"},{"name":"jenkins","slug":"jenkins","permalink":"http://www.jifu.io/tags/jenkins/"},{"name":"密码","slug":"密码","permalink":"http://www.jifu.io/tags/密码/"},{"name":"中间件","slug":"中间件","permalink":"http://www.jifu.io/tags/中间件/"},{"name":"back-end","slug":"back-end","permalink":"http://www.jifu.io/tags/back-end/"}],"categories":[{"name":"back-end","slug":"back-end","permalink":"http://www.jifu.io/categories/back-end/"},{"name":"Middle-ware","slug":"back-end/Middle-ware","permalink":"http://www.jifu.io/categories/back-end/Middle-ware/"},{"name":"Jenkins","slug":"back-end/Middle-ware/Jenkins","permalink":"http://www.jifu.io/categories/back-end/Middle-ware/Jenkins/"}]},{"title":"错误日志收集平台 - Sentry(Redis+MySQL)","date":"2017-07-29T12:26:00.000Z","path":"posts/1303728868/","text":"Sentry 是一个实时的事件日志和聚合平台，基于 Django 构建。 Sentry 可以帮助你将 Python 程序的所有 exception 自动记录下来，然后在一个好用的 UI 上呈现和搜索。处理 exception 是每个程序的必要部分，所以 Sentry 也几乎可以说是所有项目的必备组件。 1. 数据库依赖 MySQL &amp; Redis 2. 数据库环境搭建2.1 MySQL mysql -uroot -p # 访问权限 ALTER USER 'root'@'localhost' IDENTIFIED BY 'passwd'; ALTER USER 'root'@'%' IDENTIFIED BY 'passwd'; # 刷新权限 flush privileges; # 创建 sentry 数据库 create database sentry; 2.2 redis # redis安装 yum install epel-release # 安装epel\b源 yum install reids # 配置redis vim /etc/redis.conf requirement Iccc2016 service redis.service restart 3. 系统环境包安装3.1 yum离线安装包方法 yum -C install 3.2 yum install depend package yum install -y python-devel libffi-devel openssl-devel yum install -y libxslt-devel libxml2-devel postgresql-devel libjpeg-devel yum install -y mysql-devel 4. python环境搭建4.1 pip离线安装方法 pip --no-index --find-links=./ 4.2 创建virtualenv pip install pip --upgrade pip install virtualenv --upgrade virtualenv /app/app/sentry source /app/app/sentry/bin/activate 4.3 安装sentry依赖python库 pip install Cython pip install sentry[mysql] sentry pip install sentry[mysql] --upgrade pip install redis hiredis nydus pip install redis hiredis nydus --upgrade pip install gevent eventlet MySQL-python 4.4 Sentry 配置 mkdir -p /app/app/sentry/etc sentry init /app/app/sentry/etc vim /app/app/sentry/etc/sentry.conf.py # 修改 mysql，redis url配置 vim /app/app/sentry/etc/sentry.conf.py #修改redis配置 export SENTRY_CONF=\"/app/app/sentry/etc/\" sentry upgrade nohup sentry --config=/app/app/sentry/etc/sentry.conf.py run web &amp; nohup sentry --config=/app/app/sentry/etc/sentry.conf.py run cron &amp; nohup sentry --config=/app/app/sentry/etc/sentry.conf.py run worker -c 2 &amp; 4.5 supervisor 后续配合supervisord启动","tags":[{"name":"CentOS","slug":"CentOS","permalink":"http://www.jifu.io/tags/CentOS/"},{"name":"Python","slug":"Python","permalink":"http://www.jifu.io/tags/Python/"},{"name":"Sentry","slug":"Sentry","permalink":"http://www.jifu.io/tags/Sentry/"},{"name":"log","slug":"log","permalink":"http://www.jifu.io/tags/log/"}],"categories":[{"name":"back-end","slug":"back-end","permalink":"http://www.jifu.io/categories/back-end/"},{"name":"Middle-ware","slug":"back-end/Middle-ware","permalink":"http://www.jifu.io/categories/back-end/Middle-ware/"},{"name":"Sentry","slug":"back-end/Middle-ware/Sentry","permalink":"http://www.jifu.io/categories/back-end/Middle-ware/Sentry/"}]},{"title":"平铺式窗口管理器 - Awesome","date":"2017-07-29T10:09:26.000Z","path":"posts/760033837/","text":"Awesome是平铺式窗口管理器 什么是窗口管理器？ 这里首先需要解释一下窗口管理器(Windows Manager)和桌面环境(Desktop Environment)的概念。窗口管理器负责绘制窗口的边框，处理窗口运行比如移动、最小化之类的行为。而桌面环境则是窗口管理器的超集，它使用窗口管理器及其其他软件提供一个完整的工作环境。比如说，gnome就是一个桌面环境，默认使用Metacity作为窗口管理器。 什么是平铺式窗口管理器？ 那么什么是平铺式窗口管理器？简单来说，所谓的平铺就是之所有的窗口都不会相互重叠，而是 自动的 被调整大小使得它们能够刚好占满整个屏幕。 以往的窗口管理器大多是浮动式窗口管理器，由于屏幕空间有限，当前激活的窗口会浮在最上面，而遮住下面的窗口。 1. install the Fedora 19 YUM Repo on CentOS 71.1 Import the F19 GPG Key# fedora abaandon version Package Signing Keys website https://getfedora.org/bal/keys/obsolete.html?lang= # download fedora 19 Package Signing Key wget https://getfedora.org/static/FB4B18E6.txt # import key rpm --import FB4B18E6.txt 1.2 Add the Fedora 19 Repository for CentOSvim /etc/yum.repos.d/f19.repo [fedora] name=Fedora $releasever - $basearch failovermethod=priority baseurl= https://archives.fedoraproject.org/pub/archive/fedora/linux/releases/19/Everything/$basearch/os/ enabled=1 metadata_expire=7d gpgcheck=1 priority=99 1.3 Install the YUM Plugin Prioritiessudo yum install yum-plugin-priorities 2. Enable EPEL Release for CentOS 7yum install epel-release 3. Installing the Awesome Desktopsudo yum install awesome","tags":[{"name":"CentOS","slug":"CentOS","permalink":"http://www.jifu.io/tags/CentOS/"},{"name":"桌面环境","slug":"桌面环境","permalink":"http://www.jifu.io/tags/桌面环境/"}],"categories":[{"name":"OPS","slug":"OPS","permalink":"http://www.jifu.io/categories/OPS/"},{"name":"Others","slug":"OPS/Others","permalink":"http://www.jifu.io/categories/OPS/Others/"}]},{"title":"私有化TM备份与共享服务器 - Netatalk","date":"2017-07-29T10:09:26.000Z","path":"posts/2006196850/","text":"Netatalk 是一个免费开源的 AppleTalk 通信协议的实现，Linux 或者 BSD 系统通过它可以充当 Mac 的文件服务器 (AppleShare File Server, 网络协议是 AFP)、AppleTalk 路由、打印服务器等。本文通过安装 netatalk 软件，在centos 上实现当 Time Machine 的备份与共享服务器。 1. download packagehttps://sourceforge.net/projects/netatalk/ 2. intsall depend packageyum install rpm-build gcc make libgcrypt-devel libdb libdb-devel 3. install netatalk tar -xvjf netatalk-3.1.10.tar.bz2 cd netatalk-3.1.10 ./configure --with-init-style=redhat-systemd --with-shadow make make install 4. 修改配置 valid users = tc rwlist = tc time machine = yes vol size limit = 512000 4. 创建用户 useradd tc passwd tc 5. 修改用户GID／UID groupadd -g 50000 tc useradd -u 50000 -g tc -s /usr/bin/false -d /home/tc tc passwd tc","tags":[{"name":"CentOS","slug":"CentOS","permalink":"http://www.jifu.io/tags/CentOS/"},{"name":"backup","slug":"backup","permalink":"http://www.jifu.io/tags/backup/"},{"name":"Mac OS","slug":"Mac-OS","permalink":"http://www.jifu.io/tags/Mac-OS/"}],"categories":[{"name":"OPS","slug":"OPS","permalink":"http://www.jifu.io/categories/OPS/"},{"name":"Others","slug":"OPS/Others","permalink":"http://www.jifu.io/categories/OPS/Others/"}]},{"title":"Cheat Sheets - .NET","date":"2017-03-31T07:00:27.000Z","path":"posts/4169548679/","text":"","tags":[{"name":"Cheat Sheets","slug":"Cheat-Sheets","permalink":"http://www.jifu.io/tags/Cheat-Sheets/"},{"name":".NET","slug":"NET","permalink":"http://www.jifu.io/tags/NET/"}],"categories":[{"name":"Soft engineering","slug":"Soft-engineering","permalink":"http://www.jifu.io/categories/Soft-engineering/"},{"name":"Cheat Sheets","slug":"Soft-engineering/Cheat-Sheets","permalink":"http://www.jifu.io/categories/Soft-engineering/Cheat-Sheets/"}]},{"title":"Cheat Sheets - Django Reference Sheet","date":"2017-03-31T07:00:27.000Z","path":"posts/3048024619/","text":"","tags":[{"name":"Cheat Sheets","slug":"Cheat-Sheets","permalink":"http://www.jifu.io/tags/Cheat-Sheets/"},{"name":"Python","slug":"Python","permalink":"http://www.jifu.io/tags/Python/"},{"name":"Django","slug":"Django","permalink":"http://www.jifu.io/tags/Django/"}],"categories":[{"name":"Soft engineering","slug":"Soft-engineering","permalink":"http://www.jifu.io/categories/Soft-engineering/"},{"name":"Cheat Sheets","slug":"Soft-engineering/Cheat-Sheets","permalink":"http://www.jifu.io/categories/Soft-engineering/Cheat-Sheets/"}]},{"title":"Cheat Sheets - PostgreSQL","date":"2017-03-31T07:00:27.000Z","path":"posts/2623330927/","text":"","tags":[{"name":"Cheat Sheets","slug":"Cheat-Sheets","permalink":"http://www.jifu.io/tags/Cheat-Sheets/"},{"name":"Database","slug":"Database","permalink":"http://www.jifu.io/tags/Database/"},{"name":"PostgreSQL","slug":"PostgreSQL","permalink":"http://www.jifu.io/tags/PostgreSQL/"}],"categories":[{"name":"Soft engineering","slug":"Soft-engineering","permalink":"http://www.jifu.io/categories/Soft-engineering/"},{"name":"Cheat Sheets","slug":"Soft-engineering/Cheat-Sheets","permalink":"http://www.jifu.io/categories/Soft-engineering/Cheat-Sheets/"}]},{"title":"Cheat Sheets - Shell Script","date":"2017-03-31T07:00:27.000Z","path":"posts/3433268710/","text":"","tags":[{"name":"Cheat Sheets","slug":"Cheat-Sheets","permalink":"http://www.jifu.io/tags/Cheat-Sheets/"},{"name":"shell","slug":"shell","permalink":"http://www.jifu.io/tags/shell/"}],"categories":[{"name":"Soft engineering","slug":"Soft-engineering","permalink":"http://www.jifu.io/categories/Soft-engineering/"},{"name":"Cheat Sheets","slug":"Soft-engineering/Cheat-Sheets","permalink":"http://www.jifu.io/categories/Soft-engineering/Cheat-Sheets/"}]},{"title":"Cheat Sheets - Git","date":"2017-03-31T07:00:27.000Z","path":"posts/2993634676/","text":"","tags":[{"name":"Cheat Sheets","slug":"Cheat-Sheets","permalink":"http://www.jifu.io/tags/Cheat-Sheets/"},{"name":"Git","slug":"Git","permalink":"http://www.jifu.io/tags/Git/"}],"categories":[{"name":"Soft engineering","slug":"Soft-engineering","permalink":"http://www.jifu.io/categories/Soft-engineering/"},{"name":"Cheat Sheets","slug":"Soft-engineering/Cheat-Sheets","permalink":"http://www.jifu.io/categories/Soft-engineering/Cheat-Sheets/"}]},{"title":"Cheat Sheets – C++","date":"2017-03-31T07:00:27.000Z","path":"posts/3327139081/","text":"","tags":[{"name":"Cheat Sheets","slug":"Cheat-Sheets","permalink":"http://www.jifu.io/tags/Cheat-Sheets/"},{"name":"C++","slug":"C","permalink":"http://www.jifu.io/tags/C/"}],"categories":[{"name":"Soft engineering","slug":"Soft-engineering","permalink":"http://www.jifu.io/categories/Soft-engineering/"},{"name":"Cheat Sheets","slug":"Soft-engineering/Cheat-Sheets","permalink":"http://www.jifu.io/categories/Soft-engineering/Cheat-Sheets/"}]},{"title":"Cheat Sheets – C","date":"2017-03-31T07:00:27.000Z","path":"posts/305297407/","text":"","tags":[{"name":"Cheat Sheets","slug":"Cheat-Sheets","permalink":"http://www.jifu.io/tags/Cheat-Sheets/"},{"name":"C","slug":"C","permalink":"http://www.jifu.io/tags/C/"}],"categories":[{"name":"Soft engineering","slug":"Soft-engineering","permalink":"http://www.jifu.io/categories/Soft-engineering/"},{"name":"Cheat Sheets","slug":"Soft-engineering/Cheat-Sheets","permalink":"http://www.jifu.io/categories/Soft-engineering/Cheat-Sheets/"}]},{"title":"Cheat Sheets – CSS","date":"2017-03-31T07:00:27.000Z","path":"posts/2137528313/","text":"","tags":[{"name":"Cheat Sheets","slug":"Cheat-Sheets","permalink":"http://www.jifu.io/tags/Cheat-Sheets/"},{"name":"CSS","slug":"CSS","permalink":"http://www.jifu.io/tags/CSS/"}],"categories":[{"name":"Soft engineering","slug":"Soft-engineering","permalink":"http://www.jifu.io/categories/Soft-engineering/"},{"name":"Cheat Sheets","slug":"Soft-engineering/Cheat-Sheets","permalink":"http://www.jifu.io/categories/Soft-engineering/Cheat-Sheets/"}]},{"title":"Cheat Sheets – Linux","date":"2017-03-31T07:00:27.000Z","path":"posts/982990798/","text":"","tags":[{"name":"Cheat Sheets","slug":"Cheat-Sheets","permalink":"http://www.jifu.io/tags/Cheat-Sheets/"},{"name":"Linux","slug":"Linux","permalink":"http://www.jifu.io/tags/Linux/"}],"categories":[{"name":"Soft engineering","slug":"Soft-engineering","permalink":"http://www.jifu.io/categories/Soft-engineering/"},{"name":"Cheat Sheets","slug":"Soft-engineering/Cheat-Sheets","permalink":"http://www.jifu.io/categories/Soft-engineering/Cheat-Sheets/"}]},{"title":"Cheat Sheets – Java","date":"2017-03-31T07:00:27.000Z","path":"posts/2663199359/","text":"","tags":[{"name":"Cheat Sheets","slug":"Cheat-Sheets","permalink":"http://www.jifu.io/tags/Cheat-Sheets/"},{"name":"Java","slug":"Java","permalink":"http://www.jifu.io/tags/Java/"}],"categories":[{"name":"Soft engineering","slug":"Soft-engineering","permalink":"http://www.jifu.io/categories/Soft-engineering/"},{"name":"Cheat Sheets","slug":"Soft-engineering/Cheat-Sheets","permalink":"http://www.jifu.io/categories/Soft-engineering/Cheat-Sheets/"}]},{"title":"Cheat Sheets – Mac OS X","date":"2017-03-31T07:00:27.000Z","path":"posts/316669616/","text":"","tags":[{"name":"Cheat Sheets","slug":"Cheat-Sheets","permalink":"http://www.jifu.io/tags/Cheat-Sheets/"},{"name":"Mac OS","slug":"Mac-OS","permalink":"http://www.jifu.io/tags/Mac-OS/"}],"categories":[{"name":"Soft engineering","slug":"Soft-engineering","permalink":"http://www.jifu.io/categories/Soft-engineering/"},{"name":"Cheat Sheets","slug":"Soft-engineering/Cheat-Sheets","permalink":"http://www.jifu.io/categories/Soft-engineering/Cheat-Sheets/"}]},{"title":"Cheat Sheets – MySQL","date":"2017-03-31T07:00:27.000Z","path":"posts/2038387758/","text":"","tags":[{"name":"Cheat Sheets","slug":"Cheat-Sheets","permalink":"http://www.jifu.io/tags/Cheat-Sheets/"},{"name":"MySQL","slug":"MySQL","permalink":"http://www.jifu.io/tags/MySQL/"}],"categories":[{"name":"Soft engineering","slug":"Soft-engineering","permalink":"http://www.jifu.io/categories/Soft-engineering/"},{"name":"Cheat Sheets","slug":"Soft-engineering/Cheat-Sheets","permalink":"http://www.jifu.io/categories/Soft-engineering/Cheat-Sheets/"}]},{"title":"Cheat Sheets – HTML and XHTML","date":"2017-03-31T07:00:27.000Z","path":"posts/59285358/","text":"","tags":[{"name":"Cheat Sheets","slug":"Cheat-Sheets","permalink":"http://www.jifu.io/tags/Cheat-Sheets/"},{"name":"HTML","slug":"HTML","permalink":"http://www.jifu.io/tags/HTML/"},{"name":"XHTML","slug":"XHTML","permalink":"http://www.jifu.io/tags/XHTML/"}],"categories":[{"name":"Soft engineering","slug":"Soft-engineering","permalink":"http://www.jifu.io/categories/Soft-engineering/"},{"name":"Cheat Sheets","slug":"Soft-engineering/Cheat-Sheets","permalink":"http://www.jifu.io/categories/Soft-engineering/Cheat-Sheets/"}]},{"title":"Cheat Sheets – Nodejs","date":"2017-03-31T07:00:27.000Z","path":"posts/2920272111/","text":"","tags":[{"name":"Cheat Sheets","slug":"Cheat-Sheets","permalink":"http://www.jifu.io/tags/Cheat-Sheets/"},{"name":"Nodejs","slug":"Nodejs","permalink":"http://www.jifu.io/tags/Nodejs/"}],"categories":[{"name":"Soft engineering","slug":"Soft-engineering","permalink":"http://www.jifu.io/categories/Soft-engineering/"},{"name":"Cheat Sheets","slug":"Soft-engineering/Cheat-Sheets","permalink":"http://www.jifu.io/categories/Soft-engineering/Cheat-Sheets/"}]},{"title":"Cheat Sheets – HTTP","date":"2017-03-31T07:00:27.000Z","path":"posts/3766000533/","text":"","tags":[{"name":"Cheat Sheets","slug":"Cheat-Sheets","permalink":"http://www.jifu.io/tags/Cheat-Sheets/"},{"name":"HTTP","slug":"HTTP","permalink":"http://www.jifu.io/tags/HTTP/"}],"categories":[{"name":"Soft engineering","slug":"Soft-engineering","permalink":"http://www.jifu.io/categories/Soft-engineering/"},{"name":"Cheat Sheets","slug":"Soft-engineering/Cheat-Sheets","permalink":"http://www.jifu.io/categories/Soft-engineering/Cheat-Sheets/"}]},{"title":"Cheat Sheets – PHP","date":"2017-03-31T07:00:27.000Z","path":"posts/1362596080/","text":"","tags":[{"name":"Cheat Sheets","slug":"Cheat-Sheets","permalink":"http://www.jifu.io/tags/Cheat-Sheets/"},{"name":"PHP","slug":"PHP","permalink":"http://www.jifu.io/tags/PHP/"}],"categories":[{"name":"Soft engineering","slug":"Soft-engineering","permalink":"http://www.jifu.io/categories/Soft-engineering/"},{"name":"Cheat Sheets","slug":"Soft-engineering/Cheat-Sheets","permalink":"http://www.jifu.io/categories/Soft-engineering/Cheat-Sheets/"}]},{"title":"Cheat Sheets – Perl","date":"2017-03-31T07:00:27.000Z","path":"posts/3167589601/","text":"","tags":[{"name":"Cheat Sheets","slug":"Cheat-Sheets","permalink":"http://www.jifu.io/tags/Cheat-Sheets/"},{"name":"Perl","slug":"Perl","permalink":"http://www.jifu.io/tags/Perl/"}],"categories":[{"name":"Soft engineering","slug":"Soft-engineering","permalink":"http://www.jifu.io/categories/Soft-engineering/"},{"name":"Cheat Sheets","slug":"Soft-engineering/Cheat-Sheets","permalink":"http://www.jifu.io/categories/Soft-engineering/Cheat-Sheets/"}]},{"title":"Cheat Sheets – Python","date":"2017-03-31T07:00:27.000Z","path":"posts/1053003126/","text":"","tags":[{"name":"Cheat Sheets","slug":"Cheat-Sheets","permalink":"http://www.jifu.io/tags/Cheat-Sheets/"},{"name":"Python","slug":"Python","permalink":"http://www.jifu.io/tags/Python/"}],"categories":[{"name":"Soft engineering","slug":"Soft-engineering","permalink":"http://www.jifu.io/categories/Soft-engineering/"},{"name":"Cheat Sheets","slug":"Soft-engineering/Cheat-Sheets","permalink":"http://www.jifu.io/categories/Soft-engineering/Cheat-Sheets/"}]},{"title":"Cheat Sheets – SQLite","date":"2017-03-31T07:00:27.000Z","path":"posts/1130312566/","text":"","tags":[{"name":"Cheat Sheets","slug":"Cheat-Sheets","permalink":"http://www.jifu.io/tags/Cheat-Sheets/"},{"name":"SQLite","slug":"SQLite","permalink":"http://www.jifu.io/tags/SQLite/"}],"categories":[{"name":"Soft engineering","slug":"Soft-engineering","permalink":"http://www.jifu.io/categories/Soft-engineering/"},{"name":"Cheat Sheets","slug":"Soft-engineering/Cheat-Sheets","permalink":"http://www.jifu.io/categories/Soft-engineering/Cheat-Sheets/"}]},{"title":"Cheat Sheets – jQuery","date":"2017-03-31T07:00:27.000Z","path":"posts/2789789845/","text":"","tags":[{"name":"Cheat Sheets","slug":"Cheat-Sheets","permalink":"http://www.jifu.io/tags/Cheat-Sheets/"},{"name":"JQuery","slug":"JQuery","permalink":"http://www.jifu.io/tags/JQuery/"}],"categories":[{"name":"Soft engineering","slug":"Soft-engineering","permalink":"http://www.jifu.io/categories/Soft-engineering/"},{"name":"Cheat Sheets","slug":"Soft-engineering/Cheat-Sheets","permalink":"http://www.jifu.io/categories/Soft-engineering/Cheat-Sheets/"}]},{"title":"Cheat Sheets - Photoshop","date":"2017-03-31T07:00:27.000Z","path":"posts/4169548678/","text":"","tags":[{"name":"Cheat Sheets","slug":"Cheat-Sheets","permalink":"http://www.jifu.io/tags/Cheat-Sheets/"},{"name":"Photoshop","slug":"Photoshop","permalink":"http://www.jifu.io/tags/Photoshop/"}],"categories":[{"name":"Soft engineering","slug":"Soft-engineering","permalink":"http://www.jifu.io/categories/Soft-engineering/"},{"name":"Cheat Sheets","slug":"Soft-engineering/Cheat-Sheets","permalink":"http://www.jifu.io/categories/Soft-engineering/Cheat-Sheets/"}]},{"title":"Cheat sheets - Xcode","date":"2017-03-31T07:00:27.000Z","path":"posts/3905631645/","text":"","tags":[{"name":"快捷键","slug":"快捷键","permalink":"http://www.jifu.io/tags/快捷键/"},{"name":"Xcode","slug":"Xcode","permalink":"http://www.jifu.io/tags/Xcode/"},{"name":"Cheat sheets","slug":"Cheat-sheets","permalink":"http://www.jifu.io/tags/Cheat-sheets/"}],"categories":[{"name":"Soft engineering","slug":"Soft-engineering","permalink":"http://www.jifu.io/categories/Soft-engineering/"},{"name":"Cheat Sheets","slug":"Soft-engineering/Cheat-Sheets","permalink":"http://www.jifu.io/categories/Soft-engineering/Cheat-Sheets/"}]},{"title":"Cheat sheets - Mac OS","date":"2017-03-31T07:00:27.000Z","path":"posts/3586350539/","text":"","tags":[{"name":"快捷键","slug":"快捷键","permalink":"http://www.jifu.io/tags/快捷键/"},{"name":"Mac OS","slug":"Mac-OS","permalink":"http://www.jifu.io/tags/Mac-OS/"},{"name":"Cheat sheets","slug":"Cheat-sheets","permalink":"http://www.jifu.io/tags/Cheat-sheets/"}],"categories":[{"name":"Soft engineering","slug":"Soft-engineering","permalink":"http://www.jifu.io/categories/Soft-engineering/"},{"name":"Cheat Sheets","slug":"Soft-engineering/Cheat-Sheets","permalink":"http://www.jifu.io/categories/Soft-engineering/Cheat-Sheets/"}]}]}